2018-06-06 23:09:15.321063: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-06-06 23:09:15.321342: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-06-06 23:09:15.321367: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-06-06 23:09:15.321383: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-06-06 23:09:15.321398: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-06-06 23:09:15.715853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:02:00.0
Total memory: 11.93GiB
Free memory: 11.81GiB
2018-06-06 23:09:15.994914: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x40050f0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2018-06-06 23:09:15.995972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:03:00.0
Total memory: 11.93GiB
Free memory: 11.81GiB
2018-06-06 23:09:16.307383: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x40074f0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2018-06-06 23:09:16.308976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 2 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:81:00.0
Total memory: 11.93GiB
Free memory: 11.81GiB
2018-06-06 23:09:16.623319: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x400b510 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2018-06-06 23:09:16.624405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 3 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:82:00.0
Total memory: 11.93GiB
Free memory: 11.81GiB
2018-06-06 23:09:16.626823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 2
2018-06-06 23:09:16.626851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 3
2018-06-06 23:09:16.626889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 2
2018-06-06 23:09:16.626905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 3
2018-06-06 23:09:16.626921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 0
2018-06-06 23:09:16.626936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 1
2018-06-06 23:09:16.627180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 0
2018-06-06 23:09:16.627200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 1
2018-06-06 23:09:16.627307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 2 3 
2018-06-06 23:09:16.627318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y N N 
2018-06-06 23:09:16.627330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y N N 
2018-06-06 23:09:16.627336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 2:   N N Y Y 
2018-06-06 23:09:16.627342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 3:   N N Y Y 
2018-06-06 23:09:16.627362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0)
2018-06-06 23:09:16.627370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0)
2018-06-06 23:09:16.627377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)
2018-06-06 23:09:16.627384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:82:00.0)
Adding Data Augmentation
Adding Data Augmentation
iteration 0: loss 108.842 0.500000 0.531250
iteration 1: loss 60.798 0.507812 0.531250
iteration 2: loss 40.548 0.437500 0.445312
iteration 3: loss 24.483 0.523438 0.492188
iteration 4: loss 15.494 0.453125 0.507812
iteration 5: loss 12.991 0.375000 0.414062
iteration 6: loss 9.505 0.210938 0.382812
iteration 7: loss 9.691 0.101562 0.203125
iteration 8: loss 8.728 0.070312 0.078125
iteration 9: loss 8.926 0.070312 0.031250
iteration 10: loss 8.518 0.046875 0.046875
iteration 11: loss 8.060 0.101562 0.039062
iteration 12: loss 8.145 0.125000 0.046875
iteration 13: loss 8.274 0.156250 0.078125
iteration 14: loss 7.606 0.156250 0.109375
iteration 15: loss 7.218 0.148438 0.179688
iteration 16: loss 7.905 0.250000 0.187500
iteration 17: loss 6.483 0.203125 0.218750
iteration 18: loss 7.449 0.265625 0.203125
iteration 19: loss 7.162 0.132812 0.187500
iteration 20: loss 5.954 0.273438 0.203125
iteration 21: loss 7.553 0.148438 0.125000
iteration 22: loss 6.604 0.179688 0.179688
iteration 23: loss 6.919 0.250000 0.171875
iteration 24: loss 6.341 0.242188 0.164062
iteration 25: loss 7.028 0.250000 0.125000
iteration 26: loss 5.669 0.265625 0.218750
iteration 27: loss 5.124 0.234375 0.281250
iteration 28: loss 6.275 0.210938 0.226562
iteration 29: loss 6.802 0.218750 0.210938
iteration 30: loss 5.838 0.218750 0.320312
iteration 31: loss 7.104 0.296875 0.226562
iteration 32: loss 5.614 0.242188 0.250000
iteration 33: loss 6.329 0.195312 0.187500
iteration 34: loss 5.685 0.226562 0.203125
iteration 35: loss 6.189 0.148438 0.187500
iteration 36: loss 6.306 0.171875 0.179688
iteration 37: loss 6.655 0.250000 0.179688
iteration 38: loss 6.648 0.203125 0.195312
iteration 39: loss 5.090 0.242188 0.171875
iteration 40: loss 5.898 0.203125 0.226562
iteration 41: loss 5.798 0.257812 0.234375
iteration 42: loss 6.160 0.195312 0.218750
iteration 43: loss 6.373 0.234375 0.210938
iteration 44: loss 5.921 0.289062 0.218750
iteration 45: loss 5.555 0.250000 0.289062
iteration 46: loss 6.318 0.250000 0.164062
iteration 47: loss 6.002 0.273438 0.210938
iteration 48: loss 5.960 0.273438 0.210938
iteration 49: loss 5.220 0.242188 0.242188
iteration 50: loss 5.687 0.195312 0.164062
iteration 51: loss 5.710 0.242188 0.234375
iteration 52: loss 5.190 0.203125 0.242188
iteration 53: loss 6.137 0.281250 0.148438
iteration 54: loss 4.652 0.234375 0.273438
iteration 55: loss 5.004 0.242188 0.265625
iteration 56: loss 5.618 0.210938 0.203125
iteration 57: loss 6.277 0.234375 0.164062
iteration 58: loss 6.250 0.171875 0.156250
iteration 59: loss 5.681 0.226562 0.078125
iteration 60: loss 5.639 0.273438 0.234375
iteration 61: loss 5.626 0.265625 0.242188
iteration 62: loss 5.981 0.328125 0.218750
iteration 63: loss 4.710 0.296875 0.273438
iteration 64: loss 5.592 0.257812 0.281250
iteration 65: loss 5.820 0.265625 0.242188
iteration 66: loss 4.560 0.265625 0.289062
iteration 67: loss 4.350 0.296875 0.335938
iteration 68: loss 5.602 0.281250 0.265625
iteration 69: loss 5.035 0.210938 0.250000
iteration 70: loss 4.735 0.281250 0.281250
iteration 71: loss 5.344 0.289062 0.234375
iteration 72: loss 5.452 0.234375 0.226562
iteration 73: loss 6.133 0.265625 0.187500
iteration 74: loss 4.981 0.257812 0.226562
iteration 75: loss 4.963 0.304688 0.273438
iteration 76: loss 4.346 0.273438 0.257812
iteration 77: loss 5.272 0.218750 0.195312
iteration 78: loss 4.941 0.304688 0.289062
iteration 79: loss 5.390 0.304688 0.273438
iteration 80: loss 5.305 0.273438 0.250000
iteration 81: loss 5.452 0.171875 0.273438
iteration 82: loss 4.995 0.242188 0.218750
iteration 83: loss 5.227 0.218750 0.226562
iteration 84: loss 4.385 0.234375 0.257812
iteration 85: loss 5.335 0.265625 0.250000
iteration 86: loss 4.495 0.320312 0.320312
iteration 87: loss 4.888 0.296875 0.265625
iteration 88: loss 4.247 0.320312 0.320312
iteration 89: loss 5.064 0.210938 0.242188
iteration 90: loss 4.807 0.210938 0.203125
iteration 91: loss 5.423 0.335938 0.242188
iteration 92: loss 4.630 0.312500 0.328125
iteration 93: loss 5.942 0.343750 0.226562
iteration 94: loss 4.778 0.203125 0.312500
iteration 95: loss 4.937 0.265625 0.242188
iteration 96: loss 5.077 0.234375 0.296875
iteration 97: loss 5.780 0.312500 0.203125
iteration 98: loss 4.701 0.210938 0.296875
iteration 99: loss 4.999 0.226562 0.250000
iteration 100: loss 4.103 0.226562 0.382812
iteration 101: loss 4.811 0.203125 0.273438
iteration 102: loss 5.980 0.179688 0.210938
iteration 103: loss 5.523 0.312500 0.226562
iteration 104: loss 4.520 0.265625 0.250000
iteration 105: loss 4.636 0.179688 0.187500
iteration 106: loss 5.565 0.226562 0.265625
iteration 107: loss 4.642 0.265625 0.234375
iteration 108: loss 4.973 0.304688 0.265625
iteration 109: loss 5.225 0.289062 0.234375
iteration 110: loss 3.677 0.328125 0.351562
iteration 111: loss 4.832 0.250000 0.304688
iteration 112: loss 5.678 0.296875 0.320312
iteration 113: loss 5.042 0.234375 0.304688
iteration 114: loss 5.038 0.265625 0.250000
iteration 115: loss 4.930 0.156250 0.187500
iteration 116: loss 4.952 0.171875 0.179688
iteration 117: loss 6.154 0.218750 0.171875
iteration 118: loss 5.471 0.203125 0.187500
iteration 119: loss 4.599 0.289062 0.281250
iteration 120: loss 4.716 0.281250 0.312500
iteration 121: loss 5.983 0.328125 0.242188
iteration 122: loss 4.506 0.328125 0.320312
iteration 123: loss 5.103 0.289062 0.257812
iteration 124: loss 5.710 0.289062 0.226562
iteration 125: loss 5.673 0.320312 0.304688
iteration 126: loss 5.315 0.273438 0.226562
iteration 127: loss 5.604 0.257812 0.125000
iteration 128: loss 4.039 0.234375 0.257812
iteration 129: loss 4.446 0.328125 0.304688
iteration 130: loss 4.950 0.203125 0.257812
iteration 131: loss 3.899 0.343750 0.242188
iteration 132: loss 4.773 0.257812 0.257812
iteration 133: loss 4.715 0.234375 0.343750
iteration 134: loss 4.595 0.296875 0.265625
iteration 135: loss 4.284 0.296875 0.328125
iteration 136: loss 5.729 0.289062 0.218750
iteration 137: loss 4.507 0.289062 0.203125
iteration 138: loss 5.423 0.210938 0.234375
iteration 139: loss 4.186 0.265625 0.343750
iteration 140: loss 5.447 0.289062 0.226562
iteration 141: loss 4.536 0.328125 0.328125
iteration 142: loss 4.476 0.335938 0.343750
iteration 143: loss 4.905 0.328125 0.218750
iteration 144: loss 3.709 0.265625 0.304688
iteration 145: loss 4.461 0.273438 0.328125
iteration 146: loss 5.000 0.289062 0.210938
iteration 147: loss 4.909 0.289062 0.156250
iteration 148: loss 4.783 0.265625 0.234375
iteration 149: loss 3.920 0.226562 0.312500
iteration 150: loss 5.652 0.296875 0.265625
iteration 151: loss 4.432 0.273438 0.257812
iteration 152: loss 5.221 0.250000 0.265625
iteration 153: loss 4.618 0.343750 0.343750
iteration 154: loss 4.222 0.296875 0.328125
iteration 155: loss 5.017 0.343750 0.335938
iteration 156: loss 5.471 0.289062 0.226562
iteration 157: loss 4.711 0.281250 0.312500
iteration 158: loss 4.469 0.242188 0.304688
iteration 159: loss 4.799 0.320312 0.210938
iteration 160: loss 4.863 0.265625 0.265625
iteration 161: loss 4.606 0.296875 0.265625
iteration 162: loss 4.683 0.320312 0.226562
iteration 163: loss 4.755 0.226562 0.234375
iteration 164: loss 3.955 0.304688 0.304688
iteration 165: loss 5.327 0.242188 0.218750
iteration 166: loss 4.265 0.250000 0.289062
iteration 167: loss 3.983 0.242188 0.273438
iteration 168: loss 4.163 0.195312 0.289062
iteration 169: loss 4.128 0.359375 0.304688
iteration 170: loss 3.794 0.304688 0.296875
iteration 171: loss 4.193 0.328125 0.281250
iteration 172: loss 3.885 0.234375 0.304688
iteration 173: loss 5.105 0.296875 0.242188
iteration 174: loss 4.830 0.257812 0.242188
iteration 175: loss 4.876 0.242188 0.296875
iteration 176: loss 4.658 0.265625 0.257812
iteration 177: loss 4.141 0.312500 0.281250
iteration 178: loss 3.984 0.257812 0.328125
iteration 179: loss 5.133 0.257812 0.242188
iteration 180: loss 5.893 0.343750 0.179688
iteration 181: loss 4.314 0.250000 0.257812
iteration 182: loss 4.359 0.312500 0.320312
iteration 183: loss 5.169 0.289062 0.226562
iteration 184: loss 4.017 0.281250 0.312500
iteration 185: loss 3.891 0.281250 0.312500
iteration 186: loss 4.584 0.250000 0.398438
iteration 187: loss 4.327 0.281250 0.289062
iteration 188: loss 3.492 0.242188 0.367188
iteration 189: loss 3.893 0.273438 0.304688
iteration 190: loss 5.192 0.234375 0.218750
iteration 191: loss 4.948 0.257812 0.203125
iteration 192: loss 4.284 0.289062 0.281250
iteration 193: loss 3.553 0.203125 0.234375
iteration 194: loss 4.649 0.296875 0.187500
iteration 195: loss 4.162 0.203125 0.265625
iteration 196: loss 4.115 0.335938 0.390625
iteration 197: loss 4.337 0.242188 0.296875
iteration 198: loss 4.474 0.304688 0.359375
iteration 199: loss 5.231 0.234375 0.273438
iteration 200: loss 3.790 0.328125 0.335938
iteration 201: loss 3.861 0.273438 0.320312
iteration 202: loss 3.953 0.187500 0.257812
iteration 203: loss 4.341 0.312500 0.187500
iteration 204: loss 4.557 0.234375 0.242188
iteration 205: loss 5.494 0.304688 0.218750
iteration 206: loss 4.254 0.281250 0.304688
iteration 207: loss 4.794 0.390625 0.281250
iteration 208: loss 4.000 0.359375 0.296875
iteration 209: loss 3.344 0.335938 0.320312
iteration 210: loss 3.979 0.382812 0.296875
iteration 211: loss 4.325 0.304688 0.367188
iteration 212: loss 4.042 0.328125 0.312500
iteration 213: loss 4.878 0.367188 0.273438
iteration 214: loss 4.588 0.289062 0.242188
iteration 215: loss 4.572 0.328125 0.351562
iteration 216: loss 4.337 0.273438 0.265625
iteration 217: loss 4.506 0.328125 0.296875
iteration 218: loss 4.431 0.218750 0.312500
iteration 219: loss 4.075 0.210938 0.257812
iteration 220: loss 3.814 0.273438 0.273438
iteration 221: loss 5.089 0.265625 0.187500
iteration 222: loss 4.380 0.343750 0.226562
iteration 223: loss 4.452 0.179688 0.250000
iteration 224: loss 3.708 0.367188 0.281250
iteration 225: loss 4.351 0.351562 0.351562
iteration 226: loss 4.467 0.312500 0.273438
iteration 227: loss 4.349 0.265625 0.351562
iteration 228: loss 4.786 0.351562 0.289062
iteration 229: loss 5.651 0.226562 0.195312
iteration 230: loss 4.750 0.296875 0.226562
iteration 231: loss 3.664 0.242188 0.273438
iteration 232: loss 4.824 0.273438 0.171875
iteration 233: loss 3.593 0.281250 0.296875
iteration 234: loss 4.325 0.296875 0.304688
iteration 235: loss 3.844 0.242188 0.296875
iteration 236: loss 3.995 0.242188 0.273438
iteration 237: loss 5.015 0.312500 0.250000
iteration 238: loss 5.115 0.296875 0.304688
iteration 239: loss 3.948 0.265625 0.312500
iteration 240: loss 3.811 0.226562 0.273438
iteration 241: loss 4.558 0.281250 0.242188
iteration 242: loss 4.146 0.210938 0.250000
iteration 243: loss 3.837 0.250000 0.289062
iteration 244: loss 4.127 0.320312 0.265625
iteration 245: loss 4.777 0.328125 0.250000
iteration 246: loss 4.319 0.343750 0.195312
iteration 247: loss 5.171 0.304688 0.289062
iteration 248: loss 4.747 0.234375 0.203125
iteration 249: loss 4.357 0.320312 0.312500
iteration 250: loss 5.135 0.226562 0.289062
iteration 251: loss 4.256 0.289062 0.296875
iteration 252: loss 4.363 0.218750 0.296875
iteration 253: loss 4.638 0.257812 0.328125
iteration 254: loss 4.211 0.320312 0.289062
iteration 255: loss 3.607 0.257812 0.382812
iteration 256: loss 4.218 0.257812 0.367188
iteration 257: loss 4.096 0.273438 0.250000
iteration 258: loss 3.890 0.234375 0.304688
iteration 259: loss 4.398 0.273438 0.242188
iteration 260: loss 4.256 0.265625 0.242188
iteration 261: loss 4.635 0.195312 0.257812
iteration 262: loss 4.657 0.335938 0.250000
iteration 263: loss 4.361 0.304688 0.328125
iteration 264: loss 4.929 0.296875 0.273438
iteration 265: loss 4.162 0.304688 0.343750
iteration 266: loss 3.952 0.296875 0.289062
iteration 267: loss 3.725 0.234375 0.289062
iteration 268: loss 4.208 0.265625 0.359375
iteration 269: loss 4.609 0.281250 0.250000
iteration 270: loss 4.349 0.281250 0.296875
iteration 271: loss 4.724 0.250000 0.234375
iteration 272: loss 4.423 0.359375 0.281250
iteration 273: loss 4.352 0.304688 0.265625
iteration 274: loss 4.052 0.296875 0.265625
iteration 275: loss 4.352 0.296875 0.273438
iteration 276: loss 4.702 0.187500 0.328125
iteration 277: loss 3.823 0.398438 0.312500
iteration 278: loss 4.033 0.375000 0.320312
iteration 279: loss 4.516 0.304688 0.343750
iteration 280: loss 4.236 0.351562 0.304688
iteration 281: loss 4.099 0.375000 0.406250
iteration 282: loss 4.853 0.304688 0.234375
iteration 283: loss 4.271 0.289062 0.328125
iteration 284: loss 3.950 0.273438 0.281250
iteration 285: loss 4.147 0.281250 0.289062
iteration 286: loss 4.300 0.226562 0.281250
iteration 287: loss 4.086 0.265625 0.234375
iteration 288: loss 4.724 0.281250 0.210938
iteration 289: loss 4.473 0.351562 0.242188
iteration 290: loss 3.308 0.296875 0.343750
iteration 291: loss 4.438 0.328125 0.296875
iteration 292: loss 4.196 0.296875 0.335938
iteration 293: loss 3.837 0.304688 0.343750
iteration 294: loss 3.018 0.335938 0.343750
iteration 295: loss 4.309 0.296875 0.296875
iteration 296: loss 3.493 0.281250 0.304688
iteration 297: loss 4.630 0.257812 0.312500
iteration 298: loss 5.291 0.210938 0.289062
iteration 299: loss 4.013 0.273438 0.281250
iteration 300: loss 5.333 0.265625 0.273438
iteration 301: loss 3.863 0.312500 0.296875
iteration 302: loss 3.940 0.328125 0.289062
iteration 303: loss 3.922 0.281250 0.210938
iteration 304: loss 4.571 0.304688 0.242188
iteration 305: loss 4.994 0.265625 0.304688
iteration 306: loss 3.627 0.320312 0.320312
iteration 307: loss 3.877 0.335938 0.218750
iteration 308: loss 4.337 0.320312 0.242188
iteration 309: loss 4.025 0.320312 0.273438
iteration 310: loss 4.744 0.304688 0.265625
iteration 311: loss 4.821 0.289062 0.203125
iteration 312: loss 3.586 0.343750 0.320312
iteration 313: loss 4.017 0.320312 0.320312
iteration 314: loss 3.814 0.343750 0.320312
iteration 315: loss 4.422 0.320312 0.367188
iteration 316: loss 4.473 0.312500 0.359375
iteration 317: loss 4.812 0.250000 0.335938
iteration 318: loss 3.299 0.218750 0.343750
iteration 319: loss 3.129 0.343750 0.343750
iteration 320: loss 3.524 0.296875 0.328125
iteration 321: loss 3.943 0.296875 0.273438
iteration 322: loss 5.101 0.304688 0.265625
iteration 323: loss 3.857 0.234375 0.265625
iteration 324: loss 4.967 0.265625 0.273438
iteration 325: loss 3.850 0.312500 0.296875
iteration 326: loss 4.204 0.335938 0.234375
iteration 327: loss 3.556 0.289062 0.273438
iteration 328: loss 3.015 0.312500 0.343750
iteration 329: loss 3.698 0.257812 0.265625
iteration 330: loss 4.252 0.335938 0.351562
iteration 331: loss 4.350 0.343750 0.281250
iteration 332: loss 4.531 0.320312 0.273438
iteration 333: loss 3.598 0.304688 0.343750
iteration 334: loss 4.164 0.273438 0.218750
iteration 335: loss 3.261 0.359375 0.335938
iteration 336: loss 4.555 0.265625 0.242188
iteration 337: loss 4.602 0.335938 0.250000
iteration 338: loss 4.462 0.320312 0.281250
iteration 339: loss 3.768 0.320312 0.281250
iteration 340: loss 3.573 0.250000 0.343750
iteration 341: loss 3.901 0.335938 0.281250
iteration 342: loss 3.931 0.343750 0.335938
iteration 343: loss 4.135 0.312500 0.296875
iteration 344: loss 4.274 0.304688 0.328125
iteration 345: loss 3.578 0.296875 0.335938
iteration 346: loss 3.571 0.203125 0.312500
iteration 347: loss 3.692 0.210938 0.335938
iteration 348: loss 3.960 0.265625 0.234375
iteration 349: loss 3.309 0.257812 0.343750
iteration 350: loss 4.217 0.195312 0.234375
iteration 351: loss 4.190 0.289062 0.257812
iteration 352: loss 3.367 0.273438 0.281250
iteration 353: loss 4.176 0.304688 0.273438
iteration 354: loss 3.422 0.289062 0.296875
iteration 355: loss 4.461 0.390625 0.289062
iteration 356: loss 3.558 0.367188 0.335938
iteration 357: loss 4.049 0.359375 0.375000
iteration 358: loss 3.775 0.414062 0.351562
iteration 359: loss 3.952 0.281250 0.343750
iteration 360: loss 3.921 0.320312 0.359375
iteration 361: loss 4.173 0.304688 0.320312
iteration 362: loss 3.521 0.218750 0.367188
iteration 363: loss 4.660 0.296875 0.289062
iteration 364: loss 3.218 0.328125 0.335938
iteration 365: loss 3.312 0.343750 0.351562
iteration 366: loss 4.028 0.281250 0.281250
iteration 367: loss 4.212 0.273438 0.281250
iteration 368: loss 2.927 0.296875 0.359375
iteration 369: loss 3.904 0.343750 0.320312
iteration 370: loss 4.027 0.281250 0.312500
iteration 371: loss 4.030 0.320312 0.242188
iteration 372: loss 4.526 0.289062 0.289062
iteration 373: loss 4.424 0.281250 0.320312
iteration 374: loss 2.599 0.257812 0.343750
iteration 375: loss 3.933 0.226562 0.367188
iteration 376: loss 4.344 0.226562 0.296875
iteration 377: loss 4.397 0.281250 0.273438
iteration 378: loss 4.214 0.257812 0.289062
iteration 379: loss 4.482 0.320312 0.304688
iteration 380: loss 4.729 0.304688 0.257812
iteration 381: loss 3.570 0.289062 0.351562
iteration 382: loss 4.183 0.281250 0.375000
iteration 383: loss 3.841 0.289062 0.351562
iteration 384: loss 4.056 0.296875 0.312500
iteration 385: loss 4.823 0.343750 0.281250
iteration 386: loss 4.244 0.312500 0.328125
iteration 387: loss 3.174 0.250000 0.335938
iteration 388: loss 4.310 0.250000 0.289062
iteration 389: loss 4.046 0.304688 0.281250
iteration 390: loss 4.209 0.257812 0.289062
iteration 391: loss 3.662 0.257812 0.296875
iteration 392: loss 4.055 0.242188 0.250000
iteration 393: loss 4.313 0.414062 0.281250
iteration 394: loss 4.155 0.343750 0.312500
iteration 395: loss 4.077 0.343750 0.320312
iteration 396: loss 3.447 0.328125 0.429688
iteration 397: loss 4.643 0.414062 0.250000
iteration 398: loss 4.850 0.429688 0.296875
iteration 399: loss 4.221 0.359375 0.351562
iteration 400: loss 3.749 0.328125 0.289062
iteration 401: loss 3.925 0.406250 0.351562
iteration 402: loss 3.748 0.335938 0.226562
iteration 403: loss 3.980 0.273438 0.257812
iteration 404: loss 3.910 0.218750 0.289062
iteration 405: loss 3.658 0.218750 0.257812
iteration 406: loss 3.306 0.281250 0.281250
iteration 407: loss 3.508 0.281250 0.335938
iteration 408: loss 3.909 0.257812 0.265625
iteration 409: loss 4.195 0.312500 0.234375
iteration 410: loss 4.972 0.281250 0.226562
iteration 411: loss 4.322 0.328125 0.296875
iteration 412: loss 3.596 0.335938 0.281250
iteration 413: loss 4.133 0.367188 0.359375
iteration 414: loss 3.744 0.312500 0.367188
iteration 415: loss 3.196 0.367188 0.335938
iteration 416: loss 3.659 0.343750 0.304688
iteration 417: loss 4.294 0.289062 0.328125
iteration 418: loss 3.707 0.367188 0.289062
iteration 419: loss 2.609 0.335938 0.492188
iteration 420: loss 3.814 0.320312 0.351562
iteration 421: loss 3.246 0.250000 0.359375
iteration 422: loss 3.461 0.359375 0.296875
iteration 423: loss 4.424 0.281250 0.335938
iteration 424: loss 3.767 0.320312 0.242188
iteration 425: loss 3.778 0.281250 0.328125
iteration 426: loss 3.847 0.265625 0.250000
iteration 427: loss 3.615 0.343750 0.390625
iteration 428: loss 3.232 0.343750 0.289062
iteration 429: loss 3.252 0.304688 0.375000
iteration 430: loss 3.739 0.351562 0.351562
iteration 431: loss 3.181 0.328125 0.390625
iteration 432: loss 3.999 0.398438 0.312500
iteration 433: loss 3.855 0.242188 0.320312
iteration 434: loss 3.309 0.289062 0.281250
iteration 435: loss 3.590 0.335938 0.343750
iteration 436: loss 3.216 0.289062 0.328125
iteration 437: loss 3.330 0.289062 0.289062
iteration 438: loss 3.657 0.296875 0.265625
iteration 439: loss 3.638 0.328125 0.304688
iteration 440: loss 3.605 0.273438 0.296875
iteration 441: loss 3.825 0.335938 0.226562
iteration 442: loss 3.408 0.375000 0.328125
iteration 443: loss 4.109 0.250000 0.296875
iteration 444: loss 3.770 0.296875 0.320312
iteration 445: loss 3.108 0.304688 0.273438
iteration 446: loss 4.056 0.296875 0.281250
iteration 447: loss 3.247 0.421875 0.359375
iteration 448: loss 3.399 0.328125 0.320312
iteration 449: loss 3.947 0.289062 0.320312
iteration 450: loss 3.843 0.234375 0.367188
iteration 451: loss 4.080 0.250000 0.273438
iteration 452: loss 4.037 0.382812 0.281250
iteration 453: loss 4.129 0.281250 0.320312
iteration 454: loss 3.209 0.359375 0.382812
iteration 455: loss 3.438 0.328125 0.289062
iteration 456: loss 4.002 0.265625 0.296875
iteration 457: loss 3.683 0.273438 0.242188
iteration 458: loss 4.095 0.257812 0.289062
iteration 459: loss 3.464 0.312500 0.328125
iteration 460: loss 4.341 0.312500 0.296875
iteration 461: loss 3.588 0.304688 0.242188
iteration 462: loss 3.105 0.375000 0.406250
iteration 463: loss 3.674 0.289062 0.328125
iteration 464: loss 4.128 0.390625 0.304688
iteration 465: loss 3.569 0.367188 0.398438
iteration 466: loss 4.223 0.390625 0.289062
iteration 467: loss 3.578 0.335938 0.343750
iteration 468: loss 4.642 0.320312 0.304688
iteration 469: loss 4.678 0.296875 0.281250
iteration 470: loss 4.274 0.265625 0.312500
iteration 471: loss 3.375 0.328125 0.304688
iteration 472: loss 3.275 0.351562 0.382812
iteration 473: loss 3.565 0.328125 0.289062
iteration 474: loss 3.262 0.289062 0.398438
iteration 475: loss 2.928 0.242188 0.398438
iteration 476: loss 4.488 0.273438 0.250000
iteration 477: loss 3.315 0.257812 0.328125
iteration 478: loss 3.815 0.320312 0.234375
iteration 479: loss 3.904 0.312500 0.343750
iteration 480: loss 3.862 0.343750 0.312500
iteration 481: loss 3.806 0.382812 0.257812
iteration 482: loss 3.643 0.390625 0.296875
iteration 483: loss 4.171 0.312500 0.265625
iteration 484: loss 4.031 0.289062 0.296875
iteration 485: loss 3.606 0.312500 0.320312
iteration 486: loss 4.301 0.328125 0.312500
iteration 487: loss 4.363 0.281250 0.351562
iteration 488: loss 4.686 0.335938 0.281250
iteration 489: loss 4.322 0.265625 0.312500
iteration 490: loss 3.517 0.218750 0.359375
iteration 491: loss 3.213 0.351562 0.328125
iteration 492: loss 3.465 0.289062 0.312500
iteration 493: loss 3.731 0.312500 0.312500
iteration 494: loss 3.624 0.375000 0.281250
iteration 495: loss 3.339 0.320312 0.296875
iteration 496: loss 3.208 0.273438 0.320312
iteration 497: loss 3.481 0.343750 0.265625
iteration 498: loss 3.261 0.289062 0.312500
iteration 499: loss 4.202 0.273438 0.273438
iteration 500: loss 3.275 0.250000 0.312500
iteration 501: loss 3.179 0.328125 0.359375
iteration 502: loss 4.041 0.312500 0.296875
iteration 503: loss 3.931 0.273438 0.242188
iteration 504: loss 4.231 0.367188 0.296875
iteration 505: loss 3.730 0.273438 0.382812
iteration 506: loss 3.657 0.382812 0.320312
iteration 507: loss 2.982 0.367188 0.406250
iteration 508: loss 3.643 0.351562 0.335938
iteration 509: loss 3.402 0.289062 0.320312
iteration 510: loss 3.926 0.203125 0.296875
iteration 511: loss 3.294 0.289062 0.320312
iteration 512: loss 3.993 0.265625 0.289062
iteration 513: loss 3.786 0.304688 0.312500
iteration 514: loss 3.540 0.320312 0.335938
iteration 515: loss 3.079 0.351562 0.343750
iteration 516: loss 3.234 0.367188 0.343750
iteration 517: loss 3.647 0.304688 0.335938
iteration 518: loss 4.494 0.351562 0.273438
iteration 519: loss 3.325 0.257812 0.304688
iteration 520: loss 3.797 0.328125 0.320312
iteration 521: loss 3.484 0.320312 0.296875
iteration 522: loss 3.590 0.312500 0.281250
iteration 523: loss 3.994 0.226562 0.257812
iteration 524: loss 2.840 0.265625 0.312500
iteration 525: loss 3.597 0.312500 0.273438
iteration 526: loss 3.567 0.320312 0.312500
iteration 527: loss 4.107 0.250000 0.210938
iteration 528: loss 3.762 0.250000 0.328125
iteration 529: loss 3.730 0.296875 0.304688
iteration 530: loss 3.685 0.289062 0.406250
iteration 531: loss 3.685 0.320312 0.335938
iteration 532: loss 3.321 0.281250 0.304688
iteration 533: loss 3.292 0.289062 0.359375
iteration 534: loss 3.635 0.289062 0.367188
iteration 535: loss 3.882 0.296875 0.273438
iteration 536: loss 3.650 0.242188 0.265625
iteration 537: loss 4.447 0.351562 0.195312
iteration 538: loss 3.256 0.328125 0.351562
iteration 539: loss 3.814 0.281250 0.304688
iteration 540: loss 3.191 0.273438 0.414062
iteration 541: loss 3.112 0.304688 0.367188
iteration 542: loss 3.166 0.335938 0.406250
iteration 543: loss 3.173 0.320312 0.335938
iteration 544: loss 4.302 0.304688 0.281250
iteration 545: loss 3.464 0.312500 0.273438
iteration 546: loss 3.338 0.226562 0.445312
iteration 547: loss 3.998 0.218750 0.359375
iteration 548: loss 3.892 0.304688 0.242188
iteration 549: loss 3.089 0.250000 0.320312
iteration 550: loss 3.183 0.234375 0.335938
iteration 551: loss 3.874 0.312500 0.343750
iteration 552: loss 4.406 0.359375 0.296875
iteration 553: loss 3.073 0.304688 0.335938
iteration 554: loss 3.917 0.421875 0.226562
iteration 555: loss 3.026 0.281250 0.343750
iteration 556: loss 4.240 0.273438 0.265625
iteration 557: loss 3.574 0.195312 0.367188
iteration 558: loss 3.407 0.343750 0.250000
iteration 559: loss 3.355 0.328125 0.257812
iteration 560: loss 3.526 0.328125 0.335938
iteration 561: loss 3.225 0.328125 0.289062
iteration 562: loss 2.994 0.289062 0.351562
iteration 563: loss 4.025 0.210938 0.312500
iteration 564: loss 3.208 0.265625 0.343750
iteration 565: loss 2.990 0.234375 0.289062
iteration 566: loss 3.695 0.281250 0.406250
iteration 567: loss 2.974 0.398438 0.359375
iteration 568: loss 3.663 0.265625 0.304688
iteration 569: loss 3.427 0.328125 0.367188
iteration 570: loss 2.699 0.320312 0.328125
iteration 571: loss 2.955 0.320312 0.296875
iteration 572: loss 3.917 0.320312 0.328125
iteration 573: loss 3.814 0.265625 0.296875
iteration 574: loss 2.254 0.257812 0.351562
iteration 575: loss 2.741 0.281250 0.414062
iteration 576: loss 2.991 0.351562 0.343750
iteration 577: loss 3.734 0.281250 0.265625
iteration 578: loss 4.413 0.296875 0.289062
iteration 579: loss 3.378 0.281250 0.335938
iteration 580: loss 2.831 0.234375 0.328125
iteration 581: loss 2.899 0.304688 0.382812
iteration 582: loss 3.037 0.351562 0.382812
iteration 583: loss 3.522 0.328125 0.382812
iteration 584: loss 3.289 0.406250 0.343750
iteration 585: loss 3.303 0.351562 0.414062
iteration 586: loss 4.080 0.351562 0.343750
iteration 587: loss 4.238 0.390625 0.289062
iteration 588: loss 3.853 0.351562 0.351562
iteration 589: loss 3.330 0.335938 0.367188
iteration 590: loss 3.071 0.273438 0.406250
iteration 591: loss 3.358 0.281250 0.335938
iteration 592: loss 3.955 0.273438 0.312500
iteration 593: loss 2.753 0.289062 0.320312
iteration 594: loss 2.797 0.273438 0.328125
iteration 595: loss 3.342 0.304688 0.343750
iteration 596: loss 2.967 0.273438 0.351562
iteration 597: loss 3.142 0.265625 0.304688
iteration 598: loss 3.899 0.304688 0.304688
iteration 599: loss 3.834 0.335938 0.312500
iteration 600: loss 3.180 0.351562 0.312500
iteration 601: loss 3.767 0.265625 0.343750
iteration 602: loss 3.148 0.296875 0.289062
iteration 603: loss 3.679 0.265625 0.296875
iteration 604: loss 3.241 0.273438 0.351562
iteration 605: loss 3.343 0.320312 0.304688
iteration 606: loss 3.776 0.273438 0.289062
iteration 607: loss 3.400 0.296875 0.296875
iteration 608: loss 3.445 0.265625 0.281250
iteration 609: loss 2.891 0.273438 0.343750
iteration 610: loss 3.739 0.296875 0.273438
iteration 611: loss 3.263 0.210938 0.289062
iteration 612: loss 4.014 0.265625 0.312500
iteration 613: loss 3.625 0.343750 0.312500
iteration 614: loss 3.609 0.281250 0.265625
iteration 615: loss 3.318 0.273438 0.281250
iteration 616: loss 3.269 0.328125 0.359375
iteration 617: loss 3.187 0.390625 0.320312
iteration 618: loss 3.370 0.296875 0.281250
iteration 619: loss 2.848 0.468750 0.328125
iteration 620: loss 3.216 0.296875 0.281250
iteration 621: loss 3.413 0.234375 0.304688
iteration 622: loss 2.878 0.320312 0.273438
iteration 623: loss 3.431 0.281250 0.328125
iteration 624: loss 3.305 0.390625 0.343750
iteration 625: loss 3.714 0.312500 0.296875
iteration 626: loss 3.345 0.242188 0.343750
iteration 627: loss 3.228 0.335938 0.289062
iteration 628: loss 4.232 0.328125 0.218750
iteration 629: loss 3.518 0.234375 0.281250
iteration 630: loss 3.272 0.375000 0.351562
iteration 631: loss 3.802 0.281250 0.289062
iteration 632: loss 3.409 0.273438 0.281250
iteration 633: loss 3.417 0.375000 0.343750
iteration 634: loss 3.533 0.281250 0.359375
iteration 635: loss 3.710 0.359375 0.289062
iteration 636: loss 3.987 0.273438 0.328125
iteration 637: loss 3.824 0.359375 0.328125
iteration 638: loss 3.262 0.234375 0.312500
iteration 639: loss 3.419 0.335938 0.273438
iteration 640: loss 3.705 0.257812 0.250000
iteration 641: loss 3.443 0.273438 0.335938
iteration 642: loss 3.635 0.320312 0.328125
iteration 643: loss 2.889 0.273438 0.312500
iteration 644: loss 3.329 0.265625 0.343750
iteration 645: loss 2.987 0.265625 0.375000
iteration 646: loss 3.756 0.398438 0.343750
iteration 647: loss 4.255 0.304688 0.242188
iteration 648: loss 3.207 0.296875 0.335938
iteration 649: loss 3.335 0.335938 0.351562
iteration 650: loss 1.871 0.429688 0.437500
iteration 651: loss 3.847 0.414062 0.390625
iteration 652: loss 2.846 0.281250 0.398438
iteration 653: loss 3.603 0.312500 0.335938
iteration 654: loss 3.708 0.367188 0.359375
iteration 655: loss 3.426 0.382812 0.320312
iteration 656: loss 2.377 0.312500 0.390625
iteration 657: loss 3.639 0.257812 0.335938
iteration 658: loss 3.749 0.296875 0.273438
iteration 659: loss 3.532 0.234375 0.382812
iteration 660: loss 3.952 0.296875 0.250000
iteration 661: loss 2.819 0.320312 0.304688
iteration 662: loss 3.333 0.312500 0.367188
iteration 663: loss 3.632 0.289062 0.320312
iteration 664: loss 2.529 0.343750 0.445312
iteration 665: loss 2.970 0.289062 0.382812
iteration 666: loss 3.856 0.265625 0.406250
iteration 667: loss 3.440 0.328125 0.257812
iteration 668: loss 2.858 0.343750 0.335938
iteration 669: loss 3.305 0.328125 0.296875
iteration 670: loss 3.319 0.257812 0.273438
iteration 671: loss 4.063 0.312500 0.281250
iteration 672: loss 3.170 0.320312 0.375000
iteration 673: loss 3.386 0.328125 0.343750
iteration 674: loss 2.649 0.359375 0.335938
iteration 675: loss 3.046 0.289062 0.328125
iteration 676: loss 2.892 0.320312 0.320312
iteration 677: loss 3.409 0.343750 0.304688
iteration 678: loss 3.833 0.390625 0.273438
iteration 679: loss 3.553 0.343750 0.304688
iteration 680: loss 2.296 0.367188 0.367188
iteration 681: loss 2.965 0.390625 0.398438
iteration 682: loss 3.190 0.304688 0.398438
iteration 683: loss 2.097 0.343750 0.429688
iteration 684: loss 2.828 0.273438 0.328125
iteration 685: loss 3.290 0.226562 0.304688
iteration 686: loss 4.117 0.250000 0.257812
iteration 687: loss 3.161 0.289062 0.367188
iteration 688: loss 3.337 0.242188 0.257812
iteration 689: loss 2.930 0.328125 0.328125
iteration 690: loss 3.889 0.359375 0.335938
iteration 691: loss 2.889 0.304688 0.320312
iteration 692: loss 2.851 0.320312 0.304688
iteration 693: loss 3.589 0.281250 0.304688
iteration 694: loss 3.127 0.289062 0.281250
iteration 695: loss 3.179 0.328125 0.281250
iteration 696: loss 3.753 0.406250 0.328125
iteration 697: loss 2.941 0.289062 0.398438
iteration 698: loss 4.119 0.281250 0.257812
iteration 699: loss 2.746 0.296875 0.320312
iteration 700: loss 3.228 0.265625 0.359375
iteration 701: loss 2.878 0.312500 0.281250
iteration 702: loss 3.292 0.257812 0.273438
iteration 703: loss 2.988 0.390625 0.273438
iteration 704: loss 3.347 0.296875 0.382812
iteration 705: loss 2.721 0.351562 0.375000
iteration 706: loss 3.276 0.312500 0.406250
iteration 707: loss 2.864 0.335938 0.398438
iteration 708: loss 3.322 0.351562 0.359375
iteration 709: loss 3.375 0.296875 0.398438
iteration 710: loss 3.646 0.296875 0.320312
iteration 711: loss 2.751 0.250000 0.289062
iteration 712: loss 3.041 0.281250 0.335938
iteration 713: loss 3.753 0.382812 0.210938
iteration 714: loss 3.714 0.320312 0.296875
iteration 715: loss 3.292 0.335938 0.351562
iteration 716: loss 3.066 0.273438 0.382812
iteration 717: loss 4.063 0.320312 0.296875
iteration 718: loss 3.701 0.281250 0.273438
iteration 719: loss 3.291 0.343750 0.382812
iteration 720: loss 2.774 0.367188 0.382812
iteration 721: loss 3.347 0.328125 0.382812
iteration 722: loss 3.495 0.289062 0.320312
iteration 723: loss 3.753 0.343750 0.320312
iteration 724: loss 3.378 0.406250 0.296875
iteration 725: loss 3.300 0.218750 0.296875
iteration 726: loss 2.832 0.312500 0.296875
iteration 727: loss 3.113 0.187500 0.320312
iteration 728: loss 3.507 0.289062 0.296875
iteration 729: loss 3.245 0.281250 0.273438
iteration 730: loss 3.743 0.296875 0.320312
iteration 731: loss 2.939 0.296875 0.367188
iteration 732: loss 3.012 0.234375 0.382812
iteration 733: loss 3.417 0.312500 0.398438
iteration 734: loss 3.365 0.328125 0.359375
iteration 735: loss 3.224 0.312500 0.367188
iteration 736: loss 5.118 0.281250 0.335938
iteration 737: loss 3.396 0.281250 0.304688
iteration 738: loss 3.199 0.351562 0.296875
iteration 739: loss 3.229 0.320312 0.406250
iteration 740: loss 2.457 0.273438 0.320312
iteration 741: loss 3.204 0.281250 0.281250
iteration 742: loss 3.526 0.234375 0.273438
iteration 743: loss 2.684 0.289062 0.335938
iteration 744: loss 2.859 0.335938 0.304688
iteration 745: loss 2.972 0.257812 0.296875
iteration 746: loss 4.354 0.289062 0.296875
iteration 747: loss 3.343 0.367188 0.273438
iteration 748: loss 2.372 0.398438 0.398438
iteration 749: loss 3.123 0.312500 0.281250
iteration 750: loss 3.217 0.328125 0.453125
iteration 751: loss 3.256 0.359375 0.320312
iteration 752: loss 3.121 0.250000 0.273438
iteration 753: loss 2.745 0.328125 0.437500
iteration 754: loss 2.838 0.273438 0.351562
iteration 755: loss 2.552 0.312500 0.304688
iteration 756: loss 2.871 0.367188 0.320312
iteration 757: loss 3.261 0.328125 0.304688
iteration 758: loss 3.239 0.359375 0.328125
iteration 759: loss 2.992 0.320312 0.484375
iteration 760: loss 3.254 0.343750 0.335938
iteration 761: loss 3.058 0.296875 0.367188
iteration 762: loss 3.027 0.359375 0.406250
iteration 763: loss 2.895 0.304688 0.359375
iteration 764: loss 3.022 0.312500 0.328125
iteration 765: loss 3.510 0.226562 0.320312
iteration 766: loss 4.078 0.273438 0.328125
iteration 767: loss 3.838 0.343750 0.281250
iteration 768: loss 2.927 0.320312 0.289062
iteration 769: loss 3.367 0.265625 0.359375
iteration 770: loss 3.450 0.390625 0.343750
iteration 771: loss 3.710 0.343750 0.351562
iteration 772: loss 3.532 0.343750 0.320312
iteration 773: loss 2.825 0.359375 0.273438
iteration 774: loss 3.267 0.343750 0.367188
iteration 775: loss 3.150 0.351562 0.304688
iteration 776: loss 3.151 0.304688 0.289062
iteration 777: loss 2.572 0.367188 0.367188
iteration 778: loss 2.536 0.234375 0.406250
iteration 779: loss 2.950 0.351562 0.312500
iteration 780: loss 2.815 0.328125 0.398438
iteration 781: loss 3.645 0.328125 0.296875
iteration 782: loss 2.318 0.242188 0.281250
iteration 783: loss 3.142 0.375000 0.328125
iteration 784: loss 3.272 0.312500 0.359375
iteration 785: loss 3.022 0.328125 0.312500
iteration 786: loss 2.888 0.289062 0.320312
iteration 787: loss 2.606 0.234375 0.390625
iteration 788: loss 3.156 0.304688 0.390625
iteration 789: loss 2.857 0.296875 0.328125
iteration 790: loss 3.151 0.328125 0.328125
iteration 791: loss 3.065 0.328125 0.406250
iteration 792: loss 3.292 0.312500 0.296875
iteration 793: loss 3.743 0.320312 0.257812
iteration 794: loss 3.275 0.359375 0.312500
iteration 795: loss 2.861 0.281250 0.304688
iteration 796: loss 3.046 0.281250 0.320312
iteration 797: loss 3.390 0.304688 0.273438
iteration 798: loss 2.670 0.273438 0.359375
iteration 799: loss 2.909 0.406250 0.304688
iteration 800: loss 3.261 0.359375 0.320312
iteration 801: loss 3.155 0.320312 0.320312
iteration 802: loss 3.180 0.335938 0.281250
iteration 803: loss 4.224 0.343750 0.257812
iteration 804: loss 3.252 0.320312 0.250000
iteration 805: loss 3.132 0.265625 0.250000
iteration 806: loss 2.878 0.312500 0.328125
iteration 807: loss 3.235 0.328125 0.367188
iteration 808: loss 3.348 0.281250 0.375000
iteration 809: loss 3.919 0.335938 0.335938
iteration 810: loss 2.977 0.289062 0.304688
iteration 811: loss 2.805 0.320312 0.335938
iteration 812: loss 2.706 0.281250 0.382812
iteration 813: loss 2.714 0.281250 0.312500
iteration 814: loss 3.360 0.328125 0.296875
iteration 815: loss 3.511 0.281250 0.257812
iteration 816: loss 3.087 0.343750 0.281250
iteration 817: loss 3.422 0.296875 0.289062
iteration 818: loss 2.951 0.406250 0.265625
iteration 819: loss 3.170 0.312500 0.304688
iteration 820: loss 3.105 0.304688 0.312500
iteration 821: loss 3.635 0.296875 0.375000
iteration 822: loss 3.338 0.312500 0.398438
iteration 823: loss 3.363 0.320312 0.367188
iteration 824: loss 3.543 0.367188 0.351562
iteration 825: loss 3.231 0.382812 0.367188
iteration 826: loss 3.363 0.335938 0.367188
iteration 827: loss 3.127 0.312500 0.359375
iteration 828: loss 3.479 0.273438 0.328125
iteration 829: loss 3.221 0.312500 0.351562
iteration 830: loss 2.930 0.367188 0.304688
iteration 831: loss 3.591 0.312500 0.320312
iteration 832: loss 3.263 0.343750 0.296875
iteration 833: loss 3.241 0.304688 0.320312
iteration 834: loss 2.589 0.289062 0.406250
iteration 835: loss 2.995 0.359375 0.382812
iteration 836: loss 3.535 0.320312 0.343750
iteration 837: loss 3.176 0.398438 0.328125
iteration 838: loss 2.814 0.367188 0.367188
iteration 839: loss 3.836 0.328125 0.242188
iteration 840: loss 2.957 0.351562 0.414062
iteration 841: loss 2.956 0.312500 0.343750
iteration 842: loss 2.907 0.296875 0.359375
iteration 843: loss 2.767 0.304688 0.398438
iteration 844: loss 3.008 0.328125 0.304688
iteration 845: loss 2.339 0.312500 0.406250
iteration 846: loss 2.240 0.281250 0.445312
iteration 847: loss 3.478 0.273438 0.320312
iteration 848: loss 3.242 0.304688 0.234375
iteration 849: loss 3.004 0.359375 0.328125
iteration 850: loss 3.375 0.351562 0.328125
iteration 851: loss 3.638 0.281250 0.328125
iteration 852: loss 3.053 0.359375 0.335938
iteration 853: loss 3.173 0.335938 0.375000
iteration 854: loss 3.139 0.312500 0.367188
iteration 855: loss 2.966 0.328125 0.351562
iteration 856: loss 3.257 0.281250 0.343750
iteration 857: loss 3.409 0.320312 0.414062
iteration 858: loss 2.875 0.281250 0.406250
iteration 859: loss 3.654 0.343750 0.273438
iteration 860: loss 2.845 0.226562 0.328125
iteration 861: loss 2.766 0.351562 0.289062
iteration 862: loss 2.783 0.265625 0.250000
iteration 863: loss 3.131 0.242188 0.351562
iteration 864: loss 3.216 0.304688 0.273438
iteration 865: loss 4.038 0.273438 0.281250
iteration 866: loss 3.054 0.265625 0.328125
iteration 867: loss 3.247 0.281250 0.351562
iteration 868: loss 2.864 0.375000 0.351562
iteration 869: loss 2.945 0.312500 0.375000
iteration 870: loss 2.891 0.320312 0.375000
iteration 871: loss 3.512 0.304688 0.320312
iteration 872: loss 3.348 0.351562 0.359375
iteration 873: loss 2.953 0.335938 0.367188
iteration 874: loss 2.954 0.343750 0.320312
iteration 875: loss 3.613 0.242188 0.328125
iteration 876: loss 4.073 0.265625 0.289062
iteration 877: loss 3.433 0.343750 0.343750
iteration 878: loss 2.377 0.375000 0.398438
iteration 879: loss 2.254 0.257812 0.414062
iteration 880: loss 2.237 0.289062 0.437500
iteration 881: loss 3.699 0.320312 0.320312
iteration 882: loss 2.938 0.367188 0.429688
iteration 883: loss 3.106 0.304688 0.382812
iteration 884: loss 2.352 0.304688 0.390625
iteration 885: loss 2.358 0.289062 0.429688
iteration 886: loss 3.448 0.312500 0.304688
iteration 887: loss 2.655 0.367188 0.343750
iteration 888: loss 2.843 0.359375 0.343750
iteration 889: loss 2.766 0.296875 0.312500
iteration 890: loss 2.854 0.304688 0.382812
iteration 891: loss 3.251 0.312500 0.351562
iteration 892: loss 3.579 0.289062 0.359375
iteration 893: loss 3.285 0.343750 0.250000
iteration 894: loss 3.132 0.273438 0.289062
iteration 895: loss 2.517 0.273438 0.281250
iteration 896: loss 3.091 0.328125 0.320312
iteration 897: loss 3.002 0.343750 0.359375
iteration 898: loss 2.420 0.304688 0.296875
iteration 899: loss 3.471 0.281250 0.281250
iteration 900: loss 3.257 0.312500 0.281250
iteration 901: loss 3.649 0.234375 0.320312
iteration 902: loss 3.165 0.328125 0.398438
iteration 903: loss 3.205 0.328125 0.382812
iteration 904: loss 3.096 0.328125 0.335938
iteration 905: loss 2.221 0.359375 0.437500
iteration 906: loss 2.617 0.328125 0.375000
iteration 907: loss 2.681 0.289062 0.351562
iteration 908: loss 2.660 0.335938 0.367188
iteration 909: loss 2.407 0.328125 0.382812
iteration 910: loss 2.838 0.335938 0.359375
iteration 911: loss 2.602 0.273438 0.320312
iteration 912: loss 2.646 0.250000 0.390625
iteration 913: loss 3.287 0.421875 0.351562
iteration 914: loss 3.257 0.335938 0.382812
iteration 915: loss 3.044 0.382812 0.375000
iteration 916: loss 3.006 0.296875 0.328125
iteration 917: loss 2.669 0.289062 0.320312
iteration 918: loss 3.087 0.343750 0.367188
iteration 919: loss 2.707 0.312500 0.351562
iteration 920: loss 2.347 0.289062 0.375000
iteration 921: loss 2.392 0.296875 0.421875
iteration 922: loss 2.392 0.328125 0.406250
iteration 923: loss 2.584 0.218750 0.343750
iteration 924: loss 3.766 0.320312 0.304688
iteration 925: loss 2.682 0.367188 0.312500
iteration 926: loss 2.498 0.289062 0.429688
iteration 927: loss 2.801 0.320312 0.289062
iteration 928: loss 2.545 0.351562 0.328125
iteration 929: loss 2.908 0.351562 0.382812
iteration 930: loss 3.103 0.312500 0.367188
iteration 931: loss 2.960 0.367188 0.382812
iteration 932: loss 2.709 0.335938 0.429688
iteration 933: loss 2.630 0.304688 0.390625
iteration 934: loss 2.547 0.281250 0.351562
iteration 935: loss 3.203 0.304688 0.343750
iteration 936: loss 2.903 0.265625 0.328125
iteration 937: loss 2.623 0.242188 0.351562
iteration 938: loss 2.238 0.265625 0.390625
iteration 939: loss 2.739 0.304688 0.375000
iteration 940: loss 2.765 0.367188 0.375000
iteration 941: loss 2.550 0.335938 0.335938
iteration 942: loss 2.541 0.281250 0.328125
iteration 943: loss 3.754 0.281250 0.312500
iteration 944: loss 3.333 0.382812 0.343750
iteration 945: loss 2.615 0.289062 0.429688
iteration 946: loss 2.584 0.265625 0.398438
iteration 947: loss 3.150 0.328125 0.304688
iteration 948: loss 2.381 0.343750 0.375000
iteration 949: loss 2.719 0.265625 0.343750
iteration 950: loss 2.661 0.335938 0.328125
iteration 951: loss 2.830 0.351562 0.335938
iteration 952: loss 2.684 0.343750 0.382812
iteration 953: loss 2.500 0.265625 0.343750
iteration 954: loss 3.338 0.273438 0.304688
iteration 955: loss 2.929 0.351562 0.359375
iteration 956: loss 2.772 0.296875 0.351562
iteration 957: loss 2.482 0.320312 0.359375
iteration 958: loss 3.324 0.335938 0.390625
iteration 959: loss 2.644 0.328125 0.351562
iteration 960: loss 2.790 0.289062 0.375000
iteration 961: loss 2.555 0.414062 0.273438
iteration 962: loss 2.998 0.343750 0.304688
iteration 963: loss 2.236 0.351562 0.421875
iteration 964: loss 2.890 0.343750 0.351562
iteration 965: loss 3.016 0.320312 0.429688
iteration 966: loss 2.942 0.390625 0.335938
iteration 967: loss 2.446 0.359375 0.390625
iteration 968: loss 2.374 0.312500 0.351562
iteration 969: loss 2.655 0.359375 0.304688
iteration 970: loss 2.392 0.375000 0.406250
iteration 971: loss 2.891 0.351562 0.343750
iteration 972: loss 2.568 0.421875 0.335938
iteration 973: loss 2.767 0.398438 0.335938
iteration 974: loss 2.772 0.367188 0.304688
iteration 975: loss 2.586 0.312500 0.398438
iteration 976: loss 2.970 0.226562 0.343750
iteration 977: loss 3.263 0.265625 0.312500
iteration 978: loss 2.725 0.351562 0.312500
iteration 979: loss 2.919 0.367188 0.320312
iteration 980: loss 2.925 0.273438 0.351562
iteration 981: loss 3.208 0.250000 0.304688
iteration 982: loss 2.854 0.281250 0.320312
iteration 983: loss 2.532 0.265625 0.414062
iteration 984: loss 1.996 0.343750 0.445312
iteration 985: loss 3.371 0.367188 0.304688
iteration 986: loss 3.039 0.289062 0.320312
iteration 987: loss 2.677 0.421875 0.335938
iteration 988: loss 2.810 0.335938 0.367188
iteration 989: loss 2.665 0.304688 0.429688
iteration 990: loss 2.636 0.304688 0.382812
iteration 991: loss 2.999 0.328125 0.265625
iteration 992: loss 2.791 0.312500 0.328125
iteration 993: loss 3.183 0.320312 0.289062
iteration 994: loss 3.205 0.328125 0.296875
iteration 995: loss 2.784 0.343750 0.304688
iteration 996: loss 2.609 0.281250 0.390625
iteration 997: loss 2.500 0.351562 0.375000
iteration 998: loss 2.424 0.335938 0.398438
iteration 999: loss 2.759 0.328125 0.375000
epoch 0: training: 0.359375 validation: 0.195312
iteration 0: loss 2.659 0.335938 0.390625
iteration 1: loss 2.584 0.351562 0.437500
iteration 2: loss 3.422 0.351562 0.273438
iteration 3: loss 2.248 0.296875 0.390625
iteration 4: loss 2.271 0.328125 0.351562
iteration 5: loss 3.292 0.351562 0.312500
iteration 6: loss 2.299 0.359375 0.289062
iteration 7: loss 2.910 0.289062 0.351562
iteration 8: loss 2.181 0.343750 0.359375
iteration 9: loss 2.795 0.429688 0.351562
iteration 10: loss 3.051 0.343750 0.351562
iteration 11: loss 2.697 0.312500 0.359375
iteration 12: loss 2.599 0.296875 0.414062
iteration 13: loss 2.267 0.382812 0.476562
iteration 14: loss 2.876 0.328125 0.343750
iteration 15: loss 2.944 0.304688 0.421875
iteration 16: loss 2.375 0.359375 0.445312
iteration 17: loss 2.819 0.375000 0.398438
iteration 18: loss 2.844 0.406250 0.351562
iteration 19: loss 2.799 0.304688 0.429688
iteration 20: loss 2.662 0.265625 0.343750
iteration 21: loss 2.930 0.289062 0.320312
iteration 22: loss 2.804 0.320312 0.304688
iteration 23: loss 3.073 0.359375 0.367188
iteration 24: loss 3.323 0.257812 0.320312
iteration 25: loss 3.156 0.273438 0.218750
iteration 26: loss 2.467 0.273438 0.382812
iteration 27: loss 2.683 0.351562 0.281250
iteration 28: loss 2.289 0.265625 0.390625
iteration 29: loss 2.350 0.312500 0.398438
iteration 30: loss 2.659 0.328125 0.375000
iteration 31: loss 3.760 0.375000 0.359375
iteration 32: loss 2.115 0.320312 0.351562
iteration 33: loss 3.138 0.343750 0.320312
iteration 34: loss 2.859 0.289062 0.335938
iteration 35: loss 2.781 0.281250 0.351562
iteration 36: loss 2.625 0.343750 0.304688
iteration 37: loss 2.521 0.273438 0.304688
iteration 38: loss 2.940 0.312500 0.351562
iteration 39: loss 2.447 0.296875 0.351562
iteration 40: loss 3.109 0.289062 0.343750
iteration 41: loss 2.699 0.312500 0.359375
iteration 42: loss 2.797 0.320312 0.398438
iteration 43: loss 2.894 0.367188 0.445312
iteration 44: loss 2.467 0.304688 0.406250
iteration 45: loss 2.088 0.406250 0.390625
iteration 46: loss 3.292 0.242188 0.320312
iteration 47: loss 3.153 0.375000 0.273438
iteration 48: loss 2.456 0.320312 0.375000
iteration 49: loss 2.760 0.375000 0.351562
iteration 50: loss 3.352 0.328125 0.328125
iteration 51: loss 3.168 0.304688 0.406250
iteration 52: loss 2.621 0.281250 0.328125
iteration 53: loss 2.197 0.296875 0.320312
iteration 54: loss 2.761 0.296875 0.343750
iteration 55: loss 2.366 0.304688 0.382812
iteration 56: loss 2.879 0.343750 0.343750
iteration 57: loss 2.375 0.312500 0.421875
iteration 58: loss 2.221 0.304688 0.367188
iteration 59: loss 2.488 0.250000 0.398438
iteration 60: loss 3.277 0.367188 0.375000
iteration 61: loss 3.279 0.257812 0.304688
iteration 62: loss 3.084 0.312500 0.398438
iteration 63: loss 3.011 0.328125 0.351562
iteration 64: loss 3.047 0.250000 0.382812
iteration 65: loss 3.314 0.265625 0.335938
iteration 66: loss 3.893 0.273438 0.289062
iteration 67: loss 3.450 0.265625 0.312500
iteration 68: loss 2.811 0.335938 0.335938
iteration 69: loss 2.613 0.359375 0.328125
iteration 70: loss 2.327 0.328125 0.343750
iteration 71: loss 2.407 0.328125 0.351562
iteration 72: loss 2.658 0.257812 0.312500
iteration 73: loss 2.150 0.359375 0.382812
iteration 74: loss 2.832 0.328125 0.304688
iteration 75: loss 3.549 0.367188 0.281250
iteration 76: loss 2.815 0.265625 0.320312
iteration 77: loss 2.688 0.304688 0.335938
iteration 78: loss 3.025 0.257812 0.335938
iteration 79: loss 2.307 0.390625 0.453125
iteration 80: loss 2.413 0.351562 0.382812
iteration 81: loss 2.896 0.367188 0.359375
iteration 82: loss 2.516 0.312500 0.343750
iteration 83: loss 2.861 0.312500 0.351562
iteration 84: loss 2.615 0.273438 0.414062
iteration 85: loss 2.905 0.335938 0.304688
iteration 86: loss 2.480 0.328125 0.343750
iteration 87: loss 2.599 0.453125 0.367188
iteration 88: loss 1.957 0.289062 0.468750
iteration 89: loss 2.665 0.312500 0.492188
iteration 90: loss 2.648 0.343750 0.351562
iteration 91: loss 2.295 0.335938 0.453125
iteration 92: loss 1.921 0.359375 0.382812
iteration 93: loss 2.620 0.289062 0.304688
iteration 94: loss 2.550 0.351562 0.382812
iteration 95: loss 2.407 0.406250 0.359375
iteration 96: loss 2.108 0.304688 0.375000
iteration 97: loss 2.935 0.335938 0.390625
iteration 98: loss 3.052 0.382812 0.304688
iteration 99: loss 2.773 0.250000 0.320312
iteration 100: loss 2.781 0.328125 0.382812
iteration 101: loss 3.080 0.367188 0.335938
iteration 102: loss 2.103 0.343750 0.414062
iteration 103: loss 3.489 0.351562 0.320312
iteration 104: loss 2.790 0.320312 0.382812
iteration 105: loss 2.728 0.281250 0.382812
iteration 106: loss 2.792 0.250000 0.328125
iteration 107: loss 2.399 0.343750 0.375000
iteration 108: loss 3.513 0.273438 0.210938
iteration 109: loss 2.648 0.328125 0.351562
iteration 110: loss 2.252 0.296875 0.359375
iteration 111: loss 2.793 0.343750 0.351562
iteration 112: loss 2.330 0.351562 0.375000
iteration 113: loss 2.695 0.304688 0.320312
iteration 114: loss 2.685 0.359375 0.359375
iteration 115: loss 2.759 0.289062 0.343750
iteration 116: loss 2.783 0.312500 0.289062
iteration 117: loss 2.135 0.296875 0.375000
iteration 118: loss 2.696 0.296875 0.367188
iteration 119: loss 2.536 0.320312 0.351562
iteration 120: loss 1.962 0.390625 0.429688
iteration 121: loss 2.576 0.367188 0.359375
iteration 122: loss 2.521 0.289062 0.382812
iteration 123: loss 2.931 0.375000 0.382812
iteration 124: loss 3.172 0.359375 0.335938
iteration 125: loss 2.478 0.265625 0.367188
iteration 126: loss 1.881 0.296875 0.445312
iteration 127: loss 2.697 0.359375 0.398438
iteration 128: loss 2.572 0.335938 0.351562
iteration 129: loss 2.173 0.375000 0.429688
iteration 130: loss 2.664 0.312500 0.328125
iteration 131: loss 3.432 0.382812 0.312500
iteration 132: loss 2.751 0.296875 0.398438
iteration 133: loss 2.652 0.375000 0.421875
iteration 134: loss 3.222 0.242188 0.398438
iteration 135: loss 2.775 0.390625 0.359375
iteration 136: loss 2.054 0.312500 0.429688
iteration 137: loss 2.786 0.367188 0.273438
iteration 138: loss 3.046 0.312500 0.343750
iteration 139: loss 2.816 0.328125 0.398438
iteration 140: loss 2.961 0.351562 0.328125
iteration 141: loss 2.840 0.320312 0.414062
iteration 142: loss 2.472 0.343750 0.382812
iteration 143: loss 1.984 0.281250 0.390625
iteration 144: loss 2.289 0.312500 0.359375
iteration 145: loss 3.000 0.320312 0.320312
iteration 146: loss 2.447 0.296875 0.359375
iteration 147: loss 3.655 0.335938 0.398438
iteration 148: loss 2.657 0.328125 0.382812
iteration 149: loss 2.193 0.328125 0.375000
iteration 150: loss 2.349 0.390625 0.398438
iteration 151: loss 2.194 0.296875 0.429688
iteration 152: loss 3.258 0.273438 0.335938
iteration 153: loss 2.377 0.289062 0.398438
iteration 154: loss 2.452 0.296875 0.398438
iteration 155: loss 2.292 0.296875 0.367188
iteration 156: loss 2.350 0.328125 0.468750
iteration 157: loss 2.870 0.351562 0.390625
iteration 158: loss 2.876 0.273438 0.320312
iteration 159: loss 2.587 0.312500 0.351562
iteration 160: loss 2.337 0.281250 0.367188
iteration 161: loss 2.098 0.390625 0.468750
iteration 162: loss 2.583 0.320312 0.390625
iteration 163: loss 2.163 0.320312 0.375000
iteration 164: loss 2.320 0.257812 0.382812
iteration 165: loss 2.195 0.343750 0.296875
iteration 166: loss 2.159 0.406250 0.375000
iteration 167: loss 2.417 0.351562 0.421875
iteration 168: loss 2.311 0.343750 0.382812
iteration 169: loss 2.692 0.343750 0.382812
iteration 170: loss 3.001 0.328125 0.328125
iteration 171: loss 2.497 0.265625 0.335938
iteration 172: loss 2.315 0.406250 0.335938
iteration 173: loss 3.516 0.328125 0.335938
iteration 174: loss 2.147 0.351562 0.414062
iteration 175: loss 3.224 0.312500 0.359375
iteration 176: loss 2.443 0.343750 0.390625
iteration 177: loss 2.879 0.304688 0.304688
iteration 178: loss 2.928 0.304688 0.398438
iteration 179: loss 2.497 0.320312 0.281250
iteration 180: loss 2.936 0.273438 0.359375
iteration 181: loss 2.654 0.351562 0.328125
iteration 182: loss 2.651 0.335938 0.328125
iteration 183: loss 2.885 0.367188 0.398438
iteration 184: loss 2.654 0.343750 0.328125
iteration 185: loss 1.893 0.312500 0.414062
iteration 186: loss 2.457 0.304688 0.335938
iteration 187: loss 2.565 0.320312 0.398438
iteration 188: loss 3.135 0.304688 0.359375
iteration 189: loss 2.195 0.250000 0.320312
iteration 190: loss 2.363 0.359375 0.351562
iteration 191: loss 2.487 0.304688 0.343750
iteration 192: loss 2.221 0.335938 0.359375
iteration 193: loss 2.258 0.320312 0.367188
iteration 194: loss 2.610 0.273438 0.398438
iteration 195: loss 2.897 0.406250 0.351562
iteration 196: loss 2.442 0.343750 0.421875
iteration 197: loss 1.982 0.390625 0.453125
iteration 198: loss 1.763 0.382812 0.382812
iteration 199: loss 2.299 0.312500 0.406250
iteration 200: loss 1.845 0.367188 0.421875
iteration 201: loss 1.959 0.343750 0.414062
iteration 202: loss 2.272 0.382812 0.390625
iteration 203: loss 2.131 0.382812 0.429688
iteration 204: loss 2.512 0.343750 0.343750
iteration 205: loss 2.090 0.273438 0.453125
iteration 206: loss 2.525 0.296875 0.460938
iteration 207: loss 2.288 0.351562 0.429688
iteration 208: loss 2.673 0.335938 0.335938
iteration 209: loss 2.394 0.375000 0.351562
iteration 210: loss 1.768 0.343750 0.476562
iteration 211: loss 2.163 0.265625 0.390625
iteration 212: loss 2.309 0.382812 0.406250
iteration 213: loss 2.185 0.328125 0.406250
iteration 214: loss 2.757 0.375000 0.367188
iteration 215: loss 2.488 0.289062 0.382812
iteration 216: loss 1.924 0.304688 0.429688
iteration 217: loss 1.983 0.304688 0.367188
iteration 218: loss 2.759 0.328125 0.312500
iteration 219: loss 2.883 0.296875 0.304688
iteration 220: loss 1.922 0.343750 0.367188
iteration 221: loss 2.594 0.343750 0.335938
iteration 222: loss 3.207 0.312500 0.335938
iteration 223: loss 2.078 0.328125 0.359375
iteration 224: loss 2.255 0.359375 0.445312
iteration 225: loss 2.041 0.289062 0.398438
iteration 226: loss 2.451 0.335938 0.359375
iteration 227: loss 2.920 0.281250 0.382812
iteration 228: loss 3.472 0.390625 0.351562
iteration 229: loss 2.293 0.351562 0.375000
iteration 230: loss 2.487 0.328125 0.367188
iteration 231: loss 2.653 0.250000 0.296875
iteration 232: loss 2.803 0.351562 0.273438
iteration 233: loss 2.753 0.281250 0.312500
iteration 234: loss 2.513 0.375000 0.398438
iteration 235: loss 3.117 0.250000 0.296875
iteration 236: loss 2.145 0.218750 0.398438
iteration 237: loss 2.569 0.390625 0.359375
iteration 238: loss 3.128 0.320312 0.328125
iteration 239: loss 2.277 0.359375 0.445312
iteration 240: loss 1.998 0.304688 0.367188
iteration 241: loss 2.404 0.367188 0.445312
iteration 242: loss 2.738 0.312500 0.382812
iteration 243: loss 1.939 0.289062 0.453125
iteration 244: loss 2.364 0.398438 0.351562
iteration 245: loss 1.978 0.343750 0.398438
iteration 246: loss 1.733 0.359375 0.460938
iteration 247: loss 2.829 0.367188 0.304688
iteration 248: loss 2.476 0.250000 0.312500
iteration 249: loss 2.737 0.343750 0.265625
iteration 250: loss 2.426 0.375000 0.390625
iteration 251: loss 2.291 0.367188 0.367188
iteration 252: loss 2.366 0.359375 0.421875
iteration 253: loss 2.643 0.367188 0.367188
iteration 254: loss 1.895 0.296875 0.484375
iteration 255: loss 3.601 0.273438 0.320312
iteration 256: loss 2.222 0.367188 0.421875
iteration 257: loss 2.223 0.281250 0.421875
iteration 258: loss 2.657 0.343750 0.382812
iteration 259: loss 2.495 0.375000 0.390625
iteration 260: loss 2.010 0.351562 0.398438
iteration 261: loss 2.566 0.296875 0.375000
iteration 262: loss 2.274 0.328125 0.390625
iteration 263: loss 2.563 0.320312 0.359375
iteration 264: loss 2.605 0.328125 0.343750
iteration 265: loss 2.340 0.304688 0.343750
iteration 266: loss 2.323 0.351562 0.320312
iteration 267: loss 2.589 0.335938 0.304688
iteration 268: loss 2.145 0.320312 0.421875
iteration 269: loss 2.331 0.398438 0.445312
iteration 270: loss 2.745 0.265625 0.359375
iteration 271: loss 2.457 0.304688 0.367188
iteration 272: loss 2.564 0.296875 0.367188
iteration 273: loss 2.251 0.304688 0.382812
iteration 274: loss 3.073 0.304688 0.351562
iteration 275: loss 1.939 0.296875 0.421875
iteration 276: loss 2.266 0.312500 0.390625
iteration 277: loss 2.460 0.359375 0.351562
iteration 278: loss 1.818 0.335938 0.429688
iteration 279: loss 2.831 0.382812 0.367188
iteration 280: loss 2.679 0.281250 0.359375
iteration 281: loss 2.290 0.328125 0.359375
iteration 282: loss 2.507 0.312500 0.398438
iteration 283: loss 2.226 0.437500 0.453125
iteration 284: loss 1.954 0.281250 0.460938
iteration 285: loss 2.743 0.390625 0.312500
iteration 286: loss 2.612 0.390625 0.328125
iteration 287: loss 3.011 0.351562 0.351562
iteration 288: loss 2.010 0.320312 0.421875
iteration 289: loss 2.042 0.343750 0.421875
iteration 290: loss 2.373 0.281250 0.296875
iteration 291: loss 2.841 0.351562 0.351562
iteration 292: loss 2.208 0.296875 0.375000
iteration 293: loss 2.263 0.351562 0.382812
iteration 294: loss 2.129 0.250000 0.375000
iteration 295: loss 2.822 0.304688 0.351562
iteration 296: loss 1.888 0.304688 0.429688
iteration 297: loss 2.478 0.328125 0.320312
iteration 298: loss 2.023 0.367188 0.335938
iteration 299: loss 2.643 0.273438 0.390625
iteration 300: loss 2.214 0.343750 0.343750
iteration 301: loss 2.481 0.375000 0.359375
iteration 302: loss 2.248 0.265625 0.437500
iteration 303: loss 2.520 0.390625 0.343750
iteration 304: loss 2.086 0.281250 0.390625
iteration 305: loss 2.500 0.421875 0.320312
iteration 306: loss 1.948 0.328125 0.429688
iteration 307: loss 2.566 0.343750 0.359375
iteration 308: loss 2.055 0.398438 0.390625
iteration 309: loss 1.683 0.367188 0.390625
iteration 310: loss 2.252 0.328125 0.359375
iteration 311: loss 2.315 0.312500 0.312500
iteration 312: loss 2.085 0.320312 0.429688
iteration 313: loss 2.767 0.273438 0.328125
iteration 314: loss 2.478 0.351562 0.335938
iteration 315: loss 2.370 0.296875 0.398438
iteration 316: loss 2.307 0.226562 0.406250
iteration 317: loss 1.792 0.289062 0.398438
iteration 318: loss 2.799 0.281250 0.273438
iteration 319: loss 2.245 0.367188 0.460938
iteration 320: loss 2.678 0.304688 0.328125
iteration 321: loss 1.993 0.312500 0.398438
iteration 322: loss 2.518 0.429688 0.335938
iteration 323: loss 2.468 0.320312 0.367188
iteration 324: loss 2.398 0.281250 0.406250
iteration 325: loss 1.849 0.320312 0.390625
iteration 326: loss 2.102 0.304688 0.343750
iteration 327: loss 2.446 0.335938 0.328125
iteration 328: loss 3.008 0.304688 0.375000
iteration 329: loss 2.427 0.343750 0.343750
iteration 330: loss 2.311 0.312500 0.382812
iteration 331: loss 1.911 0.390625 0.406250
iteration 332: loss 2.783 0.351562 0.367188
iteration 333: loss 2.070 0.406250 0.437500
iteration 334: loss 2.254 0.296875 0.453125
iteration 335: loss 2.436 0.382812 0.343750
iteration 336: loss 2.162 0.226562 0.375000
iteration 337: loss 2.186 0.343750 0.429688
iteration 338: loss 2.447 0.359375 0.359375
iteration 339: loss 3.020 0.304688 0.359375
iteration 340: loss 2.446 0.367188 0.281250
iteration 341: loss 1.635 0.367188 0.375000
iteration 342: loss 2.667 0.382812 0.304688
iteration 343: loss 2.468 0.320312 0.359375
iteration 344: loss 2.067 0.320312 0.328125
iteration 345: loss 2.406 0.304688 0.367188
iteration 346: loss 2.326 0.328125 0.406250
iteration 347: loss 2.722 0.304688 0.289062
iteration 348: loss 2.075 0.351562 0.351562
iteration 349: loss 2.039 0.351562 0.382812
iteration 350: loss 2.103 0.304688 0.367188
iteration 351: loss 2.457 0.398438 0.375000
iteration 352: loss 1.743 0.320312 0.367188
iteration 353: loss 2.206 0.351562 0.375000
iteration 354: loss 3.066 0.320312 0.328125
iteration 355: loss 2.140 0.320312 0.382812
iteration 356: loss 2.118 0.351562 0.398438
iteration 357: loss 2.438 0.320312 0.367188
iteration 358: loss 2.174 0.343750 0.359375
iteration 359: loss 2.310 0.312500 0.382812
iteration 360: loss 2.585 0.328125 0.437500
iteration 361: loss 2.806 0.304688 0.320312
iteration 362: loss 2.311 0.390625 0.320312
iteration 363: loss 2.827 0.312500 0.328125
iteration 364: loss 2.325 0.179688 0.367188
iteration 365: loss 2.264 0.414062 0.335938
iteration 366: loss 1.794 0.414062 0.375000
iteration 367: loss 2.076 0.304688 0.406250
iteration 368: loss 3.070 0.375000 0.289062
iteration 369: loss 2.016 0.414062 0.382812
iteration 370: loss 2.704 0.367188 0.359375
iteration 371: loss 2.352 0.281250 0.335938
iteration 372: loss 2.005 0.421875 0.367188
iteration 373: loss 2.076 0.359375 0.398438
iteration 374: loss 2.187 0.320312 0.375000
iteration 375: loss 2.247 0.312500 0.460938
iteration 376: loss 2.494 0.343750 0.296875
iteration 377: loss 2.289 0.234375 0.375000
iteration 378: loss 2.086 0.289062 0.375000
iteration 379: loss 1.953 0.351562 0.414062
iteration 380: loss 2.402 0.273438 0.343750
iteration 381: loss 2.188 0.320312 0.414062
iteration 382: loss 1.972 0.320312 0.382812
iteration 383: loss 2.572 0.289062 0.421875
iteration 384: loss 2.387 0.375000 0.382812
iteration 385: loss 2.202 0.320312 0.304688
iteration 386: loss 2.378 0.250000 0.359375
iteration 387: loss 2.102 0.382812 0.437500
iteration 388: loss 2.245 0.312500 0.390625
iteration 389: loss 2.199 0.328125 0.359375
iteration 390: loss 2.011 0.367188 0.445312
iteration 391: loss 2.282 0.304688 0.406250
iteration 392: loss 2.125 0.382812 0.406250
iteration 393: loss 2.101 0.351562 0.437500
iteration 394: loss 2.012 0.265625 0.414062
iteration 395: loss 2.372 0.335938 0.375000
iteration 396: loss 2.144 0.328125 0.406250
iteration 397: loss 1.864 0.335938 0.406250
iteration 398: loss 1.941 0.296875 0.382812
iteration 399: loss 2.535 0.281250 0.312500
iteration 400: loss 2.029 0.304688 0.437500
iteration 401: loss 2.217 0.312500 0.398438
iteration 402: loss 2.337 0.289062 0.328125
iteration 403: loss 1.955 0.281250 0.320312
iteration 404: loss 2.688 0.359375 0.351562
iteration 405: loss 2.553 0.312500 0.382812
iteration 406: loss 2.298 0.335938 0.351562
iteration 407: loss 2.183 0.382812 0.367188
iteration 408: loss 2.142 0.382812 0.453125
iteration 409: loss 2.539 0.351562 0.367188
iteration 410: loss 1.767 0.273438 0.414062
iteration 411: loss 2.466 0.375000 0.343750
iteration 412: loss 2.299 0.320312 0.421875
iteration 413: loss 2.299 0.242188 0.437500
iteration 414: loss 3.262 0.289062 0.273438
iteration 415: loss 2.309 0.296875 0.437500
iteration 416: loss 3.675 0.406250 0.320312
iteration 417: loss 2.059 0.414062 0.359375
iteration 418: loss 2.313 0.273438 0.351562
iteration 419: loss 2.607 0.343750 0.304688
iteration 420: loss 2.593 0.351562 0.375000
iteration 421: loss 1.846 0.367188 0.429688
iteration 422: loss 2.460 0.312500 0.390625
iteration 423: loss 1.679 0.335938 0.460938
iteration 424: loss 1.870 0.296875 0.484375
iteration 425: loss 2.042 0.390625 0.500000
iteration 426: loss 1.857 0.351562 0.453125
iteration 427: loss 2.416 0.367188 0.382812
iteration 428: loss 2.386 0.335938 0.351562
iteration 429: loss 2.215 0.335938 0.421875
iteration 430: loss 2.637 0.375000 0.320312
iteration 431: loss 2.855 0.343750 0.382812
iteration 432: loss 2.203 0.265625 0.289062
iteration 433: loss 2.227 0.328125 0.320312
iteration 434: loss 2.089 0.375000 0.367188
iteration 435: loss 2.536 0.265625 0.335938
iteration 436: loss 2.060 0.382812 0.382812
iteration 437: loss 2.127 0.375000 0.296875
iteration 438: loss 1.954 0.320312 0.429688
iteration 439: loss 2.046 0.296875 0.398438
iteration 440: loss 2.501 0.328125 0.367188
iteration 441: loss 2.303 0.382812 0.421875
iteration 442: loss 1.729 0.398438 0.453125
iteration 443: loss 2.437 0.343750 0.390625
iteration 444: loss 2.412 0.359375 0.359375
iteration 445: loss 2.430 0.281250 0.367188
iteration 446: loss 2.431 0.312500 0.367188
iteration 447: loss 1.862 0.328125 0.523438
iteration 448: loss 1.904 0.304688 0.367188
iteration 449: loss 2.164 0.304688 0.382812
iteration 450: loss 2.301 0.304688 0.414062
iteration 451: loss 2.119 0.335938 0.367188
iteration 452: loss 2.299 0.335938 0.375000
iteration 453: loss 1.986 0.382812 0.390625
iteration 454: loss 1.802 0.335938 0.445312
iteration 455: loss 1.996 0.367188 0.375000
iteration 456: loss 2.289 0.437500 0.351562
iteration 457: loss 2.451 0.328125 0.453125
iteration 458: loss 2.242 0.335938 0.382812
iteration 459: loss 2.173 0.343750 0.398438
iteration 460: loss 2.501 0.343750 0.390625
iteration 461: loss 2.525 0.421875 0.390625
iteration 462: loss 2.111 0.335938 0.398438
iteration 463: loss 2.566 0.375000 0.351562
iteration 464: loss 2.681 0.250000 0.351562
iteration 465: loss 3.085 0.320312 0.359375
iteration 466: loss 2.183 0.296875 0.359375
iteration 467: loss 1.662 0.328125 0.382812
iteration 468: loss 2.131 0.312500 0.359375
iteration 469: loss 3.284 0.304688 0.351562
iteration 470: loss 2.715 0.351562 0.460938
iteration 471: loss 2.180 0.421875 0.359375
iteration 472: loss 2.126 0.320312 0.421875
iteration 473: loss 2.511 0.320312 0.445312
iteration 474: loss 2.116 0.351562 0.335938
iteration 475: loss 2.532 0.304688 0.382812
iteration 476: loss 2.127 0.328125 0.429688
iteration 477: loss 1.980 0.335938 0.351562
iteration 478: loss 2.040 0.328125 0.382812
iteration 479: loss 2.409 0.335938 0.359375
iteration 480: loss 2.076 0.281250 0.359375
iteration 481: loss 1.866 0.359375 0.390625
iteration 482: loss 2.504 0.335938 0.335938
iteration 483: loss 1.983 0.359375 0.390625
iteration 484: loss 2.146 0.312500 0.359375
iteration 485: loss 2.541 0.351562 0.437500
iteration 486: loss 2.894 0.289062 0.351562
iteration 487: loss 1.979 0.351562 0.390625
iteration 488: loss 2.388 0.312500 0.390625
iteration 489: loss 1.479 0.312500 0.437500
iteration 490: loss 2.029 0.210938 0.414062
iteration 491: loss 2.197 0.375000 0.351562
iteration 492: loss 2.369 0.351562 0.296875
iteration 493: loss 2.385 0.343750 0.343750
iteration 494: loss 2.052 0.375000 0.382812
iteration 495: loss 1.654 0.398438 0.453125
iteration 496: loss 2.260 0.289062 0.382812
iteration 497: loss 2.177 0.382812 0.375000
iteration 498: loss 2.856 0.343750 0.351562
iteration 499: loss 1.840 0.304688 0.429688
iteration 500: loss 2.110 0.343750 0.421875
iteration 501: loss 1.735 0.367188 0.484375
iteration 502: loss 2.770 0.351562 0.351562
iteration 503: loss 2.516 0.320312 0.390625
iteration 504: loss 1.769 0.257812 0.406250
iteration 505: loss 1.839 0.289062 0.390625
iteration 506: loss 1.786 0.289062 0.390625
iteration 507: loss 1.980 0.312500 0.343750
iteration 508: loss 2.025 0.382812 0.351562
iteration 509: loss 2.332 0.296875 0.375000
iteration 510: loss 1.834 0.343750 0.335938
iteration 511: loss 1.961 0.375000 0.367188
iteration 512: loss 1.988 0.312500 0.414062
iteration 513: loss 1.791 0.335938 0.500000
iteration 514: loss 2.353 0.359375 0.375000
iteration 515: loss 1.941 0.320312 0.406250
iteration 516: loss 1.972 0.265625 0.429688
iteration 517: loss 2.477 0.343750 0.398438
iteration 518: loss 1.633 0.335938 0.476562
iteration 519: loss 1.927 0.320312 0.406250
iteration 520: loss 2.127 0.343750 0.406250
iteration 521: loss 1.982 0.296875 0.453125
iteration 522: loss 1.994 0.335938 0.406250
iteration 523: loss 1.870 0.398438 0.406250
iteration 524: loss 2.284 0.335938 0.382812
iteration 525: loss 2.413 0.304688 0.359375
iteration 526: loss 2.188 0.265625 0.335938
iteration 527: loss 2.842 0.273438 0.320312
iteration 528: loss 2.117 0.414062 0.406250
iteration 529: loss 2.804 0.343750 0.367188
iteration 530: loss 2.214 0.320312 0.335938
iteration 531: loss 2.094 0.343750 0.335938
iteration 532: loss 2.566 0.359375 0.320312
iteration 533: loss 2.476 0.351562 0.382812
iteration 534: loss 2.400 0.320312 0.453125
iteration 535: loss 2.045 0.375000 0.382812
iteration 536: loss 1.830 0.312500 0.398438
iteration 537: loss 2.766 0.359375 0.421875
iteration 538: loss 2.221 0.335938 0.398438
iteration 539: loss 2.646 0.351562 0.382812
iteration 540: loss 1.987 0.304688 0.445312
iteration 541: loss 2.899 0.304688 0.312500
iteration 542: loss 2.228 0.375000 0.398438
iteration 543: loss 1.845 0.343750 0.351562
iteration 544: loss 1.648 0.335938 0.421875
iteration 545: loss 1.988 0.335938 0.335938
iteration 546: loss 2.113 0.304688 0.304688
iteration 547: loss 2.382 0.296875 0.414062
iteration 548: loss 2.015 0.242188 0.421875
iteration 549: loss 2.113 0.328125 0.382812
iteration 550: loss 2.046 0.406250 0.335938
iteration 551: loss 1.788 0.320312 0.398438
iteration 552: loss 3.104 0.359375 0.367188
iteration 553: loss 1.841 0.343750 0.398438
iteration 554: loss 2.144 0.289062 0.351562
iteration 555: loss 2.180 0.281250 0.328125
iteration 556: loss 1.639 0.328125 0.414062
iteration 557: loss 1.804 0.375000 0.359375
iteration 558: loss 2.139 0.257812 0.359375
iteration 559: loss 2.094 0.312500 0.351562
iteration 560: loss 1.731 0.351562 0.359375
iteration 561: loss 1.723 0.296875 0.437500
iteration 562: loss 2.403 0.273438 0.367188
iteration 563: loss 2.365 0.296875 0.343750
iteration 564: loss 2.005 0.335938 0.375000
iteration 565: loss 1.577 0.312500 0.445312
iteration 566: loss 1.753 0.320312 0.476562
iteration 567: loss 2.101 0.359375 0.390625
iteration 568: loss 1.789 0.304688 0.476562
iteration 569: loss 2.105 0.304688 0.421875
iteration 570: loss 1.927 0.312500 0.382812
iteration 571: loss 1.943 0.390625 0.468750
iteration 572: loss 1.876 0.265625 0.414062
iteration 573: loss 2.085 0.304688 0.437500
iteration 574: loss 1.712 0.359375 0.390625
iteration 575: loss 2.136 0.289062 0.343750
iteration 576: loss 1.723 0.328125 0.437500
iteration 577: loss 2.086 0.281250 0.367188
iteration 578: loss 1.824 0.281250 0.351562
iteration 579: loss 2.329 0.343750 0.343750
iteration 580: loss 2.274 0.359375 0.421875
iteration 581: loss 1.753 0.296875 0.453125
iteration 582: loss 2.179 0.312500 0.437500
iteration 583: loss 2.504 0.382812 0.304688
iteration 584: loss 2.069 0.382812 0.406250
iteration 585: loss 2.085 0.304688 0.460938
iteration 586: loss 1.828 0.437500 0.453125
iteration 587: loss 1.919 0.335938 0.437500
iteration 588: loss 2.612 0.437500 0.328125
iteration 589: loss 1.994 0.312500 0.421875
iteration 590: loss 2.267 0.359375 0.406250
iteration 591: loss 2.202 0.367188 0.421875
iteration 592: loss 2.123 0.390625 0.304688
iteration 593: loss 1.845 0.312500 0.398438
iteration 594: loss 1.678 0.343750 0.390625
iteration 595: loss 2.188 0.289062 0.343750
iteration 596: loss 1.595 0.265625 0.390625
iteration 597: loss 2.350 0.375000 0.375000
iteration 598: loss 2.589 0.367188 0.406250
iteration 599: loss 1.992 0.296875 0.375000
iteration 600: loss 1.797 0.398438 0.390625
iteration 601: loss 2.044 0.312500 0.406250
iteration 602: loss 1.965 0.335938 0.359375
iteration 603: loss 1.672 0.289062 0.429688
iteration 604: loss 2.202 0.320312 0.359375
iteration 605: loss 2.141 0.312500 0.335938
iteration 606: loss 2.983 0.320312 0.281250
iteration 607: loss 1.734 0.320312 0.429688
iteration 608: loss 2.407 0.351562 0.367188
iteration 609: loss 2.206 0.234375 0.375000
iteration 610: loss 2.350 0.289062 0.335938
iteration 611: loss 2.520 0.210938 0.304688
iteration 612: loss 2.308 0.273438 0.328125
iteration 613: loss 2.365 0.351562 0.390625
iteration 614: loss 2.130 0.320312 0.359375
iteration 615: loss 1.703 0.265625 0.367188
iteration 616: loss 2.119 0.398438 0.367188
iteration 617: loss 1.789 0.351562 0.382812
iteration 618: loss 2.031 0.296875 0.406250
iteration 619: loss 2.270 0.281250 0.359375
iteration 620: loss 1.624 0.367188 0.500000
iteration 621: loss 2.395 0.296875 0.375000
iteration 622: loss 2.435 0.312500 0.335938
iteration 623: loss 1.865 0.296875 0.445312
iteration 624: loss 1.258 0.343750 0.500000
iteration 625: loss 2.297 0.273438 0.382812
iteration 626: loss 2.307 0.320312 0.375000
iteration 627: loss 2.488 0.203125 0.429688
iteration 628: loss 2.178 0.304688 0.460938
iteration 629: loss 2.219 0.351562 0.414062
iteration 630: loss 1.810 0.398438 0.445312
iteration 631: loss 2.420 0.335938 0.453125
iteration 632: loss 1.214 0.406250 0.484375
iteration 633: loss 2.410 0.359375 0.359375
iteration 634: loss 1.936 0.351562 0.343750
iteration 635: loss 1.909 0.296875 0.390625
iteration 636: loss 2.326 0.250000 0.320312
iteration 637: loss 1.881 0.312500 0.390625
iteration 638: loss 1.918 0.304688 0.437500
iteration 639: loss 1.848 0.382812 0.429688
iteration 640: loss 1.740 0.328125 0.476562
iteration 641: loss 2.256 0.265625 0.382812
iteration 642: loss 1.491 0.328125 0.445312
iteration 643: loss 2.271 0.289062 0.328125
iteration 644: loss 1.845 0.359375 0.429688
iteration 645: loss 2.796 0.351562 0.390625
iteration 646: loss 2.135 0.296875 0.335938
iteration 647: loss 1.685 0.281250 0.460938
iteration 648: loss 1.634 0.304688 0.476562
iteration 649: loss 1.861 0.328125 0.359375
iteration 650: loss 1.983 0.367188 0.414062
iteration 651: loss 1.801 0.328125 0.406250
iteration 652: loss 2.142 0.390625 0.390625
iteration 653: loss 1.917 0.296875 0.421875
iteration 654: loss 2.193 0.296875 0.304688
iteration 655: loss 2.291 0.281250 0.375000
iteration 656: loss 2.108 0.281250 0.367188
iteration 657: loss 1.817 0.351562 0.414062
iteration 658: loss 2.057 0.351562 0.312500
iteration 659: loss 1.880 0.320312 0.421875
iteration 660: loss 1.932 0.250000 0.421875
iteration 661: loss 1.650 0.289062 0.445312
iteration 662: loss 2.264 0.320312 0.382812
iteration 663: loss 1.435 0.289062 0.484375
iteration 664: loss 2.107 0.273438 0.382812
iteration 665: loss 2.033 0.382812 0.351562
iteration 666: loss 1.740 0.382812 0.382812
iteration 667: loss 1.673 0.265625 0.335938
iteration 668: loss 2.157 0.281250 0.390625
iteration 669: loss 1.974 0.304688 0.390625
iteration 670: loss 2.323 0.328125 0.289062
iteration 671: loss 2.016 0.351562 0.390625
iteration 672: loss 1.731 0.289062 0.367188
iteration 673: loss 2.006 0.343750 0.414062
iteration 674: loss 2.697 0.335938 0.359375
iteration 675: loss 1.993 0.312500 0.429688
iteration 676: loss 2.516 0.351562 0.328125
iteration 677: loss 1.695 0.257812 0.375000
iteration 678: loss 2.244 0.359375 0.390625
iteration 679: loss 1.494 0.320312 0.453125
iteration 680: loss 2.018 0.320312 0.421875
iteration 681: loss 2.182 0.320312 0.343750
iteration 682: loss 1.724 0.273438 0.382812
iteration 683: loss 2.071 0.289062 0.414062
iteration 684: loss 1.996 0.320312 0.437500
iteration 685: loss 1.815 0.289062 0.406250
iteration 686: loss 1.945 0.359375 0.398438
iteration 687: loss 1.791 0.382812 0.367188
iteration 688: loss 2.224 0.312500 0.359375
iteration 689: loss 1.991 0.375000 0.429688
iteration 690: loss 2.005 0.320312 0.453125
iteration 691: loss 2.164 0.359375 0.367188
iteration 692: loss 1.941 0.382812 0.406250
iteration 693: loss 1.876 0.296875 0.414062
iteration 694: loss 2.327 0.304688 0.343750
iteration 695: loss 2.822 0.312500 0.351562
iteration 696: loss 1.897 0.328125 0.351562
iteration 697: loss 2.133 0.367188 0.359375
iteration 698: loss 1.698 0.234375 0.414062
iteration 699: loss 2.226 0.304688 0.328125
iteration 700: loss 1.778 0.296875 0.367188
iteration 701: loss 1.706 0.273438 0.406250
iteration 702: loss 1.681 0.328125 0.414062
iteration 703: loss 1.479 0.265625 0.476562
iteration 704: loss 2.233 0.304688 0.398438
iteration 705: loss 1.953 0.335938 0.460938
iteration 706: loss 2.098 0.343750 0.398438
iteration 707: loss 2.896 0.328125 0.406250
iteration 708: loss 1.297 0.296875 0.523438
iteration 709: loss 2.208 0.320312 0.414062
iteration 710: loss 1.843 0.304688 0.382812
iteration 711: loss 1.727 0.265625 0.343750
iteration 712: loss 2.229 0.257812 0.367188
iteration 713: loss 1.853 0.335938 0.406250
iteration 714: loss 1.927 0.335938 0.367188
iteration 715: loss 2.258 0.343750 0.312500
iteration 716: loss 1.572 0.281250 0.359375
iteration 717: loss 1.553 0.421875 0.414062
iteration 718: loss 2.330 0.359375 0.296875
iteration 719: loss 1.813 0.382812 0.398438
iteration 720: loss 1.801 0.343750 0.390625
iteration 721: loss 1.880 0.351562 0.382812
iteration 722: loss 1.670 0.359375 0.359375
iteration 723: loss 2.002 0.351562 0.414062
iteration 724: loss 1.696 0.304688 0.500000
iteration 725: loss 1.743 0.281250 0.421875
iteration 726: loss 1.717 0.367188 0.468750
iteration 727: loss 1.774 0.343750 0.398438
iteration 728: loss 1.572 0.328125 0.429688
iteration 729: loss 2.247 0.312500 0.359375
iteration 730: loss 1.643 0.312500 0.445312
iteration 731: loss 1.877 0.421875 0.437500
iteration 732: loss 1.694 0.414062 0.343750
iteration 733: loss 2.188 0.437500 0.421875
iteration 734: loss 1.599 0.250000 0.453125
iteration 735: loss 2.115 0.304688 0.437500
iteration 736: loss 1.955 0.273438 0.359375
iteration 737: loss 1.615 0.328125 0.421875
iteration 738: loss 1.876 0.359375 0.414062
iteration 739: loss 1.915 0.351562 0.375000
iteration 740: loss 2.059 0.320312 0.406250
iteration 741: loss 1.672 0.328125 0.460938
iteration 742: loss 2.136 0.296875 0.445312
iteration 743: loss 1.776 0.320312 0.429688
iteration 744: loss 1.749 0.328125 0.437500
iteration 745: loss 1.418 0.328125 0.476562
iteration 746: loss 1.619 0.398438 0.437500
iteration 747: loss 1.759 0.367188 0.453125
iteration 748: loss 2.547 0.398438 0.445312
iteration 749: loss 1.650 0.359375 0.429688
iteration 750: loss 2.240 0.351562 0.398438
iteration 751: loss 1.658 0.375000 0.476562
iteration 752: loss 1.889 0.312500 0.421875
iteration 753: loss 1.900 0.367188 0.406250
iteration 754: loss 1.939 0.359375 0.390625
iteration 755: loss 1.732 0.289062 0.414062
iteration 756: loss 1.893 0.312500 0.382812
iteration 757: loss 2.303 0.335938 0.359375
iteration 758: loss 2.708 0.289062 0.289062
iteration 759: loss 1.816 0.312500 0.468750
iteration 760: loss 2.087 0.320312 0.382812
iteration 761: loss 2.428 0.312500 0.320312
iteration 762: loss 1.773 0.187500 0.343750
iteration 763: loss 2.331 0.304688 0.429688
iteration 764: loss 1.956 0.320312 0.382812
iteration 765: loss 2.313 0.351562 0.273438
iteration 766: loss 2.219 0.289062 0.304688
iteration 767: loss 1.836 0.312500 0.406250
iteration 768: loss 2.286 0.343750 0.390625
iteration 769: loss 1.794 0.414062 0.460938
iteration 770: loss 2.273 0.312500 0.375000
iteration 771: loss 1.636 0.421875 0.515625
iteration 772: loss 1.925 0.398438 0.453125
iteration 773: loss 1.871 0.265625 0.421875
iteration 774: loss 1.885 0.351562 0.437500
iteration 775: loss 1.721 0.406250 0.421875
iteration 776: loss 1.602 0.328125 0.390625
iteration 777: loss 1.953 0.351562 0.390625
iteration 778: loss 2.081 0.328125 0.406250
iteration 779: loss 1.775 0.351562 0.398438
iteration 780: loss 1.740 0.351562 0.375000
iteration 781: loss 1.638 0.304688 0.453125
iteration 782: loss 1.677 0.351562 0.421875
iteration 783: loss 2.576 0.343750 0.320312
iteration 784: loss 1.569 0.343750 0.414062
iteration 785: loss 1.712 0.312500 0.382812
iteration 786: loss 1.864 0.320312 0.359375
iteration 787: loss 2.217 0.320312 0.375000
iteration 788: loss 1.787 0.351562 0.460938
iteration 789: loss 2.145 0.312500 0.437500
iteration 790: loss 1.761 0.398438 0.414062
iteration 791: loss 2.014 0.335938 0.453125
iteration 792: loss 2.104 0.406250 0.382812
iteration 793: loss 1.712 0.398438 0.429688
iteration 794: loss 1.424 0.265625 0.468750
iteration 795: loss 2.178 0.375000 0.398438
iteration 796: loss 1.647 0.335938 0.390625
iteration 797: loss 1.497 0.406250 0.453125
iteration 798: loss 2.088 0.257812 0.406250
iteration 799: loss 2.120 0.375000 0.335938
iteration 800: loss 1.383 0.320312 0.484375
iteration 801: loss 1.870 0.328125 0.351562
iteration 802: loss 1.685 0.460938 0.406250
iteration 803: loss 2.274 0.335938 0.445312
iteration 804: loss 2.093 0.296875 0.382812
iteration 805: loss 2.540 0.273438 0.367188
iteration 806: loss 1.700 0.226562 0.437500
iteration 807: loss 1.755 0.312500 0.375000
iteration 808: loss 2.100 0.320312 0.320312
iteration 809: loss 1.977 0.320312 0.382812
iteration 810: loss 1.697 0.289062 0.414062
iteration 811: loss 1.851 0.312500 0.351562
iteration 812: loss 1.675 0.320312 0.335938
iteration 813: loss 2.275 0.328125 0.390625
iteration 814: loss 1.527 0.398438 0.414062
iteration 815: loss 1.793 0.304688 0.375000
iteration 816: loss 1.531 0.281250 0.382812
iteration 817: loss 1.926 0.328125 0.398438
iteration 818: loss 1.948 0.320312 0.382812
iteration 819: loss 1.653 0.359375 0.414062
iteration 820: loss 2.309 0.296875 0.320312
iteration 821: loss 1.865 0.375000 0.390625
iteration 822: loss 1.691 0.312500 0.414062
iteration 823: loss 1.591 0.328125 0.429688
iteration 824: loss 1.449 0.375000 0.468750
iteration 825: loss 1.551 0.367188 0.367188
iteration 826: loss 2.278 0.320312 0.265625
iteration 827: loss 1.532 0.343750 0.320312
iteration 828: loss 1.779 0.289062 0.414062
iteration 829: loss 1.718 0.375000 0.406250
iteration 830: loss 1.766 0.304688 0.367188
iteration 831: loss 1.341 0.296875 0.492188
iteration 832: loss 2.005 0.328125 0.375000
iteration 833: loss 1.926 0.328125 0.445312
iteration 834: loss 1.542 0.406250 0.445312
iteration 835: loss 1.538 0.335938 0.414062
iteration 836: loss 1.836 0.406250 0.437500
iteration 837: loss 1.908 0.390625 0.406250
iteration 838: loss 1.991 0.367188 0.414062
iteration 839: loss 1.833 0.226562 0.382812
iteration 840: loss 1.429 0.343750 0.492188
iteration 841: loss 1.281 0.312500 0.406250
iteration 842: loss 1.655 0.382812 0.414062
iteration 843: loss 1.691 0.281250 0.343750
iteration 844: loss 1.587 0.382812 0.437500
iteration 845: loss 1.517 0.328125 0.398438
iteration 846: loss 1.492 0.250000 0.382812
iteration 847: loss 1.809 0.375000 0.460938
iteration 848: loss 1.721 0.265625 0.382812
iteration 849: loss 2.168 0.335938 0.421875
iteration 850: loss 1.936 0.398438 0.304688
iteration 851: loss 1.830 0.335938 0.375000
iteration 852: loss 1.606 0.328125 0.367188
iteration 853: loss 2.004 0.273438 0.437500
iteration 854: loss 1.460 0.367188 0.414062
iteration 855: loss 1.372 0.335938 0.437500
iteration 856: loss 1.787 0.343750 0.375000
iteration 857: loss 1.659 0.265625 0.445312
iteration 858: loss 1.446 0.281250 0.492188
iteration 859: loss 2.040 0.343750 0.367188
iteration 860: loss 1.456 0.320312 0.476562
iteration 861: loss 2.133 0.351562 0.375000
iteration 862: loss 1.568 0.304688 0.460938
iteration 863: loss 1.835 0.343750 0.382812
iteration 864: loss 1.906 0.320312 0.382812
iteration 865: loss 1.855 0.367188 0.406250
iteration 866: loss 1.937 0.304688 0.398438
iteration 867: loss 1.589 0.343750 0.382812
iteration 868: loss 1.313 0.320312 0.460938
iteration 869: loss 1.194 0.328125 0.507812
iteration 870: loss 1.540 0.414062 0.445312
iteration 871: loss 1.795 0.265625 0.406250
iteration 872: loss 1.367 0.367188 0.476562
iteration 873: loss 2.051 0.390625 0.367188
iteration 874: loss 1.664 0.281250 0.375000
iteration 875: loss 2.253 0.273438 0.335938
iteration 876: loss 1.482 0.343750 0.367188
iteration 877: loss 1.494 0.382812 0.398438
iteration 878: loss 1.876 0.320312 0.375000
iteration 879: loss 1.687 0.421875 0.460938
iteration 880: loss 1.777 0.351562 0.460938
iteration 881: loss 1.758 0.367188 0.437500
iteration 882: loss 1.743 0.390625 0.429688
iteration 883: loss 1.772 0.312500 0.421875
iteration 884: loss 1.902 0.390625 0.382812
iteration 885: loss 1.768 0.312500 0.437500
iteration 886: loss 1.525 0.335938 0.468750
iteration 887: loss 1.916 0.382812 0.328125
iteration 888: loss 1.653 0.375000 0.390625
iteration 889: loss 2.075 0.335938 0.343750
iteration 890: loss 1.767 0.375000 0.414062
iteration 891: loss 1.698 0.320312 0.367188
iteration 892: loss 1.773 0.328125 0.359375
iteration 893: loss 1.717 0.289062 0.406250
iteration 894: loss 1.834 0.312500 0.375000
iteration 895: loss 1.784 0.335938 0.390625
iteration 896: loss 1.999 0.281250 0.414062
iteration 897: loss 1.817 0.382812 0.406250
iteration 898: loss 1.520 0.257812 0.453125
iteration 899: loss 1.791 0.335938 0.375000
iteration 900: loss 1.796 0.351562 0.382812
iteration 901: loss 1.806 0.351562 0.445312
iteration 902: loss 1.361 0.343750 0.484375
iteration 903: loss 1.631 0.351562 0.468750
iteration 904: loss 1.553 0.343750 0.445312
iteration 905: loss 1.820 0.289062 0.390625
iteration 906: loss 1.734 0.359375 0.359375
iteration 907: loss 1.718 0.367188 0.367188
iteration 908: loss 1.472 0.320312 0.453125
iteration 909: loss 1.396 0.343750 0.375000
iteration 910: loss 1.560 0.335938 0.453125
iteration 911: loss 1.776 0.296875 0.421875
iteration 912: loss 1.827 0.367188 0.507812
iteration 913: loss 1.697 0.320312 0.414062
iteration 914: loss 1.591 0.367188 0.515625
iteration 915: loss 1.950 0.367188 0.414062
iteration 916: loss 1.638 0.367188 0.406250
iteration 917: loss 1.741 0.304688 0.429688
iteration 918: loss 1.482 0.390625 0.453125
iteration 919: loss 1.106 0.320312 0.429688
iteration 920: loss 1.785 0.367188 0.335938
iteration 921: loss 2.218 0.312500 0.382812
iteration 922: loss 1.554 0.281250 0.382812
iteration 923: loss 1.647 0.320312 0.429688
iteration 924: loss 1.727 0.289062 0.414062
iteration 925: loss 2.077 0.281250 0.390625
iteration 926: loss 1.319 0.390625 0.304688
iteration 927: loss 1.327 0.367188 0.484375
iteration 928: loss 1.508 0.367188 0.500000
iteration 929: loss 1.672 0.343750 0.421875
iteration 930: loss 1.954 0.351562 0.429688
iteration 931: loss 1.630 0.265625 0.382812
iteration 932: loss 2.173 0.273438 0.289062
iteration 933: loss 2.360 0.312500 0.351562
iteration 934: loss 1.681 0.273438 0.390625
iteration 935: loss 1.768 0.312500 0.375000
iteration 936: loss 1.652 0.398438 0.351562
iteration 937: loss 1.862 0.320312 0.390625
iteration 938: loss 1.662 0.265625 0.398438
iteration 939: loss 1.795 0.320312 0.359375
iteration 940: loss 1.526 0.375000 0.390625
iteration 941: loss 1.537 0.351562 0.445312
iteration 942: loss 1.637 0.351562 0.437500
iteration 943: loss 1.749 0.367188 0.390625
iteration 944: loss 1.816 0.335938 0.421875
iteration 945: loss 1.926 0.390625 0.382812
iteration 946: loss 1.550 0.320312 0.429688
iteration 947: loss 1.674 0.296875 0.429688
iteration 948: loss 2.027 0.382812 0.437500
iteration 949: loss 1.312 0.367188 0.507812
iteration 950: loss 1.156 0.382812 0.460938
iteration 951: loss 1.295 0.328125 0.476562
iteration 952: loss 1.677 0.390625 0.367188
iteration 953: loss 1.440 0.281250 0.390625
iteration 954: loss 1.549 0.390625 0.468750
iteration 955: loss 1.905 0.375000 0.359375
iteration 956: loss 1.977 0.289062 0.375000
iteration 957: loss 1.533 0.328125 0.453125
iteration 958: loss 1.867 0.304688 0.398438
iteration 959: loss 1.578 0.320312 0.445312
iteration 960: loss 1.779 0.367188 0.359375
iteration 961: loss 1.384 0.296875 0.421875
iteration 962: loss 1.552 0.281250 0.351562
iteration 963: loss 1.538 0.359375 0.437500
iteration 964: loss 1.671 0.351562 0.507812
iteration 965: loss 2.294 0.289062 0.406250
iteration 966: loss 1.886 0.351562 0.398438
iteration 967: loss 1.739 0.312500 0.382812
iteration 968: loss 1.674 0.304688 0.351562
iteration 969: loss 1.229 0.296875 0.468750
iteration 970: loss 1.581 0.312500 0.429688
iteration 971: loss 1.883 0.390625 0.375000
iteration 972: loss 1.999 0.320312 0.406250
iteration 973: loss 2.060 0.265625 0.351562
iteration 974: loss 1.653 0.351562 0.414062
iteration 975: loss 1.195 0.382812 0.421875
iteration 976: loss 1.507 0.281250 0.382812
iteration 977: loss 1.816 0.289062 0.398438
iteration 978: loss 1.805 0.304688 0.375000
iteration 979: loss 1.518 0.273438 0.343750
iteration 980: loss 1.405 0.335938 0.414062
iteration 981: loss 2.173 0.382812 0.421875
iteration 982: loss 1.431 0.367188 0.445312
iteration 983: loss 1.971 0.265625 0.460938
iteration 984: loss 2.263 0.328125 0.429688
iteration 985: loss 2.348 0.359375 0.351562
iteration 986: loss 1.582 0.343750 0.500000
iteration 987: loss 1.758 0.359375 0.398438
iteration 988: loss 1.929 0.328125 0.492188
iteration 989: loss 1.712 0.312500 0.421875
iteration 990: loss 1.805 0.304688 0.398438
iteration 991: loss 1.878 0.367188 0.398438
iteration 992: loss 1.876 0.320312 0.406250
iteration 993: loss 1.627 0.226562 0.398438
iteration 994: loss 1.705 0.289062 0.414062
iteration 995: loss 1.541 0.273438 0.437500
iteration 996: loss 1.713 0.328125 0.421875
iteration 997: loss 1.894 0.296875 0.359375
iteration 998: loss 1.773 0.335938 0.343750
iteration 999: loss 1.605 0.335938 0.398438
epoch 1: training: 0.437500 validation: 0.179688
iteration 0: loss 1.763 0.359375 0.445312
iteration 1: loss 1.566 0.382812 0.492188
iteration 2: loss 1.963 0.328125 0.390625
iteration 3: loss 2.036 0.359375 0.328125
iteration 4: loss 2.226 0.335938 0.335938
iteration 5: loss 1.718 0.265625 0.367188
iteration 6: loss 2.279 0.304688 0.367188
iteration 7: loss 1.710 0.296875 0.375000
iteration 8: loss 1.426 0.312500 0.421875
iteration 9: loss 2.215 0.265625 0.343750
iteration 10: loss 1.945 0.273438 0.359375
iteration 11: loss 2.021 0.312500 0.312500
iteration 12: loss 1.816 0.289062 0.382812
iteration 13: loss 1.572 0.390625 0.453125
iteration 14: loss 1.770 0.367188 0.421875
iteration 15: loss 1.635 0.398438 0.414062
iteration 16: loss 1.670 0.281250 0.476562
iteration 17: loss 1.379 0.335938 0.484375
iteration 18: loss 2.160 0.312500 0.398438
iteration 19: loss 1.651 0.343750 0.429688
iteration 20: loss 2.132 0.351562 0.320312
iteration 21: loss 1.454 0.390625 0.421875
iteration 22: loss 1.728 0.343750 0.382812
iteration 23: loss 1.774 0.351562 0.367188
iteration 24: loss 1.664 0.250000 0.421875
iteration 25: loss 1.690 0.242188 0.375000
iteration 26: loss 1.697 0.304688 0.421875
iteration 27: loss 2.007 0.382812 0.335938
iteration 28: loss 2.061 0.289062 0.359375
iteration 29: loss 2.643 0.328125 0.359375
iteration 30: loss 1.759 0.320312 0.390625
iteration 31: loss 2.016 0.359375 0.437500
iteration 32: loss 2.019 0.375000 0.445312
iteration 33: loss 1.370 0.312500 0.468750
iteration 34: loss 1.526 0.296875 0.429688
iteration 35: loss 1.341 0.359375 0.453125
iteration 36: loss 1.889 0.351562 0.390625
iteration 37: loss 1.638 0.375000 0.445312
iteration 38: loss 2.321 0.281250 0.406250
iteration 39: loss 1.748 0.343750 0.351562
iteration 40: loss 1.973 0.390625 0.351562
iteration 41: loss 1.649 0.257812 0.343750
iteration 42: loss 1.559 0.359375 0.414062
iteration 43: loss 1.577 0.375000 0.398438
iteration 44: loss 1.829 0.328125 0.375000
iteration 45: loss 1.904 0.343750 0.406250
iteration 46: loss 1.303 0.390625 0.468750
iteration 47: loss 1.377 0.359375 0.539062
iteration 48: loss 1.875 0.359375 0.429688
iteration 49: loss 1.523 0.359375 0.429688
iteration 50: loss 1.700 0.234375 0.343750
iteration 51: loss 1.589 0.320312 0.437500
iteration 52: loss 2.072 0.390625 0.335938
iteration 53: loss 1.397 0.312500 0.492188
iteration 54: loss 1.807 0.273438 0.328125
iteration 55: loss 1.749 0.312500 0.375000
iteration 56: loss 1.624 0.312500 0.468750
iteration 57: loss 1.604 0.304688 0.445312
iteration 58: loss 1.632 0.312500 0.453125
iteration 59: loss 1.529 0.335938 0.406250
iteration 60: loss 1.205 0.328125 0.507812
iteration 61: loss 1.613 0.328125 0.398438
iteration 62: loss 2.355 0.289062 0.367188
iteration 63: loss 1.523 0.367188 0.445312
iteration 64: loss 1.433 0.304688 0.429688
iteration 65: loss 1.378 0.304688 0.453125
iteration 66: loss 1.418 0.359375 0.414062
iteration 67: loss 1.869 0.328125 0.390625
iteration 68: loss 2.247 0.296875 0.273438
iteration 69: loss 1.587 0.335938 0.414062
iteration 70: loss 1.196 0.304688 0.421875
iteration 71: loss 1.540 0.289062 0.437500
iteration 72: loss 1.688 0.320312 0.429688
iteration 73: loss 1.819 0.335938 0.398438
iteration 74: loss 1.492 0.328125 0.460938
iteration 75: loss 1.891 0.335938 0.375000
iteration 76: loss 1.828 0.335938 0.421875
iteration 77: loss 1.470 0.335938 0.507812
iteration 78: loss 1.566 0.375000 0.390625
iteration 79: loss 1.645 0.320312 0.460938
iteration 80: loss 1.577 0.289062 0.437500
iteration 81: loss 1.801 0.312500 0.453125
iteration 82: loss 1.624 0.351562 0.398438
iteration 83: loss 1.353 0.304688 0.445312
iteration 84: loss 1.463 0.289062 0.429688
iteration 85: loss 1.577 0.304688 0.437500
iteration 86: loss 1.136 0.328125 0.492188
iteration 87: loss 1.612 0.273438 0.281250
iteration 88: loss 1.820 0.234375 0.359375
iteration 89: loss 2.138 0.250000 0.406250
iteration 90: loss 1.978 0.367188 0.359375
iteration 91: loss 2.120 0.289062 0.304688
iteration 92: loss 2.121 0.296875 0.390625
iteration 93: loss 1.734 0.304688 0.351562
iteration 94: loss 2.278 0.335938 0.437500
iteration 95: loss 1.835 0.304688 0.367188
iteration 96: loss 1.602 0.359375 0.460938
iteration 97: loss 1.474 0.335938 0.476562
iteration 98: loss 1.883 0.375000 0.437500
iteration 99: loss 1.699 0.367188 0.468750
iteration 100: loss 1.442 0.406250 0.414062
iteration 101: loss 1.249 0.359375 0.437500
iteration 102: loss 1.575 0.367188 0.398438
iteration 103: loss 1.843 0.335938 0.359375
iteration 104: loss 1.882 0.328125 0.421875
iteration 105: loss 1.970 0.312500 0.382812
iteration 106: loss 1.997 0.320312 0.343750
iteration 107: loss 1.406 0.320312 0.414062
iteration 108: loss 1.783 0.296875 0.328125
iteration 109: loss 1.508 0.335938 0.375000
iteration 110: loss 1.951 0.265625 0.304688
iteration 111: loss 1.479 0.273438 0.359375
iteration 112: loss 1.682 0.296875 0.421875
iteration 113: loss 1.514 0.304688 0.398438
iteration 114: loss 1.664 0.304688 0.398438
iteration 115: loss 1.444 0.375000 0.414062
iteration 116: loss 1.865 0.320312 0.398438
iteration 117: loss 1.898 0.359375 0.453125
iteration 118: loss 1.806 0.257812 0.414062
iteration 119: loss 1.554 0.265625 0.398438
iteration 120: loss 1.433 0.281250 0.453125
iteration 121: loss 1.699 0.335938 0.375000
iteration 122: loss 1.712 0.328125 0.492188
iteration 123: loss 1.681 0.343750 0.421875
iteration 124: loss 1.637 0.343750 0.453125
iteration 125: loss 1.309 0.359375 0.437500
iteration 126: loss 1.766 0.351562 0.343750
iteration 127: loss 1.331 0.359375 0.437500
iteration 128: loss 1.465 0.335938 0.328125
iteration 129: loss 1.440 0.281250 0.406250
iteration 130: loss 1.760 0.359375 0.414062
iteration 131: loss 1.524 0.359375 0.390625
iteration 132: loss 1.413 0.343750 0.421875
iteration 133: loss 1.331 0.320312 0.414062
iteration 134: loss 1.254 0.320312 0.429688
iteration 135: loss 1.698 0.367188 0.390625
iteration 136: loss 1.577 0.328125 0.484375
iteration 137: loss 2.215 0.359375 0.367188
iteration 138: loss 1.502 0.359375 0.406250
iteration 139: loss 1.855 0.367188 0.445312
iteration 140: loss 1.753 0.359375 0.445312
iteration 141: loss 1.700 0.351562 0.445312
iteration 142: loss 1.472 0.375000 0.421875
iteration 143: loss 1.896 0.296875 0.390625
iteration 144: loss 1.775 0.375000 0.390625
iteration 145: loss 0.995 0.296875 0.609375
iteration 146: loss 1.633 0.367188 0.476562
iteration 147: loss 1.639 0.312500 0.398438
iteration 148: loss 1.788 0.328125 0.453125
iteration 149: loss 1.529 0.328125 0.343750
iteration 150: loss 1.896 0.359375 0.390625
iteration 151: loss 1.638 0.335938 0.398438
iteration 152: loss 2.095 0.312500 0.375000
iteration 153: loss 1.326 0.273438 0.414062
iteration 154: loss 1.621 0.304688 0.437500
iteration 155: loss 1.460 0.335938 0.453125
iteration 156: loss 1.518 0.296875 0.382812
iteration 157: loss 1.389 0.265625 0.367188
iteration 158: loss 1.282 0.351562 0.523438
iteration 159: loss 1.708 0.375000 0.375000
iteration 160: loss 1.492 0.335938 0.414062
iteration 161: loss 1.672 0.375000 0.421875
iteration 162: loss 1.378 0.390625 0.476562
iteration 163: loss 1.432 0.421875 0.429688
iteration 164: loss 2.304 0.328125 0.445312
iteration 165: loss 2.087 0.257812 0.406250
iteration 166: loss 1.428 0.242188 0.437500
iteration 167: loss 1.567 0.281250 0.367188
iteration 168: loss 1.268 0.359375 0.312500
iteration 169: loss 1.501 0.304688 0.289062
iteration 170: loss 1.306 0.343750 0.335938
iteration 171: loss 1.391 0.351562 0.429688
iteration 172: loss 1.333 0.343750 0.406250
iteration 173: loss 1.614 0.312500 0.398438
iteration 174: loss 1.707 0.429688 0.398438
iteration 175: loss 1.613 0.398438 0.484375
iteration 176: loss 1.557 0.398438 0.398438
iteration 177: loss 1.574 0.375000 0.414062
iteration 178: loss 2.012 0.359375 0.367188
iteration 179: loss 1.417 0.382812 0.390625
iteration 180: loss 1.376 0.343750 0.492188
iteration 181: loss 1.538 0.234375 0.453125
iteration 182: loss 1.742 0.351562 0.476562
iteration 183: loss 1.222 0.289062 0.492188
iteration 184: loss 1.567 0.328125 0.500000
iteration 185: loss 1.470 0.257812 0.460938
iteration 186: loss 1.477 0.421875 0.484375
iteration 187: loss 1.728 0.273438 0.343750
iteration 188: loss 1.561 0.312500 0.437500
iteration 189: loss 1.634 0.343750 0.414062
iteration 190: loss 1.666 0.375000 0.406250
iteration 191: loss 2.251 0.289062 0.273438
iteration 192: loss 1.923 0.304688 0.273438
iteration 193: loss 2.041 0.320312 0.375000
iteration 194: loss 1.495 0.250000 0.453125
iteration 195: loss 1.886 0.312500 0.359375
iteration 196: loss 1.866 0.351562 0.367188
iteration 197: loss 1.401 0.265625 0.421875
iteration 198: loss 1.517 0.335938 0.492188
iteration 199: loss 1.683 0.257812 0.445312
iteration 200: loss 2.051 0.335938 0.453125
iteration 201: loss 1.691 0.320312 0.414062
iteration 202: loss 1.604 0.390625 0.390625
iteration 203: loss 1.456 0.250000 0.468750
iteration 204: loss 1.337 0.296875 0.468750
iteration 205: loss 1.503 0.304688 0.421875
iteration 206: loss 1.818 0.367188 0.398438
iteration 207: loss 1.464 0.335938 0.437500
iteration 208: loss 1.452 0.343750 0.414062
iteration 209: loss 1.472 0.312500 0.398438
iteration 210: loss 1.783 0.406250 0.335938
iteration 211: loss 1.692 0.335938 0.351562
iteration 212: loss 1.674 0.343750 0.375000
iteration 213: loss 1.576 0.250000 0.382812
iteration 214: loss 1.396 0.335938 0.414062
iteration 215: loss 1.378 0.367188 0.382812
iteration 216: loss 1.556 0.359375 0.429688
iteration 217: loss 1.853 0.335938 0.429688
iteration 218: loss 1.394 0.335938 0.453125
iteration 219: loss 1.546 0.421875 0.437500
iteration 220: loss 1.683 0.257812 0.414062
iteration 221: loss 1.614 0.304688 0.398438
iteration 222: loss 1.392 0.351562 0.429688
iteration 223: loss 1.713 0.320312 0.406250
iteration 224: loss 1.521 0.335938 0.390625
iteration 225: loss 1.410 0.335938 0.460938
iteration 226: loss 1.530 0.312500 0.468750
iteration 227: loss 1.381 0.382812 0.375000
iteration 228: loss 1.096 0.242188 0.453125
iteration 229: loss 1.686 0.312500 0.390625
iteration 230: loss 1.932 0.289062 0.429688
iteration 231: loss 1.344 0.335938 0.460938
iteration 232: loss 1.586 0.367188 0.398438
iteration 233: loss 1.358 0.289062 0.437500
iteration 234: loss 1.810 0.312500 0.343750
iteration 235: loss 1.546 0.234375 0.421875
iteration 236: loss 1.618 0.335938 0.296875
iteration 237: loss 1.650 0.328125 0.414062
iteration 238: loss 1.042 0.312500 0.500000
iteration 239: loss 1.205 0.398438 0.453125
iteration 240: loss 1.527 0.312500 0.437500
iteration 241: loss 1.613 0.351562 0.414062
iteration 242: loss 1.457 0.343750 0.437500
iteration 243: loss 1.421 0.289062 0.367188
iteration 244: loss 1.394 0.281250 0.460938
iteration 245: loss 1.531 0.351562 0.429688
iteration 246: loss 1.561 0.328125 0.445312
iteration 247: loss 1.354 0.343750 0.398438
iteration 248: loss 1.759 0.359375 0.398438
iteration 249: loss 1.176 0.328125 0.484375
iteration 250: loss 1.244 0.335938 0.523438
iteration 251: loss 1.446 0.390625 0.445312
iteration 252: loss 1.289 0.312500 0.468750
iteration 253: loss 2.150 0.375000 0.390625
iteration 254: loss 1.610 0.367188 0.382812
iteration 255: loss 1.494 0.382812 0.406250
iteration 256: loss 1.692 0.359375 0.492188
iteration 257: loss 1.850 0.335938 0.453125
iteration 258: loss 1.442 0.390625 0.468750
iteration 259: loss 1.515 0.296875 0.476562
iteration 260: loss 1.330 0.343750 0.460938
iteration 261: loss 1.258 0.328125 0.445312
iteration 262: loss 1.697 0.312500 0.398438
iteration 263: loss 1.341 0.367188 0.421875
iteration 264: loss 1.869 0.265625 0.320312
iteration 265: loss 1.670 0.335938 0.343750
iteration 266: loss 1.524 0.320312 0.484375
iteration 267: loss 1.600 0.335938 0.390625
iteration 268: loss 1.475 0.328125 0.421875
iteration 269: loss 1.408 0.328125 0.484375
iteration 270: loss 1.488 0.367188 0.437500
iteration 271: loss 1.617 0.382812 0.390625
iteration 272: loss 2.017 0.406250 0.507812
iteration 273: loss 1.436 0.367188 0.406250
iteration 274: loss 1.572 0.320312 0.429688
iteration 275: loss 1.306 0.289062 0.421875
iteration 276: loss 1.735 0.375000 0.367188
iteration 277: loss 2.067 0.335938 0.382812
iteration 278: loss 1.609 0.289062 0.398438
iteration 279: loss 1.882 0.312500 0.351562
iteration 280: loss 1.434 0.359375 0.421875
iteration 281: loss 1.548 0.289062 0.414062
iteration 282: loss 1.509 0.375000 0.351562
iteration 283: loss 1.719 0.296875 0.445312
iteration 284: loss 1.629 0.281250 0.382812
iteration 285: loss 1.400 0.265625 0.414062
iteration 286: loss 1.710 0.382812 0.437500
iteration 287: loss 1.429 0.320312 0.398438
iteration 288: loss 2.058 0.343750 0.382812
iteration 289: loss 1.439 0.312500 0.468750
iteration 290: loss 1.780 0.351562 0.406250
iteration 291: loss 1.559 0.296875 0.359375
iteration 292: loss 1.783 0.335938 0.382812
iteration 293: loss 1.286 0.320312 0.406250
iteration 294: loss 1.495 0.312500 0.453125
iteration 295: loss 1.503 0.328125 0.460938
iteration 296: loss 1.301 0.312500 0.484375
iteration 297: loss 1.567 0.296875 0.375000
iteration 298: loss 2.232 0.312500 0.351562
iteration 299: loss 1.299 0.304688 0.437500
iteration 300: loss 1.760 0.296875 0.406250
iteration 301: loss 1.950 0.265625 0.359375
iteration 302: loss 1.330 0.320312 0.382812
iteration 303: loss 1.504 0.320312 0.367188
iteration 304: loss 2.101 0.312500 0.359375
iteration 305: loss 1.625 0.320312 0.351562
iteration 306: loss 1.329 0.359375 0.421875
iteration 307: loss 2.230 0.242188 0.398438
iteration 308: loss 1.612 0.328125 0.484375
iteration 309: loss 1.640 0.281250 0.421875
iteration 310: loss 1.148 0.359375 0.523438
iteration 311: loss 1.299 0.390625 0.468750
iteration 312: loss 1.450 0.304688 0.554688
iteration 313: loss 1.339 0.242188 0.445312
iteration 314: loss 1.464 0.320312 0.390625
iteration 315: loss 1.281 0.335938 0.437500
iteration 316: loss 1.856 0.335938 0.382812
iteration 317: loss 1.605 0.304688 0.367188
iteration 318: loss 1.332 0.335938 0.468750
iteration 319: loss 1.552 0.304688 0.406250
iteration 320: loss 1.253 0.359375 0.468750
iteration 321: loss 1.284 0.312500 0.421875
iteration 322: loss 1.645 0.289062 0.414062
iteration 323: loss 1.687 0.375000 0.390625
iteration 324: loss 1.451 0.265625 0.382812
iteration 325: loss 1.470 0.273438 0.375000
iteration 326: loss 1.489 0.320312 0.390625
iteration 327: loss 1.536 0.320312 0.367188
iteration 328: loss 1.549 0.265625 0.445312
iteration 329: loss 1.320 0.273438 0.335938
iteration 330: loss 1.553 0.351562 0.398438
iteration 331: loss 1.348 0.296875 0.515625
iteration 332: loss 1.683 0.367188 0.414062
iteration 333: loss 1.449 0.367188 0.429688
iteration 334: loss 1.991 0.359375 0.421875
iteration 335: loss 1.454 0.320312 0.421875
iteration 336: loss 1.675 0.234375 0.328125
iteration 337: loss 1.177 0.296875 0.468750
iteration 338: loss 1.347 0.328125 0.429688
iteration 339: loss 1.494 0.304688 0.382812
iteration 340: loss 1.453 0.312500 0.429688
iteration 341: loss 1.840 0.375000 0.398438
iteration 342: loss 1.637 0.296875 0.351562
iteration 343: loss 1.769 0.367188 0.390625
iteration 344: loss 1.645 0.296875 0.429688
iteration 345: loss 1.655 0.242188 0.367188
iteration 346: loss 1.151 0.304688 0.476562
iteration 347: loss 1.268 0.328125 0.421875
iteration 348: loss 1.678 0.367188 0.382812
iteration 349: loss 1.423 0.351562 0.359375
iteration 350: loss 1.301 0.312500 0.359375
iteration 351: loss 1.272 0.320312 0.351562
iteration 352: loss 1.875 0.289062 0.398438
iteration 353: loss 1.517 0.351562 0.406250
iteration 354: loss 1.583 0.281250 0.453125
iteration 355: loss 1.494 0.281250 0.382812
iteration 356: loss 1.490 0.351562 0.453125
iteration 357: loss 1.289 0.281250 0.406250
iteration 358: loss 1.374 0.351562 0.429688
iteration 359: loss 1.477 0.343750 0.398438
iteration 360: loss 1.275 0.320312 0.437500
iteration 361: loss 1.099 0.343750 0.476562
iteration 362: loss 1.388 0.367188 0.437500
iteration 363: loss 1.307 0.265625 0.492188
iteration 364: loss 1.308 0.242188 0.484375
iteration 365: loss 1.261 0.359375 0.390625
iteration 366: loss 1.326 0.273438 0.437500
iteration 367: loss 1.162 0.343750 0.445312
iteration 368: loss 1.368 0.320312 0.460938
iteration 369: loss 1.252 0.375000 0.476562
iteration 370: loss 1.406 0.367188 0.406250
iteration 371: loss 1.698 0.398438 0.429688
iteration 372: loss 1.900 0.351562 0.476562
iteration 373: loss 1.958 0.382812 0.375000
iteration 374: loss 1.296 0.335938 0.429688
iteration 375: loss 1.297 0.304688 0.453125
iteration 376: loss 1.403 0.335938 0.437500
iteration 377: loss 1.589 0.296875 0.390625
iteration 378: loss 1.261 0.312500 0.398438
iteration 379: loss 1.296 0.304688 0.367188
iteration 380: loss 1.937 0.328125 0.343750
iteration 381: loss 1.380 0.320312 0.351562
iteration 382: loss 1.471 0.320312 0.351562
iteration 383: loss 1.593 0.296875 0.375000
iteration 384: loss 1.413 0.328125 0.414062
iteration 385: loss 1.332 0.312500 0.382812
iteration 386: loss 1.087 0.375000 0.453125
iteration 387: loss 1.480 0.343750 0.390625
iteration 388: loss 1.268 0.351562 0.453125
iteration 389: loss 1.212 0.304688 0.460938
iteration 390: loss 1.628 0.367188 0.406250
iteration 391: loss 1.586 0.320312 0.484375
iteration 392: loss 1.411 0.351562 0.390625
iteration 393: loss 1.190 0.320312 0.468750
iteration 394: loss 1.580 0.312500 0.484375
iteration 395: loss 1.333 0.343750 0.390625
iteration 396: loss 1.622 0.351562 0.390625
iteration 397: loss 1.256 0.367188 0.406250
iteration 398: loss 1.314 0.375000 0.398438
iteration 399: loss 1.642 0.281250 0.390625
iteration 400: loss 1.404 0.367188 0.406250
iteration 401: loss 1.160 0.343750 0.476562
iteration 402: loss 1.508 0.328125 0.382812
iteration 403: loss 1.727 0.203125 0.414062
iteration 404: loss 1.649 0.351562 0.273438
iteration 405: loss 1.378 0.304688 0.375000
iteration 406: loss 1.412 0.296875 0.398438
iteration 407: loss 1.143 0.375000 0.492188
iteration 408: loss 1.373 0.343750 0.367188
iteration 409: loss 1.153 0.343750 0.421875
iteration 410: loss 1.259 0.343750 0.453125
iteration 411: loss 1.481 0.343750 0.398438
iteration 412: loss 1.121 0.320312 0.476562
iteration 413: loss 1.520 0.335938 0.406250
iteration 414: loss 1.310 0.351562 0.507812
iteration 415: loss 1.872 0.320312 0.460938
iteration 416: loss 1.434 0.242188 0.468750
iteration 417: loss 1.547 0.304688 0.335938
iteration 418: loss 1.371 0.296875 0.484375
iteration 419: loss 1.313 0.335938 0.375000
iteration 420: loss 1.455 0.289062 0.414062
iteration 421: loss 1.263 0.312500 0.367188
iteration 422: loss 1.835 0.359375 0.406250
iteration 423: loss 1.717 0.359375 0.351562
iteration 424: loss 1.289 0.281250 0.445312
iteration 425: loss 1.622 0.406250 0.398438
iteration 426: loss 1.306 0.304688 0.367188
iteration 427: loss 1.573 0.304688 0.460938
iteration 428: loss 1.503 0.296875 0.445312
iteration 429: loss 1.887 0.351562 0.484375
iteration 430: loss 1.655 0.289062 0.414062
iteration 431: loss 1.790 0.343750 0.320312
iteration 432: loss 1.423 0.320312 0.390625
iteration 433: loss 1.382 0.273438 0.367188
iteration 434: loss 1.176 0.312500 0.414062
iteration 435: loss 1.311 0.320312 0.500000
iteration 436: loss 1.586 0.320312 0.335938
iteration 437: loss 1.542 0.351562 0.437500
iteration 438: loss 1.154 0.343750 0.492188
iteration 439: loss 1.649 0.351562 0.421875
iteration 440: loss 1.501 0.281250 0.414062
iteration 441: loss 1.623 0.375000 0.429688
iteration 442: loss 1.414 0.250000 0.468750
iteration 443: loss 1.377 0.375000 0.414062
iteration 444: loss 1.093 0.304688 0.468750
iteration 445: loss 1.307 0.375000 0.453125
iteration 446: loss 1.395 0.343750 0.328125
iteration 447: loss 1.333 0.343750 0.453125
iteration 448: loss 1.802 0.359375 0.343750
iteration 449: loss 1.721 0.304688 0.375000
iteration 450: loss 1.422 0.367188 0.406250
iteration 451: loss 1.325 0.351562 0.367188
iteration 452: loss 1.532 0.312500 0.375000
iteration 453: loss 1.553 0.359375 0.359375
iteration 454: loss 1.230 0.289062 0.382812
iteration 455: loss 1.529 0.265625 0.484375
iteration 456: loss 1.258 0.335938 0.421875
iteration 457: loss 1.529 0.390625 0.437500
iteration 458: loss 1.381 0.328125 0.406250
iteration 459: loss 1.537 0.312500 0.398438
iteration 460: loss 1.384 0.359375 0.367188
iteration 461: loss 1.497 0.382812 0.390625
iteration 462: loss 1.442 0.289062 0.476562
iteration 463: loss 1.508 0.335938 0.351562
iteration 464: loss 1.144 0.281250 0.445312
iteration 465: loss 1.263 0.289062 0.414062
iteration 466: loss 1.574 0.281250 0.398438
iteration 467: loss 1.545 0.328125 0.398438
iteration 468: loss 1.225 0.312500 0.437500
iteration 469: loss 1.386 0.343750 0.351562
iteration 470: loss 1.760 0.281250 0.421875
iteration 471: loss 1.095 0.367188 0.539062
iteration 472: loss 1.799 0.375000 0.414062
iteration 473: loss 1.144 0.335938 0.523438
iteration 474: loss 1.245 0.335938 0.500000
iteration 475: loss 1.748 0.375000 0.375000
iteration 476: loss 1.556 0.242188 0.414062
iteration 477: loss 1.599 0.375000 0.421875
iteration 478: loss 1.290 0.320312 0.492188
iteration 479: loss 1.190 0.429688 0.453125
iteration 480: loss 1.599 0.312500 0.367188
iteration 481: loss 1.411 0.335938 0.398438
iteration 482: loss 1.309 0.289062 0.476562
iteration 483: loss 1.278 0.296875 0.406250
iteration 484: loss 1.173 0.390625 0.406250
iteration 485: loss 1.429 0.242188 0.414062
iteration 486: loss 1.162 0.367188 0.515625
iteration 487: loss 1.601 0.367188 0.390625
iteration 488: loss 1.323 0.367188 0.468750
iteration 489: loss 1.327 0.312500 0.398438
iteration 490: loss 1.332 0.367188 0.453125
iteration 491: loss 1.441 0.335938 0.437500
iteration 492: loss 0.880 0.335938 0.500000
iteration 493: loss 1.410 0.312500 0.398438
iteration 494: loss 1.410 0.328125 0.398438
iteration 495: loss 1.433 0.265625 0.421875
iteration 496: loss 1.228 0.312500 0.414062
iteration 497: loss 1.191 0.304688 0.429688
iteration 498: loss 1.304 0.312500 0.476562
iteration 499: loss 1.319 0.296875 0.460938
iteration 500: loss 1.146 0.335938 0.492188
iteration 501: loss 1.166 0.398438 0.492188
iteration 502: loss 1.481 0.343750 0.398438
iteration 503: loss 1.276 0.296875 0.390625
iteration 504: loss 1.251 0.320312 0.523438
iteration 505: loss 1.636 0.304688 0.296875
iteration 506: loss 1.312 0.351562 0.367188
iteration 507: loss 1.242 0.343750 0.367188
iteration 508: loss 1.269 0.367188 0.414062
iteration 509: loss 1.312 0.351562 0.375000
iteration 510: loss 1.072 0.289062 0.406250
iteration 511: loss 1.304 0.289062 0.398438
iteration 512: loss 1.237 0.289062 0.429688
iteration 513: loss 1.437 0.320312 0.351562
iteration 514: loss 1.321 0.367188 0.460938
iteration 515: loss 1.687 0.359375 0.414062
iteration 516: loss 1.314 0.257812 0.460938
iteration 517: loss 1.611 0.382812 0.398438
iteration 518: loss 1.015 0.343750 0.554688
iteration 519: loss 1.496 0.406250 0.414062
iteration 520: loss 1.182 0.359375 0.437500
iteration 521: loss 1.091 0.289062 0.476562
iteration 522: loss 1.486 0.281250 0.414062
iteration 523: loss 1.384 0.375000 0.414062
iteration 524: loss 1.409 0.218750 0.406250
iteration 525: loss 1.378 0.390625 0.406250
iteration 526: loss 1.414 0.359375 0.335938
iteration 527: loss 1.289 0.281250 0.406250
iteration 528: loss 1.485 0.359375 0.390625
iteration 529: loss 1.526 0.242188 0.453125
iteration 530: loss 1.272 0.351562 0.375000
iteration 531: loss 1.421 0.289062 0.492188
iteration 532: loss 1.519 0.242188 0.468750
iteration 533: loss 1.444 0.289062 0.445312
iteration 534: loss 1.276 0.351562 0.382812
iteration 535: loss 1.641 0.335938 0.382812
iteration 536: loss 1.193 0.296875 0.460938
iteration 537: loss 1.325 0.328125 0.468750
iteration 538: loss 1.139 0.312500 0.476562
iteration 539: loss 1.730 0.250000 0.351562
iteration 540: loss 1.157 0.289062 0.406250
iteration 541: loss 1.678 0.335938 0.429688
iteration 542: loss 1.063 0.359375 0.531250
iteration 543: loss 1.172 0.359375 0.445312
iteration 544: loss 1.474 0.296875 0.421875
iteration 545: loss 1.348 0.343750 0.460938
iteration 546: loss 1.178 0.312500 0.476562
iteration 547: loss 1.586 0.414062 0.460938
iteration 548: loss 1.602 0.296875 0.445312
iteration 549: loss 1.477 0.367188 0.414062
iteration 550: loss 1.456 0.328125 0.367188
iteration 551: loss 1.448 0.250000 0.421875
iteration 552: loss 1.440 0.289062 0.437500
iteration 553: loss 1.806 0.320312 0.367188
iteration 554: loss 1.181 0.335938 0.460938
iteration 555: loss 1.312 0.351562 0.398438
iteration 556: loss 1.177 0.273438 0.429688
iteration 557: loss 1.383 0.328125 0.421875
iteration 558: loss 1.275 0.335938 0.445312
iteration 559: loss 1.719 0.382812 0.492188
iteration 560: loss 1.376 0.328125 0.476562
iteration 561: loss 1.680 0.328125 0.335938
iteration 562: loss 1.608 0.343750 0.390625
iteration 563: loss 1.278 0.281250 0.382812
iteration 564: loss 1.312 0.367188 0.414062
iteration 565: loss 1.740 0.390625 0.367188
iteration 566: loss 1.384 0.382812 0.453125
iteration 567: loss 1.648 0.312500 0.351562
iteration 568: loss 1.488 0.304688 0.406250
iteration 569: loss 1.418 0.367188 0.375000
iteration 570: loss 1.347 0.367188 0.421875
iteration 571: loss 1.513 0.328125 0.437500
iteration 572: loss 1.117 0.367188 0.437500
iteration 573: loss 1.504 0.320312 0.414062
iteration 574: loss 1.067 0.484375 0.476562
iteration 575: loss 1.423 0.296875 0.390625
iteration 576: loss 1.503 0.312500 0.406250
iteration 577: loss 1.484 0.367188 0.445312
iteration 578: loss 1.331 0.304688 0.460938
iteration 579: loss 1.302 0.242188 0.460938
iteration 580: loss 1.254 0.273438 0.359375
iteration 581: loss 1.505 0.328125 0.421875
iteration 582: loss 1.416 0.328125 0.382812
iteration 583: loss 1.424 0.335938 0.296875
iteration 584: loss 1.235 0.367188 0.367188
iteration 585: loss 1.200 0.289062 0.406250
iteration 586: loss 1.387 0.359375 0.398438
iteration 587: loss 1.248 0.328125 0.531250
iteration 588: loss 1.329 0.312500 0.460938
iteration 589: loss 1.278 0.281250 0.484375
iteration 590: loss 1.244 0.328125 0.492188
iteration 591: loss 1.709 0.359375 0.421875
iteration 592: loss 1.041 0.343750 0.523438
iteration 593: loss 1.261 0.273438 0.437500
iteration 594: loss 1.382 0.367188 0.429688
iteration 595: loss 1.153 0.296875 0.484375
iteration 596: loss 1.560 0.265625 0.429688
iteration 597: loss 1.519 0.226562 0.367188
iteration 598: loss 1.358 0.304688 0.414062
iteration 599: loss 1.292 0.312500 0.398438
iteration 600: loss 1.366 0.343750 0.414062
iteration 601: loss 1.524 0.351562 0.367188
iteration 602: loss 1.558 0.359375 0.375000
iteration 603: loss 1.156 0.273438 0.382812
iteration 604: loss 1.348 0.351562 0.453125
iteration 605: loss 1.372 0.359375 0.382812
iteration 606: loss 1.154 0.359375 0.460938
iteration 607: loss 1.420 0.320312 0.468750
iteration 608: loss 1.438 0.398438 0.437500
iteration 609: loss 1.471 0.273438 0.406250
iteration 610: loss 0.950 0.312500 0.500000
iteration 611: loss 1.227 0.382812 0.476562
iteration 612: loss 1.212 0.320312 0.484375
iteration 613: loss 1.047 0.320312 0.500000
iteration 614: loss 1.318 0.335938 0.429688
iteration 615: loss 1.405 0.328125 0.359375
iteration 616: loss 1.506 0.320312 0.351562
iteration 617: loss 1.616 0.335938 0.343750
iteration 618: loss 1.314 0.367188 0.351562
iteration 619: loss 1.175 0.320312 0.460938
iteration 620: loss 1.417 0.343750 0.375000
iteration 621: loss 1.646 0.304688 0.406250
iteration 622: loss 1.323 0.281250 0.484375
iteration 623: loss 1.389 0.273438 0.500000
iteration 624: loss 1.116 0.343750 0.546875
iteration 625: loss 1.182 0.328125 0.468750
iteration 626: loss 1.314 0.351562 0.492188
iteration 627: loss 1.448 0.281250 0.453125
iteration 628: loss 1.565 0.382812 0.476562
iteration 629: loss 1.526 0.296875 0.421875
iteration 630: loss 1.405 0.320312 0.390625
iteration 631: loss 1.234 0.335938 0.398438
iteration 632: loss 1.505 0.367188 0.375000
iteration 633: loss 1.679 0.375000 0.351562
iteration 634: loss 1.350 0.320312 0.382812
iteration 635: loss 1.475 0.351562 0.382812
iteration 636: loss 1.220 0.328125 0.445312
iteration 637: loss 1.114 0.367188 0.460938
iteration 638: loss 1.143 0.398438 0.453125
iteration 639: loss 1.606 0.367188 0.429688
iteration 640: loss 1.392 0.335938 0.476562
iteration 641: loss 1.262 0.351562 0.531250
iteration 642: loss 1.245 0.257812 0.445312
iteration 643: loss 1.455 0.320312 0.437500
iteration 644: loss 1.480 0.382812 0.429688
iteration 645: loss 1.514 0.335938 0.421875
iteration 646: loss 1.257 0.257812 0.382812
iteration 647: loss 1.374 0.343750 0.429688
iteration 648: loss 1.189 0.343750 0.453125
iteration 649: loss 1.888 0.289062 0.414062
iteration 650: loss 1.341 0.296875 0.468750
iteration 651: loss 1.010 0.367188 0.531250
iteration 652: loss 1.331 0.367188 0.398438
iteration 653: loss 1.352 0.328125 0.406250
iteration 654: loss 1.332 0.343750 0.398438
iteration 655: loss 1.334 0.375000 0.406250
iteration 656: loss 1.418 0.335938 0.492188
iteration 657: loss 1.318 0.351562 0.437500
iteration 658: loss 1.155 0.351562 0.429688
iteration 659: loss 1.284 0.242188 0.390625
iteration 660: loss 1.131 0.367188 0.453125
iteration 661: loss 1.440 0.250000 0.375000
iteration 662: loss 1.281 0.312500 0.414062
iteration 663: loss 1.411 0.320312 0.421875
iteration 664: loss 1.181 0.265625 0.437500
iteration 665: loss 1.613 0.281250 0.453125
iteration 666: loss 1.467 0.320312 0.421875
iteration 667: loss 1.692 0.226562 0.406250
iteration 668: loss 1.328 0.265625 0.421875
iteration 669: loss 1.455 0.210938 0.312500
iteration 670: loss 1.365 0.328125 0.273438
iteration 671: loss 1.400 0.328125 0.421875
iteration 672: loss 1.373 0.382812 0.429688
iteration 673: loss 1.346 0.234375 0.367188
iteration 674: loss 1.304 0.312500 0.390625
iteration 675: loss 1.315 0.242188 0.382812
iteration 676: loss 1.155 0.296875 0.468750
iteration 677: loss 1.538 0.351562 0.421875
iteration 678: loss 1.068 0.312500 0.484375
iteration 679: loss 1.084 0.335938 0.390625
iteration 680: loss 1.841 0.343750 0.429688
iteration 681: loss 1.456 0.296875 0.414062
iteration 682: loss 1.328 0.257812 0.460938
iteration 683: loss 1.312 0.296875 0.445312
iteration 684: loss 1.855 0.304688 0.367188
iteration 685: loss 1.554 0.296875 0.382812
iteration 686: loss 1.536 0.250000 0.343750
iteration 687: loss 1.394 0.257812 0.312500
iteration 688: loss 1.717 0.289062 0.359375
iteration 689: loss 1.435 0.312500 0.421875
iteration 690: loss 1.245 0.320312 0.421875
iteration 691: loss 1.247 0.367188 0.453125
iteration 692: loss 1.178 0.351562 0.375000
iteration 693: loss 1.435 0.289062 0.460938
iteration 694: loss 1.138 0.304688 0.421875
iteration 695: loss 1.346 0.359375 0.476562
iteration 696: loss 1.424 0.359375 0.390625
iteration 697: loss 1.148 0.320312 0.484375
iteration 698: loss 1.007 0.296875 0.414062
iteration 699: loss 1.419 0.414062 0.406250
iteration 700: loss 1.038 0.296875 0.539062
iteration 701: loss 1.303 0.375000 0.492188
iteration 702: loss 1.512 0.382812 0.468750
iteration 703: loss 1.272 0.304688 0.429688
iteration 704: loss 1.293 0.312500 0.421875
iteration 705: loss 1.436 0.343750 0.453125
iteration 706: loss 1.669 0.289062 0.328125
iteration 707: loss 1.518 0.312500 0.328125
iteration 708: loss 1.191 0.359375 0.429688
iteration 709: loss 1.321 0.281250 0.421875
iteration 710: loss 1.254 0.296875 0.429688
iteration 711: loss 1.295 0.312500 0.484375
iteration 712: loss 1.506 0.250000 0.367188
iteration 713: loss 1.444 0.359375 0.359375
iteration 714: loss 1.528 0.304688 0.437500
iteration 715: loss 1.296 0.304688 0.421875
iteration 716: loss 1.273 0.312500 0.398438
iteration 717: loss 1.205 0.304688 0.468750
iteration 718: loss 0.991 0.382812 0.500000
iteration 719: loss 1.273 0.343750 0.445312
iteration 720: loss 1.390 0.328125 0.382812
iteration 721: loss 1.205 0.390625 0.421875
iteration 722: loss 1.234 0.320312 0.421875
iteration 723: loss 1.440 0.289062 0.398438
iteration 724: loss 1.495 0.265625 0.500000
iteration 725: loss 1.371 0.351562 0.515625
iteration 726: loss 1.179 0.250000 0.398438
iteration 727: loss 1.607 0.296875 0.406250
iteration 728: loss 1.335 0.304688 0.539062
iteration 729: loss 1.076 0.257812 0.453125
iteration 730: loss 1.352 0.320312 0.382812
iteration 731: loss 1.484 0.406250 0.351562
iteration 732: loss 1.173 0.359375 0.460938
iteration 733: loss 1.134 0.281250 0.554688
iteration 734: loss 1.452 0.367188 0.390625
iteration 735: loss 1.321 0.382812 0.429688
iteration 736: loss 0.920 0.328125 0.460938
iteration 737: loss 1.434 0.320312 0.390625
iteration 738: loss 1.438 0.351562 0.445312
iteration 739: loss 1.282 0.312500 0.476562
iteration 740: loss 1.247 0.273438 0.375000
iteration 741: loss 1.368 0.312500 0.500000
iteration 742: loss 1.389 0.328125 0.375000
iteration 743: loss 1.278 0.335938 0.421875
iteration 744: loss 1.712 0.320312 0.414062
iteration 745: loss 1.803 0.382812 0.390625
iteration 746: loss 1.401 0.273438 0.445312
iteration 747: loss 1.238 0.281250 0.453125
iteration 748: loss 1.128 0.335938 0.437500
iteration 749: loss 1.147 0.312500 0.468750
iteration 750: loss 1.566 0.312500 0.367188
iteration 751: loss 1.525 0.351562 0.406250
iteration 752: loss 1.242 0.273438 0.375000
iteration 753: loss 1.198 0.281250 0.429688
iteration 754: loss 1.699 0.312500 0.351562
iteration 755: loss 1.242 0.359375 0.460938
iteration 756: loss 1.556 0.312500 0.375000
iteration 757: loss 1.162 0.343750 0.445312
iteration 758: loss 1.327 0.304688 0.382812
iteration 759: loss 1.379 0.382812 0.453125
iteration 760: loss 1.135 0.296875 0.554688
iteration 761: loss 1.332 0.421875 0.429688
iteration 762: loss 1.240 0.304688 0.468750
iteration 763: loss 1.663 0.335938 0.367188
iteration 764: loss 1.325 0.335938 0.429688
iteration 765: loss 1.121 0.367188 0.421875
iteration 766: loss 1.317 0.382812 0.398438
iteration 767: loss 1.332 0.312500 0.398438
iteration 768: loss 1.210 0.226562 0.468750
iteration 769: loss 1.100 0.328125 0.476562
iteration 770: loss 1.514 0.281250 0.390625
iteration 771: loss 1.682 0.328125 0.414062
iteration 772: loss 1.322 0.296875 0.437500
iteration 773: loss 1.319 0.289062 0.468750
iteration 774: loss 1.182 0.359375 0.460938
iteration 775: loss 1.175 0.296875 0.445312
iteration 776: loss 1.346 0.328125 0.421875
iteration 777: loss 1.078 0.257812 0.468750
iteration 778: loss 1.465 0.281250 0.351562
iteration 779: loss 1.107 0.312500 0.484375
iteration 780: loss 1.263 0.359375 0.437500
iteration 781: loss 1.241 0.375000 0.484375
iteration 782: loss 0.907 0.250000 0.531250
iteration 783: loss 1.291 0.335938 0.421875
iteration 784: loss 1.263 0.351562 0.460938
iteration 785: loss 1.160 0.367188 0.437500
iteration 786: loss 1.573 0.296875 0.390625
iteration 787: loss 1.057 0.367188 0.414062
iteration 788: loss 1.325 0.359375 0.390625
iteration 789: loss 1.311 0.289062 0.343750
iteration 790: loss 1.120 0.289062 0.398438
iteration 791: loss 0.958 0.312500 0.453125
iteration 792: loss 1.272 0.343750 0.382812
iteration 793: loss 1.381 0.328125 0.406250
iteration 794: loss 1.155 0.375000 0.492188
iteration 795: loss 1.116 0.375000 0.570312
iteration 796: loss 1.114 0.312500 0.414062
iteration 797: loss 1.592 0.281250 0.296875
iteration 798: loss 1.210 0.351562 0.468750
iteration 799: loss 1.594 0.375000 0.328125
iteration 800: loss 1.165 0.312500 0.437500
iteration 801: loss 1.341 0.398438 0.398438
iteration 802: loss 1.130 0.234375 0.453125
iteration 803: loss 1.161 0.335938 0.429688
iteration 804: loss 1.040 0.320312 0.445312
iteration 805: loss 1.230 0.328125 0.476562
iteration 806: loss 1.283 0.289062 0.437500
iteration 807: loss 1.412 0.343750 0.414062
iteration 808: loss 1.281 0.265625 0.390625
iteration 809: loss 0.896 0.296875 0.437500
iteration 810: loss 1.038 0.312500 0.445312
iteration 811: loss 1.123 0.296875 0.437500
iteration 812: loss 1.034 0.289062 0.476562
iteration 813: loss 0.974 0.351562 0.460938
iteration 814: loss 1.053 0.375000 0.476562
iteration 815: loss 1.190 0.335938 0.460938
iteration 816: loss 1.449 0.406250 0.414062
iteration 817: loss 1.110 0.367188 0.507812
iteration 818: loss 1.257 0.390625 0.476562
iteration 819: loss 1.278 0.390625 0.445312
iteration 820: loss 1.299 0.343750 0.390625
iteration 821: loss 1.290 0.359375 0.390625
iteration 822: loss 1.165 0.437500 0.429688
iteration 823: loss 1.057 0.320312 0.375000
iteration 824: loss 0.853 0.367188 0.414062
iteration 825: loss 0.987 0.398438 0.492188
iteration 826: loss 1.436 0.390625 0.359375
iteration 827: loss 1.014 0.281250 0.476562
iteration 828: loss 1.027 0.421875 0.406250
iteration 829: loss 0.987 0.320312 0.492188
iteration 830: loss 0.968 0.343750 0.429688
iteration 831: loss 1.172 0.328125 0.359375
iteration 832: loss 1.284 0.335938 0.375000
iteration 833: loss 1.219 0.375000 0.484375
iteration 834: loss 1.298 0.296875 0.468750
iteration 835: loss 1.250 0.335938 0.484375
iteration 836: loss 1.334 0.351562 0.398438
iteration 837: loss 1.116 0.328125 0.453125
iteration 838: loss 1.516 0.296875 0.382812
iteration 839: loss 1.417 0.296875 0.320312
iteration 840: loss 1.504 0.328125 0.359375
iteration 841: loss 1.210 0.296875 0.421875
iteration 842: loss 1.446 0.296875 0.375000
iteration 843: loss 1.351 0.343750 0.429688
iteration 844: loss 1.429 0.367188 0.445312
iteration 845: loss 1.275 0.296875 0.476562
iteration 846: loss 1.010 0.367188 0.570312
iteration 847: loss 1.337 0.382812 0.445312
iteration 848: loss 1.429 0.320312 0.445312
iteration 849: loss 0.991 0.320312 0.453125
iteration 850: loss 1.542 0.289062 0.421875
iteration 851: loss 1.309 0.335938 0.375000
iteration 852: loss 1.314 0.265625 0.398438
iteration 853: loss 1.356 0.304688 0.351562
iteration 854: loss 1.653 0.296875 0.390625
iteration 855: loss 0.963 0.296875 0.507812
iteration 856: loss 1.218 0.398438 0.414062
iteration 857: loss 1.386 0.367188 0.453125
iteration 858: loss 1.243 0.382812 0.445312
iteration 859: loss 1.626 0.320312 0.382812
iteration 860: loss 1.474 0.382812 0.343750
iteration 861: loss 1.308 0.304688 0.351562
iteration 862: loss 1.490 0.343750 0.375000
iteration 863: loss 1.149 0.304688 0.437500
iteration 864: loss 1.711 0.320312 0.406250
iteration 865: loss 1.191 0.250000 0.468750
iteration 866: loss 1.228 0.320312 0.500000
iteration 867: loss 1.005 0.281250 0.460938
iteration 868: loss 1.223 0.320312 0.351562
iteration 869: loss 1.157 0.351562 0.437500
iteration 870: loss 1.276 0.320312 0.445312
iteration 871: loss 1.592 0.351562 0.390625
iteration 872: loss 1.727 0.265625 0.484375
iteration 873: loss 1.044 0.328125 0.468750
iteration 874: loss 1.452 0.335938 0.476562
iteration 875: loss 1.598 0.359375 0.468750
iteration 876: loss 1.926 0.312500 0.414062
iteration 877: loss 1.210 0.351562 0.359375
iteration 878: loss 1.291 0.289062 0.421875
iteration 879: loss 1.132 0.265625 0.476562
iteration 880: loss 1.296 0.304688 0.328125
iteration 881: loss 1.333 0.312500 0.421875
iteration 882: loss 1.103 0.328125 0.406250
iteration 883: loss 1.134 0.296875 0.406250
iteration 884: loss 1.299 0.367188 0.414062
iteration 885: loss 1.229 0.312500 0.531250
iteration 886: loss 1.585 0.382812 0.429688
iteration 887: loss 1.047 0.375000 0.476562
iteration 888: loss 1.038 0.281250 0.507812
iteration 889: loss 1.188 0.320312 0.445312
iteration 890: loss 1.340 0.351562 0.398438
iteration 891: loss 1.280 0.335938 0.476562
iteration 892: loss 1.226 0.390625 0.429688
iteration 893: loss 1.570 0.328125 0.421875
iteration 894: loss 0.939 0.281250 0.507812
iteration 895: loss 1.068 0.289062 0.500000
iteration 896: loss 1.331 0.367188 0.460938
iteration 897: loss 1.197 0.382812 0.500000
iteration 898: loss 1.052 0.320312 0.484375
iteration 899: loss 1.216 0.335938 0.460938
iteration 900: loss 1.001 0.304688 0.500000
iteration 901: loss 0.920 0.281250 0.570312
iteration 902: loss 1.492 0.312500 0.390625
iteration 903: loss 1.401 0.304688 0.429688
iteration 904: loss 1.148 0.265625 0.468750
iteration 905: loss 1.276 0.281250 0.398438
iteration 906: loss 1.052 0.335938 0.429688
iteration 907: loss 1.207 0.242188 0.406250
iteration 908: loss 1.292 0.359375 0.406250
iteration 909: loss 1.000 0.257812 0.476562
iteration 910: loss 1.202 0.359375 0.406250
iteration 911: loss 1.216 0.359375 0.429688
iteration 912: loss 1.142 0.414062 0.421875
iteration 913: loss 1.051 0.312500 0.453125
iteration 914: loss 1.318 0.343750 0.359375
iteration 915: loss 0.925 0.359375 0.445312
iteration 916: loss 1.614 0.359375 0.320312
iteration 917: loss 1.347 0.296875 0.414062
iteration 918: loss 1.518 0.351562 0.382812
iteration 919: loss 1.276 0.312500 0.437500
iteration 920: loss 1.286 0.328125 0.429688
iteration 921: loss 1.124 0.320312 0.429688
iteration 922: loss 1.270 0.359375 0.421875
iteration 923: loss 1.002 0.359375 0.507812
iteration 924: loss 1.053 0.320312 0.484375
iteration 925: loss 1.257 0.390625 0.507812
iteration 926: loss 1.219 0.304688 0.421875
iteration 927: loss 1.420 0.343750 0.468750
iteration 928: loss 1.567 0.382812 0.390625
iteration 929: loss 1.487 0.289062 0.390625
iteration 930: loss 1.207 0.273438 0.351562
iteration 931: loss 1.323 0.250000 0.367188
iteration 932: loss 0.986 0.218750 0.492188
iteration 933: loss 1.274 0.296875 0.421875
iteration 934: loss 1.131 0.210938 0.390625
iteration 935: loss 1.243 0.289062 0.429688
iteration 936: loss 1.480 0.320312 0.445312
iteration 937: loss 0.979 0.312500 0.507812
iteration 938: loss 1.204 0.367188 0.445312
iteration 939: loss 1.020 0.328125 0.515625
iteration 940: loss 1.131 0.343750 0.414062
iteration 941: loss 1.181 0.328125 0.453125
iteration 942: loss 1.003 0.320312 0.500000
iteration 943: loss 1.152 0.343750 0.382812
iteration 944: loss 1.347 0.265625 0.351562
iteration 945: loss 1.201 0.328125 0.453125
iteration 946: loss 0.999 0.328125 0.453125
iteration 947: loss 0.964 0.320312 0.468750
iteration 948: loss 1.447 0.359375 0.406250
iteration 949: loss 1.277 0.445312 0.406250
iteration 950: loss 0.922 0.351562 0.468750
iteration 951: loss 1.218 0.320312 0.445312
iteration 952: loss 1.423 0.335938 0.367188
iteration 953: loss 1.105 0.257812 0.398438
iteration 954: loss 0.844 0.320312 0.453125
iteration 955: loss 0.869 0.320312 0.507812
iteration 956: loss 1.047 0.367188 0.382812
iteration 957: loss 1.662 0.320312 0.437500
iteration 958: loss 1.256 0.335938 0.460938
iteration 959: loss 1.305 0.335938 0.367188
iteration 960: loss 1.050 0.351562 0.460938
iteration 961: loss 1.207 0.375000 0.460938
iteration 962: loss 1.138 0.351562 0.492188
iteration 963: loss 1.152 0.265625 0.414062
iteration 964: loss 1.199 0.328125 0.445312
iteration 965: loss 1.106 0.351562 0.437500
iteration 966: loss 1.323 0.351562 0.421875
iteration 967: loss 1.327 0.359375 0.421875
iteration 968: loss 1.187 0.226562 0.453125
iteration 969: loss 0.920 0.234375 0.468750
iteration 970: loss 1.218 0.351562 0.453125
iteration 971: loss 1.185 0.281250 0.453125
iteration 972: loss 1.307 0.234375 0.476562
iteration 973: loss 1.112 0.445312 0.421875
iteration 974: loss 1.196 0.335938 0.421875
iteration 975: loss 1.191 0.320312 0.421875
iteration 976: loss 1.190 0.343750 0.437500
iteration 977: loss 1.242 0.265625 0.398438
iteration 978: loss 1.092 0.328125 0.460938
iteration 979: loss 1.103 0.398438 0.414062
iteration 980: loss 1.207 0.375000 0.406250
iteration 981: loss 0.904 0.335938 0.476562
iteration 982: loss 1.304 0.335938 0.421875
iteration 983: loss 1.196 0.375000 0.484375
iteration 984: loss 1.263 0.296875 0.468750
iteration 985: loss 1.488 0.289062 0.382812
iteration 986: loss 0.978 0.351562 0.523438
iteration 987: loss 1.258 0.320312 0.453125
iteration 988: loss 1.325 0.382812 0.429688
iteration 989: loss 1.365 0.351562 0.414062
iteration 990: loss 1.533 0.390625 0.421875
iteration 991: loss 1.468 0.359375 0.468750
iteration 992: loss 1.259 0.312500 0.414062
iteration 993: loss 1.313 0.289062 0.414062
iteration 994: loss 0.947 0.359375 0.484375
iteration 995: loss 1.151 0.320312 0.460938
iteration 996: loss 1.238 0.281250 0.421875
iteration 997: loss 1.340 0.328125 0.445312
iteration 998: loss 1.269 0.351562 0.382812
iteration 999: loss 1.202 0.281250 0.414062
epoch 2: training: 0.289062 validation: 0.226562
iteration 0: loss 1.198 0.289062 0.460938
iteration 1: loss 1.413 0.359375 0.421875
iteration 2: loss 1.220 0.375000 0.406250
iteration 3: loss 1.073 0.289062 0.445312
iteration 4: loss 1.131 0.328125 0.468750
iteration 5: loss 1.250 0.382812 0.398438
iteration 6: loss 1.314 0.375000 0.531250
iteration 7: loss 1.129 0.335938 0.453125
iteration 8: loss 1.539 0.367188 0.445312
iteration 9: loss 0.955 0.304688 0.500000
iteration 10: loss 1.211 0.351562 0.429688
iteration 11: loss 1.093 0.312500 0.429688
iteration 12: loss 1.141 0.304688 0.445312
iteration 13: loss 1.343 0.390625 0.375000
iteration 14: loss 1.126 0.312500 0.406250
iteration 15: loss 0.940 0.343750 0.382812
iteration 16: loss 1.176 0.335938 0.429688
iteration 17: loss 1.114 0.390625 0.390625
iteration 18: loss 0.977 0.320312 0.492188
iteration 19: loss 1.088 0.320312 0.414062
iteration 20: loss 1.094 0.367188 0.429688
iteration 21: loss 0.949 0.296875 0.421875
iteration 22: loss 1.361 0.328125 0.390625
iteration 23: loss 1.017 0.296875 0.484375
iteration 24: loss 1.086 0.359375 0.390625
iteration 25: loss 1.010 0.351562 0.437500
iteration 26: loss 1.159 0.265625 0.343750
iteration 27: loss 0.956 0.328125 0.523438
iteration 28: loss 0.795 0.351562 0.546875
iteration 29: loss 1.115 0.375000 0.468750
iteration 30: loss 1.269 0.257812 0.421875
iteration 31: loss 0.870 0.375000 0.523438
iteration 32: loss 1.503 0.343750 0.343750
iteration 33: loss 0.993 0.343750 0.484375
iteration 34: loss 1.305 0.328125 0.390625
iteration 35: loss 1.287 0.375000 0.414062
iteration 36: loss 1.501 0.328125 0.359375
iteration 37: loss 0.990 0.375000 0.453125
iteration 38: loss 1.285 0.382812 0.359375
iteration 39: loss 1.017 0.382812 0.531250
iteration 40: loss 0.843 0.343750 0.570312
iteration 41: loss 1.249 0.359375 0.429688
iteration 42: loss 1.019 0.289062 0.453125
iteration 43: loss 1.017 0.367188 0.453125
iteration 44: loss 0.928 0.312500 0.476562
iteration 45: loss 1.323 0.328125 0.414062
iteration 46: loss 1.157 0.304688 0.335938
iteration 47: loss 1.175 0.351562 0.460938
iteration 48: loss 1.002 0.312500 0.460938
iteration 49: loss 1.186 0.414062 0.453125
iteration 50: loss 1.245 0.242188 0.500000
iteration 51: loss 1.155 0.359375 0.460938
iteration 52: loss 1.077 0.296875 0.453125
iteration 53: loss 1.028 0.289062 0.500000
iteration 54: loss 1.231 0.351562 0.421875
iteration 55: loss 1.092 0.281250 0.382812
iteration 56: loss 1.249 0.343750 0.421875
iteration 57: loss 1.456 0.289062 0.437500
iteration 58: loss 1.556 0.320312 0.421875
iteration 59: loss 1.048 0.351562 0.468750
iteration 60: loss 1.221 0.296875 0.460938
iteration 61: loss 0.979 0.296875 0.414062
iteration 62: loss 1.021 0.273438 0.453125
iteration 63: loss 1.350 0.304688 0.375000
iteration 64: loss 1.093 0.289062 0.437500
iteration 65: loss 1.092 0.367188 0.500000
iteration 66: loss 1.424 0.304688 0.468750
iteration 67: loss 1.278 0.289062 0.468750
iteration 68: loss 1.133 0.335938 0.515625
iteration 69: loss 1.255 0.351562 0.437500
iteration 70: loss 1.310 0.265625 0.437500
iteration 71: loss 0.998 0.328125 0.500000
iteration 72: loss 1.884 0.375000 0.414062
iteration 73: loss 1.525 0.343750 0.351562
iteration 74: loss 1.171 0.250000 0.390625
iteration 75: loss 1.240 0.257812 0.351562
iteration 76: loss 1.166 0.273438 0.382812
iteration 77: loss 1.222 0.320312 0.437500
iteration 78: loss 1.130 0.320312 0.437500
iteration 79: loss 1.108 0.343750 0.468750
iteration 80: loss 1.204 0.242188 0.468750
iteration 81: loss 1.360 0.390625 0.460938
iteration 82: loss 1.029 0.335938 0.500000
iteration 83: loss 1.075 0.382812 0.492188
iteration 84: loss 1.486 0.320312 0.460938
iteration 85: loss 1.343 0.281250 0.484375
iteration 86: loss 1.303 0.351562 0.382812
iteration 87: loss 1.096 0.335938 0.406250
iteration 88: loss 1.102 0.320312 0.468750
iteration 89: loss 1.163 0.296875 0.367188
iteration 90: loss 1.101 0.281250 0.453125
iteration 91: loss 1.224 0.421875 0.507812
iteration 92: loss 1.444 0.375000 0.453125
iteration 93: loss 1.017 0.359375 0.515625
iteration 94: loss 1.076 0.382812 0.492188
iteration 95: loss 1.115 0.351562 0.515625
iteration 96: loss 0.889 0.367188 0.507812
iteration 97: loss 1.195 0.367188 0.460938
iteration 98: loss 1.046 0.296875 0.468750
iteration 99: loss 1.433 0.328125 0.359375
iteration 100: loss 0.902 0.335938 0.460938
iteration 101: loss 1.360 0.304688 0.351562
iteration 102: loss 1.082 0.320312 0.398438
iteration 103: loss 0.866 0.312500 0.523438
iteration 104: loss 1.088 0.273438 0.453125
iteration 105: loss 1.174 0.367188 0.484375
iteration 106: loss 1.070 0.312500 0.437500
iteration 107: loss 1.255 0.414062 0.429688
iteration 108: loss 1.086 0.296875 0.554688
iteration 109: loss 1.158 0.382812 0.429688
iteration 110: loss 1.238 0.343750 0.429688
iteration 111: loss 1.057 0.312500 0.484375
iteration 112: loss 1.192 0.304688 0.406250
iteration 113: loss 1.288 0.257812 0.429688
iteration 114: loss 1.163 0.335938 0.398438
iteration 115: loss 1.203 0.359375 0.390625
iteration 116: loss 1.111 0.367188 0.382812
iteration 117: loss 0.782 0.343750 0.476562
iteration 118: loss 1.275 0.304688 0.476562
iteration 119: loss 1.261 0.335938 0.414062
iteration 120: loss 0.892 0.328125 0.476562
iteration 121: loss 0.963 0.296875 0.414062
iteration 122: loss 1.002 0.359375 0.460938
iteration 123: loss 1.341 0.328125 0.421875
iteration 124: loss 0.942 0.265625 0.421875
iteration 125: loss 1.194 0.343750 0.382812
iteration 126: loss 1.141 0.406250 0.437500
iteration 127: loss 1.189 0.359375 0.414062
iteration 128: loss 0.968 0.328125 0.429688
iteration 129: loss 0.943 0.289062 0.468750
iteration 130: loss 1.269 0.328125 0.406250
iteration 131: loss 0.963 0.304688 0.468750
iteration 132: loss 1.281 0.359375 0.367188
iteration 133: loss 1.173 0.375000 0.476562
iteration 134: loss 0.829 0.296875 0.492188
iteration 135: loss 1.153 0.265625 0.421875
iteration 136: loss 1.298 0.351562 0.515625
iteration 137: loss 1.036 0.250000 0.421875
iteration 138: loss 0.950 0.312500 0.453125
iteration 139: loss 1.234 0.312500 0.390625
iteration 140: loss 1.044 0.398438 0.453125
iteration 141: loss 1.300 0.250000 0.445312
iteration 142: loss 1.028 0.304688 0.437500
iteration 143: loss 1.213 0.328125 0.429688
iteration 144: loss 0.999 0.312500 0.484375
iteration 145: loss 1.364 0.312500 0.351562
iteration 146: loss 1.151 0.375000 0.445312
iteration 147: loss 1.091 0.250000 0.406250
iteration 148: loss 0.947 0.289062 0.406250
iteration 149: loss 0.964 0.359375 0.484375
iteration 150: loss 1.111 0.367188 0.453125
iteration 151: loss 1.151 0.289062 0.476562
iteration 152: loss 1.410 0.335938 0.414062
iteration 153: loss 1.383 0.367188 0.476562
iteration 154: loss 1.018 0.281250 0.492188
iteration 155: loss 1.658 0.351562 0.406250
iteration 156: loss 1.486 0.328125 0.367188
iteration 157: loss 1.588 0.335938 0.359375
iteration 158: loss 0.875 0.304688 0.437500
iteration 159: loss 1.252 0.320312 0.390625
iteration 160: loss 1.324 0.359375 0.445312
iteration 161: loss 1.148 0.296875 0.375000
iteration 162: loss 1.102 0.312500 0.453125
iteration 163: loss 1.200 0.351562 0.468750
iteration 164: loss 1.102 0.320312 0.500000
iteration 165: loss 1.154 0.437500 0.468750
iteration 166: loss 1.129 0.312500 0.421875
iteration 167: loss 1.061 0.289062 0.515625
iteration 168: loss 1.384 0.328125 0.382812
iteration 169: loss 1.245 0.328125 0.414062
iteration 170: loss 1.113 0.367188 0.414062
iteration 171: loss 1.348 0.257812 0.398438
iteration 172: loss 1.073 0.359375 0.476562
iteration 173: loss 1.437 0.304688 0.382812
iteration 174: loss 1.077 0.343750 0.429688
iteration 175: loss 1.379 0.289062 0.359375
iteration 176: loss 1.124 0.382812 0.421875
iteration 177: loss 0.850 0.281250 0.500000
iteration 178: loss 1.277 0.289062 0.421875
iteration 179: loss 1.039 0.359375 0.460938
iteration 180: loss 1.273 0.304688 0.437500
iteration 181: loss 1.149 0.320312 0.390625
iteration 182: loss 1.078 0.320312 0.437500
iteration 183: loss 1.151 0.328125 0.468750
iteration 184: loss 1.093 0.375000 0.476562
iteration 185: loss 1.413 0.304688 0.351562
iteration 186: loss 1.281 0.304688 0.398438
iteration 187: loss 1.304 0.304688 0.343750
iteration 188: loss 1.302 0.351562 0.406250
iteration 189: loss 1.234 0.390625 0.414062
iteration 190: loss 1.603 0.414062 0.421875
iteration 191: loss 1.554 0.304688 0.421875
iteration 192: loss 1.055 0.257812 0.484375
iteration 193: loss 1.134 0.328125 0.453125
iteration 194: loss 1.352 0.351562 0.406250
iteration 195: loss 1.684 0.351562 0.414062
iteration 196: loss 0.964 0.281250 0.484375
iteration 197: loss 1.407 0.289062 0.421875
iteration 198: loss 1.001 0.328125 0.406250
iteration 199: loss 1.050 0.351562 0.429688
iteration 200: loss 1.416 0.265625 0.390625
iteration 201: loss 1.128 0.335938 0.445312
iteration 202: loss 1.259 0.335938 0.468750
iteration 203: loss 1.171 0.265625 0.429688
iteration 204: loss 1.423 0.312500 0.359375
iteration 205: loss 1.256 0.304688 0.414062
iteration 206: loss 1.148 0.351562 0.414062
iteration 207: loss 1.283 0.320312 0.453125
iteration 208: loss 1.223 0.335938 0.398438
iteration 209: loss 1.043 0.210938 0.429688
iteration 210: loss 1.203 0.242188 0.421875
iteration 211: loss 1.382 0.289062 0.406250
iteration 212: loss 1.030 0.367188 0.468750
iteration 213: loss 1.324 0.367188 0.406250
iteration 214: loss 1.314 0.351562 0.359375
iteration 215: loss 1.264 0.312500 0.375000
iteration 216: loss 1.121 0.335938 0.437500
iteration 217: loss 1.765 0.289062 0.421875
iteration 218: loss 1.270 0.382812 0.468750
iteration 219: loss 1.356 0.359375 0.398438
iteration 220: loss 1.006 0.281250 0.539062
iteration 221: loss 1.741 0.351562 0.328125
iteration 222: loss 1.289 0.289062 0.382812
iteration 223: loss 1.346 0.312500 0.414062
iteration 224: loss 1.074 0.296875 0.414062
iteration 225: loss 1.077 0.273438 0.437500
iteration 226: loss 0.838 0.351562 0.453125
iteration 227: loss 0.970 0.289062 0.437500
iteration 228: loss 1.008 0.304688 0.515625
iteration 229: loss 0.977 0.382812 0.515625
iteration 230: loss 1.524 0.359375 0.460938
iteration 231: loss 1.206 0.367188 0.484375
iteration 232: loss 1.230 0.328125 0.429688
iteration 233: loss 1.098 0.273438 0.445312
iteration 234: loss 1.090 0.359375 0.437500
iteration 235: loss 1.246 0.273438 0.445312
iteration 236: loss 1.169 0.398438 0.406250
iteration 237: loss 0.959 0.335938 0.453125
iteration 238: loss 1.103 0.390625 0.445312
iteration 239: loss 1.337 0.359375 0.351562
iteration 240: loss 1.095 0.343750 0.398438
iteration 241: loss 1.588 0.328125 0.500000
iteration 242: loss 1.253 0.375000 0.414062
iteration 243: loss 0.868 0.273438 0.429688
iteration 244: loss 1.364 0.265625 0.414062
iteration 245: loss 1.101 0.414062 0.421875
iteration 246: loss 1.457 0.289062 0.351562
iteration 247: loss 1.115 0.281250 0.421875
iteration 248: loss 1.132 0.281250 0.359375
iteration 249: loss 1.427 0.281250 0.406250
iteration 250: loss 0.941 0.296875 0.453125
iteration 251: loss 1.228 0.359375 0.468750
iteration 252: loss 0.794 0.273438 0.546875
iteration 253: loss 1.026 0.351562 0.492188
iteration 254: loss 1.045 0.328125 0.429688
iteration 255: loss 1.151 0.343750 0.445312
iteration 256: loss 0.865 0.382812 0.492188
iteration 257: loss 0.967 0.343750 0.476562
iteration 258: loss 1.149 0.320312 0.453125
iteration 259: loss 1.117 0.343750 0.429688
iteration 260: loss 0.973 0.289062 0.484375
iteration 261: loss 1.290 0.289062 0.398438
iteration 262: loss 1.159 0.312500 0.429688
iteration 263: loss 1.520 0.234375 0.398438
iteration 264: loss 1.214 0.296875 0.429688
iteration 265: loss 1.142 0.281250 0.429688
iteration 266: loss 1.316 0.359375 0.468750
iteration 267: loss 1.188 0.335938 0.468750
iteration 268: loss 1.448 0.335938 0.421875
iteration 269: loss 1.160 0.367188 0.437500
iteration 270: loss 1.361 0.343750 0.367188
iteration 271: loss 1.004 0.335938 0.492188
iteration 272: loss 1.257 0.312500 0.421875
iteration 273: loss 0.990 0.343750 0.429688
iteration 274: loss 1.293 0.328125 0.343750
iteration 275: loss 1.041 0.281250 0.343750
iteration 276: loss 1.262 0.320312 0.367188
iteration 277: loss 1.005 0.226562 0.445312
iteration 278: loss 1.336 0.351562 0.367188
iteration 279: loss 1.082 0.351562 0.460938
iteration 280: loss 1.253 0.367188 0.406250
iteration 281: loss 1.361 0.273438 0.359375
iteration 282: loss 1.030 0.304688 0.445312
iteration 283: loss 1.095 0.320312 0.429688
iteration 284: loss 1.074 0.320312 0.445312
iteration 285: loss 1.060 0.453125 0.484375
iteration 286: loss 1.159 0.281250 0.515625
iteration 287: loss 1.310 0.304688 0.460938
iteration 288: loss 1.128 0.296875 0.500000
iteration 289: loss 1.179 0.281250 0.390625
iteration 290: loss 1.007 0.289062 0.468750
iteration 291: loss 1.042 0.351562 0.429688
iteration 292: loss 0.979 0.273438 0.507812
iteration 293: loss 1.304 0.351562 0.398438
iteration 294: loss 1.101 0.265625 0.492188
iteration 295: loss 1.268 0.343750 0.453125
iteration 296: loss 1.770 0.382812 0.367188
iteration 297: loss 1.205 0.312500 0.445312
iteration 298: loss 0.935 0.335938 0.460938
iteration 299: loss 0.988 0.273438 0.414062
iteration 300: loss 1.153 0.343750 0.429688
iteration 301: loss 0.893 0.351562 0.531250
iteration 302: loss 1.080 0.351562 0.437500
iteration 303: loss 1.040 0.289062 0.453125
iteration 304: loss 1.220 0.367188 0.421875
iteration 305: loss 1.144 0.328125 0.414062
iteration 306: loss 0.837 0.281250 0.492188
iteration 307: loss 0.926 0.328125 0.476562
iteration 308: loss 1.303 0.367188 0.398438
iteration 309: loss 0.924 0.367188 0.492188
iteration 310: loss 1.287 0.296875 0.437500
iteration 311: loss 1.430 0.359375 0.382812
iteration 312: loss 0.952 0.398438 0.445312
iteration 313: loss 1.057 0.304688 0.414062
iteration 314: loss 1.120 0.296875 0.453125
iteration 315: loss 1.205 0.343750 0.429688
iteration 316: loss 0.955 0.320312 0.476562
iteration 317: loss 1.025 0.296875 0.414062
iteration 318: loss 1.055 0.328125 0.406250
iteration 319: loss 1.176 0.320312 0.375000
iteration 320: loss 1.131 0.281250 0.390625
iteration 321: loss 0.982 0.281250 0.437500
iteration 322: loss 1.159 0.328125 0.414062
iteration 323: loss 1.011 0.320312 0.476562
iteration 324: loss 1.283 0.343750 0.445312
iteration 325: loss 1.198 0.281250 0.437500
iteration 326: loss 1.604 0.257812 0.468750
iteration 327: loss 1.076 0.289062 0.445312
iteration 328: loss 0.907 0.281250 0.500000
iteration 329: loss 1.149 0.312500 0.429688
iteration 330: loss 1.020 0.367188 0.437500
iteration 331: loss 1.159 0.265625 0.421875
iteration 332: loss 1.155 0.328125 0.421875
iteration 333: loss 0.990 0.328125 0.437500
iteration 334: loss 1.325 0.328125 0.375000
iteration 335: loss 1.023 0.382812 0.468750
iteration 336: loss 1.294 0.296875 0.390625
iteration 337: loss 1.186 0.320312 0.390625
iteration 338: loss 0.929 0.343750 0.453125
iteration 339: loss 1.251 0.242188 0.445312
iteration 340: loss 1.056 0.335938 0.562500
iteration 341: loss 1.082 0.359375 0.437500
iteration 342: loss 1.346 0.289062 0.429688
iteration 343: loss 0.881 0.343750 0.421875
iteration 344: loss 1.302 0.257812 0.382812
iteration 345: loss 1.148 0.273438 0.335938
iteration 346: loss 1.042 0.351562 0.421875
iteration 347: loss 1.441 0.351562 0.359375
iteration 348: loss 0.963 0.382812 0.390625
iteration 349: loss 1.306 0.328125 0.390625
iteration 350: loss 1.073 0.421875 0.453125
iteration 351: loss 1.033 0.390625 0.476562
iteration 352: loss 1.300 0.445312 0.500000
iteration 353: loss 1.189 0.375000 0.460938
iteration 354: loss 1.449 0.390625 0.445312
iteration 355: loss 1.353 0.312500 0.492188
iteration 356: loss 1.129 0.375000 0.476562
iteration 357: loss 0.956 0.421875 0.531250
iteration 358: loss 0.941 0.296875 0.554688
iteration 359: loss 1.246 0.359375 0.445312
iteration 360: loss 1.191 0.312500 0.421875
iteration 361: loss 1.249 0.265625 0.398438
iteration 362: loss 1.011 0.265625 0.484375
iteration 363: loss 1.145 0.289062 0.453125
iteration 364: loss 1.291 0.414062 0.500000
iteration 365: loss 1.326 0.296875 0.328125
iteration 366: loss 1.420 0.242188 0.351562
iteration 367: loss 0.971 0.375000 0.382812
iteration 368: loss 1.259 0.296875 0.414062
iteration 369: loss 1.100 0.273438 0.390625
iteration 370: loss 1.073 0.351562 0.437500
iteration 371: loss 1.026 0.312500 0.445312
iteration 372: loss 0.982 0.304688 0.445312
iteration 373: loss 1.229 0.320312 0.492188
iteration 374: loss 1.075 0.328125 0.421875
iteration 375: loss 1.150 0.296875 0.437500
iteration 376: loss 1.090 0.312500 0.390625
iteration 377: loss 1.057 0.296875 0.406250
iteration 378: loss 0.950 0.351562 0.476562
iteration 379: loss 1.217 0.335938 0.468750
iteration 380: loss 0.970 0.320312 0.460938
iteration 381: loss 1.043 0.312500 0.453125
iteration 382: loss 1.150 0.320312 0.437500
iteration 383: loss 1.210 0.250000 0.351562
iteration 384: loss 1.325 0.359375 0.351562
iteration 385: loss 0.728 0.382812 0.578125
iteration 386: loss 0.916 0.343750 0.554688
iteration 387: loss 0.897 0.304688 0.562500
iteration 388: loss 1.163 0.265625 0.546875
iteration 389: loss 1.280 0.320312 0.468750
iteration 390: loss 1.004 0.296875 0.468750
iteration 391: loss 1.181 0.328125 0.351562
iteration 392: loss 1.205 0.343750 0.382812
iteration 393: loss 0.919 0.328125 0.500000
iteration 394: loss 1.020 0.382812 0.453125
iteration 395: loss 1.149 0.343750 0.421875
iteration 396: loss 1.135 0.351562 0.468750
iteration 397: loss 1.246 0.390625 0.476562
iteration 398: loss 1.290 0.304688 0.406250
iteration 399: loss 1.472 0.390625 0.406250
iteration 400: loss 0.889 0.359375 0.437500
iteration 401: loss 1.086 0.296875 0.445312
iteration 402: loss 0.839 0.257812 0.445312
iteration 403: loss 1.363 0.296875 0.335938
iteration 404: loss 1.065 0.234375 0.382812
iteration 405: loss 0.955 0.351562 0.515625
iteration 406: loss 0.949 0.343750 0.445312
iteration 407: loss 1.021 0.382812 0.507812
iteration 408: loss 0.865 0.289062 0.515625
iteration 409: loss 1.249 0.296875 0.414062
iteration 410: loss 1.049 0.359375 0.460938
iteration 411: loss 1.062 0.343750 0.523438
iteration 412: loss 1.178 0.375000 0.468750
iteration 413: loss 1.243 0.273438 0.367188
iteration 414: loss 1.115 0.273438 0.406250
iteration 415: loss 1.065 0.320312 0.421875
iteration 416: loss 1.291 0.296875 0.343750
iteration 417: loss 1.192 0.265625 0.421875
iteration 418: loss 1.006 0.382812 0.453125
iteration 419: loss 1.366 0.281250 0.421875
iteration 420: loss 0.899 0.328125 0.500000
iteration 421: loss 1.098 0.351562 0.421875
iteration 422: loss 0.991 0.320312 0.468750
iteration 423: loss 0.928 0.320312 0.500000
iteration 424: loss 1.098 0.312500 0.453125
iteration 425: loss 1.616 0.281250 0.351562
iteration 426: loss 1.080 0.273438 0.429688
iteration 427: loss 1.079 0.343750 0.429688
iteration 428: loss 1.100 0.281250 0.367188
iteration 429: loss 0.736 0.351562 0.546875
iteration 430: loss 1.119 0.281250 0.429688
iteration 431: loss 0.910 0.257812 0.468750
iteration 432: loss 1.206 0.343750 0.414062
iteration 433: loss 1.111 0.320312 0.468750
iteration 434: loss 0.970 0.367188 0.453125
iteration 435: loss 1.049 0.304688 0.460938
iteration 436: loss 1.136 0.351562 0.492188
iteration 437: loss 1.209 0.359375 0.468750
iteration 438: loss 1.047 0.351562 0.500000
iteration 439: loss 1.045 0.351562 0.484375
iteration 440: loss 1.280 0.312500 0.398438
iteration 441: loss 1.043 0.351562 0.421875
iteration 442: loss 1.059 0.289062 0.406250
iteration 443: loss 1.142 0.421875 0.460938
iteration 444: loss 1.093 0.328125 0.453125
iteration 445: loss 0.944 0.320312 0.367188
iteration 446: loss 1.141 0.304688 0.421875
iteration 447: loss 0.989 0.335938 0.453125
iteration 448: loss 1.020 0.367188 0.515625
iteration 449: loss 1.383 0.210938 0.406250
iteration 450: loss 1.368 0.312500 0.460938
iteration 451: loss 1.136 0.414062 0.453125
iteration 452: loss 1.170 0.289062 0.468750
iteration 453: loss 0.951 0.312500 0.429688
iteration 454: loss 1.141 0.312500 0.414062
iteration 455: loss 1.120 0.234375 0.453125
iteration 456: loss 0.814 0.375000 0.539062
iteration 457: loss 1.411 0.328125 0.500000
iteration 458: loss 1.071 0.343750 0.468750
iteration 459: loss 1.194 0.343750 0.382812
iteration 460: loss 1.011 0.359375 0.492188
iteration 461: loss 0.910 0.390625 0.500000
iteration 462: loss 1.354 0.273438 0.375000
iteration 463: loss 1.237 0.343750 0.437500
iteration 464: loss 0.980 0.351562 0.453125
iteration 465: loss 1.036 0.359375 0.460938
iteration 466: loss 1.488 0.382812 0.460938
iteration 467: loss 0.852 0.367188 0.445312
iteration 468: loss 0.985 0.359375 0.414062
iteration 469: loss 1.231 0.328125 0.421875
iteration 470: loss 1.169 0.382812 0.375000
iteration 471: loss 1.386 0.312500 0.437500
iteration 472: loss 1.404 0.281250 0.398438
iteration 473: loss 1.070 0.312500 0.421875
iteration 474: loss 0.914 0.375000 0.492188
iteration 475: loss 1.309 0.289062 0.367188
iteration 476: loss 1.352 0.265625 0.375000
iteration 477: loss 1.014 0.359375 0.429688
iteration 478: loss 1.714 0.289062 0.335938
iteration 479: loss 0.951 0.289062 0.437500
iteration 480: loss 1.115 0.289062 0.398438
iteration 481: loss 1.530 0.367188 0.507812
iteration 482: loss 1.185 0.281250 0.429688
iteration 483: loss 0.907 0.390625 0.476562
iteration 484: loss 1.041 0.359375 0.484375
iteration 485: loss 0.936 0.242188 0.500000
iteration 486: loss 1.052 0.257812 0.437500
iteration 487: loss 0.815 0.335938 0.484375
iteration 488: loss 0.919 0.273438 0.445312
iteration 489: loss 1.100 0.367188 0.445312
iteration 490: loss 1.022 0.312500 0.445312
iteration 491: loss 1.047 0.265625 0.468750
iteration 492: loss 1.435 0.335938 0.406250
iteration 493: loss 1.078 0.320312 0.375000
iteration 494: loss 0.997 0.328125 0.492188
iteration 495: loss 0.904 0.273438 0.539062
iteration 496: loss 1.157 0.343750 0.445312
iteration 497: loss 1.070 0.390625 0.531250
iteration 498: loss 1.044 0.328125 0.421875
iteration 499: loss 0.962 0.335938 0.437500
iteration 500: loss 0.811 0.296875 0.531250
iteration 501: loss 1.056 0.312500 0.476562
iteration 502: loss 1.139 0.289062 0.476562
iteration 503: loss 0.835 0.304688 0.492188
iteration 504: loss 0.932 0.328125 0.500000
iteration 505: loss 1.154 0.320312 0.468750
iteration 506: loss 0.864 0.289062 0.476562
iteration 507: loss 0.988 0.304688 0.468750
iteration 508: loss 0.895 0.312500 0.445312
iteration 509: loss 1.209 0.312500 0.390625
iteration 510: loss 1.000 0.304688 0.492188
iteration 511: loss 1.295 0.320312 0.437500
iteration 512: loss 0.961 0.328125 0.445312
iteration 513: loss 1.170 0.359375 0.453125
iteration 514: loss 0.862 0.406250 0.546875
iteration 515: loss 1.230 0.304688 0.414062
iteration 516: loss 1.270 0.265625 0.406250
iteration 517: loss 1.157 0.343750 0.398438
iteration 518: loss 0.937 0.296875 0.484375
iteration 519: loss 1.026 0.312500 0.453125
iteration 520: loss 0.838 0.351562 0.476562
iteration 521: loss 0.848 0.414062 0.492188
iteration 522: loss 0.959 0.218750 0.500000
iteration 523: loss 1.104 0.234375 0.398438
iteration 524: loss 1.111 0.328125 0.500000
iteration 525: loss 0.888 0.367188 0.468750
iteration 526: loss 1.347 0.281250 0.421875
iteration 527: loss 1.000 0.312500 0.421875
iteration 528: loss 1.051 0.257812 0.445312
iteration 529: loss 0.953 0.335938 0.414062
iteration 530: loss 1.028 0.218750 0.421875
iteration 531: loss 0.924 0.304688 0.460938
iteration 532: loss 0.875 0.281250 0.445312
iteration 533: loss 0.951 0.265625 0.445312
iteration 534: loss 1.077 0.296875 0.453125
iteration 535: loss 1.317 0.320312 0.492188
iteration 536: loss 1.175 0.312500 0.476562
iteration 537: loss 1.153 0.359375 0.476562
iteration 538: loss 1.085 0.328125 0.437500
iteration 539: loss 1.350 0.468750 0.429688
iteration 540: loss 1.035 0.304688 0.476562
iteration 541: loss 0.976 0.320312 0.445312
iteration 542: loss 1.067 0.335938 0.437500
iteration 543: loss 0.953 0.320312 0.507812
iteration 544: loss 1.094 0.335938 0.414062
iteration 545: loss 0.998 0.351562 0.476562
iteration 546: loss 1.047 0.335938 0.398438
iteration 547: loss 1.332 0.296875 0.453125
iteration 548: loss 1.180 0.359375 0.484375
iteration 549: loss 0.903 0.351562 0.453125
iteration 550: loss 1.334 0.281250 0.312500
iteration 551: loss 1.126 0.359375 0.429688
iteration 552: loss 0.978 0.265625 0.468750
iteration 553: loss 0.973 0.257812 0.421875
iteration 554: loss 1.207 0.296875 0.445312
iteration 555: loss 1.309 0.265625 0.406250
iteration 556: loss 1.179 0.335938 0.429688
iteration 557: loss 1.188 0.281250 0.414062
iteration 558: loss 0.869 0.414062 0.437500
iteration 559: loss 1.162 0.359375 0.421875
iteration 560: loss 1.162 0.273438 0.453125
iteration 561: loss 0.981 0.375000 0.460938
iteration 562: loss 1.006 0.273438 0.476562
iteration 563: loss 1.048 0.335938 0.414062
iteration 564: loss 0.940 0.312500 0.507812
iteration 565: loss 0.856 0.367188 0.562500
iteration 566: loss 1.078 0.320312 0.421875
iteration 567: loss 1.172 0.375000 0.406250
iteration 568: loss 0.994 0.367188 0.414062
iteration 569: loss 1.149 0.335938 0.445312
iteration 570: loss 1.565 0.359375 0.421875
iteration 571: loss 1.143 0.289062 0.429688
iteration 572: loss 1.018 0.335938 0.468750
iteration 573: loss 1.096 0.320312 0.468750
iteration 574: loss 1.125 0.359375 0.476562
iteration 575: loss 1.102 0.343750 0.453125
iteration 576: loss 0.968 0.273438 0.453125
iteration 577: loss 1.223 0.328125 0.367188
iteration 578: loss 1.318 0.281250 0.359375
iteration 579: loss 1.031 0.351562 0.421875
iteration 580: loss 1.085 0.335938 0.390625
iteration 581: loss 1.026 0.296875 0.476562
iteration 582: loss 1.142 0.242188 0.429688
iteration 583: loss 1.032 0.304688 0.484375
iteration 584: loss 1.284 0.281250 0.406250
iteration 585: loss 0.938 0.335938 0.500000
iteration 586: loss 1.105 0.367188 0.437500
iteration 587: loss 0.956 0.343750 0.437500
iteration 588: loss 1.015 0.296875 0.468750
iteration 589: loss 1.226 0.265625 0.421875
iteration 590: loss 0.839 0.265625 0.453125
iteration 591: loss 1.026 0.289062 0.507812
iteration 592: loss 1.039 0.359375 0.468750
iteration 593: loss 1.065 0.343750 0.437500
iteration 594: loss 1.507 0.320312 0.375000
iteration 595: loss 1.154 0.289062 0.429688
iteration 596: loss 0.979 0.351562 0.421875
iteration 597: loss 1.067 0.226562 0.359375
iteration 598: loss 0.919 0.273438 0.406250
iteration 599: loss 1.009 0.250000 0.421875
iteration 600: loss 0.969 0.312500 0.476562
iteration 601: loss 1.038 0.359375 0.453125
iteration 602: loss 0.922 0.281250 0.523438
iteration 603: loss 0.910 0.351562 0.460938
iteration 604: loss 1.074 0.335938 0.406250
iteration 605: loss 1.125 0.281250 0.460938
iteration 606: loss 1.091 0.304688 0.421875
iteration 607: loss 1.096 0.359375 0.460938
iteration 608: loss 1.082 0.335938 0.429688
iteration 609: loss 1.107 0.281250 0.460938
iteration 610: loss 0.959 0.351562 0.421875
iteration 611: loss 0.939 0.335938 0.492188
iteration 612: loss 1.028 0.289062 0.367188
iteration 613: loss 0.953 0.343750 0.437500
iteration 614: loss 1.110 0.328125 0.453125
iteration 615: loss 0.877 0.257812 0.445312
iteration 616: loss 0.984 0.304688 0.375000
iteration 617: loss 0.928 0.273438 0.414062
iteration 618: loss 1.027 0.320312 0.468750
iteration 619: loss 1.152 0.359375 0.414062
iteration 620: loss 0.923 0.328125 0.421875
iteration 621: loss 1.148 0.382812 0.445312
iteration 622: loss 0.941 0.382812 0.460938
iteration 623: loss 1.038 0.367188 0.453125
iteration 624: loss 1.206 0.304688 0.546875
iteration 625: loss 1.208 0.304688 0.382812
iteration 626: loss 0.886 0.296875 0.492188
iteration 627: loss 0.995 0.367188 0.437500
iteration 628: loss 1.217 0.367188 0.554688
iteration 629: loss 0.980 0.398438 0.414062
iteration 630: loss 1.156 0.296875 0.398438
iteration 631: loss 0.973 0.335938 0.437500
iteration 632: loss 1.037 0.367188 0.476562
iteration 633: loss 1.242 0.265625 0.398438
iteration 634: loss 1.252 0.375000 0.468750
iteration 635: loss 1.061 0.304688 0.414062
iteration 636: loss 1.075 0.343750 0.476562
iteration 637: loss 1.049 0.335938 0.437500
iteration 638: loss 0.867 0.312500 0.476562
iteration 639: loss 0.837 0.359375 0.460938
iteration 640: loss 1.118 0.304688 0.406250
iteration 641: loss 1.275 0.367188 0.453125
iteration 642: loss 1.057 0.328125 0.437500
iteration 643: loss 1.099 0.242188 0.445312
iteration 644: loss 1.105 0.289062 0.437500
iteration 645: loss 1.016 0.351562 0.406250
iteration 646: loss 1.419 0.328125 0.390625
iteration 647: loss 1.162 0.273438 0.437500
iteration 648: loss 1.358 0.296875 0.320312
iteration 649: loss 0.927 0.296875 0.476562
iteration 650: loss 1.089 0.320312 0.453125
iteration 651: loss 1.199 0.320312 0.437500
iteration 652: loss 0.835 0.312500 0.578125
iteration 653: loss 1.283 0.320312 0.406250
iteration 654: loss 1.046 0.351562 0.476562
iteration 655: loss 1.063 0.382812 0.437500
iteration 656: loss 1.007 0.296875 0.507812
iteration 657: loss 1.062 0.304688 0.460938
iteration 658: loss 1.156 0.281250 0.406250
iteration 659: loss 0.958 0.320312 0.445312
iteration 660: loss 1.113 0.281250 0.500000
iteration 661: loss 0.929 0.343750 0.476562
iteration 662: loss 1.168 0.367188 0.445312
iteration 663: loss 1.063 0.273438 0.398438
iteration 664: loss 1.079 0.359375 0.406250
iteration 665: loss 0.966 0.367188 0.484375
iteration 666: loss 0.869 0.351562 0.484375
iteration 667: loss 1.215 0.328125 0.390625
iteration 668: loss 1.081 0.265625 0.382812
iteration 669: loss 0.852 0.273438 0.460938
iteration 670: loss 1.173 0.257812 0.382812
iteration 671: loss 1.148 0.312500 0.398438
iteration 672: loss 0.901 0.273438 0.453125
iteration 673: loss 1.012 0.328125 0.507812
iteration 674: loss 1.113 0.312500 0.468750
iteration 675: loss 1.074 0.289062 0.429688
iteration 676: loss 1.074 0.273438 0.453125
iteration 677: loss 0.957 0.312500 0.453125
iteration 678: loss 1.128 0.296875 0.398438
iteration 679: loss 1.055 0.375000 0.351562
iteration 680: loss 1.076 0.382812 0.367188
iteration 681: loss 1.034 0.281250 0.453125
iteration 682: loss 1.065 0.273438 0.359375
iteration 683: loss 1.059 0.234375 0.421875
iteration 684: loss 0.912 0.250000 0.468750
iteration 685: loss 1.165 0.359375 0.414062
iteration 686: loss 1.059 0.351562 0.460938
iteration 687: loss 1.103 0.359375 0.468750
iteration 688: loss 0.986 0.351562 0.492188
iteration 689: loss 1.046 0.390625 0.460938
iteration 690: loss 0.958 0.406250 0.523438
iteration 691: loss 0.934 0.382812 0.492188
iteration 692: loss 1.096 0.343750 0.460938
iteration 693: loss 0.988 0.359375 0.429688
iteration 694: loss 0.997 0.328125 0.539062
iteration 695: loss 0.995 0.367188 0.515625
iteration 696: loss 1.078 0.351562 0.437500
iteration 697: loss 1.297 0.296875 0.351562
iteration 698: loss 1.042 0.265625 0.406250
iteration 699: loss 0.989 0.312500 0.335938
iteration 700: loss 1.058 0.359375 0.367188
iteration 701: loss 1.154 0.343750 0.351562
iteration 702: loss 1.318 0.328125 0.468750
iteration 703: loss 0.892 0.250000 0.468750
iteration 704: loss 0.827 0.390625 0.460938
iteration 705: loss 1.097 0.343750 0.421875
iteration 706: loss 1.256 0.304688 0.367188
iteration 707: loss 1.125 0.320312 0.414062
iteration 708: loss 1.117 0.351562 0.437500
iteration 709: loss 0.912 0.359375 0.445312
iteration 710: loss 1.091 0.335938 0.421875
iteration 711: loss 0.942 0.273438 0.460938
iteration 712: loss 0.891 0.367188 0.421875
iteration 713: loss 1.054 0.351562 0.460938
iteration 714: loss 0.782 0.289062 0.523438
iteration 715: loss 1.083 0.312500 0.460938
iteration 716: loss 0.975 0.296875 0.460938
iteration 717: loss 1.219 0.390625 0.437500
iteration 718: loss 0.920 0.289062 0.507812
iteration 719: loss 1.238 0.320312 0.437500
iteration 720: loss 1.222 0.312500 0.398438
iteration 721: loss 1.077 0.304688 0.390625
iteration 722: loss 0.883 0.406250 0.421875
iteration 723: loss 1.064 0.304688 0.437500
iteration 724: loss 0.844 0.312500 0.492188
iteration 725: loss 1.139 0.218750 0.453125
iteration 726: loss 1.009 0.328125 0.406250
iteration 727: loss 1.372 0.296875 0.343750
iteration 728: loss 0.800 0.359375 0.531250
iteration 729: loss 0.894 0.359375 0.468750
iteration 730: loss 0.854 0.335938 0.492188
iteration 731: loss 0.918 0.382812 0.515625
iteration 732: loss 0.812 0.265625 0.507812
iteration 733: loss 1.101 0.296875 0.492188
iteration 734: loss 1.051 0.343750 0.414062
iteration 735: loss 0.935 0.351562 0.468750
iteration 736: loss 1.174 0.289062 0.445312
iteration 737: loss 0.684 0.289062 0.523438
iteration 738: loss 0.928 0.335938 0.445312
iteration 739: loss 1.217 0.351562 0.375000
iteration 740: loss 1.286 0.335938 0.445312
iteration 741: loss 0.941 0.289062 0.484375
iteration 742: loss 0.926 0.257812 0.460938
iteration 743: loss 1.181 0.257812 0.406250
iteration 744: loss 1.034 0.296875 0.421875
iteration 745: loss 0.950 0.359375 0.476562
iteration 746: loss 1.070 0.296875 0.484375
iteration 747: loss 0.880 0.328125 0.484375
iteration 748: loss 1.000 0.367188 0.515625
iteration 749: loss 0.889 0.351562 0.492188
iteration 750: loss 0.833 0.367188 0.460938
iteration 751: loss 1.152 0.359375 0.468750
iteration 752: loss 1.051 0.328125 0.484375
iteration 753: loss 1.120 0.273438 0.492188
iteration 754: loss 0.894 0.343750 0.453125
iteration 755: loss 0.818 0.320312 0.437500
iteration 756: loss 0.967 0.406250 0.437500
iteration 757: loss 0.992 0.328125 0.382812
iteration 758: loss 1.191 0.289062 0.359375
iteration 759: loss 1.048 0.320312 0.468750
iteration 760: loss 1.100 0.257812 0.453125
iteration 761: loss 1.166 0.343750 0.445312
iteration 762: loss 1.090 0.312500 0.460938
iteration 763: loss 0.963 0.265625 0.453125
iteration 764: loss 0.945 0.312500 0.429688
iteration 765: loss 0.927 0.367188 0.507812
iteration 766: loss 1.020 0.328125 0.460938
iteration 767: loss 0.943 0.351562 0.414062
iteration 768: loss 0.824 0.367188 0.468750
iteration 769: loss 1.061 0.320312 0.390625
iteration 770: loss 1.004 0.234375 0.375000
iteration 771: loss 0.809 0.304688 0.492188
iteration 772: loss 1.106 0.398438 0.445312
iteration 773: loss 0.918 0.343750 0.437500
iteration 774: loss 0.790 0.390625 0.523438
iteration 775: loss 0.768 0.289062 0.562500
iteration 776: loss 1.093 0.382812 0.429688
iteration 777: loss 1.015 0.359375 0.445312
iteration 778: loss 0.938 0.359375 0.460938
iteration 779: loss 1.059 0.343750 0.468750
iteration 780: loss 1.057 0.273438 0.406250
iteration 781: loss 1.048 0.343750 0.468750
iteration 782: loss 0.907 0.343750 0.429688
iteration 783: loss 0.939 0.335938 0.437500
iteration 784: loss 1.184 0.335938 0.453125
iteration 785: loss 1.071 0.328125 0.476562
iteration 786: loss 1.036 0.273438 0.375000
iteration 787: loss 1.111 0.312500 0.406250
iteration 788: loss 0.828 0.328125 0.445312
iteration 789: loss 0.883 0.328125 0.476562
iteration 790: loss 1.117 0.343750 0.398438
iteration 791: loss 1.014 0.320312 0.468750
iteration 792: loss 1.149 0.328125 0.437500
iteration 793: loss 1.484 0.429688 0.484375
iteration 794: loss 1.005 0.304688 0.468750
iteration 795: loss 1.025 0.343750 0.398438
iteration 796: loss 0.920 0.328125 0.453125
iteration 797: loss 0.798 0.312500 0.484375
iteration 798: loss 1.122 0.281250 0.421875
iteration 799: loss 0.920 0.335938 0.468750
iteration 800: loss 0.924 0.343750 0.437500
iteration 801: loss 0.956 0.250000 0.445312
iteration 802: loss 1.174 0.437500 0.398438
iteration 803: loss 1.110 0.390625 0.359375
iteration 804: loss 1.011 0.375000 0.492188
iteration 805: loss 0.997 0.328125 0.460938
iteration 806: loss 1.104 0.375000 0.414062
iteration 807: loss 1.212 0.320312 0.406250
iteration 808: loss 0.894 0.375000 0.406250
iteration 809: loss 1.005 0.367188 0.367188
iteration 810: loss 0.824 0.351562 0.468750
iteration 811: loss 0.961 0.320312 0.414062
iteration 812: loss 0.970 0.218750 0.437500
iteration 813: loss 1.101 0.390625 0.390625
iteration 814: loss 0.851 0.250000 0.500000
iteration 815: loss 0.780 0.335938 0.523438
iteration 816: loss 1.024 0.320312 0.445312
iteration 817: loss 0.981 0.273438 0.523438
iteration 818: loss 1.134 0.296875 0.484375
iteration 819: loss 1.059 0.296875 0.476562
iteration 820: loss 1.061 0.390625 0.468750
iteration 821: loss 1.175 0.328125 0.414062
iteration 822: loss 1.138 0.265625 0.437500
iteration 823: loss 1.054 0.265625 0.437500
iteration 824: loss 1.109 0.281250 0.398438
iteration 825: loss 0.811 0.304688 0.484375
iteration 826: loss 1.025 0.367188 0.359375
iteration 827: loss 1.024 0.351562 0.437500
iteration 828: loss 1.350 0.281250 0.437500
iteration 829: loss 1.096 0.296875 0.437500
iteration 830: loss 1.092 0.289062 0.484375
iteration 831: loss 0.891 0.414062 0.492188
iteration 832: loss 1.279 0.304688 0.453125
iteration 833: loss 1.106 0.335938 0.398438
iteration 834: loss 0.833 0.304688 0.437500
iteration 835: loss 1.304 0.265625 0.406250
iteration 836: loss 1.060 0.375000 0.445312
iteration 837: loss 1.215 0.359375 0.437500
iteration 838: loss 1.110 0.273438 0.351562
iteration 839: loss 0.916 0.320312 0.453125
iteration 840: loss 1.163 0.382812 0.398438
iteration 841: loss 1.086 0.343750 0.476562
iteration 842: loss 1.013 0.281250 0.414062
iteration 843: loss 0.861 0.312500 0.507812
iteration 844: loss 1.033 0.320312 0.351562
iteration 845: loss 1.408 0.421875 0.453125
iteration 846: loss 0.990 0.398438 0.507812
iteration 847: loss 1.004 0.367188 0.468750
iteration 848: loss 0.905 0.328125 0.500000
iteration 849: loss 1.086 0.351562 0.398438
iteration 850: loss 0.943 0.406250 0.414062
iteration 851: loss 1.172 0.281250 0.437500
iteration 852: loss 0.931 0.367188 0.453125
iteration 853: loss 0.935 0.390625 0.453125
iteration 854: loss 1.017 0.320312 0.398438
iteration 855: loss 0.897 0.367188 0.539062
iteration 856: loss 1.258 0.296875 0.351562
iteration 857: loss 1.139 0.312500 0.382812
iteration 858: loss 1.278 0.343750 0.531250
iteration 859: loss 0.730 0.210938 0.523438
iteration 860: loss 0.880 0.250000 0.500000
iteration 861: loss 1.055 0.281250 0.453125
iteration 862: loss 0.897 0.304688 0.335938
iteration 863: loss 0.990 0.289062 0.367188
iteration 864: loss 1.164 0.335938 0.351562
iteration 865: loss 1.197 0.328125 0.421875
iteration 866: loss 1.047 0.289062 0.453125
iteration 867: loss 1.122 0.359375 0.500000
iteration 868: loss 0.996 0.257812 0.414062
iteration 869: loss 0.961 0.296875 0.468750
iteration 870: loss 1.091 0.312500 0.398438
iteration 871: loss 1.130 0.320312 0.460938
iteration 872: loss 1.200 0.296875 0.421875
iteration 873: loss 1.393 0.335938 0.468750
iteration 874: loss 1.090 0.375000 0.406250
iteration 875: loss 1.285 0.367188 0.429688
iteration 876: loss 1.103 0.367188 0.445312
iteration 877: loss 1.133 0.226562 0.460938
iteration 878: loss 0.732 0.289062 0.515625
iteration 879: loss 1.265 0.351562 0.468750
iteration 880: loss 1.047 0.367188 0.476562
iteration 881: loss 1.000 0.312500 0.507812
iteration 882: loss 1.613 0.250000 0.414062
iteration 883: loss 1.149 0.406250 0.398438
iteration 884: loss 0.760 0.328125 0.554688
iteration 885: loss 1.046 0.304688 0.421875
iteration 886: loss 0.963 0.304688 0.476562
iteration 887: loss 1.110 0.343750 0.437500
iteration 888: loss 0.912 0.335938 0.484375
iteration 889: loss 0.962 0.312500 0.406250
iteration 890: loss 0.838 0.320312 0.421875
iteration 891: loss 0.839 0.320312 0.500000
iteration 892: loss 0.938 0.320312 0.500000
iteration 893: loss 1.026 0.312500 0.437500
iteration 894: loss 1.168 0.343750 0.437500
iteration 895: loss 1.186 0.343750 0.476562
iteration 896: loss 1.001 0.320312 0.437500
iteration 897: loss 1.021 0.265625 0.500000
iteration 898: loss 1.029 0.289062 0.390625
iteration 899: loss 0.905 0.328125 0.437500
iteration 900: loss 0.866 0.390625 0.507812
iteration 901: loss 1.029 0.257812 0.437500
iteration 902: loss 0.949 0.273438 0.429688
iteration 903: loss 0.872 0.359375 0.476562
iteration 904: loss 0.884 0.320312 0.445312
iteration 905: loss 0.832 0.375000 0.507812
iteration 906: loss 1.036 0.359375 0.492188
iteration 907: loss 1.019 0.367188 0.406250
iteration 908: loss 1.137 0.257812 0.476562
iteration 909: loss 0.950 0.351562 0.453125
iteration 910: loss 1.011 0.390625 0.484375
iteration 911: loss 1.448 0.234375 0.437500
iteration 912: loss 1.003 0.296875 0.468750
iteration 913: loss 1.138 0.304688 0.453125
iteration 914: loss 1.254 0.320312 0.398438
iteration 915: loss 0.781 0.257812 0.492188
iteration 916: loss 1.352 0.281250 0.320312
iteration 917: loss 0.939 0.296875 0.398438
iteration 918: loss 0.764 0.335938 0.515625
iteration 919: loss 1.130 0.320312 0.421875
iteration 920: loss 1.009 0.273438 0.421875
iteration 921: loss 1.050 0.335938 0.414062
iteration 922: loss 1.011 0.359375 0.429688
iteration 923: loss 1.211 0.335938 0.437500
iteration 924: loss 1.260 0.312500 0.390625
iteration 925: loss 0.956 0.335938 0.453125
iteration 926: loss 1.118 0.320312 0.367188
iteration 927: loss 1.077 0.335938 0.460938
iteration 928: loss 1.093 0.320312 0.460938
iteration 929: loss 1.159 0.375000 0.453125
iteration 930: loss 0.791 0.312500 0.515625
iteration 931: loss 0.896 0.367188 0.539062
iteration 932: loss 1.003 0.242188 0.468750
iteration 933: loss 1.108 0.265625 0.453125
iteration 934: loss 1.117 0.257812 0.406250
iteration 935: loss 1.121 0.257812 0.390625
iteration 936: loss 1.116 0.273438 0.382812
iteration 937: loss 1.194 0.328125 0.382812
iteration 938: loss 0.954 0.375000 0.421875
iteration 939: loss 0.925 0.218750 0.453125
iteration 940: loss 1.108 0.343750 0.398438
iteration 941: loss 0.865 0.218750 0.515625
iteration 942: loss 1.021 0.390625 0.375000
iteration 943: loss 1.347 0.328125 0.390625
iteration 944: loss 0.688 0.367188 0.609375
iteration 945: loss 0.901 0.382812 0.476562
iteration 946: loss 0.842 0.242188 0.468750
iteration 947: loss 0.872 0.296875 0.453125
iteration 948: loss 0.984 0.289062 0.492188
iteration 949: loss 1.127 0.289062 0.421875
iteration 950: loss 1.124 0.320312 0.406250
iteration 951: loss 0.932 0.335938 0.453125
iteration 952: loss 1.052 0.320312 0.445312
iteration 953: loss 0.932 0.289062 0.476562
iteration 954: loss 1.020 0.367188 0.453125
iteration 955: loss 0.776 0.296875 0.523438
iteration 956: loss 1.129 0.335938 0.406250
iteration 957: loss 0.936 0.398438 0.500000
iteration 958: loss 0.964 0.335938 0.453125
iteration 959: loss 0.979 0.273438 0.437500
iteration 960: loss 0.933 0.281250 0.429688
iteration 961: loss 1.009 0.328125 0.500000
iteration 962: loss 1.014 0.296875 0.476562
iteration 963: loss 1.170 0.320312 0.476562
iteration 964: loss 0.893 0.304688 0.468750
iteration 965: loss 1.085 0.234375 0.414062
iteration 966: loss 1.019 0.296875 0.375000
iteration 967: loss 0.991 0.289062 0.460938
iteration 968: loss 1.141 0.335938 0.312500
iteration 969: loss 0.983 0.406250 0.414062
iteration 970: loss 0.853 0.328125 0.515625
iteration 971: loss 1.035 0.351562 0.460938
iteration 972: loss 0.808 0.335938 0.515625
iteration 973: loss 0.900 0.343750 0.562500
iteration 974: loss 1.110 0.335938 0.476562
iteration 975: loss 0.794 0.320312 0.468750
iteration 976: loss 1.145 0.328125 0.406250
iteration 977: loss 1.080 0.296875 0.437500
iteration 978: loss 1.107 0.328125 0.429688
iteration 979: loss 1.005 0.312500 0.507812
iteration 980: loss 1.015 0.273438 0.359375
iteration 981: loss 0.893 0.304688 0.453125
iteration 982: loss 1.000 0.351562 0.414062
iteration 983: loss 1.144 0.351562 0.468750
iteration 984: loss 0.959 0.382812 0.484375
iteration 985: loss 0.984 0.335938 0.468750
iteration 986: loss 0.895 0.414062 0.507812
iteration 987: loss 1.166 0.312500 0.453125
iteration 988: loss 0.945 0.398438 0.460938
iteration 989: loss 0.956 0.304688 0.453125
iteration 990: loss 0.927 0.328125 0.476562
iteration 991: loss 1.087 0.304688 0.421875
iteration 992: loss 1.312 0.335938 0.468750
iteration 993: loss 1.189 0.296875 0.414062
iteration 994: loss 0.844 0.250000 0.476562
iteration 995: loss 0.899 0.359375 0.453125
iteration 996: loss 0.931 0.343750 0.421875
iteration 997: loss 0.904 0.312500 0.429688
iteration 998: loss 0.844 0.390625 0.437500
iteration 999: loss 1.326 0.304688 0.367188
epoch 3: training: 0.273438 validation: 0.195312
iteration 0: loss 0.890 0.382812 0.460938
iteration 1: loss 1.051 0.304688 0.437500
iteration 2: loss 1.016 0.312500 0.460938
iteration 3: loss 0.915 0.250000 0.437500
iteration 4: loss 0.828 0.273438 0.500000
iteration 5: loss 0.968 0.351562 0.437500
iteration 6: loss 0.832 0.296875 0.460938
iteration 7: loss 0.882 0.343750 0.476562
iteration 8: loss 0.938 0.320312 0.398438
iteration 9: loss 0.943 0.328125 0.429688
iteration 10: loss 1.081 0.273438 0.460938
iteration 11: loss 0.884 0.343750 0.460938
iteration 12: loss 1.098 0.359375 0.359375
iteration 13: loss 1.037 0.234375 0.429688
iteration 14: loss 0.777 0.257812 0.484375
iteration 15: loss 1.045 0.343750 0.468750
iteration 16: loss 1.213 0.312500 0.351562
iteration 17: loss 1.110 0.351562 0.406250
iteration 18: loss 0.773 0.351562 0.507812
iteration 19: loss 0.858 0.281250 0.445312
iteration 20: loss 0.940 0.250000 0.429688
iteration 21: loss 0.879 0.242188 0.468750
iteration 22: loss 0.895 0.328125 0.421875
iteration 23: loss 1.042 0.296875 0.406250
iteration 24: loss 1.211 0.320312 0.351562
iteration 25: loss 1.083 0.281250 0.414062
iteration 26: loss 0.991 0.343750 0.460938
iteration 27: loss 1.063 0.351562 0.484375
iteration 28: loss 0.950 0.281250 0.468750
iteration 29: loss 0.723 0.312500 0.585938
iteration 30: loss 0.935 0.320312 0.484375
iteration 31: loss 1.295 0.335938 0.398438
iteration 32: loss 0.844 0.320312 0.468750
iteration 33: loss 0.810 0.351562 0.445312
iteration 34: loss 0.922 0.320312 0.460938
iteration 35: loss 1.129 0.296875 0.375000
iteration 36: loss 0.926 0.296875 0.500000
iteration 37: loss 0.911 0.312500 0.429688
iteration 38: loss 1.043 0.328125 0.476562
iteration 39: loss 0.888 0.343750 0.476562
iteration 40: loss 1.042 0.273438 0.445312
iteration 41: loss 0.987 0.273438 0.437500
iteration 42: loss 1.166 0.289062 0.429688
iteration 43: loss 0.975 0.281250 0.476562
iteration 44: loss 0.950 0.367188 0.468750
iteration 45: loss 1.064 0.343750 0.468750
iteration 46: loss 0.972 0.390625 0.468750
iteration 47: loss 1.073 0.312500 0.468750
iteration 48: loss 1.102 0.437500 0.445312
iteration 49: loss 1.056 0.296875 0.421875
iteration 50: loss 0.837 0.398438 0.484375
iteration 51: loss 1.279 0.335938 0.414062
iteration 52: loss 0.935 0.234375 0.445312
iteration 53: loss 1.260 0.406250 0.398438
iteration 54: loss 0.923 0.320312 0.515625
iteration 55: loss 1.343 0.312500 0.367188
iteration 56: loss 0.953 0.281250 0.476562
iteration 57: loss 1.356 0.320312 0.453125
iteration 58: loss 1.222 0.429688 0.398438
iteration 59: loss 1.015 0.359375 0.414062
iteration 60: loss 1.136 0.351562 0.398438
iteration 61: loss 1.067 0.398438 0.445312
iteration 62: loss 0.975 0.335938 0.421875
iteration 63: loss 0.990 0.320312 0.460938
iteration 64: loss 0.747 0.328125 0.453125
iteration 65: loss 1.025 0.312500 0.335938
iteration 66: loss 0.980 0.289062 0.421875
iteration 67: loss 0.842 0.367188 0.437500
iteration 68: loss 0.921 0.273438 0.460938
iteration 69: loss 1.113 0.281250 0.390625
iteration 70: loss 0.874 0.328125 0.476562
iteration 71: loss 0.878 0.265625 0.453125
iteration 72: loss 0.746 0.328125 0.492188
iteration 73: loss 0.984 0.304688 0.515625
iteration 74: loss 0.791 0.289062 0.484375
iteration 75: loss 1.066 0.335938 0.492188
iteration 76: loss 1.594 0.304688 0.382812
iteration 77: loss 1.121 0.367188 0.460938
iteration 78: loss 0.840 0.343750 0.414062
iteration 79: loss 1.073 0.289062 0.398438
iteration 80: loss 1.188 0.296875 0.367188
iteration 81: loss 0.917 0.296875 0.468750
iteration 82: loss 0.949 0.304688 0.476562
iteration 83: loss 0.801 0.351562 0.492188
iteration 84: loss 1.014 0.218750 0.507812
iteration 85: loss 1.332 0.257812 0.484375
iteration 86: loss 1.278 0.320312 0.421875
iteration 87: loss 1.438 0.242188 0.382812
iteration 88: loss 1.006 0.375000 0.484375
iteration 89: loss 0.948 0.257812 0.507812
iteration 90: loss 1.182 0.250000 0.414062
iteration 91: loss 1.089 0.335938 0.476562
iteration 92: loss 0.999 0.351562 0.367188
iteration 93: loss 0.917 0.242188 0.484375
iteration 94: loss 0.859 0.312500 0.468750
iteration 95: loss 0.847 0.421875 0.453125
iteration 96: loss 1.102 0.375000 0.390625
iteration 97: loss 1.201 0.328125 0.421875
iteration 98: loss 0.868 0.304688 0.468750
iteration 99: loss 1.030 0.257812 0.437500
iteration 100: loss 1.268 0.265625 0.406250
iteration 101: loss 1.224 0.343750 0.382812
iteration 102: loss 1.205 0.296875 0.351562
iteration 103: loss 1.147 0.312500 0.406250
iteration 104: loss 0.996 0.296875 0.367188
iteration 105: loss 1.176 0.398438 0.460938
iteration 106: loss 0.973 0.312500 0.351562
iteration 107: loss 0.910 0.367188 0.390625
iteration 108: loss 0.814 0.445312 0.468750
iteration 109: loss 0.791 0.250000 0.484375
iteration 110: loss 1.085 0.359375 0.460938
iteration 111: loss 1.111 0.367188 0.445312
iteration 112: loss 0.712 0.375000 0.578125
iteration 113: loss 1.163 0.359375 0.476562
iteration 114: loss 1.533 0.312500 0.492188
iteration 115: loss 0.980 0.304688 0.437500
iteration 116: loss 1.274 0.359375 0.476562
iteration 117: loss 0.777 0.328125 0.492188
iteration 118: loss 0.935 0.312500 0.437500
iteration 119: loss 1.030 0.398438 0.437500
iteration 120: loss 1.190 0.312500 0.390625
iteration 121: loss 0.956 0.367188 0.484375
iteration 122: loss 1.092 0.257812 0.445312
iteration 123: loss 0.867 0.289062 0.476562
iteration 124: loss 1.137 0.312500 0.468750
iteration 125: loss 1.118 0.281250 0.421875
iteration 126: loss 1.008 0.453125 0.437500
iteration 127: loss 1.364 0.312500 0.429688
iteration 128: loss 1.033 0.328125 0.437500
iteration 129: loss 0.797 0.359375 0.515625
iteration 130: loss 0.918 0.320312 0.398438
iteration 131: loss 1.245 0.359375 0.375000
iteration 132: loss 0.959 0.273438 0.406250
iteration 133: loss 0.708 0.296875 0.507812
iteration 134: loss 0.767 0.359375 0.421875
iteration 135: loss 0.927 0.343750 0.445312
iteration 136: loss 0.974 0.312500 0.406250
iteration 137: loss 0.870 0.359375 0.406250
iteration 138: loss 0.903 0.367188 0.421875
iteration 139: loss 1.169 0.335938 0.390625
iteration 140: loss 0.738 0.273438 0.460938
iteration 141: loss 0.860 0.328125 0.484375
iteration 142: loss 1.202 0.343750 0.367188
iteration 143: loss 0.655 0.351562 0.585938
iteration 144: loss 0.781 0.296875 0.468750
iteration 145: loss 1.350 0.312500 0.382812
iteration 146: loss 1.000 0.328125 0.375000
iteration 147: loss 1.290 0.343750 0.382812
iteration 148: loss 0.981 0.335938 0.367188
iteration 149: loss 0.871 0.375000 0.359375
iteration 150: loss 0.988 0.343750 0.390625
iteration 151: loss 1.033 0.265625 0.343750
iteration 152: loss 1.014 0.335938 0.414062
iteration 153: loss 1.231 0.382812 0.351562
iteration 154: loss 1.069 0.281250 0.421875
iteration 155: loss 0.975 0.257812 0.406250
iteration 156: loss 0.900 0.281250 0.460938
iteration 157: loss 1.467 0.265625 0.367188
iteration 158: loss 0.925 0.320312 0.484375
iteration 159: loss 0.850 0.320312 0.429688
iteration 160: loss 0.813 0.312500 0.437500
iteration 161: loss 1.221 0.312500 0.382812
iteration 162: loss 0.697 0.320312 0.507812
iteration 163: loss 0.893 0.296875 0.468750
iteration 164: loss 0.862 0.359375 0.382812
iteration 165: loss 1.320 0.289062 0.328125
iteration 166: loss 0.829 0.335938 0.429688
iteration 167: loss 0.995 0.335938 0.468750
iteration 168: loss 1.007 0.429688 0.476562
iteration 169: loss 1.258 0.328125 0.429688
iteration 170: loss 1.194 0.296875 0.484375
iteration 171: loss 1.168 0.359375 0.351562
iteration 172: loss 0.892 0.390625 0.523438
iteration 173: loss 0.872 0.234375 0.414062
iteration 174: loss 0.841 0.312500 0.390625
iteration 175: loss 1.069 0.335938 0.484375
iteration 176: loss 1.028 0.328125 0.453125
iteration 177: loss 1.254 0.312500 0.398438
iteration 178: loss 0.893 0.328125 0.421875
iteration 179: loss 0.914 0.289062 0.414062
iteration 180: loss 0.858 0.328125 0.484375
iteration 181: loss 1.101 0.250000 0.468750
iteration 182: loss 0.995 0.351562 0.437500
iteration 183: loss 0.923 0.367188 0.437500
iteration 184: loss 1.021 0.304688 0.453125
iteration 185: loss 0.978 0.320312 0.460938
iteration 186: loss 1.017 0.328125 0.500000
iteration 187: loss 1.025 0.351562 0.445312
iteration 188: loss 0.819 0.343750 0.468750
iteration 189: loss 0.856 0.351562 0.468750
iteration 190: loss 1.138 0.343750 0.437500
iteration 191: loss 1.205 0.375000 0.390625
iteration 192: loss 0.959 0.289062 0.414062
iteration 193: loss 1.139 0.312500 0.421875
iteration 194: loss 1.243 0.312500 0.445312
iteration 195: loss 1.230 0.359375 0.375000
iteration 196: loss 0.817 0.328125 0.507812
iteration 197: loss 1.197 0.289062 0.484375
iteration 198: loss 1.034 0.250000 0.437500
iteration 199: loss 0.876 0.296875 0.515625
iteration 200: loss 1.070 0.304688 0.523438
iteration 201: loss 0.956 0.289062 0.445312
iteration 202: loss 1.000 0.320312 0.390625
iteration 203: loss 1.022 0.351562 0.437500
iteration 204: loss 1.055 0.343750 0.414062
iteration 205: loss 1.066 0.406250 0.398438
iteration 206: loss 1.117 0.296875 0.429688
iteration 207: loss 1.043 0.281250 0.398438
iteration 208: loss 0.662 0.265625 0.500000
iteration 209: loss 0.830 0.351562 0.445312
iteration 210: loss 0.966 0.328125 0.484375
iteration 211: loss 1.051 0.398438 0.359375
iteration 212: loss 0.849 0.312500 0.468750
iteration 213: loss 1.120 0.281250 0.421875
iteration 214: loss 1.056 0.343750 0.398438
iteration 215: loss 0.797 0.382812 0.492188
iteration 216: loss 1.327 0.242188 0.445312
iteration 217: loss 0.993 0.437500 0.429688
iteration 218: loss 1.134 0.296875 0.468750
iteration 219: loss 0.893 0.304688 0.476562
iteration 220: loss 0.893 0.265625 0.421875
iteration 221: loss 1.102 0.351562 0.406250
iteration 222: loss 1.164 0.265625 0.492188
iteration 223: loss 0.881 0.351562 0.484375
iteration 224: loss 1.038 0.250000 0.406250
iteration 225: loss 1.229 0.328125 0.367188
iteration 226: loss 1.036 0.234375 0.468750
iteration 227: loss 0.970 0.281250 0.398438
iteration 228: loss 1.004 0.312500 0.453125
iteration 229: loss 0.783 0.328125 0.484375
iteration 230: loss 0.861 0.328125 0.453125
iteration 231: loss 0.685 0.273438 0.554688
iteration 232: loss 1.139 0.234375 0.484375
iteration 233: loss 0.967 0.351562 0.429688
iteration 234: loss 0.854 0.335938 0.460938
iteration 235: loss 1.227 0.367188 0.390625
iteration 236: loss 0.771 0.335938 0.515625
iteration 237: loss 1.225 0.328125 0.312500
iteration 238: loss 0.992 0.351562 0.460938
iteration 239: loss 0.881 0.289062 0.460938
iteration 240: loss 0.957 0.335938 0.460938
iteration 241: loss 0.877 0.281250 0.492188
iteration 242: loss 0.814 0.367188 0.468750
iteration 243: loss 0.955 0.328125 0.429688
iteration 244: loss 1.034 0.351562 0.492188
iteration 245: loss 0.961 0.328125 0.414062
iteration 246: loss 0.768 0.343750 0.500000
iteration 247: loss 0.748 0.406250 0.492188
iteration 248: loss 1.099 0.281250 0.382812
iteration 249: loss 1.035 0.343750 0.406250
iteration 250: loss 0.920 0.359375 0.437500
iteration 251: loss 0.952 0.312500 0.484375
iteration 252: loss 0.850 0.281250 0.562500
iteration 253: loss 1.332 0.382812 0.453125
iteration 254: loss 1.355 0.414062 0.312500
iteration 255: loss 0.889 0.382812 0.445312
iteration 256: loss 0.951 0.367188 0.468750
iteration 257: loss 1.180 0.304688 0.398438
iteration 258: loss 0.937 0.304688 0.500000
iteration 259: loss 0.933 0.328125 0.437500
iteration 260: loss 0.960 0.265625 0.414062
iteration 261: loss 1.018 0.265625 0.437500
iteration 262: loss 0.876 0.281250 0.476562
iteration 263: loss 0.717 0.234375 0.492188
iteration 264: loss 1.006 0.281250 0.421875
iteration 265: loss 0.994 0.328125 0.414062
iteration 266: loss 0.886 0.304688 0.406250
iteration 267: loss 1.213 0.328125 0.359375
iteration 268: loss 0.963 0.296875 0.414062
iteration 269: loss 0.940 0.312500 0.453125
iteration 270: loss 1.036 0.375000 0.445312
iteration 271: loss 0.932 0.343750 0.476562
iteration 272: loss 0.826 0.375000 0.500000
iteration 273: loss 1.014 0.289062 0.523438
iteration 274: loss 1.006 0.304688 0.414062
iteration 275: loss 1.048 0.359375 0.507812
iteration 276: loss 1.017 0.273438 0.476562
iteration 277: loss 0.859 0.335938 0.484375
iteration 278: loss 0.956 0.445312 0.460938
iteration 279: loss 0.821 0.351562 0.531250
iteration 280: loss 0.860 0.328125 0.453125
iteration 281: loss 1.090 0.304688 0.406250
iteration 282: loss 1.081 0.312500 0.414062
iteration 283: loss 0.809 0.312500 0.445312
iteration 284: loss 0.872 0.304688 0.515625
iteration 285: loss 1.182 0.328125 0.398438
iteration 286: loss 1.078 0.343750 0.453125
iteration 287: loss 0.894 0.382812 0.492188
iteration 288: loss 1.428 0.242188 0.382812
iteration 289: loss 0.933 0.289062 0.429688
iteration 290: loss 0.927 0.312500 0.476562
iteration 291: loss 1.120 0.328125 0.460938
iteration 292: loss 1.006 0.312500 0.398438
iteration 293: loss 0.928 0.304688 0.484375
iteration 294: loss 1.047 0.296875 0.492188
iteration 295: loss 1.061 0.359375 0.343750
iteration 296: loss 0.835 0.312500 0.546875
iteration 297: loss 1.011 0.273438 0.453125
iteration 298: loss 1.276 0.328125 0.414062
iteration 299: loss 0.987 0.250000 0.460938
iteration 300: loss 0.760 0.398438 0.484375
iteration 301: loss 1.305 0.335938 0.437500
iteration 302: loss 1.178 0.312500 0.437500
iteration 303: loss 1.121 0.359375 0.460938
iteration 304: loss 1.048 0.335938 0.453125
iteration 305: loss 0.869 0.273438 0.500000
iteration 306: loss 1.233 0.351562 0.304688
iteration 307: loss 1.251 0.320312 0.429688
iteration 308: loss 1.282 0.281250 0.445312
iteration 309: loss 0.697 0.320312 0.460938
iteration 310: loss 0.957 0.304688 0.453125
iteration 311: loss 0.868 0.351562 0.476562
iteration 312: loss 0.682 0.351562 0.554688
iteration 313: loss 0.804 0.343750 0.523438
iteration 314: loss 0.987 0.367188 0.492188
iteration 315: loss 1.214 0.382812 0.500000
iteration 316: loss 0.889 0.312500 0.492188
iteration 317: loss 1.144 0.359375 0.398438
iteration 318: loss 0.799 0.312500 0.507812
iteration 319: loss 1.017 0.343750 0.500000
iteration 320: loss 0.832 0.367188 0.414062
iteration 321: loss 0.996 0.234375 0.445312
iteration 322: loss 1.005 0.359375 0.429688
iteration 323: loss 1.038 0.335938 0.437500
iteration 324: loss 0.841 0.242188 0.437500
iteration 325: loss 0.873 0.406250 0.468750
iteration 326: loss 0.989 0.343750 0.500000
iteration 327: loss 1.125 0.234375 0.445312
iteration 328: loss 0.921 0.312500 0.437500
iteration 329: loss 1.033 0.289062 0.406250
iteration 330: loss 0.874 0.250000 0.453125
iteration 331: loss 0.880 0.328125 0.515625
iteration 332: loss 0.918 0.296875 0.507812
iteration 333: loss 1.085 0.312500 0.429688
iteration 334: loss 1.070 0.273438 0.414062
iteration 335: loss 0.910 0.312500 0.437500
iteration 336: loss 1.206 0.296875 0.375000
iteration 337: loss 0.757 0.343750 0.515625
iteration 338: loss 0.983 0.312500 0.453125
iteration 339: loss 0.702 0.265625 0.445312
iteration 340: loss 0.920 0.257812 0.453125
iteration 341: loss 0.944 0.257812 0.406250
iteration 342: loss 0.816 0.343750 0.453125
iteration 343: loss 0.965 0.343750 0.468750
iteration 344: loss 1.020 0.390625 0.390625
iteration 345: loss 0.825 0.375000 0.476562
iteration 346: loss 1.312 0.257812 0.453125
iteration 347: loss 0.950 0.242188 0.500000
iteration 348: loss 0.876 0.414062 0.468750
iteration 349: loss 0.944 0.328125 0.507812
iteration 350: loss 0.891 0.398438 0.453125
iteration 351: loss 1.186 0.281250 0.359375
iteration 352: loss 1.002 0.304688 0.398438
iteration 353: loss 0.894 0.265625 0.492188
iteration 354: loss 0.898 0.273438 0.468750
iteration 355: loss 0.944 0.273438 0.437500
iteration 356: loss 1.132 0.320312 0.375000
iteration 357: loss 1.200 0.304688 0.406250
iteration 358: loss 0.883 0.273438 0.468750
iteration 359: loss 0.830 0.320312 0.484375
iteration 360: loss 0.862 0.390625 0.406250
iteration 361: loss 0.828 0.328125 0.445312
iteration 362: loss 0.987 0.367188 0.398438
iteration 363: loss 0.862 0.320312 0.562500
iteration 364: loss 1.038 0.281250 0.382812
iteration 365: loss 0.969 0.382812 0.492188
iteration 366: loss 0.937 0.320312 0.476562
iteration 367: loss 0.755 0.382812 0.492188
iteration 368: loss 1.111 0.257812 0.421875
iteration 369: loss 1.140 0.375000 0.445312
iteration 370: loss 1.450 0.312500 0.375000
iteration 371: loss 0.727 0.281250 0.468750
iteration 372: loss 0.907 0.281250 0.421875
iteration 373: loss 0.998 0.257812 0.375000
iteration 374: loss 0.966 0.289062 0.390625
iteration 375: loss 1.496 0.281250 0.320312
iteration 376: loss 1.062 0.289062 0.406250
iteration 377: loss 1.044 0.250000 0.421875
iteration 378: loss 0.746 0.367188 0.484375
iteration 379: loss 0.873 0.312500 0.460938
iteration 380: loss 0.972 0.328125 0.453125
iteration 381: loss 0.979 0.265625 0.484375
iteration 382: loss 1.339 0.273438 0.468750
iteration 383: loss 0.796 0.304688 0.484375
iteration 384: loss 1.001 0.289062 0.476562
iteration 385: loss 1.172 0.273438 0.359375
iteration 386: loss 1.089 0.281250 0.429688
iteration 387: loss 0.870 0.351562 0.460938
iteration 388: loss 0.803 0.312500 0.500000
iteration 389: loss 0.882 0.304688 0.460938
iteration 390: loss 1.160 0.382812 0.460938
iteration 391: loss 0.924 0.281250 0.468750
iteration 392: loss 0.822 0.250000 0.531250
iteration 393: loss 0.845 0.343750 0.468750
iteration 394: loss 0.882 0.351562 0.453125
iteration 395: loss 1.305 0.328125 0.460938
iteration 396: loss 0.952 0.304688 0.406250
iteration 397: loss 0.987 0.312500 0.375000
iteration 398: loss 0.835 0.242188 0.500000
iteration 399: loss 1.082 0.343750 0.476562
iteration 400: loss 0.856 0.351562 0.453125
iteration 401: loss 0.784 0.328125 0.484375
iteration 402: loss 1.300 0.351562 0.382812
iteration 403: loss 0.856 0.320312 0.593750
iteration 404: loss 1.197 0.406250 0.406250
iteration 405: loss 0.930 0.343750 0.429688
iteration 406: loss 0.908 0.328125 0.437500
iteration 407: loss 1.109 0.281250 0.351562
iteration 408: loss 0.791 0.304688 0.414062
iteration 409: loss 0.952 0.359375 0.453125
iteration 410: loss 0.968 0.304688 0.460938
iteration 411: loss 0.746 0.335938 0.492188
iteration 412: loss 1.220 0.328125 0.375000
iteration 413: loss 1.148 0.335938 0.414062
iteration 414: loss 0.984 0.289062 0.398438
iteration 415: loss 0.850 0.343750 0.437500
iteration 416: loss 1.135 0.328125 0.421875
iteration 417: loss 0.882 0.328125 0.500000
iteration 418: loss 0.929 0.335938 0.421875
iteration 419: loss 0.802 0.343750 0.460938
iteration 420: loss 0.977 0.343750 0.460938
iteration 421: loss 0.977 0.281250 0.406250
iteration 422: loss 0.732 0.343750 0.500000
iteration 423: loss 0.802 0.312500 0.500000
iteration 424: loss 1.004 0.382812 0.437500
iteration 425: loss 1.110 0.312500 0.468750
iteration 426: loss 1.132 0.351562 0.453125
iteration 427: loss 1.036 0.328125 0.468750
iteration 428: loss 0.984 0.406250 0.453125
iteration 429: loss 0.934 0.390625 0.429688
iteration 430: loss 0.756 0.335938 0.476562
iteration 431: loss 1.078 0.312500 0.507812
iteration 432: loss 0.885 0.312500 0.460938
iteration 433: loss 0.782 0.304688 0.500000
iteration 434: loss 0.728 0.304688 0.484375
iteration 435: loss 0.852 0.257812 0.414062
iteration 436: loss 0.992 0.281250 0.437500
iteration 437: loss 1.134 0.312500 0.406250
iteration 438: loss 0.924 0.320312 0.390625
iteration 439: loss 0.836 0.265625 0.500000
iteration 440: loss 1.051 0.304688 0.414062
iteration 441: loss 0.959 0.289062 0.429688
iteration 442: loss 0.843 0.304688 0.453125
iteration 443: loss 1.141 0.289062 0.406250
iteration 444: loss 1.150 0.453125 0.468750
iteration 445: loss 1.087 0.375000 0.429688
iteration 446: loss 0.891 0.359375 0.421875
iteration 447: loss 1.009 0.312500 0.406250
iteration 448: loss 0.867 0.289062 0.484375
iteration 449: loss 0.933 0.343750 0.414062
iteration 450: loss 0.837 0.273438 0.460938
iteration 451: loss 1.031 0.335938 0.445312
iteration 452: loss 0.698 0.281250 0.546875
iteration 453: loss 0.776 0.375000 0.468750
iteration 454: loss 1.057 0.351562 0.421875
iteration 455: loss 0.994 0.304688 0.406250
iteration 456: loss 0.860 0.390625 0.476562
iteration 457: loss 1.125 0.390625 0.406250
iteration 458: loss 1.057 0.328125 0.484375
iteration 459: loss 1.272 0.328125 0.414062
iteration 460: loss 0.980 0.390625 0.515625
iteration 461: loss 1.146 0.304688 0.429688
iteration 462: loss 0.790 0.304688 0.554688
iteration 463: loss 1.125 0.367188 0.398438
iteration 464: loss 0.807 0.335938 0.445312
iteration 465: loss 0.832 0.328125 0.546875
iteration 466: loss 1.100 0.320312 0.453125
iteration 467: loss 1.125 0.304688 0.406250
iteration 468: loss 0.875 0.328125 0.476562
iteration 469: loss 0.868 0.312500 0.437500
iteration 470: loss 0.792 0.320312 0.500000
iteration 471: loss 0.967 0.421875 0.445312
iteration 472: loss 1.112 0.359375 0.437500
iteration 473: loss 0.938 0.320312 0.554688
iteration 474: loss 1.046 0.281250 0.539062
iteration 475: loss 0.801 0.343750 0.546875
iteration 476: loss 1.101 0.359375 0.406250
iteration 477: loss 1.106 0.304688 0.453125
iteration 478: loss 1.002 0.351562 0.468750
iteration 479: loss 1.018 0.281250 0.523438
iteration 480: loss 0.820 0.289062 0.460938
iteration 481: loss 0.899 0.351562 0.453125
iteration 482: loss 0.853 0.265625 0.468750
iteration 483: loss 0.956 0.289062 0.492188
iteration 484: loss 0.990 0.328125 0.414062
iteration 485: loss 1.187 0.304688 0.359375
iteration 486: loss 1.291 0.281250 0.500000
iteration 487: loss 0.959 0.257812 0.445312
iteration 488: loss 0.958 0.375000 0.453125
iteration 489: loss 1.020 0.312500 0.398438
iteration 490: loss 0.994 0.304688 0.406250
iteration 491: loss 1.133 0.281250 0.429688
iteration 492: loss 1.214 0.312500 0.367188
iteration 493: loss 1.106 0.289062 0.421875
iteration 494: loss 0.703 0.304688 0.531250
iteration 495: loss 1.132 0.265625 0.414062
iteration 496: loss 0.807 0.289062 0.468750
iteration 497: loss 1.055 0.390625 0.453125
iteration 498: loss 1.007 0.375000 0.507812
iteration 499: loss 0.900 0.296875 0.468750
iteration 500: loss 1.220 0.328125 0.406250
iteration 501: loss 0.663 0.320312 0.484375
iteration 502: loss 0.815 0.335938 0.437500
iteration 503: loss 0.887 0.273438 0.429688
iteration 504: loss 0.682 0.304688 0.554688
iteration 505: loss 0.846 0.273438 0.476562
iteration 506: loss 0.984 0.382812 0.414062
iteration 507: loss 1.183 0.343750 0.429688
iteration 508: loss 0.836 0.382812 0.507812
iteration 509: loss 0.879 0.304688 0.445312
iteration 510: loss 0.873 0.320312 0.398438
iteration 511: loss 1.127 0.390625 0.445312
iteration 512: loss 0.761 0.367188 0.500000
iteration 513: loss 0.914 0.265625 0.421875
iteration 514: loss 0.939 0.304688 0.484375
iteration 515: loss 0.881 0.398438 0.453125
iteration 516: loss 0.901 0.414062 0.445312
iteration 517: loss 1.083 0.335938 0.375000
iteration 518: loss 1.144 0.328125 0.437500
iteration 519: loss 1.057 0.359375 0.460938
iteration 520: loss 1.056 0.296875 0.460938
iteration 521: loss 0.924 0.273438 0.445312
iteration 522: loss 1.037 0.257812 0.406250
iteration 523: loss 0.782 0.367188 0.484375
iteration 524: loss 0.816 0.304688 0.484375
iteration 525: loss 0.780 0.257812 0.453125
iteration 526: loss 1.183 0.406250 0.375000
iteration 527: loss 0.867 0.265625 0.484375
iteration 528: loss 0.816 0.351562 0.492188
iteration 529: loss 1.089 0.343750 0.445312
iteration 530: loss 0.906 0.375000 0.460938
iteration 531: loss 0.965 0.414062 0.406250
iteration 532: loss 0.981 0.234375 0.429688
iteration 533: loss 0.748 0.304688 0.507812
iteration 534: loss 0.856 0.351562 0.460938
iteration 535: loss 0.830 0.265625 0.515625
iteration 536: loss 0.881 0.359375 0.492188
iteration 537: loss 1.431 0.296875 0.367188
iteration 538: loss 1.066 0.296875 0.429688
iteration 539: loss 0.775 0.335938 0.523438
iteration 540: loss 0.973 0.320312 0.437500
iteration 541: loss 0.856 0.265625 0.523438
iteration 542: loss 1.004 0.320312 0.382812
iteration 543: loss 0.754 0.312500 0.468750
iteration 544: loss 0.973 0.382812 0.445312
iteration 545: loss 0.955 0.304688 0.414062
iteration 546: loss 1.060 0.265625 0.421875
iteration 547: loss 1.147 0.406250 0.375000
iteration 548: loss 0.955 0.273438 0.429688
iteration 549: loss 0.963 0.328125 0.414062
iteration 550: loss 0.921 0.296875 0.382812
iteration 551: loss 0.871 0.281250 0.398438
iteration 552: loss 1.033 0.304688 0.398438
iteration 553: loss 0.928 0.320312 0.500000
iteration 554: loss 0.962 0.296875 0.351562
iteration 555: loss 1.039 0.304688 0.476562
iteration 556: loss 0.941 0.359375 0.445312
iteration 557: loss 0.826 0.351562 0.453125
iteration 558: loss 0.746 0.328125 0.507812
iteration 559: loss 0.860 0.265625 0.468750
iteration 560: loss 0.961 0.351562 0.468750
iteration 561: loss 0.870 0.375000 0.531250
iteration 562: loss 0.812 0.382812 0.476562
iteration 563: loss 0.826 0.390625 0.539062
iteration 564: loss 0.945 0.296875 0.429688
iteration 565: loss 0.761 0.234375 0.500000
iteration 566: loss 0.746 0.367188 0.515625
iteration 567: loss 0.766 0.304688 0.437500
iteration 568: loss 1.192 0.312500 0.437500
iteration 569: loss 0.705 0.242188 0.523438
iteration 570: loss 0.881 0.265625 0.468750
iteration 571: loss 1.084 0.304688 0.312500
iteration 572: loss 0.637 0.304688 0.562500
iteration 573: loss 0.849 0.281250 0.429688
iteration 574: loss 0.878 0.335938 0.445312
iteration 575: loss 0.795 0.351562 0.476562
iteration 576: loss 1.020 0.429688 0.484375
iteration 577: loss 0.971 0.328125 0.460938
iteration 578: loss 0.987 0.312500 0.406250
iteration 579: loss 0.856 0.328125 0.445312
iteration 580: loss 1.038 0.203125 0.468750
iteration 581: loss 0.867 0.335938 0.492188
iteration 582: loss 0.802 0.312500 0.445312
iteration 583: loss 0.792 0.351562 0.500000
iteration 584: loss 0.808 0.320312 0.445312
iteration 585: loss 0.961 0.359375 0.320312
iteration 586: loss 0.827 0.312500 0.515625
iteration 587: loss 0.735 0.312500 0.453125
iteration 588: loss 0.743 0.242188 0.492188
iteration 589: loss 0.710 0.328125 0.523438
iteration 590: loss 0.835 0.312500 0.468750
iteration 591: loss 0.731 0.359375 0.515625
iteration 592: loss 1.057 0.320312 0.406250
iteration 593: loss 0.653 0.343750 0.507812
iteration 594: loss 0.964 0.289062 0.468750
iteration 595: loss 1.116 0.328125 0.460938
iteration 596: loss 1.230 0.304688 0.367188
iteration 597: loss 0.921 0.265625 0.445312
iteration 598: loss 1.169 0.265625 0.328125
iteration 599: loss 0.995 0.250000 0.375000
iteration 600: loss 0.926 0.289062 0.382812
iteration 601: loss 1.024 0.328125 0.398438
iteration 602: loss 1.034 0.320312 0.320312
iteration 603: loss 0.787 0.328125 0.421875
iteration 604: loss 0.771 0.351562 0.484375
iteration 605: loss 0.856 0.296875 0.539062
iteration 606: loss 0.879 0.312500 0.500000
iteration 607: loss 1.274 0.359375 0.445312
iteration 608: loss 0.865 0.289062 0.492188
iteration 609: loss 0.891 0.304688 0.492188
iteration 610: loss 0.972 0.320312 0.476562
iteration 611: loss 1.118 0.312500 0.437500
iteration 612: loss 0.688 0.281250 0.500000
iteration 613: loss 0.895 0.320312 0.429688
iteration 614: loss 0.997 0.390625 0.468750
iteration 615: loss 0.813 0.312500 0.492188
iteration 616: loss 0.908 0.328125 0.492188
iteration 617: loss 0.777 0.281250 0.507812
iteration 618: loss 1.079 0.265625 0.421875
iteration 619: loss 1.025 0.250000 0.406250
iteration 620: loss 0.881 0.343750 0.406250
iteration 621: loss 1.103 0.421875 0.367188
iteration 622: loss 1.003 0.250000 0.421875
iteration 623: loss 0.818 0.343750 0.437500
iteration 624: loss 0.924 0.335938 0.421875
iteration 625: loss 0.747 0.320312 0.484375
iteration 626: loss 0.904 0.296875 0.437500
iteration 627: loss 0.835 0.250000 0.421875
iteration 628: loss 0.779 0.289062 0.484375
iteration 629: loss 0.906 0.359375 0.507812
iteration 630: loss 0.798 0.289062 0.468750
iteration 631: loss 1.097 0.382812 0.375000
iteration 632: loss 1.089 0.281250 0.453125
iteration 633: loss 0.975 0.343750 0.421875
iteration 634: loss 0.827 0.273438 0.453125
iteration 635: loss 1.013 0.390625 0.437500
iteration 636: loss 1.033 0.281250 0.437500
iteration 637: loss 1.245 0.367188 0.500000
iteration 638: loss 0.898 0.234375 0.476562
iteration 639: loss 0.832 0.335938 0.476562
iteration 640: loss 0.882 0.351562 0.460938
iteration 641: loss 0.942 0.289062 0.437500
iteration 642: loss 0.991 0.304688 0.406250
iteration 643: loss 0.961 0.312500 0.398438
iteration 644: loss 0.893 0.320312 0.445312
iteration 645: loss 0.935 0.289062 0.414062
iteration 646: loss 0.887 0.289062 0.437500
iteration 647: loss 0.697 0.343750 0.445312
iteration 648: loss 0.792 0.335938 0.460938
iteration 649: loss 0.869 0.343750 0.460938
iteration 650: loss 1.034 0.281250 0.460938
iteration 651: loss 0.932 0.367188 0.445312
iteration 652: loss 1.032 0.289062 0.453125
iteration 653: loss 1.156 0.304688 0.382812
iteration 654: loss 1.316 0.210938 0.421875
iteration 655: loss 0.886 0.367188 0.382812
iteration 656: loss 0.925 0.242188 0.437500
iteration 657: loss 1.051 0.289062 0.382812
iteration 658: loss 1.027 0.296875 0.445312
iteration 659: loss 0.945 0.382812 0.437500
iteration 660: loss 0.666 0.328125 0.523438
iteration 661: loss 0.740 0.296875 0.468750
iteration 662: loss 1.140 0.335938 0.421875
iteration 663: loss 0.821 0.375000 0.507812
iteration 664: loss 0.924 0.429688 0.492188
iteration 665: loss 0.782 0.296875 0.539062
iteration 666: loss 1.117 0.328125 0.398438
iteration 667: loss 0.934 0.335938 0.453125
iteration 668: loss 0.984 0.375000 0.375000
iteration 669: loss 0.984 0.273438 0.375000
iteration 670: loss 1.097 0.335938 0.343750
iteration 671: loss 0.763 0.296875 0.484375
iteration 672: loss 0.940 0.265625 0.421875
iteration 673: loss 0.914 0.312500 0.398438
iteration 674: loss 0.947 0.281250 0.414062
iteration 675: loss 0.755 0.359375 0.507812
iteration 676: loss 0.896 0.351562 0.476562
iteration 677: loss 0.919 0.289062 0.468750
iteration 678: loss 0.845 0.320312 0.460938
iteration 679: loss 0.959 0.343750 0.398438
iteration 680: loss 1.138 0.312500 0.375000
iteration 681: loss 0.830 0.343750 0.460938
iteration 682: loss 0.738 0.289062 0.484375
iteration 683: loss 0.848 0.320312 0.382812
iteration 684: loss 0.945 0.328125 0.453125
iteration 685: loss 0.770 0.312500 0.539062
iteration 686: loss 0.806 0.281250 0.414062
iteration 687: loss 0.937 0.289062 0.460938
iteration 688: loss 0.950 0.273438 0.429688
iteration 689: loss 1.082 0.296875 0.468750
iteration 690: loss 0.972 0.265625 0.390625
iteration 691: loss 0.987 0.367188 0.390625
iteration 692: loss 0.874 0.289062 0.476562
iteration 693: loss 0.794 0.312500 0.500000
iteration 694: loss 0.779 0.335938 0.523438
iteration 695: loss 0.836 0.257812 0.445312
iteration 696: loss 1.055 0.382812 0.453125
iteration 697: loss 0.975 0.320312 0.453125
iteration 698: loss 0.891 0.273438 0.453125
iteration 699: loss 0.827 0.367188 0.453125
iteration 700: loss 0.854 0.343750 0.460938
iteration 701: loss 0.971 0.273438 0.437500
iteration 702: loss 0.885 0.296875 0.460938
iteration 703: loss 0.853 0.296875 0.500000
iteration 704: loss 0.912 0.296875 0.429688
iteration 705: loss 1.004 0.218750 0.445312
iteration 706: loss 1.052 0.382812 0.429688
iteration 707: loss 0.949 0.289062 0.414062
iteration 708: loss 0.690 0.265625 0.507812
iteration 709: loss 0.878 0.375000 0.515625
iteration 710: loss 1.014 0.398438 0.406250
iteration 711: loss 1.210 0.296875 0.398438
iteration 712: loss 0.793 0.312500 0.492188
iteration 713: loss 1.238 0.289062 0.492188
iteration 714: loss 0.946 0.375000 0.484375
iteration 715: loss 0.814 0.234375 0.453125
iteration 716: loss 1.034 0.367188 0.429688
iteration 717: loss 0.896 0.257812 0.484375
iteration 718: loss 0.915 0.289062 0.421875
iteration 719: loss 0.813 0.289062 0.460938
iteration 720: loss 0.874 0.359375 0.429688
iteration 721: loss 0.795 0.343750 0.507812
iteration 722: loss 0.796 0.304688 0.437500
iteration 723: loss 0.833 0.320312 0.398438
iteration 724: loss 0.743 0.265625 0.453125
iteration 725: loss 0.711 0.335938 0.476562
iteration 726: loss 0.677 0.312500 0.492188
iteration 727: loss 0.766 0.312500 0.453125
iteration 728: loss 0.927 0.296875 0.453125
iteration 729: loss 0.867 0.375000 0.453125
iteration 730: loss 0.812 0.351562 0.492188
iteration 731: loss 0.822 0.351562 0.453125
iteration 732: loss 0.975 0.257812 0.359375
iteration 733: loss 1.049 0.312500 0.343750
iteration 734: loss 0.789 0.351562 0.468750
iteration 735: loss 0.821 0.304688 0.460938
iteration 736: loss 0.763 0.257812 0.476562
iteration 737: loss 0.963 0.335938 0.445312
iteration 738: loss 1.414 0.312500 0.453125
iteration 739: loss 0.749 0.359375 0.492188
iteration 740: loss 0.763 0.242188 0.484375
iteration 741: loss 0.942 0.296875 0.367188
iteration 742: loss 0.907 0.304688 0.453125
iteration 743: loss 0.956 0.320312 0.390625
iteration 744: loss 0.971 0.343750 0.523438
iteration 745: loss 1.138 0.359375 0.382812
iteration 746: loss 0.922 0.265625 0.437500
iteration 747: loss 1.070 0.250000 0.375000
iteration 748: loss 0.919 0.335938 0.453125
iteration 749: loss 0.789 0.304688 0.492188
iteration 750: loss 0.861 0.304688 0.406250
iteration 751: loss 0.676 0.328125 0.593750
iteration 752: loss 0.803 0.257812 0.507812
iteration 753: loss 1.142 0.359375 0.421875
iteration 754: loss 0.793 0.328125 0.507812
iteration 755: loss 1.093 0.335938 0.414062
iteration 756: loss 1.091 0.320312 0.375000
iteration 757: loss 0.884 0.343750 0.406250
iteration 758: loss 1.164 0.296875 0.398438
iteration 759: loss 1.273 0.304688 0.398438
iteration 760: loss 0.758 0.273438 0.507812
iteration 761: loss 1.000 0.289062 0.445312
iteration 762: loss 0.978 0.304688 0.492188
iteration 763: loss 0.912 0.343750 0.500000
iteration 764: loss 0.675 0.320312 0.523438
iteration 765: loss 0.942 0.273438 0.460938
iteration 766: loss 0.730 0.367188 0.523438
iteration 767: loss 0.969 0.390625 0.492188
iteration 768: loss 0.700 0.304688 0.570312
iteration 769: loss 0.960 0.250000 0.406250
iteration 770: loss 0.617 0.296875 0.554688
iteration 771: loss 0.987 0.335938 0.546875
iteration 772: loss 0.887 0.304688 0.445312
iteration 773: loss 0.738 0.273438 0.484375
iteration 774: loss 0.924 0.328125 0.390625
iteration 775: loss 1.020 0.304688 0.429688
iteration 776: loss 0.800 0.375000 0.429688
iteration 777: loss 0.774 0.265625 0.476562
iteration 778: loss 0.949 0.382812 0.445312
iteration 779: loss 1.046 0.367188 0.429688
iteration 780: loss 0.852 0.265625 0.468750
iteration 781: loss 0.738 0.296875 0.492188
iteration 782: loss 0.836 0.304688 0.468750
iteration 783: loss 0.939 0.351562 0.429688
iteration 784: loss 0.768 0.273438 0.523438
iteration 785: loss 0.850 0.273438 0.445312
iteration 786: loss 0.937 0.304688 0.468750
iteration 787: loss 0.896 0.343750 0.414062
iteration 788: loss 0.700 0.351562 0.515625
iteration 789: loss 0.966 0.304688 0.351562
iteration 790: loss 1.336 0.226562 0.406250
iteration 791: loss 1.056 0.367188 0.437500
iteration 792: loss 1.029 0.335938 0.445312
iteration 793: loss 1.009 0.328125 0.406250
iteration 794: loss 0.872 0.351562 0.515625
iteration 795: loss 0.846 0.304688 0.460938
iteration 796: loss 0.982 0.343750 0.484375
iteration 797: loss 0.883 0.343750 0.484375
iteration 798: loss 1.052 0.312500 0.398438
iteration 799: loss 0.897 0.328125 0.445312
iteration 800: loss 0.897 0.273438 0.398438
iteration 801: loss 0.884 0.367188 0.445312
iteration 802: loss 1.145 0.273438 0.398438
iteration 803: loss 0.815 0.289062 0.484375
iteration 804: loss 0.936 0.335938 0.390625
iteration 805: loss 0.748 0.328125 0.507812
iteration 806: loss 0.623 0.257812 0.460938
iteration 807: loss 0.973 0.343750 0.414062
iteration 808: loss 1.108 0.382812 0.468750
iteration 809: loss 0.829 0.304688 0.468750
iteration 810: loss 0.778 0.296875 0.460938
iteration 811: loss 0.779 0.304688 0.468750
iteration 812: loss 0.821 0.320312 0.500000
iteration 813: loss 0.782 0.351562 0.445312
iteration 814: loss 0.922 0.390625 0.453125
iteration 815: loss 0.984 0.312500 0.421875
iteration 816: loss 1.001 0.382812 0.421875
iteration 817: loss 0.998 0.289062 0.429688
iteration 818: loss 0.870 0.320312 0.429688
iteration 819: loss 0.801 0.375000 0.484375
iteration 820: loss 0.998 0.320312 0.421875
iteration 821: loss 0.826 0.289062 0.515625
iteration 822: loss 0.857 0.398438 0.414062
iteration 823: loss 0.970 0.343750 0.453125
iteration 824: loss 1.141 0.359375 0.453125
iteration 825: loss 1.016 0.296875 0.390625
iteration 826: loss 0.752 0.359375 0.507812
iteration 827: loss 0.941 0.320312 0.414062
iteration 828: loss 0.997 0.335938 0.429688
iteration 829: loss 0.855 0.328125 0.429688
iteration 830: loss 1.052 0.328125 0.421875
iteration 831: loss 0.946 0.296875 0.414062
iteration 832: loss 0.982 0.328125 0.492188
iteration 833: loss 1.152 0.351562 0.523438
iteration 834: loss 0.989 0.296875 0.406250
iteration 835: loss 1.031 0.210938 0.492188
iteration 836: loss 1.055 0.351562 0.414062
iteration 837: loss 0.872 0.375000 0.468750
iteration 838: loss 1.035 0.351562 0.382812
iteration 839: loss 1.073 0.343750 0.507812
iteration 840: loss 0.900 0.289062 0.421875
iteration 841: loss 1.071 0.257812 0.382812
iteration 842: loss 0.985 0.257812 0.445312
iteration 843: loss 0.770 0.359375 0.468750
iteration 844: loss 1.003 0.328125 0.492188
iteration 845: loss 0.878 0.304688 0.460938
iteration 846: loss 1.019 0.281250 0.507812
iteration 847: loss 0.917 0.343750 0.484375
iteration 848: loss 0.867 0.281250 0.476562
iteration 849: loss 0.973 0.335938 0.484375
iteration 850: loss 0.834 0.296875 0.421875
iteration 851: loss 1.383 0.343750 0.468750
iteration 852: loss 0.944 0.265625 0.375000
iteration 853: loss 0.769 0.281250 0.406250
iteration 854: loss 1.021 0.312500 0.406250
iteration 855: loss 0.828 0.242188 0.398438
iteration 856: loss 0.857 0.304688 0.453125
iteration 857: loss 0.821 0.289062 0.484375
iteration 858: loss 0.785 0.359375 0.578125
iteration 859: loss 0.889 0.312500 0.445312
iteration 860: loss 0.763 0.421875 0.523438
iteration 861: loss 0.704 0.320312 0.515625
iteration 862: loss 1.161 0.367188 0.375000
iteration 863: loss 0.748 0.328125 0.460938
iteration 864: loss 0.717 0.406250 0.531250
iteration 865: loss 0.920 0.343750 0.453125
iteration 866: loss 0.900 0.265625 0.382812
iteration 867: loss 0.711 0.289062 0.554688
iteration 868: loss 0.756 0.351562 0.398438
iteration 869: loss 0.961 0.242188 0.320312
iteration 870: loss 0.941 0.257812 0.343750
iteration 871: loss 0.963 0.312500 0.414062
iteration 872: loss 1.031 0.312500 0.398438
iteration 873: loss 0.786 0.359375 0.515625
iteration 874: loss 0.929 0.359375 0.445312
iteration 875: loss 1.061 0.359375 0.507812
iteration 876: loss 0.965 0.296875 0.515625
iteration 877: loss 0.733 0.281250 0.539062
iteration 878: loss 0.855 0.281250 0.484375
iteration 879: loss 0.737 0.195312 0.468750
iteration 880: loss 0.958 0.328125 0.406250
iteration 881: loss 0.834 0.218750 0.421875
iteration 882: loss 0.757 0.359375 0.437500
iteration 883: loss 0.833 0.367188 0.476562
iteration 884: loss 1.010 0.320312 0.398438
iteration 885: loss 0.858 0.296875 0.460938
iteration 886: loss 0.752 0.281250 0.453125
iteration 887: loss 0.976 0.351562 0.500000
iteration 888: loss 0.766 0.289062 0.500000
iteration 889: loss 0.906 0.351562 0.437500
iteration 890: loss 0.868 0.375000 0.437500
iteration 891: loss 0.718 0.335938 0.476562
iteration 892: loss 0.895 0.312500 0.445312
iteration 893: loss 0.768 0.375000 0.390625
iteration 894: loss 1.050 0.335938 0.468750
iteration 895: loss 0.677 0.367188 0.546875
iteration 896: loss 0.869 0.234375 0.429688
iteration 897: loss 0.769 0.312500 0.492188
iteration 898: loss 0.771 0.296875 0.421875
iteration 899: loss 0.824 0.296875 0.484375
iteration 900: loss 0.864 0.343750 0.421875
iteration 901: loss 0.835 0.328125 0.460938
iteration 902: loss 0.714 0.335938 0.437500
iteration 903: loss 0.761 0.289062 0.468750
iteration 904: loss 0.820 0.312500 0.484375
iteration 905: loss 0.898 0.265625 0.445312
iteration 906: loss 0.875 0.312500 0.460938
iteration 907: loss 0.984 0.289062 0.398438
iteration 908: loss 1.121 0.289062 0.445312
iteration 909: loss 0.781 0.320312 0.398438
iteration 910: loss 0.837 0.328125 0.453125
iteration 911: loss 1.078 0.335938 0.406250
iteration 912: loss 0.938 0.359375 0.398438
iteration 913: loss 0.943 0.312500 0.390625
iteration 914: loss 0.783 0.289062 0.492188
iteration 915: loss 0.812 0.289062 0.414062
iteration 916: loss 0.869 0.335938 0.445312
iteration 917: loss 1.008 0.343750 0.437500
iteration 918: loss 0.863 0.351562 0.429688
iteration 919: loss 0.788 0.304688 0.453125
iteration 920: loss 0.661 0.312500 0.507812
iteration 921: loss 0.832 0.265625 0.437500
iteration 922: loss 0.820 0.296875 0.468750
iteration 923: loss 0.884 0.304688 0.421875
iteration 924: loss 0.999 0.289062 0.437500
iteration 925: loss 0.951 0.273438 0.468750
iteration 926: loss 1.070 0.296875 0.335938
iteration 927: loss 1.053 0.296875 0.320312
iteration 928: loss 0.992 0.304688 0.351562
iteration 929: loss 0.876 0.375000 0.453125
iteration 930: loss 0.901 0.335938 0.492188
iteration 931: loss 0.793 0.289062 0.500000
iteration 932: loss 0.830 0.429688 0.546875
iteration 933: loss 0.814 0.328125 0.507812
iteration 934: loss 0.921 0.351562 0.492188
iteration 935: loss 0.899 0.320312 0.460938
iteration 936: loss 0.959 0.367188 0.429688
iteration 937: loss 0.739 0.359375 0.492188
iteration 938: loss 0.831 0.312500 0.421875
iteration 939: loss 0.832 0.328125 0.523438
iteration 940: loss 0.820 0.304688 0.453125
iteration 941: loss 0.891 0.289062 0.476562
iteration 942: loss 0.696 0.281250 0.468750
iteration 943: loss 0.857 0.296875 0.476562
iteration 944: loss 0.910 0.343750 0.468750
iteration 945: loss 1.047 0.359375 0.453125
iteration 946: loss 0.789 0.304688 0.500000
iteration 947: loss 0.710 0.312500 0.460938
iteration 948: loss 0.826 0.335938 0.484375
iteration 949: loss 0.892 0.382812 0.437500
iteration 950: loss 0.858 0.226562 0.460938
iteration 951: loss 0.946 0.328125 0.359375
iteration 952: loss 0.975 0.398438 0.492188
iteration 953: loss 0.804 0.312500 0.492188
iteration 954: loss 0.861 0.375000 0.445312
iteration 955: loss 0.880 0.328125 0.500000
iteration 956: loss 0.846 0.320312 0.468750
iteration 957: loss 0.903 0.335938 0.500000
iteration 958: loss 0.809 0.343750 0.468750
iteration 959: loss 0.786 0.367188 0.460938
iteration 960: loss 0.914 0.320312 0.367188
iteration 961: loss 1.176 0.296875 0.484375
iteration 962: loss 0.744 0.343750 0.484375
iteration 963: loss 1.145 0.335938 0.453125
iteration 964: loss 0.961 0.328125 0.492188
iteration 965: loss 1.042 0.320312 0.429688
iteration 966: loss 0.651 0.320312 0.515625
iteration 967: loss 0.963 0.328125 0.429688
iteration 968: loss 0.807 0.328125 0.445312
iteration 969: loss 0.873 0.343750 0.406250
iteration 970: loss 0.781 0.390625 0.437500
iteration 971: loss 0.852 0.320312 0.460938
iteration 972: loss 0.852 0.289062 0.460938
iteration 973: loss 0.742 0.320312 0.500000
iteration 974: loss 0.928 0.335938 0.406250
iteration 975: loss 1.061 0.320312 0.414062
iteration 976: loss 0.891 0.234375 0.421875
iteration 977: loss 0.965 0.328125 0.367188
iteration 978: loss 1.022 0.304688 0.453125
iteration 979: loss 0.962 0.335938 0.429688
iteration 980: loss 0.803 0.281250 0.484375
iteration 981: loss 1.324 0.359375 0.398438
iteration 982: loss 0.735 0.304688 0.539062
iteration 983: loss 0.942 0.257812 0.421875
iteration 984: loss 0.865 0.335938 0.539062
iteration 985: loss 0.955 0.320312 0.359375
iteration 986: loss 0.873 0.304688 0.500000
iteration 987: loss 0.970 0.359375 0.484375
iteration 988: loss 1.040 0.312500 0.468750
iteration 989: loss 0.888 0.281250 0.414062
iteration 990: loss 0.840 0.289062 0.484375
iteration 991: loss 0.808 0.359375 0.507812
iteration 992: loss 0.841 0.226562 0.445312
iteration 993: loss 0.697 0.320312 0.546875
iteration 994: loss 0.823 0.250000 0.476562
iteration 995: loss 0.949 0.343750 0.421875
iteration 996: loss 0.941 0.335938 0.515625
iteration 997: loss 0.810 0.351562 0.476562
iteration 998: loss 0.803 0.312500 0.484375
iteration 999: loss 0.995 0.304688 0.421875
epoch 4: training: 0.296875 validation: 0.187500
iteration 0: loss 0.710 0.281250 0.554688
iteration 1: loss 0.925 0.312500 0.406250
iteration 2: loss 0.763 0.296875 0.523438
iteration 3: loss 0.826 0.398438 0.531250
iteration 4: loss 0.945 0.320312 0.445312
iteration 5: loss 0.838 0.351562 0.523438
iteration 6: loss 0.938 0.351562 0.437500
iteration 7: loss 0.888 0.320312 0.437500
iteration 8: loss 0.668 0.335938 0.500000
iteration 9: loss 0.916 0.343750 0.421875
iteration 10: loss 0.892 0.281250 0.460938
iteration 11: loss 0.905 0.335938 0.484375
iteration 12: loss 0.844 0.265625 0.437500
iteration 13: loss 0.958 0.265625 0.437500
iteration 14: loss 1.089 0.328125 0.421875
iteration 15: loss 0.884 0.375000 0.507812
iteration 16: loss 0.890 0.398438 0.500000
iteration 17: loss 0.732 0.359375 0.507812
iteration 18: loss 0.851 0.273438 0.484375
iteration 19: loss 0.783 0.335938 0.492188
iteration 20: loss 0.711 0.320312 0.531250
iteration 21: loss 0.880 0.296875 0.460938
iteration 22: loss 0.788 0.414062 0.531250
iteration 23: loss 1.144 0.289062 0.476562
iteration 24: loss 0.814 0.406250 0.406250
iteration 25: loss 0.968 0.343750 0.445312
iteration 26: loss 0.920 0.328125 0.468750
iteration 27: loss 0.960 0.320312 0.429688
iteration 28: loss 0.944 0.367188 0.414062
iteration 29: loss 0.893 0.328125 0.468750
iteration 30: loss 0.862 0.320312 0.523438
iteration 31: loss 0.973 0.250000 0.507812
iteration 32: loss 0.746 0.312500 0.515625
iteration 33: loss 1.279 0.335938 0.437500
iteration 34: loss 1.155 0.328125 0.546875
iteration 35: loss 0.898 0.320312 0.429688
iteration 36: loss 1.018 0.273438 0.484375
iteration 37: loss 1.099 0.351562 0.398438
iteration 38: loss 1.006 0.304688 0.390625
iteration 39: loss 0.985 0.273438 0.359375
iteration 40: loss 1.034 0.281250 0.445312
iteration 41: loss 1.382 0.328125 0.382812
iteration 42: loss 0.884 0.351562 0.460938
iteration 43: loss 0.841 0.328125 0.453125
iteration 44: loss 1.008 0.351562 0.406250
iteration 45: loss 0.977 0.359375 0.382812
iteration 46: loss 1.029 0.343750 0.437500
iteration 47: loss 0.929 0.296875 0.414062
iteration 48: loss 0.890 0.320312 0.492188
iteration 49: loss 0.791 0.281250 0.429688
iteration 50: loss 0.944 0.304688 0.445312
iteration 51: loss 1.068 0.312500 0.320312
iteration 52: loss 0.953 0.250000 0.421875
iteration 53: loss 0.769 0.289062 0.421875
iteration 54: loss 1.085 0.312500 0.304688
iteration 55: loss 0.751 0.265625 0.531250
iteration 56: loss 1.318 0.375000 0.445312
iteration 57: loss 0.812 0.296875 0.562500
iteration 58: loss 0.834 0.359375 0.500000
iteration 59: loss 0.886 0.351562 0.507812
iteration 60: loss 1.070 0.226562 0.398438
iteration 61: loss 0.794 0.382812 0.492188
iteration 62: loss 1.054 0.343750 0.429688
iteration 63: loss 0.855 0.304688 0.468750
iteration 64: loss 0.921 0.281250 0.468750
iteration 65: loss 0.740 0.351562 0.453125
iteration 66: loss 0.972 0.351562 0.445312
iteration 67: loss 1.043 0.289062 0.531250
iteration 68: loss 1.193 0.304688 0.390625
iteration 69: loss 1.073 0.296875 0.421875
iteration 70: loss 0.950 0.343750 0.406250
iteration 71: loss 1.038 0.289062 0.375000
iteration 72: loss 0.929 0.234375 0.351562
iteration 73: loss 1.026 0.328125 0.414062
iteration 74: loss 0.969 0.265625 0.437500
iteration 75: loss 1.131 0.312500 0.460938
iteration 76: loss 0.793 0.281250 0.500000
iteration 77: loss 0.863 0.382812 0.500000
iteration 78: loss 0.973 0.312500 0.437500
iteration 79: loss 1.078 0.289062 0.421875
iteration 80: loss 0.891 0.320312 0.476562
iteration 81: loss 0.880 0.375000 0.421875
iteration 82: loss 0.977 0.320312 0.367188
iteration 83: loss 0.952 0.320312 0.406250
iteration 84: loss 1.227 0.335938 0.421875
iteration 85: loss 0.902 0.335938 0.539062
iteration 86: loss 0.924 0.320312 0.492188
iteration 87: loss 1.035 0.367188 0.453125
iteration 88: loss 0.813 0.281250 0.515625
iteration 89: loss 0.872 0.195312 0.421875
iteration 90: loss 0.953 0.273438 0.406250
iteration 91: loss 0.877 0.359375 0.382812
iteration 92: loss 0.910 0.242188 0.414062
iteration 93: loss 1.079 0.304688 0.398438
iteration 94: loss 0.949 0.312500 0.484375
iteration 95: loss 0.770 0.289062 0.539062
iteration 96: loss 0.793 0.281250 0.445312
iteration 97: loss 0.819 0.296875 0.468750
iteration 98: loss 1.052 0.375000 0.453125
iteration 99: loss 0.675 0.218750 0.531250
iteration 100: loss 0.920 0.304688 0.460938
iteration 101: loss 0.764 0.398438 0.429688
iteration 102: loss 0.643 0.398438 0.539062
iteration 103: loss 0.907 0.335938 0.421875
iteration 104: loss 0.971 0.335938 0.367188
iteration 105: loss 0.824 0.351562 0.476562
iteration 106: loss 0.808 0.328125 0.468750
iteration 107: loss 0.762 0.343750 0.468750
iteration 108: loss 0.783 0.406250 0.492188
iteration 109: loss 1.247 0.320312 0.421875
iteration 110: loss 0.855 0.335938 0.507812
iteration 111: loss 1.056 0.265625 0.375000
iteration 112: loss 1.067 0.343750 0.382812
iteration 113: loss 0.891 0.335938 0.476562
iteration 114: loss 0.894 0.296875 0.429688
iteration 115: loss 0.843 0.335938 0.484375
iteration 116: loss 0.897 0.335938 0.390625
iteration 117: loss 0.742 0.265625 0.468750
iteration 118: loss 1.006 0.234375 0.390625
iteration 119: loss 0.650 0.328125 0.500000
iteration 120: loss 0.846 0.265625 0.351562
iteration 121: loss 0.961 0.296875 0.406250
iteration 122: loss 0.862 0.273438 0.476562
iteration 123: loss 0.945 0.328125 0.468750
iteration 124: loss 1.152 0.359375 0.390625
iteration 125: loss 0.861 0.320312 0.414062
iteration 126: loss 0.762 0.273438 0.460938
iteration 127: loss 0.854 0.304688 0.421875
iteration 128: loss 0.853 0.296875 0.492188
iteration 129: loss 0.876 0.328125 0.546875
iteration 130: loss 0.698 0.343750 0.507812
iteration 131: loss 1.141 0.257812 0.429688
iteration 132: loss 1.071 0.375000 0.406250
iteration 133: loss 1.042 0.195312 0.343750
iteration 134: loss 0.778 0.296875 0.421875
iteration 135: loss 0.844 0.226562 0.398438
iteration 136: loss 1.129 0.343750 0.390625
iteration 137: loss 0.820 0.296875 0.507812
iteration 138: loss 0.984 0.328125 0.460938
iteration 139: loss 0.851 0.367188 0.515625
iteration 140: loss 0.852 0.281250 0.460938
iteration 141: loss 0.821 0.429688 0.507812
iteration 142: loss 0.774 0.265625 0.523438
iteration 143: loss 0.838 0.320312 0.406250
iteration 144: loss 0.755 0.257812 0.484375
iteration 145: loss 0.746 0.335938 0.460938
iteration 146: loss 0.657 0.304688 0.523438
iteration 147: loss 1.102 0.312500 0.429688
iteration 148: loss 0.980 0.265625 0.460938
iteration 149: loss 0.814 0.281250 0.562500
iteration 150: loss 1.010 0.359375 0.484375
iteration 151: loss 0.840 0.320312 0.445312
iteration 152: loss 0.953 0.398438 0.421875
iteration 153: loss 0.906 0.250000 0.453125
iteration 154: loss 0.872 0.359375 0.421875
iteration 155: loss 0.800 0.328125 0.507812
iteration 156: loss 0.840 0.335938 0.500000
iteration 157: loss 0.777 0.304688 0.507812
iteration 158: loss 1.008 0.328125 0.382812
iteration 159: loss 0.896 0.382812 0.437500
iteration 160: loss 0.711 0.328125 0.531250
iteration 161: loss 0.867 0.312500 0.492188
iteration 162: loss 0.772 0.273438 0.453125
iteration 163: loss 0.875 0.257812 0.468750
iteration 164: loss 1.023 0.203125 0.546875
iteration 165: loss 0.701 0.328125 0.539062
iteration 166: loss 0.878 0.289062 0.445312
iteration 167: loss 0.730 0.335938 0.539062
iteration 168: loss 0.977 0.312500 0.500000
iteration 169: loss 0.782 0.304688 0.507812
iteration 170: loss 0.934 0.328125 0.421875
iteration 171: loss 0.893 0.367188 0.367188
iteration 172: loss 0.894 0.320312 0.375000
iteration 173: loss 0.904 0.328125 0.437500
iteration 174: loss 0.873 0.343750 0.445312
iteration 175: loss 0.775 0.273438 0.453125
iteration 176: loss 0.881 0.343750 0.492188
iteration 177: loss 0.719 0.335938 0.500000
iteration 178: loss 0.868 0.312500 0.468750
iteration 179: loss 0.870 0.335938 0.476562
iteration 180: loss 1.123 0.343750 0.515625
iteration 181: loss 0.678 0.320312 0.484375
iteration 182: loss 0.942 0.281250 0.500000
iteration 183: loss 0.720 0.406250 0.468750
iteration 184: loss 1.001 0.320312 0.445312
iteration 185: loss 0.902 0.343750 0.429688
iteration 186: loss 0.804 0.273438 0.476562
iteration 187: loss 0.925 0.343750 0.515625
iteration 188: loss 1.085 0.328125 0.398438
iteration 189: loss 1.149 0.335938 0.359375
iteration 190: loss 1.230 0.273438 0.382812
iteration 191: loss 1.018 0.335938 0.437500
iteration 192: loss 0.798 0.343750 0.429688
iteration 193: loss 0.918 0.328125 0.429688
iteration 194: loss 0.781 0.257812 0.453125
iteration 195: loss 1.217 0.343750 0.382812
iteration 196: loss 0.788 0.296875 0.406250
iteration 197: loss 0.924 0.281250 0.445312
iteration 198: loss 0.779 0.265625 0.492188
iteration 199: loss 0.715 0.250000 0.445312
iteration 200: loss 0.814 0.382812 0.492188
iteration 201: loss 0.764 0.328125 0.453125
iteration 202: loss 0.937 0.296875 0.437500
iteration 203: loss 0.969 0.312500 0.453125
iteration 204: loss 0.820 0.296875 0.476562
iteration 205: loss 0.900 0.359375 0.406250
iteration 206: loss 0.838 0.296875 0.421875
iteration 207: loss 0.898 0.281250 0.421875
iteration 208: loss 1.081 0.328125 0.359375
iteration 209: loss 0.967 0.328125 0.414062
iteration 210: loss 0.739 0.328125 0.468750
iteration 211: loss 0.846 0.343750 0.406250
iteration 212: loss 0.835 0.296875 0.476562
iteration 213: loss 0.785 0.281250 0.460938
iteration 214: loss 0.862 0.289062 0.500000
iteration 215: loss 0.658 0.273438 0.570312
iteration 216: loss 0.787 0.296875 0.539062
iteration 217: loss 0.732 0.296875 0.476562
iteration 218: loss 0.852 0.382812 0.507812
iteration 219: loss 0.829 0.320312 0.429688
iteration 220: loss 1.033 0.304688 0.375000
iteration 221: loss 0.804 0.226562 0.460938
iteration 222: loss 0.727 0.257812 0.476562
iteration 223: loss 0.803 0.289062 0.468750
iteration 224: loss 0.816 0.273438 0.445312
iteration 225: loss 0.881 0.265625 0.429688
iteration 226: loss 0.894 0.296875 0.492188
iteration 227: loss 0.884 0.304688 0.468750
iteration 228: loss 0.773 0.312500 0.539062
iteration 229: loss 1.006 0.320312 0.398438
iteration 230: loss 1.133 0.320312 0.453125
iteration 231: loss 1.096 0.304688 0.421875
iteration 232: loss 0.765 0.367188 0.437500
iteration 233: loss 0.929 0.320312 0.445312
iteration 234: loss 1.043 0.343750 0.414062
iteration 235: loss 0.814 0.296875 0.539062
iteration 236: loss 1.003 0.328125 0.375000
iteration 237: loss 0.886 0.304688 0.476562
iteration 238: loss 0.990 0.351562 0.476562
iteration 239: loss 0.691 0.312500 0.546875
iteration 240: loss 0.873 0.281250 0.539062
iteration 241: loss 1.060 0.320312 0.398438
iteration 242: loss 0.771 0.250000 0.484375
iteration 243: loss 0.810 0.320312 0.460938
iteration 244: loss 0.845 0.296875 0.406250
iteration 245: loss 0.841 0.257812 0.492188
iteration 246: loss 0.748 0.234375 0.492188
iteration 247: loss 0.845 0.273438 0.445312
iteration 248: loss 0.821 0.273438 0.500000
iteration 249: loss 0.739 0.257812 0.500000
iteration 250: loss 1.032 0.367188 0.398438
iteration 251: loss 0.974 0.320312 0.414062
iteration 252: loss 0.788 0.351562 0.492188
iteration 253: loss 0.921 0.343750 0.406250
iteration 254: loss 0.799 0.289062 0.453125
iteration 255: loss 0.734 0.335938 0.492188
iteration 256: loss 0.900 0.382812 0.421875
iteration 257: loss 0.863 0.281250 0.460938
iteration 258: loss 0.832 0.257812 0.437500
iteration 259: loss 1.098 0.367188 0.414062
iteration 260: loss 0.808 0.390625 0.476562
iteration 261: loss 0.726 0.281250 0.460938
iteration 262: loss 0.756 0.304688 0.429688
iteration 263: loss 0.857 0.273438 0.500000
iteration 264: loss 1.128 0.296875 0.398438
iteration 265: loss 0.921 0.367188 0.382812
iteration 266: loss 0.603 0.289062 0.468750
iteration 267: loss 0.863 0.367188 0.445312
iteration 268: loss 0.846 0.351562 0.445312
iteration 269: loss 0.899 0.304688 0.453125
iteration 270: loss 0.719 0.328125 0.484375
iteration 271: loss 0.706 0.312500 0.453125
iteration 272: loss 0.898 0.351562 0.382812
iteration 273: loss 0.619 0.312500 0.468750
iteration 274: loss 0.937 0.335938 0.414062
iteration 275: loss 0.692 0.242188 0.492188
iteration 276: loss 0.812 0.312500 0.453125
iteration 277: loss 1.242 0.351562 0.421875
iteration 278: loss 1.051 0.250000 0.421875
iteration 279: loss 0.910 0.351562 0.429688
iteration 280: loss 0.908 0.281250 0.453125
iteration 281: loss 0.736 0.320312 0.531250
iteration 282: loss 0.816 0.359375 0.468750
iteration 283: loss 0.684 0.320312 0.460938
iteration 284: loss 0.745 0.328125 0.500000
iteration 285: loss 1.001 0.343750 0.414062
iteration 286: loss 0.955 0.304688 0.476562
iteration 287: loss 0.876 0.265625 0.460938
iteration 288: loss 0.771 0.328125 0.539062
iteration 289: loss 0.931 0.320312 0.468750
iteration 290: loss 0.969 0.359375 0.460938
iteration 291: loss 0.918 0.320312 0.414062
iteration 292: loss 0.875 0.304688 0.460938
iteration 293: loss 0.618 0.320312 0.468750
iteration 294: loss 1.130 0.343750 0.382812
iteration 295: loss 0.796 0.281250 0.468750
iteration 296: loss 0.856 0.289062 0.429688
iteration 297: loss 0.902 0.351562 0.437500
iteration 298: loss 0.749 0.351562 0.476562
iteration 299: loss 0.830 0.296875 0.484375
iteration 300: loss 0.804 0.281250 0.468750
iteration 301: loss 0.957 0.296875 0.414062
iteration 302: loss 0.935 0.367188 0.421875
iteration 303: loss 0.795 0.226562 0.460938
iteration 304: loss 0.910 0.281250 0.445312
iteration 305: loss 0.829 0.312500 0.468750
iteration 306: loss 0.828 0.242188 0.468750
iteration 307: loss 1.020 0.335938 0.414062
iteration 308: loss 0.800 0.281250 0.437500
iteration 309: loss 0.889 0.328125 0.492188
iteration 310: loss 0.977 0.296875 0.398438
iteration 311: loss 0.783 0.257812 0.429688
iteration 312: loss 0.842 0.343750 0.453125
iteration 313: loss 1.214 0.367188 0.429688
iteration 314: loss 1.030 0.289062 0.414062
iteration 315: loss 0.937 0.382812 0.390625
iteration 316: loss 0.850 0.375000 0.390625
iteration 317: loss 1.017 0.351562 0.398438
iteration 318: loss 0.767 0.289062 0.406250
iteration 319: loss 0.978 0.296875 0.406250
iteration 320: loss 0.854 0.289062 0.445312
iteration 321: loss 0.932 0.273438 0.414062
iteration 322: loss 0.808 0.343750 0.445312
iteration 323: loss 0.674 0.367188 0.531250
iteration 324: loss 0.773 0.257812 0.492188
iteration 325: loss 1.079 0.335938 0.406250
iteration 326: loss 0.966 0.343750 0.453125
iteration 327: loss 1.080 0.257812 0.476562
iteration 328: loss 0.920 0.335938 0.468750
iteration 329: loss 1.093 0.343750 0.476562
iteration 330: loss 0.743 0.367188 0.398438
iteration 331: loss 1.077 0.289062 0.429688
iteration 332: loss 0.998 0.296875 0.414062
iteration 333: loss 0.902 0.359375 0.406250
iteration 334: loss 1.128 0.242188 0.429688
iteration 335: loss 0.757 0.242188 0.546875
iteration 336: loss 0.948 0.351562 0.453125
iteration 337: loss 0.821 0.312500 0.445312
iteration 338: loss 0.771 0.335938 0.500000
iteration 339: loss 1.225 0.312500 0.343750
iteration 340: loss 1.241 0.359375 0.429688
iteration 341: loss 0.906 0.367188 0.460938
iteration 342: loss 0.843 0.367188 0.382812
iteration 343: loss 0.959 0.351562 0.445312
iteration 344: loss 1.118 0.289062 0.367188
iteration 345: loss 1.053 0.273438 0.406250
iteration 346: loss 0.787 0.265625 0.476562
iteration 347: loss 0.818 0.359375 0.421875
iteration 348: loss 0.890 0.359375 0.468750
iteration 349: loss 0.942 0.320312 0.382812
iteration 350: loss 0.766 0.296875 0.468750
iteration 351: loss 0.874 0.351562 0.445312
iteration 352: loss 0.856 0.320312 0.484375
iteration 353: loss 0.875 0.320312 0.484375
iteration 354: loss 0.941 0.265625 0.390625
iteration 355: loss 0.893 0.257812 0.507812
iteration 356: loss 0.914 0.304688 0.414062
iteration 357: loss 0.917 0.359375 0.468750
iteration 358: loss 0.633 0.328125 0.585938
iteration 359: loss 0.813 0.257812 0.429688
iteration 360: loss 0.626 0.296875 0.484375
iteration 361: loss 0.905 0.289062 0.437500
iteration 362: loss 0.790 0.234375 0.460938
iteration 363: loss 0.939 0.289062 0.414062
iteration 364: loss 0.802 0.296875 0.445312
iteration 365: loss 0.716 0.335938 0.523438
iteration 366: loss 1.004 0.289062 0.382812
iteration 367: loss 0.716 0.328125 0.554688
iteration 368: loss 0.891 0.351562 0.421875
iteration 369: loss 1.097 0.312500 0.421875
iteration 370: loss 1.133 0.335938 0.445312
iteration 371: loss 0.827 0.343750 0.476562
iteration 372: loss 0.997 0.312500 0.359375
iteration 373: loss 1.256 0.382812 0.367188
iteration 374: loss 0.925 0.343750 0.429688
iteration 375: loss 0.896 0.320312 0.500000
iteration 376: loss 0.905 0.375000 0.453125
iteration 377: loss 0.793 0.359375 0.546875
iteration 378: loss 0.827 0.343750 0.437500
iteration 379: loss 0.710 0.273438 0.515625
iteration 380: loss 0.792 0.257812 0.492188
iteration 381: loss 0.922 0.375000 0.453125
iteration 382: loss 0.994 0.304688 0.390625
iteration 383: loss 0.780 0.312500 0.476562
iteration 384: loss 0.950 0.257812 0.429688
iteration 385: loss 1.009 0.257812 0.437500
iteration 386: loss 0.863 0.257812 0.406250
iteration 387: loss 0.899 0.328125 0.453125
iteration 388: loss 0.665 0.273438 0.523438
iteration 389: loss 0.876 0.335938 0.484375
iteration 390: loss 0.845 0.382812 0.437500
iteration 391: loss 1.022 0.304688 0.375000
iteration 392: loss 0.749 0.281250 0.453125
iteration 393: loss 0.917 0.312500 0.414062
iteration 394: loss 0.855 0.328125 0.414062
iteration 395: loss 0.750 0.281250 0.531250
iteration 396: loss 0.755 0.328125 0.468750
iteration 397: loss 0.757 0.343750 0.429688
iteration 398: loss 0.904 0.351562 0.445312
iteration 399: loss 0.834 0.312500 0.460938
iteration 400: loss 0.868 0.382812 0.492188
iteration 401: loss 1.109 0.328125 0.437500
iteration 402: loss 0.930 0.250000 0.406250
iteration 403: loss 0.892 0.351562 0.437500
iteration 404: loss 0.767 0.250000 0.507812
iteration 405: loss 0.658 0.328125 0.562500
iteration 406: loss 0.937 0.312500 0.468750
iteration 407: loss 0.662 0.351562 0.437500
iteration 408: loss 1.057 0.320312 0.421875
iteration 409: loss 0.842 0.343750 0.492188
iteration 410: loss 0.900 0.304688 0.507812
iteration 411: loss 0.892 0.320312 0.421875
iteration 412: loss 0.848 0.289062 0.468750
iteration 413: loss 0.777 0.320312 0.421875
iteration 414: loss 0.764 0.406250 0.484375
iteration 415: loss 1.020 0.289062 0.492188
iteration 416: loss 0.866 0.289062 0.429688
iteration 417: loss 0.968 0.281250 0.453125
iteration 418: loss 0.816 0.375000 0.476562
iteration 419: loss 0.669 0.257812 0.476562
iteration 420: loss 1.032 0.375000 0.390625
iteration 421: loss 0.733 0.250000 0.437500
iteration 422: loss 1.045 0.289062 0.406250
iteration 423: loss 1.011 0.304688 0.445312
iteration 424: loss 1.018 0.296875 0.398438
iteration 425: loss 0.828 0.304688 0.507812
iteration 426: loss 0.862 0.265625 0.406250
iteration 427: loss 1.252 0.320312 0.421875
iteration 428: loss 1.082 0.281250 0.421875
iteration 429: loss 0.617 0.328125 0.601562
iteration 430: loss 0.925 0.304688 0.453125
iteration 431: loss 1.086 0.289062 0.484375
iteration 432: loss 0.854 0.273438 0.429688
iteration 433: loss 0.699 0.304688 0.460938
iteration 434: loss 0.772 0.296875 0.468750
iteration 435: loss 0.911 0.343750 0.445312
iteration 436: loss 0.925 0.273438 0.453125
iteration 437: loss 0.817 0.367188 0.460938
iteration 438: loss 0.736 0.312500 0.515625
iteration 439: loss 0.788 0.281250 0.437500
iteration 440: loss 0.927 0.304688 0.453125
iteration 441: loss 0.901 0.281250 0.445312
iteration 442: loss 0.856 0.406250 0.460938
iteration 443: loss 0.678 0.343750 0.468750
iteration 444: loss 0.889 0.289062 0.453125
iteration 445: loss 0.857 0.242188 0.421875
iteration 446: loss 0.797 0.343750 0.492188
iteration 447: loss 0.914 0.312500 0.453125
iteration 448: loss 0.958 0.281250 0.460938
iteration 449: loss 0.774 0.445312 0.476562
iteration 450: loss 0.661 0.304688 0.484375
iteration 451: loss 0.895 0.265625 0.437500
iteration 452: loss 1.107 0.343750 0.421875
iteration 453: loss 0.827 0.273438 0.515625
iteration 454: loss 0.868 0.265625 0.406250
iteration 455: loss 0.834 0.367188 0.500000
iteration 456: loss 0.771 0.281250 0.515625
iteration 457: loss 0.925 0.343750 0.453125
iteration 458: loss 0.709 0.320312 0.523438
iteration 459: loss 0.873 0.257812 0.375000
iteration 460: loss 0.795 0.304688 0.453125
iteration 461: loss 0.910 0.273438 0.453125
iteration 462: loss 0.714 0.343750 0.453125
iteration 463: loss 1.209 0.296875 0.390625
iteration 464: loss 0.850 0.273438 0.453125
iteration 465: loss 0.824 0.320312 0.406250
iteration 466: loss 1.193 0.414062 0.429688
iteration 467: loss 0.914 0.265625 0.406250
iteration 468: loss 0.775 0.273438 0.523438
iteration 469: loss 1.045 0.343750 0.445312
iteration 470: loss 0.891 0.343750 0.460938
iteration 471: loss 0.892 0.343750 0.492188
iteration 472: loss 0.822 0.328125 0.539062
iteration 473: loss 0.931 0.257812 0.335938
iteration 474: loss 0.862 0.296875 0.398438
iteration 475: loss 0.757 0.328125 0.531250
iteration 476: loss 1.119 0.343750 0.351562
iteration 477: loss 1.080 0.304688 0.343750
iteration 478: loss 0.987 0.304688 0.406250
iteration 479: loss 1.353 0.234375 0.406250
iteration 480: loss 1.086 0.343750 0.335938
iteration 481: loss 0.930 0.281250 0.421875
iteration 482: loss 0.951 0.296875 0.437500
iteration 483: loss 0.802 0.375000 0.492188
iteration 484: loss 0.895 0.320312 0.429688
iteration 485: loss 1.038 0.328125 0.421875
iteration 486: loss 0.726 0.304688 0.500000
iteration 487: loss 0.957 0.289062 0.429688
iteration 488: loss 0.857 0.390625 0.468750
iteration 489: loss 1.017 0.281250 0.414062
iteration 490: loss 0.982 0.296875 0.445312
iteration 491: loss 0.975 0.289062 0.421875
iteration 492: loss 0.916 0.296875 0.398438
iteration 493: loss 0.912 0.437500 0.437500
iteration 494: loss 0.937 0.312500 0.437500
iteration 495: loss 0.916 0.375000 0.375000
iteration 496: loss 0.808 0.343750 0.437500
iteration 497: loss 0.729 0.328125 0.476562
iteration 498: loss 0.852 0.343750 0.484375
iteration 499: loss 0.836 0.335938 0.476562
iteration 500: loss 0.891 0.312500 0.406250
iteration 501: loss 0.894 0.343750 0.453125
iteration 502: loss 0.993 0.296875 0.429688
iteration 503: loss 0.887 0.265625 0.453125
iteration 504: loss 0.681 0.328125 0.507812
iteration 505: loss 0.663 0.335938 0.453125
iteration 506: loss 0.864 0.257812 0.460938
iteration 507: loss 1.103 0.242188 0.375000
iteration 508: loss 0.834 0.320312 0.414062
iteration 509: loss 0.866 0.335938 0.414062
iteration 510: loss 0.891 0.265625 0.437500
iteration 511: loss 0.784 0.312500 0.476562
iteration 512: loss 0.794 0.281250 0.492188
iteration 513: loss 0.955 0.304688 0.484375
iteration 514: loss 0.930 0.281250 0.414062
iteration 515: loss 0.864 0.351562 0.437500
iteration 516: loss 0.639 0.351562 0.539062
iteration 517: loss 0.921 0.257812 0.406250
iteration 518: loss 0.751 0.289062 0.500000
iteration 519: loss 0.614 0.296875 0.515625
iteration 520: loss 0.984 0.312500 0.476562
iteration 521: loss 1.154 0.296875 0.437500
iteration 522: loss 1.035 0.312500 0.421875
iteration 523: loss 0.740 0.250000 0.562500
iteration 524: loss 1.065 0.335938 0.421875
iteration 525: loss 0.878 0.367188 0.453125
iteration 526: loss 0.887 0.421875 0.484375
iteration 527: loss 0.970 0.289062 0.492188
iteration 528: loss 0.815 0.250000 0.445312
iteration 529: loss 0.921 0.328125 0.468750
iteration 530: loss 0.921 0.367188 0.460938
iteration 531: loss 0.793 0.367188 0.484375
iteration 532: loss 0.799 0.218750 0.539062
iteration 533: loss 0.723 0.335938 0.492188
iteration 534: loss 0.762 0.328125 0.484375
iteration 535: loss 0.783 0.242188 0.414062
iteration 536: loss 0.844 0.250000 0.414062
iteration 537: loss 0.854 0.250000 0.476562
iteration 538: loss 0.832 0.328125 0.375000
iteration 539: loss 0.786 0.226562 0.453125
iteration 540: loss 0.854 0.351562 0.390625
iteration 541: loss 1.052 0.320312 0.367188
iteration 542: loss 0.959 0.304688 0.429688
iteration 543: loss 0.750 0.335938 0.476562
iteration 544: loss 0.804 0.281250 0.437500
iteration 545: loss 0.893 0.375000 0.390625
iteration 546: loss 0.795 0.328125 0.414062
iteration 547: loss 0.911 0.281250 0.476562
iteration 548: loss 0.998 0.242188 0.460938
iteration 549: loss 0.682 0.257812 0.515625
iteration 550: loss 0.942 0.335938 0.406250
iteration 551: loss 0.966 0.304688 0.406250
iteration 552: loss 0.767 0.382812 0.492188
iteration 553: loss 0.790 0.296875 0.476562
iteration 554: loss 0.846 0.367188 0.437500
iteration 555: loss 0.919 0.320312 0.421875
iteration 556: loss 0.891 0.281250 0.414062
iteration 557: loss 1.031 0.250000 0.453125
iteration 558: loss 0.862 0.320312 0.437500
iteration 559: loss 0.826 0.335938 0.492188
iteration 560: loss 0.909 0.304688 0.460938
iteration 561: loss 0.973 0.312500 0.460938
iteration 562: loss 0.671 0.328125 0.523438
iteration 563: loss 1.093 0.312500 0.515625
iteration 564: loss 0.688 0.304688 0.484375
iteration 565: loss 0.740 0.343750 0.414062
iteration 566: loss 0.735 0.320312 0.460938
iteration 567: loss 0.704 0.250000 0.460938
iteration 568: loss 0.867 0.343750 0.468750
iteration 569: loss 0.826 0.328125 0.468750
iteration 570: loss 0.915 0.367188 0.437500
iteration 571: loss 0.918 0.367188 0.414062
iteration 572: loss 0.739 0.289062 0.445312
iteration 573: loss 0.718 0.398438 0.492188
iteration 574: loss 0.949 0.304688 0.484375
iteration 575: loss 0.788 0.328125 0.554688
iteration 576: loss 0.711 0.273438 0.523438
iteration 577: loss 1.081 0.312500 0.460938
iteration 578: loss 0.823 0.343750 0.429688
iteration 579: loss 0.995 0.265625 0.445312
iteration 580: loss 0.833 0.281250 0.460938
iteration 581: loss 0.747 0.304688 0.398438
iteration 582: loss 0.955 0.226562 0.437500
iteration 583: loss 0.760 0.257812 0.453125
iteration 584: loss 0.846 0.242188 0.343750
iteration 585: loss 0.811 0.367188 0.507812
iteration 586: loss 0.974 0.390625 0.453125
iteration 587: loss 0.818 0.335938 0.484375
iteration 588: loss 0.675 0.343750 0.437500
iteration 589: loss 0.891 0.312500 0.406250
iteration 590: loss 0.770 0.281250 0.406250
iteration 591: loss 0.765 0.289062 0.437500
iteration 592: loss 0.853 0.320312 0.382812
iteration 593: loss 0.824 0.328125 0.421875
iteration 594: loss 0.842 0.351562 0.468750
iteration 595: loss 0.839 0.312500 0.445312
iteration 596: loss 0.907 0.304688 0.382812
iteration 597: loss 0.873 0.304688 0.367188
iteration 598: loss 0.866 0.296875 0.445312
iteration 599: loss 0.873 0.328125 0.398438
iteration 600: loss 0.602 0.281250 0.554688
iteration 601: loss 0.705 0.265625 0.492188
iteration 602: loss 0.734 0.304688 0.445312
iteration 603: loss 0.789 0.296875 0.476562
iteration 604: loss 0.779 0.312500 0.453125
iteration 605: loss 0.746 0.265625 0.484375
iteration 606: loss 0.719 0.328125 0.531250
iteration 607: loss 0.826 0.304688 0.546875
iteration 608: loss 0.751 0.320312 0.476562
iteration 609: loss 1.258 0.320312 0.398438
iteration 610: loss 0.809 0.265625 0.484375
iteration 611: loss 0.819 0.312500 0.453125
iteration 612: loss 0.957 0.257812 0.367188
iteration 613: loss 0.783 0.312500 0.414062
iteration 614: loss 0.990 0.289062 0.414062
iteration 615: loss 0.897 0.312500 0.429688
iteration 616: loss 0.664 0.257812 0.453125
iteration 617: loss 0.813 0.359375 0.351562
iteration 618: loss 0.845 0.351562 0.437500
iteration 619: loss 0.753 0.289062 0.476562
iteration 620: loss 0.861 0.281250 0.437500
iteration 621: loss 0.973 0.312500 0.421875
iteration 622: loss 0.973 0.281250 0.429688
iteration 623: loss 0.675 0.304688 0.484375
iteration 624: loss 0.635 0.367188 0.546875
iteration 625: loss 0.994 0.335938 0.437500
iteration 626: loss 0.878 0.343750 0.398438
iteration 627: loss 0.863 0.359375 0.468750
iteration 628: loss 0.777 0.257812 0.492188
iteration 629: loss 0.644 0.351562 0.460938
iteration 630: loss 0.925 0.367188 0.429688
iteration 631: loss 0.881 0.273438 0.500000
iteration 632: loss 0.827 0.359375 0.429688
iteration 633: loss 0.936 0.335938 0.429688
iteration 634: loss 0.749 0.351562 0.531250
iteration 635: loss 0.969 0.281250 0.398438
iteration 636: loss 0.913 0.304688 0.445312
iteration 637: loss 0.720 0.273438 0.398438
iteration 638: loss 0.781 0.257812 0.460938
iteration 639: loss 0.833 0.273438 0.429688
iteration 640: loss 0.718 0.296875 0.468750
iteration 641: loss 0.775 0.312500 0.421875
iteration 642: loss 0.927 0.281250 0.421875
iteration 643: loss 0.910 0.304688 0.468750
iteration 644: loss 0.842 0.312500 0.382812
iteration 645: loss 0.796 0.281250 0.515625
iteration 646: loss 0.737 0.351562 0.468750
iteration 647: loss 0.736 0.289062 0.500000
iteration 648: loss 0.863 0.312500 0.453125
iteration 649: loss 0.747 0.335938 0.375000
iteration 650: loss 0.628 0.289062 0.492188
iteration 651: loss 0.619 0.335938 0.500000
iteration 652: loss 0.874 0.398438 0.429688
iteration 653: loss 0.751 0.320312 0.531250
iteration 654: loss 1.099 0.390625 0.359375
iteration 655: loss 0.881 0.359375 0.367188
iteration 656: loss 0.741 0.304688 0.460938
iteration 657: loss 0.812 0.273438 0.382812
iteration 658: loss 0.903 0.406250 0.375000
iteration 659: loss 0.752 0.289062 0.515625
iteration 660: loss 0.897 0.351562 0.453125
iteration 661: loss 0.778 0.320312 0.468750
iteration 662: loss 1.094 0.398438 0.421875
iteration 663: loss 0.911 0.320312 0.445312
iteration 664: loss 0.768 0.375000 0.468750
iteration 665: loss 1.068 0.351562 0.398438
iteration 666: loss 0.823 0.281250 0.429688
iteration 667: loss 0.948 0.257812 0.390625
iteration 668: loss 0.787 0.281250 0.500000
iteration 669: loss 0.679 0.320312 0.507812
iteration 670: loss 0.818 0.289062 0.507812
iteration 671: loss 0.830 0.289062 0.445312
iteration 672: loss 0.839 0.398438 0.515625
iteration 673: loss 0.797 0.242188 0.421875
iteration 674: loss 0.737 0.234375 0.375000
iteration 675: loss 0.865 0.296875 0.429688
iteration 676: loss 0.974 0.328125 0.406250
iteration 677: loss 0.993 0.304688 0.367188
iteration 678: loss 0.774 0.281250 0.414062
iteration 679: loss 1.042 0.335938 0.382812
iteration 680: loss 0.809 0.375000 0.468750
iteration 681: loss 0.811 0.312500 0.476562
iteration 682: loss 0.839 0.304688 0.492188
iteration 683: loss 0.676 0.257812 0.515625
iteration 684: loss 0.833 0.335938 0.515625
iteration 685: loss 0.957 0.335938 0.453125
iteration 686: loss 0.835 0.351562 0.429688
iteration 687: loss 0.794 0.335938 0.445312
iteration 688: loss 0.817 0.343750 0.437500
iteration 689: loss 0.785 0.289062 0.445312
iteration 690: loss 1.065 0.375000 0.375000
iteration 691: loss 0.815 0.320312 0.445312
iteration 692: loss 0.764 0.359375 0.500000
iteration 693: loss 0.847 0.328125 0.406250
iteration 694: loss 0.819 0.382812 0.437500
iteration 695: loss 0.875 0.273438 0.421875
iteration 696: loss 0.628 0.320312 0.476562
iteration 697: loss 0.891 0.312500 0.382812
iteration 698: loss 0.896 0.343750 0.445312
iteration 699: loss 0.781 0.367188 0.484375
iteration 700: loss 0.819 0.328125 0.453125
iteration 701: loss 1.005 0.367188 0.414062
iteration 702: loss 0.694 0.343750 0.507812
iteration 703: loss 0.830 0.351562 0.421875
iteration 704: loss 0.832 0.406250 0.429688
iteration 705: loss 0.819 0.304688 0.515625
iteration 706: loss 0.987 0.382812 0.484375
iteration 707: loss 0.659 0.265625 0.523438
iteration 708: loss 0.691 0.296875 0.507812
iteration 709: loss 0.842 0.367188 0.429688
iteration 710: loss 0.832 0.296875 0.554688
iteration 711: loss 0.887 0.343750 0.484375
iteration 712: loss 0.840 0.304688 0.421875
iteration 713: loss 0.871 0.367188 0.453125
iteration 714: loss 0.932 0.265625 0.445312
iteration 715: loss 0.757 0.265625 0.468750
iteration 716: loss 0.682 0.320312 0.484375
iteration 717: loss 0.855 0.250000 0.429688
iteration 718: loss 0.664 0.343750 0.554688
iteration 719: loss 0.986 0.234375 0.468750
iteration 720: loss 0.978 0.320312 0.468750
iteration 721: loss 0.665 0.289062 0.484375
iteration 722: loss 0.776 0.343750 0.500000
iteration 723: loss 0.733 0.335938 0.484375
iteration 724: loss 0.683 0.351562 0.429688
iteration 725: loss 0.850 0.390625 0.406250
iteration 726: loss 0.775 0.335938 0.484375
iteration 727: loss 0.809 0.312500 0.507812
iteration 728: loss 0.885 0.304688 0.375000
iteration 729: loss 0.541 0.343750 0.523438
iteration 730: loss 0.765 0.351562 0.445312
iteration 731: loss 0.811 0.343750 0.460938
iteration 732: loss 1.131 0.359375 0.460938
iteration 733: loss 0.877 0.304688 0.484375
iteration 734: loss 0.997 0.304688 0.445312
iteration 735: loss 0.820 0.343750 0.453125
iteration 736: loss 0.823 0.312500 0.500000
iteration 737: loss 0.843 0.335938 0.460938
iteration 738: loss 0.958 0.281250 0.453125
iteration 739: loss 0.878 0.289062 0.437500
iteration 740: loss 0.792 0.289062 0.492188
iteration 741: loss 0.901 0.390625 0.445312
iteration 742: loss 1.127 0.335938 0.414062
iteration 743: loss 0.841 0.359375 0.437500
iteration 744: loss 0.975 0.304688 0.453125
iteration 745: loss 0.909 0.203125 0.406250
iteration 746: loss 0.914 0.335938 0.406250
iteration 747: loss 0.792 0.273438 0.437500
iteration 748: loss 0.790 0.335938 0.500000
iteration 749: loss 0.752 0.320312 0.406250
iteration 750: loss 0.837 0.304688 0.460938
iteration 751: loss 0.950 0.281250 0.398438
iteration 752: loss 0.606 0.273438 0.523438
iteration 753: loss 0.871 0.265625 0.421875
iteration 754: loss 0.857 0.335938 0.453125
iteration 755: loss 0.626 0.335938 0.500000
iteration 756: loss 0.821 0.304688 0.507812
iteration 757: loss 0.913 0.328125 0.437500
iteration 758: loss 0.785 0.304688 0.453125
iteration 759: loss 1.109 0.343750 0.429688
iteration 760: loss 0.756 0.234375 0.476562
iteration 761: loss 0.773 0.289062 0.406250
iteration 762: loss 1.090 0.382812 0.445312
iteration 763: loss 1.045 0.375000 0.406250
iteration 764: loss 1.074 0.312500 0.390625
iteration 765: loss 1.043 0.320312 0.406250
iteration 766: loss 0.901 0.320312 0.406250
iteration 767: loss 0.614 0.312500 0.632812
iteration 768: loss 1.022 0.289062 0.539062
iteration 769: loss 0.946 0.335938 0.390625
iteration 770: loss 0.690 0.335938 0.484375
iteration 771: loss 0.747 0.281250 0.484375
iteration 772: loss 0.633 0.265625 0.476562
iteration 773: loss 0.822 0.234375 0.429688
iteration 774: loss 0.911 0.304688 0.429688
iteration 775: loss 0.890 0.296875 0.500000
iteration 776: loss 1.108 0.226562 0.375000
iteration 777: loss 0.766 0.304688 0.406250
iteration 778: loss 0.948 0.343750 0.390625
iteration 779: loss 0.832 0.375000 0.421875
iteration 780: loss 0.984 0.359375 0.414062
iteration 781: loss 0.887 0.320312 0.460938
iteration 782: loss 0.776 0.429688 0.500000
iteration 783: loss 0.951 0.351562 0.468750
iteration 784: loss 0.688 0.320312 0.546875
iteration 785: loss 1.008 0.320312 0.453125
iteration 786: loss 0.919 0.335938 0.437500
iteration 787: loss 0.922 0.328125 0.445312
iteration 788: loss 0.665 0.359375 0.492188
iteration 789: loss 0.788 0.335938 0.453125
iteration 790: loss 1.131 0.265625 0.390625
iteration 791: loss 1.041 0.242188 0.343750
iteration 792: loss 0.856 0.335938 0.414062
iteration 793: loss 0.944 0.296875 0.390625
iteration 794: loss 0.872 0.382812 0.468750
iteration 795: loss 0.915 0.320312 0.421875
iteration 796: loss 0.892 0.312500 0.437500
iteration 797: loss 0.893 0.289062 0.398438
iteration 798: loss 0.579 0.335938 0.546875
iteration 799: loss 0.974 0.328125 0.414062
iteration 800: loss 0.718 0.343750 0.562500
iteration 801: loss 1.182 0.367188 0.375000
iteration 802: loss 0.924 0.304688 0.437500
iteration 803: loss 0.788 0.335938 0.445312
iteration 804: loss 0.937 0.359375 0.414062
iteration 805: loss 1.051 0.304688 0.367188
iteration 806: loss 0.749 0.296875 0.468750
iteration 807: loss 0.907 0.335938 0.445312
iteration 808: loss 1.037 0.242188 0.492188
iteration 809: loss 0.958 0.242188 0.421875
iteration 810: loss 0.978 0.312500 0.476562
iteration 811: loss 0.853 0.312500 0.445312
iteration 812: loss 0.734 0.328125 0.546875
iteration 813: loss 0.944 0.273438 0.398438
iteration 814: loss 0.799 0.351562 0.414062
iteration 815: loss 0.829 0.250000 0.406250
iteration 816: loss 0.975 0.304688 0.421875
iteration 817: loss 0.918 0.367188 0.421875
iteration 818: loss 0.880 0.382812 0.460938
iteration 819: loss 1.041 0.335938 0.492188
iteration 820: loss 1.046 0.320312 0.468750
iteration 821: loss 0.864 0.359375 0.468750
iteration 822: loss 0.926 0.304688 0.429688
iteration 823: loss 0.783 0.312500 0.398438
iteration 824: loss 0.760 0.359375 0.437500
iteration 825: loss 0.770 0.367188 0.507812
iteration 826: loss 0.932 0.296875 0.484375
iteration 827: loss 0.603 0.343750 0.539062
iteration 828: loss 0.827 0.382812 0.421875
iteration 829: loss 0.957 0.351562 0.460938
iteration 830: loss 0.908 0.296875 0.453125
iteration 831: loss 0.749 0.312500 0.476562
iteration 832: loss 0.784 0.250000 0.468750
iteration 833: loss 0.674 0.312500 0.539062
iteration 834: loss 0.879 0.312500 0.398438
iteration 835: loss 1.109 0.343750 0.359375
iteration 836: loss 0.676 0.273438 0.476562
iteration 837: loss 0.962 0.281250 0.414062
iteration 838: loss 0.790 0.304688 0.429688
iteration 839: loss 0.736 0.375000 0.507812
iteration 840: loss 0.968 0.367188 0.437500
iteration 841: loss 0.712 0.273438 0.500000
iteration 842: loss 0.848 0.351562 0.484375
iteration 843: loss 0.830 0.359375 0.453125
iteration 844: loss 0.928 0.390625 0.460938
iteration 845: loss 0.885 0.320312 0.460938
iteration 846: loss 0.621 0.328125 0.507812
iteration 847: loss 0.833 0.375000 0.429688
iteration 848: loss 0.899 0.281250 0.398438
iteration 849: loss 0.906 0.320312 0.437500
iteration 850: loss 0.905 0.265625 0.460938
iteration 851: loss 0.773 0.320312 0.390625
iteration 852: loss 0.864 0.312500 0.492188
iteration 853: loss 0.916 0.234375 0.476562
iteration 854: loss 0.700 0.296875 0.492188
iteration 855: loss 1.013 0.312500 0.437500
iteration 856: loss 0.908 0.304688 0.421875
iteration 857: loss 0.858 0.335938 0.437500
iteration 858: loss 0.821 0.398438 0.406250
iteration 859: loss 0.776 0.304688 0.460938
iteration 860: loss 0.799 0.304688 0.460938
iteration 861: loss 0.806 0.210938 0.453125
iteration 862: loss 0.892 0.289062 0.484375
iteration 863: loss 0.935 0.304688 0.390625
iteration 864: loss 0.894 0.343750 0.429688
iteration 865: loss 0.996 0.312500 0.437500
iteration 866: loss 0.829 0.367188 0.484375
iteration 867: loss 1.049 0.273438 0.414062
iteration 868: loss 0.870 0.250000 0.414062
iteration 869: loss 0.956 0.335938 0.367188
iteration 870: loss 0.979 0.250000 0.460938
iteration 871: loss 0.827 0.234375 0.468750
iteration 872: loss 0.733 0.367188 0.515625
iteration 873: loss 1.127 0.289062 0.375000
iteration 874: loss 0.926 0.218750 0.406250
iteration 875: loss 1.058 0.312500 0.375000
iteration 876: loss 0.955 0.304688 0.453125
iteration 877: loss 0.774 0.242188 0.445312
iteration 878: loss 0.803 0.328125 0.500000
iteration 879: loss 0.884 0.273438 0.445312
iteration 880: loss 0.790 0.296875 0.507812
iteration 881: loss 0.898 0.273438 0.453125
iteration 882: loss 0.956 0.437500 0.453125
iteration 883: loss 0.635 0.406250 0.523438
iteration 884: loss 1.169 0.296875 0.359375
iteration 885: loss 0.988 0.328125 0.414062
iteration 886: loss 0.823 0.375000 0.429688
iteration 887: loss 0.811 0.320312 0.414062
iteration 888: loss 0.854 0.281250 0.421875
iteration 889: loss 0.953 0.375000 0.484375
iteration 890: loss 1.015 0.250000 0.335938
iteration 891: loss 0.895 0.296875 0.414062
iteration 892: loss 0.873 0.289062 0.406250
iteration 893: loss 1.091 0.312500 0.382812
iteration 894: loss 0.780 0.328125 0.460938
iteration 895: loss 0.895 0.273438 0.421875
iteration 896: loss 1.005 0.312500 0.445312
iteration 897: loss 0.960 0.289062 0.367188
iteration 898: loss 1.015 0.328125 0.414062
iteration 899: loss 0.955 0.273438 0.437500
iteration 900: loss 0.882 0.289062 0.429688
iteration 901: loss 0.797 0.304688 0.500000
iteration 902: loss 0.831 0.226562 0.429688
iteration 903: loss 0.822 0.273438 0.445312
iteration 904: loss 0.963 0.265625 0.343750
iteration 905: loss 0.702 0.304688 0.453125
iteration 906: loss 0.781 0.234375 0.539062
iteration 907: loss 0.839 0.328125 0.523438
iteration 908: loss 0.755 0.328125 0.460938
iteration 909: loss 0.835 0.289062 0.484375
iteration 910: loss 1.112 0.312500 0.437500
iteration 911: loss 0.862 0.289062 0.460938
iteration 912: loss 0.803 0.296875 0.453125
iteration 913: loss 1.112 0.273438 0.453125
iteration 914: loss 1.012 0.296875 0.476562
iteration 915: loss 0.966 0.359375 0.437500
iteration 916: loss 0.852 0.281250 0.515625
iteration 917: loss 0.884 0.335938 0.429688
iteration 918: loss 0.926 0.320312 0.414062
iteration 919: loss 1.037 0.257812 0.445312
iteration 920: loss 0.796 0.328125 0.554688
iteration 921: loss 0.633 0.312500 0.445312
iteration 922: loss 0.838 0.390625 0.453125
iteration 923: loss 0.564 0.281250 0.539062
iteration 924: loss 0.702 0.265625 0.492188
iteration 925: loss 0.866 0.367188 0.484375
iteration 926: loss 1.049 0.296875 0.492188
iteration 927: loss 0.890 0.351562 0.445312
iteration 928: loss 0.704 0.343750 0.531250
iteration 929: loss 0.918 0.320312 0.414062
iteration 930: loss 0.734 0.343750 0.554688
iteration 931: loss 0.921 0.289062 0.414062
iteration 932: loss 1.188 0.242188 0.429688
iteration 933: loss 0.806 0.312500 0.398438
iteration 934: loss 0.924 0.296875 0.500000
iteration 935: loss 0.705 0.320312 0.500000
iteration 936: loss 0.782 0.312500 0.484375
iteration 937: loss 0.793 0.328125 0.445312
iteration 938: loss 0.835 0.359375 0.460938
iteration 939: loss 1.018 0.257812 0.453125
iteration 940: loss 0.802 0.304688 0.429688
iteration 941: loss 1.051 0.312500 0.375000
iteration 942: loss 0.773 0.281250 0.437500
iteration 943: loss 1.033 0.281250 0.359375
iteration 944: loss 0.822 0.203125 0.453125
iteration 945: loss 0.867 0.328125 0.398438
iteration 946: loss 0.978 0.421875 0.429688
iteration 947: loss 0.748 0.390625 0.531250
iteration 948: loss 0.724 0.312500 0.578125
iteration 949: loss 0.953 0.281250 0.468750
iteration 950: loss 0.912 0.328125 0.500000
iteration 951: loss 1.048 0.320312 0.429688
iteration 952: loss 0.826 0.304688 0.429688
iteration 953: loss 0.794 0.328125 0.484375
iteration 954: loss 0.971 0.265625 0.468750
iteration 955: loss 0.957 0.343750 0.406250
iteration 956: loss 0.810 0.406250 0.484375
iteration 957: loss 0.836 0.328125 0.507812
iteration 958: loss 0.704 0.304688 0.523438
iteration 959: loss 1.047 0.296875 0.382812
iteration 960: loss 0.981 0.265625 0.453125
iteration 961: loss 0.694 0.320312 0.492188
iteration 962: loss 0.544 0.304688 0.539062
iteration 963: loss 1.126 0.359375 0.421875
iteration 964: loss 0.736 0.375000 0.492188
iteration 965: loss 0.756 0.406250 0.539062
iteration 966: loss 0.742 0.265625 0.492188
iteration 967: loss 0.753 0.296875 0.492188
iteration 968: loss 0.965 0.320312 0.437500
iteration 969: loss 0.753 0.367188 0.476562
iteration 970: loss 0.723 0.281250 0.500000
iteration 971: loss 0.980 0.273438 0.414062
iteration 972: loss 0.849 0.296875 0.429688
iteration 973: loss 0.805 0.367188 0.476562
iteration 974: loss 0.687 0.304688 0.468750
iteration 975: loss 0.853 0.351562 0.453125
iteration 976: loss 0.812 0.304688 0.500000
iteration 977: loss 0.836 0.359375 0.437500
iteration 978: loss 0.851 0.312500 0.460938
iteration 979: loss 0.758 0.265625 0.484375
iteration 980: loss 1.093 0.398438 0.437500
iteration 981: loss 0.848 0.320312 0.445312
iteration 982: loss 1.133 0.320312 0.375000
iteration 983: loss 0.842 0.343750 0.437500
iteration 984: loss 0.681 0.242188 0.468750
iteration 985: loss 0.717 0.289062 0.507812
iteration 986: loss 0.719 0.257812 0.460938
iteration 987: loss 0.820 0.296875 0.460938
iteration 988: loss 0.941 0.312500 0.375000
iteration 989: loss 0.806 0.312500 0.429688
iteration 990: loss 0.874 0.343750 0.414062
iteration 991: loss 0.867 0.273438 0.421875
iteration 992: loss 0.727 0.320312 0.445312
iteration 993: loss 0.720 0.367188 0.429688
iteration 994: loss 0.956 0.234375 0.437500
iteration 995: loss 0.757 0.296875 0.515625
iteration 996: loss 0.825 0.289062 0.468750
iteration 997: loss 0.865 0.281250 0.421875
iteration 998: loss 0.869 0.273438 0.492188
iteration 999: loss 0.885 0.398438 0.445312
epoch 5: training: 0.328125 validation: 0.234375
iteration 0: loss 0.678 0.289062 0.546875
iteration 1: loss 0.985 0.312500 0.453125
iteration 2: loss 0.738 0.281250 0.468750
iteration 3: loss 0.917 0.250000 0.312500
iteration 4: loss 0.781 0.304688 0.406250
iteration 5: loss 0.771 0.359375 0.492188
iteration 6: loss 0.712 0.343750 0.507812
iteration 7: loss 0.861 0.289062 0.445312
iteration 8: loss 0.768 0.281250 0.476562
iteration 9: loss 0.801 0.359375 0.398438
iteration 10: loss 0.866 0.281250 0.421875
iteration 11: loss 0.663 0.328125 0.546875
iteration 12: loss 0.725 0.289062 0.562500
iteration 13: loss 0.724 0.320312 0.476562
iteration 14: loss 0.655 0.296875 0.460938
iteration 15: loss 0.836 0.312500 0.367188
iteration 16: loss 0.724 0.296875 0.500000
iteration 17: loss 0.891 0.335938 0.492188
iteration 18: loss 1.082 0.335938 0.468750
iteration 19: loss 0.709 0.312500 0.468750
iteration 20: loss 0.983 0.312500 0.367188
iteration 21: loss 0.859 0.343750 0.437500
iteration 22: loss 0.724 0.421875 0.421875
iteration 23: loss 0.699 0.382812 0.460938
iteration 24: loss 0.880 0.367188 0.445312
iteration 25: loss 0.773 0.320312 0.390625
iteration 26: loss 0.632 0.257812 0.546875
iteration 27: loss 0.728 0.328125 0.476562
iteration 28: loss 0.720 0.273438 0.468750
iteration 29: loss 1.023 0.289062 0.406250
iteration 30: loss 0.818 0.421875 0.500000
iteration 31: loss 0.677 0.359375 0.562500
iteration 32: loss 0.744 0.304688 0.515625
iteration 33: loss 0.873 0.226562 0.460938
iteration 34: loss 0.820 0.289062 0.437500
iteration 35: loss 0.907 0.265625 0.460938
iteration 36: loss 0.775 0.312500 0.476562
iteration 37: loss 0.729 0.304688 0.546875
iteration 38: loss 0.640 0.281250 0.531250
iteration 39: loss 1.011 0.359375 0.421875
iteration 40: loss 0.769 0.250000 0.500000
iteration 41: loss 0.790 0.265625 0.445312
iteration 42: loss 0.969 0.398438 0.406250
iteration 43: loss 0.847 0.351562 0.445312
iteration 44: loss 0.672 0.367188 0.484375
iteration 45: loss 0.892 0.265625 0.421875
iteration 46: loss 0.784 0.351562 0.414062
iteration 47: loss 0.752 0.367188 0.445312
iteration 48: loss 0.889 0.328125 0.398438
iteration 49: loss 0.757 0.382812 0.476562
iteration 50: loss 0.710 0.343750 0.531250
iteration 51: loss 0.739 0.335938 0.523438
iteration 52: loss 0.517 0.289062 0.601562
iteration 53: loss 0.688 0.312500 0.531250
iteration 54: loss 0.844 0.210938 0.382812
iteration 55: loss 0.669 0.304688 0.484375
iteration 56: loss 0.666 0.382812 0.500000
iteration 57: loss 0.719 0.296875 0.484375
iteration 58: loss 0.974 0.335938 0.390625
iteration 59: loss 0.754 0.359375 0.453125
iteration 60: loss 0.791 0.312500 0.476562
iteration 61: loss 0.704 0.304688 0.484375
iteration 62: loss 1.018 0.304688 0.398438
iteration 63: loss 0.987 0.273438 0.343750
iteration 64: loss 1.016 0.273438 0.390625
iteration 65: loss 1.034 0.273438 0.320312
iteration 66: loss 0.632 0.359375 0.484375
iteration 67: loss 0.642 0.289062 0.531250
iteration 68: loss 0.733 0.390625 0.500000
iteration 69: loss 0.833 0.304688 0.453125
iteration 70: loss 0.980 0.320312 0.414062
iteration 71: loss 0.768 0.257812 0.437500
iteration 72: loss 0.725 0.328125 0.515625
iteration 73: loss 0.715 0.304688 0.476562
iteration 74: loss 0.977 0.304688 0.390625
iteration 75: loss 0.731 0.328125 0.492188
iteration 76: loss 0.859 0.359375 0.468750
iteration 77: loss 0.992 0.382812 0.437500
iteration 78: loss 0.725 0.359375 0.531250
iteration 79: loss 0.882 0.375000 0.375000
iteration 80: loss 0.982 0.328125 0.390625
iteration 81: loss 0.607 0.273438 0.539062
iteration 82: loss 0.771 0.265625 0.445312
iteration 83: loss 0.967 0.351562 0.375000
iteration 84: loss 0.842 0.289062 0.429688
iteration 85: loss 0.686 0.273438 0.421875
iteration 86: loss 0.804 0.289062 0.460938
iteration 87: loss 0.823 0.406250 0.453125
iteration 88: loss 0.391 0.320312 0.695312
iteration 89: loss 1.090 0.390625 0.359375
iteration 90: loss 0.948 0.328125 0.453125
iteration 91: loss 1.013 0.281250 0.445312
iteration 92: loss 0.974 0.367188 0.437500
iteration 93: loss 0.846 0.351562 0.382812
iteration 94: loss 0.979 0.265625 0.359375
iteration 95: loss 1.009 0.382812 0.492188
iteration 96: loss 0.758 0.343750 0.546875
iteration 97: loss 0.904 0.320312 0.445312
iteration 98: loss 0.805 0.250000 0.468750
iteration 99: loss 0.947 0.328125 0.429688
iteration 100: loss 0.667 0.382812 0.515625
iteration 101: loss 0.911 0.273438 0.453125
iteration 102: loss 0.614 0.359375 0.531250
iteration 103: loss 0.882 0.296875 0.460938
iteration 104: loss 1.070 0.359375 0.398438
iteration 105: loss 1.116 0.226562 0.398438
iteration 106: loss 0.924 0.343750 0.445312
iteration 107: loss 0.807 0.320312 0.453125
iteration 108: loss 1.015 0.304688 0.468750
iteration 109: loss 1.053 0.289062 0.328125
iteration 110: loss 0.802 0.257812 0.460938
iteration 111: loss 0.871 0.351562 0.445312
iteration 112: loss 0.879 0.343750 0.414062
iteration 113: loss 0.765 0.312500 0.460938
iteration 114: loss 0.865 0.281250 0.453125
iteration 115: loss 0.972 0.265625 0.406250
iteration 116: loss 0.876 0.343750 0.460938
iteration 117: loss 0.967 0.265625 0.375000
iteration 118: loss 0.812 0.281250 0.460938
iteration 119: loss 0.724 0.304688 0.476562
iteration 120: loss 0.970 0.250000 0.492188
iteration 121: loss 1.016 0.289062 0.484375
iteration 122: loss 0.727 0.281250 0.531250
iteration 123: loss 0.963 0.289062 0.453125
iteration 124: loss 0.719 0.398438 0.476562
iteration 125: loss 0.848 0.398438 0.500000
iteration 126: loss 0.854 0.343750 0.468750
iteration 127: loss 1.044 0.296875 0.398438
iteration 128: loss 0.636 0.296875 0.492188
iteration 129: loss 0.965 0.304688 0.406250
iteration 130: loss 0.702 0.250000 0.414062
iteration 131: loss 0.699 0.320312 0.476562
iteration 132: loss 0.856 0.367188 0.460938
iteration 133: loss 0.668 0.289062 0.507812
iteration 134: loss 1.032 0.304688 0.484375
iteration 135: loss 0.992 0.304688 0.476562
iteration 136: loss 0.721 0.351562 0.492188
iteration 137: loss 0.943 0.265625 0.500000
iteration 138: loss 0.796 0.312500 0.492188
iteration 139: loss 0.808 0.281250 0.429688
iteration 140: loss 0.978 0.406250 0.406250
iteration 141: loss 0.869 0.359375 0.453125
iteration 142: loss 1.025 0.273438 0.437500
iteration 143: loss 0.622 0.335938 0.460938
iteration 144: loss 0.886 0.289062 0.390625
iteration 145: loss 0.700 0.398438 0.507812
iteration 146: loss 0.835 0.335938 0.500000
iteration 147: loss 0.871 0.328125 0.429688
iteration 148: loss 1.048 0.250000 0.421875
iteration 149: loss 1.010 0.257812 0.406250
iteration 150: loss 0.764 0.335938 0.453125
iteration 151: loss 0.757 0.367188 0.437500
iteration 152: loss 0.900 0.312500 0.398438
iteration 153: loss 0.983 0.367188 0.335938
iteration 154: loss 0.952 0.273438 0.406250
iteration 155: loss 0.792 0.335938 0.539062
iteration 156: loss 0.775 0.335938 0.554688
iteration 157: loss 0.890 0.281250 0.523438
iteration 158: loss 0.696 0.367188 0.468750
iteration 159: loss 0.887 0.304688 0.445312
iteration 160: loss 1.161 0.257812 0.421875
iteration 161: loss 0.791 0.343750 0.429688
iteration 162: loss 0.974 0.375000 0.492188
iteration 163: loss 0.923 0.328125 0.429688
iteration 164: loss 0.962 0.273438 0.476562
iteration 165: loss 0.718 0.296875 0.507812
iteration 166: loss 0.899 0.351562 0.460938
iteration 167: loss 0.924 0.335938 0.390625
iteration 168: loss 0.831 0.312500 0.468750
iteration 169: loss 0.945 0.343750 0.390625
iteration 170: loss 0.809 0.335938 0.460938
iteration 171: loss 0.886 0.304688 0.382812
iteration 172: loss 0.945 0.273438 0.484375
iteration 173: loss 0.922 0.320312 0.421875
iteration 174: loss 0.674 0.375000 0.484375
iteration 175: loss 0.621 0.250000 0.515625
iteration 176: loss 0.886 0.335938 0.476562
iteration 177: loss 1.008 0.343750 0.382812
iteration 178: loss 0.725 0.265625 0.515625
iteration 179: loss 1.138 0.312500 0.421875
iteration 180: loss 0.885 0.210938 0.429688
iteration 181: loss 0.918 0.203125 0.445312
iteration 182: loss 0.685 0.257812 0.523438
iteration 183: loss 0.758 0.359375 0.453125
iteration 184: loss 0.695 0.335938 0.476562
iteration 185: loss 0.937 0.250000 0.375000
iteration 186: loss 1.132 0.304688 0.429688
iteration 187: loss 0.909 0.265625 0.453125
iteration 188: loss 0.652 0.351562 0.460938
iteration 189: loss 0.824 0.304688 0.445312
iteration 190: loss 0.704 0.382812 0.453125
iteration 191: loss 0.866 0.289062 0.445312
iteration 192: loss 0.852 0.257812 0.476562
iteration 193: loss 0.905 0.375000 0.453125
iteration 194: loss 0.638 0.304688 0.531250
iteration 195: loss 0.865 0.273438 0.476562
iteration 196: loss 1.086 0.390625 0.382812
iteration 197: loss 0.947 0.375000 0.453125
iteration 198: loss 1.175 0.273438 0.437500
iteration 199: loss 0.922 0.281250 0.460938
iteration 200: loss 0.740 0.359375 0.468750
iteration 201: loss 0.830 0.351562 0.453125
iteration 202: loss 0.719 0.351562 0.507812
iteration 203: loss 0.982 0.312500 0.460938
iteration 204: loss 0.812 0.359375 0.453125
iteration 205: loss 0.934 0.328125 0.445312
iteration 206: loss 0.783 0.265625 0.429688
iteration 207: loss 0.879 0.273438 0.476562
iteration 208: loss 0.826 0.265625 0.515625
iteration 209: loss 0.828 0.289062 0.429688
iteration 210: loss 0.839 0.351562 0.406250
iteration 211: loss 0.813 0.250000 0.437500
iteration 212: loss 0.969 0.312500 0.453125
iteration 213: loss 0.644 0.265625 0.515625
iteration 214: loss 0.845 0.312500 0.421875
iteration 215: loss 0.590 0.320312 0.531250
iteration 216: loss 0.772 0.304688 0.460938
iteration 217: loss 0.872 0.312500 0.406250
iteration 218: loss 0.826 0.234375 0.382812
iteration 219: loss 0.692 0.328125 0.515625
iteration 220: loss 0.737 0.328125 0.445312
iteration 221: loss 0.895 0.359375 0.414062
iteration 222: loss 0.956 0.242188 0.421875
iteration 223: loss 0.846 0.296875 0.468750
iteration 224: loss 0.835 0.289062 0.437500
iteration 225: loss 0.849 0.312500 0.437500
iteration 226: loss 0.895 0.375000 0.476562
iteration 227: loss 0.975 0.312500 0.398438
iteration 228: loss 0.893 0.328125 0.445312
iteration 229: loss 0.935 0.281250 0.390625
iteration 230: loss 0.887 0.335938 0.500000
iteration 231: loss 0.742 0.273438 0.546875
iteration 232: loss 1.020 0.312500 0.375000
iteration 233: loss 0.931 0.312500 0.484375
iteration 234: loss 0.632 0.250000 0.523438
iteration 235: loss 0.813 0.351562 0.460938
iteration 236: loss 0.899 0.289062 0.468750
iteration 237: loss 0.763 0.273438 0.492188
iteration 238: loss 0.558 0.281250 0.515625
iteration 239: loss 0.803 0.281250 0.523438
iteration 240: loss 0.899 0.273438 0.460938
iteration 241: loss 0.860 0.281250 0.437500
iteration 242: loss 1.083 0.359375 0.414062
iteration 243: loss 0.787 0.289062 0.546875
iteration 244: loss 0.997 0.367188 0.421875
iteration 245: loss 1.050 0.320312 0.414062
iteration 246: loss 1.092 0.289062 0.375000
iteration 247: loss 0.915 0.351562 0.437500
iteration 248: loss 1.143 0.406250 0.343750
iteration 249: loss 0.868 0.335938 0.421875
iteration 250: loss 0.794 0.296875 0.476562
iteration 251: loss 0.836 0.304688 0.460938
iteration 252: loss 0.737 0.289062 0.492188
iteration 253: loss 0.703 0.312500 0.546875
iteration 254: loss 0.845 0.335938 0.437500
iteration 255: loss 0.931 0.257812 0.437500
iteration 256: loss 0.780 0.304688 0.507812
iteration 257: loss 0.843 0.312500 0.429688
iteration 258: loss 0.905 0.328125 0.515625
iteration 259: loss 0.563 0.390625 0.476562
iteration 260: loss 0.820 0.351562 0.429688
iteration 261: loss 0.857 0.296875 0.375000
iteration 262: loss 0.834 0.359375 0.453125
iteration 263: loss 0.842 0.304688 0.484375
iteration 264: loss 0.621 0.343750 0.523438
iteration 265: loss 0.697 0.289062 0.421875
iteration 266: loss 0.937 0.296875 0.406250
iteration 267: loss 0.966 0.390625 0.382812
iteration 268: loss 0.639 0.328125 0.546875
iteration 269: loss 0.805 0.234375 0.468750
iteration 270: loss 0.793 0.289062 0.468750
iteration 271: loss 0.825 0.359375 0.429688
iteration 272: loss 0.908 0.265625 0.437500
iteration 273: loss 1.134 0.289062 0.476562
iteration 274: loss 0.804 0.343750 0.507812
iteration 275: loss 0.775 0.312500 0.445312
iteration 276: loss 0.836 0.289062 0.484375
iteration 277: loss 0.900 0.257812 0.429688
iteration 278: loss 1.041 0.296875 0.460938
iteration 279: loss 0.875 0.351562 0.398438
iteration 280: loss 0.862 0.273438 0.406250
iteration 281: loss 0.959 0.289062 0.367188
iteration 282: loss 0.775 0.289062 0.429688
iteration 283: loss 0.729 0.312500 0.492188
iteration 284: loss 0.897 0.304688 0.414062
iteration 285: loss 0.619 0.234375 0.500000
iteration 286: loss 0.695 0.273438 0.453125
iteration 287: loss 1.099 0.312500 0.414062
iteration 288: loss 0.783 0.328125 0.476562
iteration 289: loss 0.719 0.367188 0.476562
iteration 290: loss 0.816 0.351562 0.468750
iteration 291: loss 0.804 0.296875 0.476562
iteration 292: loss 0.829 0.296875 0.468750
iteration 293: loss 0.832 0.203125 0.320312
iteration 294: loss 0.777 0.289062 0.492188
iteration 295: loss 0.711 0.335938 0.531250
iteration 296: loss 0.713 0.398438 0.539062
iteration 297: loss 0.746 0.328125 0.515625
iteration 298: loss 0.819 0.281250 0.437500
iteration 299: loss 0.734 0.335938 0.476562
iteration 300: loss 0.907 0.265625 0.453125
iteration 301: loss 0.797 0.359375 0.476562
iteration 302: loss 0.807 0.312500 0.398438
iteration 303: loss 0.698 0.257812 0.460938
iteration 304: loss 0.773 0.242188 0.390625
iteration 305: loss 0.837 0.289062 0.445312
iteration 306: loss 0.909 0.250000 0.453125
iteration 307: loss 0.953 0.250000 0.429688
iteration 308: loss 0.786 0.257812 0.429688
iteration 309: loss 0.954 0.320312 0.445312
iteration 310: loss 0.774 0.343750 0.500000
iteration 311: loss 0.989 0.343750 0.429688
iteration 312: loss 0.767 0.343750 0.500000
iteration 313: loss 0.804 0.289062 0.445312
iteration 314: loss 0.732 0.265625 0.492188
iteration 315: loss 0.883 0.218750 0.414062
iteration 316: loss 0.701 0.265625 0.492188
iteration 317: loss 0.864 0.281250 0.437500
iteration 318: loss 0.583 0.281250 0.546875
iteration 319: loss 0.750 0.359375 0.492188
iteration 320: loss 0.797 0.296875 0.414062
iteration 321: loss 0.880 0.328125 0.312500
iteration 322: loss 0.844 0.273438 0.445312
iteration 323: loss 0.749 0.398438 0.437500
iteration 324: loss 0.953 0.265625 0.445312
iteration 325: loss 0.810 0.289062 0.460938
iteration 326: loss 0.846 0.320312 0.421875
iteration 327: loss 0.847 0.289062 0.437500
iteration 328: loss 0.912 0.273438 0.468750
iteration 329: loss 0.614 0.375000 0.492188
iteration 330: loss 0.854 0.351562 0.468750
iteration 331: loss 0.793 0.242188 0.460938
iteration 332: loss 1.050 0.320312 0.398438
iteration 333: loss 0.825 0.328125 0.445312
iteration 334: loss 0.830 0.312500 0.460938
iteration 335: loss 0.798 0.296875 0.453125
iteration 336: loss 0.808 0.320312 0.500000
iteration 337: loss 0.929 0.328125 0.492188
iteration 338: loss 0.769 0.312500 0.445312
iteration 339: loss 0.895 0.242188 0.367188
iteration 340: loss 0.677 0.312500 0.539062
iteration 341: loss 0.718 0.304688 0.476562
iteration 342: loss 0.728 0.359375 0.445312
iteration 343: loss 0.717 0.296875 0.453125
iteration 344: loss 0.862 0.328125 0.437500
iteration 345: loss 0.763 0.296875 0.453125
iteration 346: loss 0.805 0.335938 0.460938
iteration 347: loss 0.986 0.289062 0.507812
iteration 348: loss 0.712 0.234375 0.515625
iteration 349: loss 0.759 0.296875 0.492188
iteration 350: loss 0.616 0.312500 0.515625
iteration 351: loss 0.902 0.304688 0.460938
iteration 352: loss 0.841 0.320312 0.500000
iteration 353: loss 0.874 0.312500 0.414062
iteration 354: loss 0.799 0.367188 0.476562
iteration 355: loss 0.737 0.343750 0.507812
iteration 356: loss 0.693 0.343750 0.492188
iteration 357: loss 0.995 0.335938 0.414062
iteration 358: loss 0.949 0.265625 0.453125
iteration 359: loss 0.716 0.250000 0.492188
iteration 360: loss 0.736 0.273438 0.476562
iteration 361: loss 0.827 0.312500 0.468750
iteration 362: loss 0.901 0.351562 0.351562
iteration 363: loss 0.820 0.312500 0.390625
iteration 364: loss 0.901 0.328125 0.335938
iteration 365: loss 0.919 0.195312 0.398438
iteration 366: loss 0.687 0.375000 0.460938
iteration 367: loss 0.518 0.273438 0.570312
iteration 368: loss 0.752 0.289062 0.445312
iteration 369: loss 0.740 0.304688 0.484375
iteration 370: loss 0.846 0.296875 0.460938
iteration 371: loss 0.769 0.335938 0.468750
iteration 372: loss 0.830 0.359375 0.507812
iteration 373: loss 0.691 0.289062 0.523438
iteration 374: loss 0.969 0.312500 0.460938
iteration 375: loss 0.848 0.289062 0.445312
iteration 376: loss 0.831 0.289062 0.476562
iteration 377: loss 0.936 0.289062 0.414062
iteration 378: loss 0.953 0.328125 0.429688
iteration 379: loss 0.820 0.382812 0.460938
iteration 380: loss 0.850 0.281250 0.429688
iteration 381: loss 1.057 0.265625 0.453125
iteration 382: loss 0.699 0.382812 0.507812
iteration 383: loss 0.835 0.335938 0.390625
iteration 384: loss 0.748 0.328125 0.460938
iteration 385: loss 0.869 0.281250 0.375000
iteration 386: loss 0.847 0.320312 0.382812
iteration 387: loss 0.773 0.328125 0.539062
iteration 388: loss 0.869 0.289062 0.437500
iteration 389: loss 0.980 0.359375 0.437500
iteration 390: loss 0.927 0.304688 0.453125
iteration 391: loss 0.832 0.351562 0.468750
iteration 392: loss 0.689 0.351562 0.562500
iteration 393: loss 0.998 0.289062 0.460938
iteration 394: loss 0.851 0.273438 0.476562
iteration 395: loss 0.927 0.312500 0.375000
iteration 396: loss 0.948 0.234375 0.351562
iteration 397: loss 0.925 0.421875 0.445312
iteration 398: loss 0.698 0.289062 0.500000
iteration 399: loss 0.725 0.312500 0.492188
iteration 400: loss 0.780 0.398438 0.562500
iteration 401: loss 0.873 0.351562 0.445312
iteration 402: loss 0.962 0.312500 0.484375
iteration 403: loss 0.850 0.335938 0.437500
iteration 404: loss 0.618 0.304688 0.484375
iteration 405: loss 0.806 0.320312 0.484375
iteration 406: loss 0.733 0.257812 0.484375
iteration 407: loss 0.700 0.281250 0.515625
iteration 408: loss 1.058 0.257812 0.367188
iteration 409: loss 0.827 0.367188 0.398438
iteration 410: loss 0.899 0.296875 0.406250
iteration 411: loss 0.816 0.281250 0.445312
iteration 412: loss 0.663 0.382812 0.554688
iteration 413: loss 0.744 0.304688 0.484375
iteration 414: loss 0.798 0.320312 0.507812
iteration 415: loss 1.210 0.328125 0.390625
iteration 416: loss 0.952 0.335938 0.398438
iteration 417: loss 0.908 0.335938 0.500000
iteration 418: loss 0.798 0.335938 0.460938
iteration 419: loss 0.896 0.359375 0.492188
iteration 420: loss 0.787 0.312500 0.429688
iteration 421: loss 0.882 0.335938 0.445312
iteration 422: loss 0.805 0.320312 0.453125
iteration 423: loss 0.653 0.273438 0.460938
iteration 424: loss 0.814 0.304688 0.500000
iteration 425: loss 0.907 0.328125 0.453125
iteration 426: loss 0.740 0.312500 0.406250
iteration 427: loss 0.964 0.242188 0.390625
iteration 428: loss 0.674 0.304688 0.539062
iteration 429: loss 0.617 0.250000 0.531250
iteration 430: loss 0.816 0.296875 0.414062
iteration 431: loss 0.936 0.320312 0.468750
iteration 432: loss 0.703 0.281250 0.484375
iteration 433: loss 0.733 0.320312 0.484375
iteration 434: loss 0.737 0.304688 0.421875
iteration 435: loss 0.993 0.328125 0.351562
iteration 436: loss 0.599 0.312500 0.500000
iteration 437: loss 0.807 0.273438 0.398438
iteration 438: loss 0.862 0.281250 0.320312
iteration 439: loss 0.842 0.265625 0.398438
iteration 440: loss 0.844 0.351562 0.437500
iteration 441: loss 0.821 0.218750 0.398438
iteration 442: loss 0.962 0.289062 0.429688
iteration 443: loss 0.870 0.390625 0.437500
iteration 444: loss 0.778 0.335938 0.406250
iteration 445: loss 0.672 0.367188 0.531250
iteration 446: loss 0.852 0.312500 0.421875
iteration 447: loss 0.839 0.289062 0.460938
iteration 448: loss 1.064 0.343750 0.445312
iteration 449: loss 0.850 0.320312 0.453125
iteration 450: loss 0.879 0.289062 0.375000
iteration 451: loss 0.720 0.328125 0.437500
iteration 452: loss 0.722 0.335938 0.414062
iteration 453: loss 0.708 0.335938 0.421875
iteration 454: loss 0.849 0.359375 0.453125
iteration 455: loss 0.659 0.382812 0.468750
iteration 456: loss 0.823 0.328125 0.468750
iteration 457: loss 0.775 0.250000 0.492188
iteration 458: loss 1.213 0.203125 0.453125
iteration 459: loss 0.723 0.359375 0.515625
iteration 460: loss 0.917 0.312500 0.421875
iteration 461: loss 1.002 0.375000 0.343750
iteration 462: loss 0.781 0.257812 0.429688
iteration 463: loss 0.861 0.296875 0.406250
iteration 464: loss 0.841 0.312500 0.390625
iteration 465: loss 0.817 0.296875 0.382812
iteration 466: loss 0.885 0.375000 0.406250
iteration 467: loss 0.611 0.234375 0.476562
iteration 468: loss 0.683 0.289062 0.562500
iteration 469: loss 0.865 0.312500 0.492188
iteration 470: loss 0.804 0.281250 0.468750
iteration 471: loss 0.943 0.328125 0.453125
iteration 472: loss 0.825 0.234375 0.437500
iteration 473: loss 0.908 0.265625 0.390625
iteration 474: loss 0.820 0.257812 0.398438
iteration 475: loss 0.891 0.312500 0.445312
iteration 476: loss 0.783 0.296875 0.476562
iteration 477: loss 0.792 0.367188 0.429688
iteration 478: loss 0.853 0.382812 0.414062
iteration 479: loss 0.917 0.265625 0.414062
iteration 480: loss 0.855 0.218750 0.398438
iteration 481: loss 0.828 0.289062 0.460938
iteration 482: loss 0.742 0.335938 0.515625
iteration 483: loss 0.719 0.335938 0.476562
iteration 484: loss 1.147 0.265625 0.375000
iteration 485: loss 0.816 0.234375 0.492188
iteration 486: loss 0.912 0.343750 0.382812
iteration 487: loss 0.705 0.328125 0.421875
iteration 488: loss 0.872 0.234375 0.429688
iteration 489: loss 0.725 0.320312 0.445312
iteration 490: loss 0.728 0.421875 0.500000
iteration 491: loss 0.642 0.289062 0.500000
iteration 492: loss 0.716 0.328125 0.484375
iteration 493: loss 0.748 0.250000 0.453125
iteration 494: loss 0.912 0.289062 0.421875
iteration 495: loss 0.708 0.328125 0.492188
iteration 496: loss 0.597 0.296875 0.492188
iteration 497: loss 0.610 0.281250 0.406250
iteration 498: loss 0.843 0.203125 0.406250
iteration 499: loss 0.847 0.273438 0.515625
iteration 500: loss 0.763 0.265625 0.500000
iteration 501: loss 0.847 0.367188 0.437500
iteration 502: loss 0.822 0.234375 0.421875
iteration 503: loss 0.803 0.273438 0.429688
iteration 504: loss 0.784 0.304688 0.375000
iteration 505: loss 0.771 0.351562 0.500000
iteration 506: loss 0.914 0.304688 0.398438
iteration 507: loss 0.831 0.242188 0.460938
iteration 508: loss 0.717 0.343750 0.492188
iteration 509: loss 0.827 0.328125 0.406250
iteration 510: loss 0.845 0.257812 0.414062
iteration 511: loss 0.721 0.304688 0.484375
iteration 512: loss 0.773 0.328125 0.398438
iteration 513: loss 0.738 0.351562 0.406250
iteration 514: loss 0.785 0.343750 0.406250
iteration 515: loss 0.788 0.375000 0.453125
iteration 516: loss 0.889 0.242188 0.460938
iteration 517: loss 0.871 0.257812 0.390625
iteration 518: loss 0.745 0.320312 0.554688
iteration 519: loss 0.704 0.320312 0.484375
iteration 520: loss 0.480 0.328125 0.523438
iteration 521: loss 0.717 0.320312 0.398438
iteration 522: loss 0.703 0.242188 0.515625
iteration 523: loss 0.833 0.242188 0.445312
iteration 524: loss 0.896 0.273438 0.453125
iteration 525: loss 0.764 0.289062 0.406250
iteration 526: loss 0.663 0.320312 0.484375
iteration 527: loss 0.628 0.312500 0.546875
iteration 528: loss 0.768 0.304688 0.398438
iteration 529: loss 0.982 0.226562 0.414062
iteration 530: loss 1.049 0.328125 0.421875
iteration 531: loss 0.688 0.312500 0.468750
iteration 532: loss 0.939 0.234375 0.414062
iteration 533: loss 0.939 0.281250 0.421875
iteration 534: loss 0.928 0.367188 0.406250
iteration 535: loss 0.713 0.242188 0.445312
iteration 536: loss 0.886 0.343750 0.453125
iteration 537: loss 0.687 0.328125 0.460938
iteration 538: loss 0.535 0.375000 0.546875
iteration 539: loss 0.687 0.351562 0.492188
iteration 540: loss 0.887 0.304688 0.429688
iteration 541: loss 0.635 0.320312 0.484375
iteration 542: loss 0.805 0.257812 0.460938
iteration 543: loss 0.869 0.343750 0.421875
iteration 544: loss 1.047 0.281250 0.351562
iteration 545: loss 0.932 0.367188 0.414062
iteration 546: loss 0.632 0.273438 0.515625
iteration 547: loss 0.683 0.312500 0.484375
iteration 548: loss 0.693 0.312500 0.437500
iteration 549: loss 0.694 0.343750 0.460938
iteration 550: loss 0.752 0.296875 0.539062
iteration 551: loss 0.795 0.281250 0.476562
iteration 552: loss 0.743 0.320312 0.500000
iteration 553: loss 0.773 0.312500 0.468750
iteration 554: loss 0.667 0.257812 0.500000
iteration 555: loss 0.683 0.265625 0.468750
iteration 556: loss 0.686 0.335938 0.453125
iteration 557: loss 0.698 0.257812 0.539062
iteration 558: loss 0.766 0.328125 0.476562
iteration 559: loss 0.791 0.242188 0.507812
iteration 560: loss 0.804 0.289062 0.468750
iteration 561: loss 0.845 0.304688 0.445312
iteration 562: loss 0.702 0.281250 0.460938
iteration 563: loss 0.674 0.304688 0.476562
iteration 564: loss 0.556 0.328125 0.562500
iteration 565: loss 0.641 0.257812 0.476562
iteration 566: loss 0.776 0.289062 0.515625
iteration 567: loss 0.761 0.328125 0.421875
iteration 568: loss 0.642 0.304688 0.468750
iteration 569: loss 0.941 0.351562 0.421875
iteration 570: loss 0.571 0.335938 0.539062
iteration 571: loss 0.753 0.382812 0.429688
iteration 572: loss 0.770 0.406250 0.406250
iteration 573: loss 0.713 0.296875 0.468750
iteration 574: loss 0.992 0.250000 0.382812
iteration 575: loss 0.749 0.335938 0.421875
iteration 576: loss 0.709 0.296875 0.445312
iteration 577: loss 0.661 0.296875 0.453125
iteration 578: loss 0.748 0.359375 0.445312
iteration 579: loss 0.785 0.367188 0.531250
iteration 580: loss 0.829 0.398438 0.453125
iteration 581: loss 0.745 0.328125 0.507812
iteration 582: loss 0.887 0.375000 0.484375
iteration 583: loss 0.637 0.351562 0.546875
iteration 584: loss 0.792 0.328125 0.429688
iteration 585: loss 0.728 0.273438 0.500000
iteration 586: loss 0.949 0.343750 0.382812
iteration 587: loss 0.759 0.312500 0.476562
iteration 588: loss 0.653 0.273438 0.476562
iteration 589: loss 0.837 0.289062 0.453125
iteration 590: loss 0.781 0.359375 0.406250
iteration 591: loss 0.868 0.273438 0.421875
iteration 592: loss 0.684 0.312500 0.453125
iteration 593: loss 0.811 0.281250 0.484375
iteration 594: loss 0.684 0.335938 0.484375
iteration 595: loss 0.835 0.320312 0.515625
iteration 596: loss 0.651 0.289062 0.531250
iteration 597: loss 0.851 0.289062 0.453125
iteration 598: loss 0.700 0.359375 0.523438
iteration 599: loss 0.798 0.343750 0.445312
iteration 600: loss 0.859 0.250000 0.500000
iteration 601: loss 0.890 0.234375 0.437500
iteration 602: loss 0.733 0.351562 0.429688
iteration 603: loss 0.670 0.265625 0.468750
iteration 604: loss 0.821 0.320312 0.421875
iteration 605: loss 0.831 0.265625 0.453125
iteration 606: loss 0.666 0.265625 0.531250
iteration 607: loss 0.647 0.367188 0.500000
iteration 608: loss 0.872 0.367188 0.414062
iteration 609: loss 0.820 0.265625 0.500000
iteration 610: loss 0.698 0.375000 0.460938
iteration 611: loss 0.651 0.351562 0.500000
iteration 612: loss 0.778 0.289062 0.453125
iteration 613: loss 1.066 0.265625 0.382812
iteration 614: loss 0.706 0.320312 0.460938
iteration 615: loss 0.695 0.351562 0.437500
iteration 616: loss 0.687 0.273438 0.437500
iteration 617: loss 0.786 0.304688 0.398438
iteration 618: loss 0.842 0.312500 0.390625
iteration 619: loss 0.671 0.390625 0.539062
iteration 620: loss 0.544 0.351562 0.484375
iteration 621: loss 0.687 0.320312 0.500000
iteration 622: loss 0.809 0.343750 0.492188
iteration 623: loss 0.752 0.359375 0.437500
iteration 624: loss 1.023 0.351562 0.445312
iteration 625: loss 0.781 0.281250 0.453125
iteration 626: loss 0.714 0.343750 0.421875
iteration 627: loss 0.903 0.304688 0.367188
iteration 628: loss 0.809 0.242188 0.398438
iteration 629: loss 0.713 0.281250 0.468750
iteration 630: loss 0.786 0.296875 0.484375
iteration 631: loss 0.766 0.335938 0.375000
iteration 632: loss 0.899 0.390625 0.460938
iteration 633: loss 0.615 0.281250 0.500000
iteration 634: loss 0.952 0.242188 0.406250
iteration 635: loss 0.727 0.281250 0.421875
iteration 636: loss 0.940 0.351562 0.468750
iteration 637: loss 0.675 0.265625 0.468750
iteration 638: loss 0.826 0.328125 0.484375
iteration 639: loss 0.818 0.281250 0.468750
iteration 640: loss 0.832 0.375000 0.445312
iteration 641: loss 0.730 0.289062 0.390625
iteration 642: loss 0.731 0.257812 0.429688
iteration 643: loss 0.740 0.328125 0.445312
iteration 644: loss 0.722 0.296875 0.453125
iteration 645: loss 0.868 0.312500 0.398438
iteration 646: loss 0.792 0.343750 0.445312
iteration 647: loss 0.702 0.296875 0.562500
iteration 648: loss 0.768 0.281250 0.500000
iteration 649: loss 0.624 0.351562 0.546875
iteration 650: loss 0.924 0.304688 0.507812
iteration 651: loss 0.820 0.382812 0.445312
iteration 652: loss 0.673 0.304688 0.476562
iteration 653: loss 0.822 0.257812 0.445312
iteration 654: loss 0.641 0.296875 0.445312
iteration 655: loss 0.814 0.328125 0.398438
iteration 656: loss 0.720 0.367188 0.414062
iteration 657: loss 0.710 0.398438 0.468750
iteration 658: loss 0.812 0.312500 0.453125
iteration 659: loss 0.920 0.226562 0.421875
iteration 660: loss 0.897 0.367188 0.492188
iteration 661: loss 0.859 0.265625 0.460938
iteration 662: loss 0.855 0.304688 0.453125
iteration 663: loss 0.859 0.250000 0.375000
iteration 664: loss 0.767 0.328125 0.414062
iteration 665: loss 0.697 0.250000 0.531250
iteration 666: loss 0.952 0.359375 0.429688
iteration 667: loss 0.902 0.289062 0.437500
iteration 668: loss 0.890 0.320312 0.429688
iteration 669: loss 0.658 0.359375 0.500000
iteration 670: loss 0.942 0.320312 0.351562
iteration 671: loss 0.771 0.359375 0.476562
iteration 672: loss 1.002 0.304688 0.367188
iteration 673: loss 0.995 0.296875 0.359375
iteration 674: loss 0.768 0.234375 0.445312
iteration 675: loss 0.780 0.312500 0.421875
iteration 676: loss 0.938 0.343750 0.539062
iteration 677: loss 0.630 0.242188 0.460938
iteration 678: loss 0.859 0.289062 0.382812
iteration 679: loss 0.889 0.296875 0.367188
iteration 680: loss 0.725 0.367188 0.445312
iteration 681: loss 0.825 0.367188 0.453125
iteration 682: loss 0.783 0.257812 0.429688
iteration 683: loss 0.651 0.289062 0.453125
iteration 684: loss 0.711 0.242188 0.437500
iteration 685: loss 0.738 0.351562 0.484375
iteration 686: loss 0.698 0.273438 0.484375
iteration 687: loss 0.967 0.343750 0.429688
iteration 688: loss 0.823 0.343750 0.468750
iteration 689: loss 0.761 0.273438 0.468750
iteration 690: loss 0.939 0.296875 0.398438
iteration 691: loss 0.880 0.320312 0.460938
iteration 692: loss 0.872 0.343750 0.429688
iteration 693: loss 0.780 0.390625 0.507812
iteration 694: loss 0.850 0.335938 0.468750
iteration 695: loss 0.979 0.250000 0.398438
iteration 696: loss 0.691 0.210938 0.484375
iteration 697: loss 0.769 0.226562 0.437500
iteration 698: loss 0.798 0.320312 0.421875
iteration 699: loss 0.779 0.296875 0.445312
iteration 700: loss 0.842 0.312500 0.367188
iteration 701: loss 0.760 0.375000 0.437500
iteration 702: loss 0.849 0.289062 0.398438
iteration 703: loss 0.765 0.312500 0.398438
iteration 704: loss 0.657 0.289062 0.468750
iteration 705: loss 1.014 0.367188 0.453125
iteration 706: loss 0.744 0.289062 0.468750
iteration 707: loss 0.906 0.320312 0.468750
iteration 708: loss 0.838 0.289062 0.460938
iteration 709: loss 0.671 0.335938 0.523438
iteration 710: loss 0.653 0.343750 0.460938
iteration 711: loss 0.895 0.304688 0.421875
iteration 712: loss 0.764 0.304688 0.421875
iteration 713: loss 0.778 0.296875 0.445312
iteration 714: loss 0.666 0.304688 0.492188
iteration 715: loss 0.839 0.250000 0.468750
iteration 716: loss 0.781 0.242188 0.382812
iteration 717: loss 0.742 0.343750 0.460938
iteration 718: loss 0.680 0.289062 0.492188
iteration 719: loss 0.835 0.367188 0.421875
iteration 720: loss 0.945 0.250000 0.429688
iteration 721: loss 0.884 0.296875 0.515625
iteration 722: loss 0.709 0.343750 0.562500
iteration 723: loss 0.773 0.359375 0.445312
iteration 724: loss 0.853 0.359375 0.390625
iteration 725: loss 0.920 0.281250 0.390625
iteration 726: loss 0.891 0.367188 0.484375
iteration 727: loss 0.888 0.289062 0.406250
iteration 728: loss 0.961 0.265625 0.421875
iteration 729: loss 0.895 0.289062 0.414062
iteration 730: loss 0.956 0.289062 0.437500
iteration 731: loss 0.869 0.304688 0.437500
iteration 732: loss 0.743 0.335938 0.406250
iteration 733: loss 0.758 0.335938 0.429688
iteration 734: loss 0.837 0.289062 0.390625
iteration 735: loss 0.883 0.320312 0.429688
iteration 736: loss 0.895 0.312500 0.484375
iteration 737: loss 0.935 0.335938 0.453125
iteration 738: loss 0.691 0.375000 0.429688
iteration 739: loss 0.787 0.289062 0.375000
iteration 740: loss 0.797 0.328125 0.437500
iteration 741: loss 0.856 0.242188 0.398438
iteration 742: loss 0.718 0.242188 0.429688
iteration 743: loss 0.783 0.273438 0.445312
iteration 744: loss 0.731 0.335938 0.468750
iteration 745: loss 0.812 0.367188 0.414062
iteration 746: loss 0.716 0.335938 0.421875
iteration 747: loss 0.649 0.281250 0.460938
iteration 748: loss 0.832 0.312500 0.437500
iteration 749: loss 0.922 0.320312 0.414062
iteration 750: loss 0.691 0.289062 0.492188
iteration 751: loss 0.754 0.359375 0.437500
iteration 752: loss 0.626 0.312500 0.500000
iteration 753: loss 0.773 0.328125 0.445312
iteration 754: loss 0.836 0.367188 0.468750
iteration 755: loss 1.008 0.406250 0.406250
iteration 756: loss 0.795 0.414062 0.429688
iteration 757: loss 0.721 0.265625 0.515625
iteration 758: loss 0.678 0.257812 0.554688
iteration 759: loss 0.764 0.289062 0.453125
iteration 760: loss 0.595 0.289062 0.507812
iteration 761: loss 0.845 0.273438 0.421875
iteration 762: loss 0.792 0.265625 0.414062
iteration 763: loss 0.693 0.203125 0.484375
iteration 764: loss 0.695 0.242188 0.507812
iteration 765: loss 0.820 0.375000 0.437500
iteration 766: loss 0.741 0.273438 0.445312
iteration 767: loss 0.753 0.296875 0.484375
iteration 768: loss 0.829 0.265625 0.437500
iteration 769: loss 0.894 0.273438 0.445312
iteration 770: loss 0.761 0.281250 0.476562
iteration 771: loss 1.026 0.312500 0.367188
iteration 772: loss 0.691 0.289062 0.492188
iteration 773: loss 0.777 0.304688 0.453125
iteration 774: loss 0.682 0.257812 0.421875
iteration 775: loss 0.664 0.320312 0.453125
iteration 776: loss 0.664 0.375000 0.539062
iteration 777: loss 0.718 0.328125 0.445312
iteration 778: loss 0.840 0.242188 0.507812
iteration 779: loss 0.857 0.265625 0.421875
iteration 780: loss 0.759 0.328125 0.445312
iteration 781: loss 0.832 0.296875 0.421875
iteration 782: loss 0.732 0.375000 0.390625
iteration 783: loss 0.730 0.359375 0.476562
iteration 784: loss 0.575 0.242188 0.453125
iteration 785: loss 0.907 0.281250 0.359375
iteration 786: loss 0.739 0.203125 0.445312
iteration 787: loss 0.667 0.304688 0.507812
iteration 788: loss 0.646 0.328125 0.468750
iteration 789: loss 0.798 0.367188 0.445312
iteration 790: loss 0.810 0.273438 0.414062
iteration 791: loss 0.814 0.273438 0.476562
iteration 792: loss 0.685 0.398438 0.515625
iteration 793: loss 0.623 0.375000 0.562500
iteration 794: loss 0.699 0.289062 0.460938
iteration 795: loss 0.674 0.390625 0.460938
iteration 796: loss 0.610 0.210938 0.492188
iteration 797: loss 0.942 0.296875 0.375000
iteration 798: loss 0.689 0.312500 0.523438
iteration 799: loss 0.974 0.281250 0.375000
iteration 800: loss 0.656 0.242188 0.453125
iteration 801: loss 1.043 0.304688 0.453125
iteration 802: loss 0.829 0.406250 0.414062
iteration 803: loss 0.695 0.281250 0.507812
iteration 804: loss 0.682 0.343750 0.484375
iteration 805: loss 0.778 0.359375 0.453125
iteration 806: loss 0.685 0.367188 0.515625
iteration 807: loss 0.605 0.265625 0.546875
iteration 808: loss 0.695 0.210938 0.500000
iteration 809: loss 0.663 0.250000 0.421875
iteration 810: loss 0.628 0.234375 0.468750
iteration 811: loss 0.604 0.312500 0.468750
iteration 812: loss 0.619 0.335938 0.500000
iteration 813: loss 0.696 0.335938 0.460938
iteration 814: loss 0.774 0.351562 0.507812
iteration 815: loss 0.797 0.335938 0.523438
iteration 816: loss 0.857 0.296875 0.484375
iteration 817: loss 0.834 0.351562 0.500000
iteration 818: loss 0.803 0.351562 0.523438
iteration 819: loss 0.859 0.289062 0.476562
iteration 820: loss 1.197 0.343750 0.398438
iteration 821: loss 0.795 0.351562 0.476562
iteration 822: loss 0.837 0.257812 0.414062
iteration 823: loss 0.774 0.257812 0.429688
iteration 824: loss 0.709 0.281250 0.460938
iteration 825: loss 0.739 0.281250 0.515625
iteration 826: loss 0.903 0.367188 0.445312
iteration 827: loss 0.708 0.289062 0.570312
iteration 828: loss 0.814 0.351562 0.484375
iteration 829: loss 0.719 0.351562 0.500000
iteration 830: loss 0.765 0.367188 0.515625
iteration 831: loss 0.959 0.320312 0.414062
iteration 832: loss 0.822 0.320312 0.359375
iteration 833: loss 0.866 0.289062 0.382812
iteration 834: loss 0.904 0.289062 0.367188
iteration 835: loss 0.749 0.281250 0.515625
iteration 836: loss 0.797 0.359375 0.460938
iteration 837: loss 0.739 0.289062 0.476562
iteration 838: loss 0.790 0.265625 0.531250
iteration 839: loss 0.731 0.304688 0.523438
iteration 840: loss 0.770 0.312500 0.468750
iteration 841: loss 0.580 0.320312 0.578125
iteration 842: loss 0.805 0.335938 0.406250
iteration 843: loss 0.770 0.328125 0.437500
iteration 844: loss 0.795 0.335938 0.468750
iteration 845: loss 0.840 0.343750 0.437500
iteration 846: loss 0.697 0.328125 0.476562
iteration 847: loss 0.818 0.390625 0.453125
iteration 848: loss 0.810 0.390625 0.398438
iteration 849: loss 0.905 0.289062 0.398438
iteration 850: loss 0.557 0.367188 0.546875
iteration 851: loss 1.012 0.296875 0.406250
iteration 852: loss 0.815 0.296875 0.585938
iteration 853: loss 0.804 0.320312 0.468750
iteration 854: loss 0.815 0.351562 0.429688
iteration 855: loss 0.906 0.335938 0.406250
iteration 856: loss 0.783 0.273438 0.445312
iteration 857: loss 0.776 0.328125 0.460938
iteration 858: loss 0.798 0.367188 0.476562
iteration 859: loss 0.551 0.328125 0.507812
iteration 860: loss 0.692 0.304688 0.484375
iteration 861: loss 0.688 0.375000 0.546875
iteration 862: loss 1.004 0.351562 0.390625
iteration 863: loss 1.162 0.343750 0.390625
iteration 864: loss 0.796 0.281250 0.390625
iteration 865: loss 0.778 0.351562 0.445312
iteration 866: loss 0.836 0.421875 0.453125
iteration 867: loss 0.872 0.421875 0.421875
iteration 868: loss 0.875 0.390625 0.460938
iteration 869: loss 0.925 0.226562 0.367188
iteration 870: loss 0.830 0.328125 0.437500
iteration 871: loss 0.829 0.234375 0.453125
iteration 872: loss 0.841 0.304688 0.421875
iteration 873: loss 0.713 0.257812 0.515625
iteration 874: loss 0.667 0.312500 0.515625
iteration 875: loss 0.723 0.375000 0.476562
iteration 876: loss 0.959 0.250000 0.414062
iteration 877: loss 0.734 0.250000 0.453125
iteration 878: loss 0.832 0.351562 0.351562
iteration 879: loss 0.846 0.296875 0.398438
iteration 880: loss 0.889 0.304688 0.390625
iteration 881: loss 0.715 0.328125 0.507812
iteration 882: loss 0.659 0.382812 0.500000
iteration 883: loss 0.682 0.367188 0.531250
iteration 884: loss 0.851 0.273438 0.414062
iteration 885: loss 0.782 0.257812 0.484375
iteration 886: loss 0.739 0.367188 0.429688
iteration 887: loss 0.786 0.320312 0.375000
iteration 888: loss 0.827 0.296875 0.398438
iteration 889: loss 0.734 0.289062 0.468750
iteration 890: loss 0.712 0.335938 0.531250
iteration 891: loss 0.830 0.296875 0.406250
iteration 892: loss 0.771 0.273438 0.445312
iteration 893: loss 0.663 0.335938 0.500000
iteration 894: loss 0.797 0.328125 0.445312
iteration 895: loss 0.625 0.289062 0.453125
iteration 896: loss 0.726 0.304688 0.484375
iteration 897: loss 0.679 0.312500 0.507812
iteration 898: loss 0.863 0.367188 0.460938
iteration 899: loss 0.697 0.312500 0.453125
iteration 900: loss 0.743 0.359375 0.429688
iteration 901: loss 0.763 0.289062 0.492188
iteration 902: loss 0.805 0.398438 0.406250
iteration 903: loss 0.807 0.304688 0.421875
iteration 904: loss 0.734 0.343750 0.476562
iteration 905: loss 0.697 0.335938 0.421875
iteration 906: loss 0.812 0.281250 0.406250
iteration 907: loss 0.604 0.296875 0.523438
iteration 908: loss 0.712 0.234375 0.445312
iteration 909: loss 0.652 0.390625 0.546875
iteration 910: loss 0.622 0.335938 0.500000
iteration 911: loss 0.739 0.328125 0.460938
iteration 912: loss 0.830 0.320312 0.390625
iteration 913: loss 0.686 0.335938 0.484375
iteration 914: loss 0.703 0.312500 0.445312
iteration 915: loss 0.710 0.273438 0.421875
iteration 916: loss 0.744 0.328125 0.398438
iteration 917: loss 0.687 0.265625 0.500000
iteration 918: loss 0.792 0.304688 0.468750
iteration 919: loss 0.792 0.328125 0.406250
iteration 920: loss 0.760 0.312500 0.476562
iteration 921: loss 0.846 0.242188 0.484375
iteration 922: loss 0.757 0.296875 0.398438
iteration 923: loss 0.745 0.320312 0.484375
iteration 924: loss 0.797 0.328125 0.429688
iteration 925: loss 0.739 0.296875 0.382812
iteration 926: loss 0.788 0.398438 0.398438
iteration 927: loss 0.616 0.296875 0.492188
iteration 928: loss 0.654 0.265625 0.484375
iteration 929: loss 0.711 0.304688 0.507812
iteration 930: loss 0.595 0.281250 0.500000
iteration 931: loss 0.890 0.273438 0.375000
iteration 932: loss 0.812 0.296875 0.460938
iteration 933: loss 1.097 0.265625 0.375000
iteration 934: loss 0.902 0.281250 0.335938
iteration 935: loss 0.705 0.281250 0.507812
iteration 936: loss 0.824 0.375000 0.390625
iteration 937: loss 0.767 0.312500 0.500000
iteration 938: loss 0.729 0.312500 0.515625
iteration 939: loss 0.734 0.312500 0.476562
iteration 940: loss 0.918 0.414062 0.523438
iteration 941: loss 0.829 0.312500 0.445312
iteration 942: loss 0.869 0.312500 0.375000
iteration 943: loss 0.743 0.328125 0.421875
iteration 944: loss 0.769 0.335938 0.414062
iteration 945: loss 0.878 0.343750 0.359375
iteration 946: loss 0.896 0.273438 0.414062
iteration 947: loss 0.737 0.390625 0.476562
iteration 948: loss 0.898 0.296875 0.492188
iteration 949: loss 0.727 0.242188 0.398438
iteration 950: loss 0.926 0.265625 0.445312
iteration 951: loss 0.617 0.359375 0.523438
iteration 952: loss 0.938 0.304688 0.453125
iteration 953: loss 0.900 0.367188 0.570312
iteration 954: loss 0.931 0.304688 0.398438
iteration 955: loss 0.807 0.265625 0.406250
iteration 956: loss 0.739 0.273438 0.484375
iteration 957: loss 0.826 0.304688 0.367188
iteration 958: loss 0.729 0.335938 0.421875
iteration 959: loss 0.824 0.289062 0.492188
iteration 960: loss 0.804 0.296875 0.406250
iteration 961: loss 0.726 0.390625 0.460938
iteration 962: loss 0.767 0.375000 0.437500
iteration 963: loss 0.608 0.312500 0.546875
iteration 964: loss 0.676 0.304688 0.484375
iteration 965: loss 0.773 0.328125 0.476562
iteration 966: loss 0.942 0.320312 0.460938
iteration 967: loss 0.690 0.320312 0.476562
iteration 968: loss 0.933 0.312500 0.468750
iteration 969: loss 0.686 0.375000 0.468750
iteration 970: loss 0.774 0.382812 0.445312
iteration 971: loss 0.665 0.304688 0.500000
iteration 972: loss 0.774 0.335938 0.468750
iteration 973: loss 0.834 0.234375 0.492188
iteration 974: loss 0.808 0.289062 0.414062
iteration 975: loss 0.921 0.351562 0.437500
iteration 976: loss 0.975 0.250000 0.382812
iteration 977: loss 0.742 0.281250 0.414062
iteration 978: loss 0.785 0.265625 0.421875
iteration 979: loss 0.837 0.359375 0.460938
iteration 980: loss 0.645 0.312500 0.562500
iteration 981: loss 0.938 0.328125 0.468750
iteration 982: loss 0.758 0.296875 0.554688
iteration 983: loss 0.637 0.351562 0.507812
iteration 984: loss 0.759 0.226562 0.492188
iteration 985: loss 0.926 0.289062 0.437500
iteration 986: loss 0.739 0.367188 0.460938
iteration 987: loss 0.718 0.281250 0.562500
iteration 988: loss 0.747 0.265625 0.484375
iteration 989: loss 0.771 0.242188 0.437500
iteration 990: loss 0.750 0.390625 0.453125
iteration 991: loss 0.580 0.304688 0.507812
iteration 992: loss 0.881 0.289062 0.359375
iteration 993: loss 0.702 0.335938 0.507812
iteration 994: loss 0.901 0.273438 0.445312
iteration 995: loss 0.592 0.265625 0.539062
iteration 996: loss 0.574 0.289062 0.492188
iteration 997: loss 0.642 0.289062 0.460938
iteration 998: loss 0.995 0.273438 0.429688
iteration 999: loss 0.678 0.281250 0.492188
epoch 6: training: 0.250000 validation: 0.281250
iteration 0: loss 0.917 0.320312 0.398438
iteration 1: loss 0.711 0.320312 0.445312
iteration 2: loss 0.747 0.281250 0.437500
iteration 3: loss 0.658 0.250000 0.437500
iteration 4: loss 0.730 0.367188 0.468750
iteration 5: loss 0.818 0.273438 0.437500
iteration 6: loss 0.728 0.343750 0.437500
iteration 7: loss 0.726 0.406250 0.500000
iteration 8: loss 0.597 0.296875 0.539062
iteration 9: loss 0.951 0.265625 0.359375
iteration 10: loss 0.811 0.265625 0.492188
iteration 11: loss 0.720 0.335938 0.468750
iteration 12: loss 0.868 0.242188 0.460938
iteration 13: loss 0.942 0.382812 0.367188
iteration 14: loss 0.615 0.296875 0.476562
iteration 15: loss 0.607 0.343750 0.523438
iteration 16: loss 0.918 0.304688 0.390625
iteration 17: loss 0.693 0.312500 0.468750
iteration 18: loss 0.607 0.265625 0.570312
iteration 19: loss 0.717 0.351562 0.476562
iteration 20: loss 0.638 0.312500 0.507812
iteration 21: loss 0.730 0.289062 0.484375
iteration 22: loss 0.753 0.359375 0.453125
iteration 23: loss 0.770 0.296875 0.398438
iteration 24: loss 0.793 0.312500 0.476562
iteration 25: loss 0.715 0.328125 0.484375
iteration 26: loss 0.642 0.398438 0.484375
iteration 27: loss 0.728 0.250000 0.453125
iteration 28: loss 0.729 0.296875 0.445312
iteration 29: loss 0.694 0.335938 0.476562
iteration 30: loss 0.888 0.187500 0.398438
iteration 31: loss 0.796 0.328125 0.359375
iteration 32: loss 0.691 0.273438 0.531250
iteration 33: loss 0.556 0.289062 0.546875
iteration 34: loss 0.792 0.273438 0.507812
iteration 35: loss 0.714 0.375000 0.437500
iteration 36: loss 0.644 0.320312 0.492188
iteration 37: loss 0.822 0.265625 0.437500
iteration 38: loss 0.818 0.351562 0.429688
iteration 39: loss 0.932 0.296875 0.445312
iteration 40: loss 0.903 0.343750 0.390625
iteration 41: loss 0.887 0.250000 0.414062
iteration 42: loss 0.804 0.304688 0.367188
iteration 43: loss 0.715 0.375000 0.437500
iteration 44: loss 0.602 0.382812 0.500000
iteration 45: loss 0.783 0.351562 0.484375
iteration 46: loss 0.740 0.320312 0.460938
iteration 47: loss 0.903 0.351562 0.460938
iteration 48: loss 0.699 0.289062 0.484375
iteration 49: loss 0.793 0.296875 0.468750
iteration 50: loss 0.777 0.296875 0.539062
iteration 51: loss 0.702 0.382812 0.531250
iteration 52: loss 0.712 0.289062 0.476562
iteration 53: loss 0.719 0.289062 0.453125
iteration 54: loss 0.704 0.296875 0.468750
iteration 55: loss 0.842 0.304688 0.421875
iteration 56: loss 0.617 0.304688 0.476562
iteration 57: loss 0.659 0.312500 0.500000
iteration 58: loss 0.593 0.320312 0.578125
iteration 59: loss 0.684 0.289062 0.390625
iteration 60: loss 0.715 0.343750 0.484375
iteration 61: loss 0.704 0.304688 0.507812
iteration 62: loss 0.737 0.242188 0.460938
iteration 63: loss 0.737 0.257812 0.421875
iteration 64: loss 0.666 0.390625 0.445312
iteration 65: loss 0.746 0.242188 0.468750
iteration 66: loss 0.815 0.265625 0.460938
iteration 67: loss 0.630 0.304688 0.460938
iteration 68: loss 0.770 0.328125 0.453125
iteration 69: loss 0.740 0.312500 0.453125
iteration 70: loss 0.821 0.367188 0.453125
iteration 71: loss 0.705 0.226562 0.531250
iteration 72: loss 0.620 0.343750 0.468750
iteration 73: loss 0.742 0.265625 0.460938
iteration 74: loss 0.864 0.312500 0.421875
iteration 75: loss 0.686 0.320312 0.421875
iteration 76: loss 0.608 0.304688 0.500000
iteration 77: loss 0.781 0.257812 0.398438
iteration 78: loss 0.789 0.382812 0.445312
iteration 79: loss 0.731 0.382812 0.523438
iteration 80: loss 0.677 0.320312 0.492188
iteration 81: loss 0.543 0.296875 0.507812
iteration 82: loss 0.773 0.320312 0.500000
iteration 83: loss 0.840 0.320312 0.429688
iteration 84: loss 0.747 0.328125 0.468750
iteration 85: loss 0.904 0.343750 0.460938
iteration 86: loss 0.794 0.250000 0.406250
iteration 87: loss 0.764 0.281250 0.460938
iteration 88: loss 0.665 0.281250 0.476562
iteration 89: loss 0.788 0.335938 0.421875
iteration 90: loss 0.694 0.320312 0.398438
iteration 91: loss 0.759 0.265625 0.421875
iteration 92: loss 0.753 0.375000 0.437500
iteration 93: loss 0.670 0.367188 0.515625
iteration 94: loss 0.761 0.343750 0.492188
iteration 95: loss 0.580 0.273438 0.515625
iteration 96: loss 0.569 0.351562 0.554688
iteration 97: loss 0.779 0.335938 0.445312
iteration 98: loss 0.908 0.265625 0.375000
iteration 99: loss 0.724 0.273438 0.492188
iteration 100: loss 0.584 0.382812 0.523438
iteration 101: loss 0.689 0.343750 0.453125
iteration 102: loss 0.805 0.304688 0.437500
iteration 103: loss 0.687 0.304688 0.468750
iteration 104: loss 0.632 0.335938 0.445312
iteration 105: loss 0.717 0.343750 0.453125
iteration 106: loss 0.762 0.398438 0.500000
iteration 107: loss 0.777 0.304688 0.476562
iteration 108: loss 0.674 0.335938 0.445312
iteration 109: loss 0.897 0.281250 0.492188
iteration 110: loss 0.786 0.273438 0.398438
iteration 111: loss 0.830 0.296875 0.382812
iteration 112: loss 0.772 0.343750 0.406250
iteration 113: loss 0.653 0.257812 0.453125
iteration 114: loss 0.785 0.351562 0.421875
iteration 115: loss 0.849 0.265625 0.437500
iteration 116: loss 0.902 0.296875 0.453125
iteration 117: loss 0.672 0.359375 0.500000
iteration 118: loss 0.766 0.328125 0.445312
iteration 119: loss 0.736 0.312500 0.437500
iteration 120: loss 0.791 0.296875 0.406250
iteration 121: loss 0.977 0.281250 0.429688
iteration 122: loss 0.823 0.320312 0.460938
iteration 123: loss 0.696 0.304688 0.531250
iteration 124: loss 0.967 0.367188 0.328125
iteration 125: loss 0.854 0.296875 0.421875
iteration 126: loss 0.874 0.273438 0.468750
iteration 127: loss 0.812 0.343750 0.460938
iteration 128: loss 0.762 0.312500 0.429688
iteration 129: loss 0.753 0.359375 0.500000
iteration 130: loss 0.772 0.304688 0.421875
iteration 131: loss 0.754 0.390625 0.367188
iteration 132: loss 0.603 0.265625 0.523438
iteration 133: loss 0.648 0.296875 0.468750
iteration 134: loss 0.644 0.289062 0.515625
iteration 135: loss 0.659 0.359375 0.460938
iteration 136: loss 0.730 0.328125 0.484375
iteration 137: loss 0.963 0.304688 0.507812
iteration 138: loss 0.676 0.351562 0.523438
iteration 139: loss 0.684 0.273438 0.492188
iteration 140: loss 0.786 0.312500 0.500000
iteration 141: loss 0.947 0.281250 0.453125
iteration 142: loss 0.591 0.351562 0.578125
iteration 143: loss 0.652 0.296875 0.531250
iteration 144: loss 0.742 0.398438 0.414062
iteration 145: loss 0.770 0.265625 0.398438
iteration 146: loss 0.768 0.343750 0.453125
iteration 147: loss 0.845 0.312500 0.445312
iteration 148: loss 0.823 0.390625 0.382812
iteration 149: loss 0.785 0.296875 0.445312
iteration 150: loss 0.755 0.250000 0.468750
iteration 151: loss 0.888 0.304688 0.382812
iteration 152: loss 0.784 0.343750 0.429688
iteration 153: loss 0.873 0.296875 0.359375
iteration 154: loss 0.988 0.312500 0.351562
iteration 155: loss 0.836 0.335938 0.351562
iteration 156: loss 0.886 0.351562 0.343750
iteration 157: loss 0.843 0.351562 0.390625
iteration 158: loss 0.632 0.304688 0.570312
iteration 159: loss 0.683 0.312500 0.539062
iteration 160: loss 0.691 0.273438 0.476562
iteration 161: loss 0.926 0.304688 0.398438
iteration 162: loss 0.650 0.367188 0.523438
iteration 163: loss 0.871 0.312500 0.429688
iteration 164: loss 0.928 0.335938 0.398438
iteration 165: loss 0.757 0.335938 0.453125
iteration 166: loss 0.678 0.296875 0.453125
iteration 167: loss 0.873 0.296875 0.375000
iteration 168: loss 0.754 0.296875 0.414062
iteration 169: loss 0.769 0.312500 0.492188
iteration 170: loss 0.738 0.289062 0.484375
iteration 171: loss 0.910 0.289062 0.406250
iteration 172: loss 0.614 0.281250 0.539062
iteration 173: loss 0.546 0.250000 0.523438
iteration 174: loss 0.822 0.281250 0.414062
iteration 175: loss 0.841 0.390625 0.476562
iteration 176: loss 0.842 0.289062 0.437500
iteration 177: loss 0.755 0.320312 0.414062
iteration 178: loss 0.718 0.320312 0.414062
iteration 179: loss 0.673 0.289062 0.484375
iteration 180: loss 0.765 0.273438 0.445312
iteration 181: loss 0.822 0.328125 0.421875
iteration 182: loss 0.852 0.312500 0.406250
iteration 183: loss 0.736 0.320312 0.492188
iteration 184: loss 0.588 0.375000 0.515625
iteration 185: loss 0.653 0.296875 0.468750
iteration 186: loss 0.725 0.281250 0.515625
iteration 187: loss 0.684 0.320312 0.492188
iteration 188: loss 0.953 0.257812 0.437500
iteration 189: loss 0.716 0.328125 0.500000
iteration 190: loss 0.889 0.257812 0.445312
iteration 191: loss 0.891 0.320312 0.460938
iteration 192: loss 0.684 0.312500 0.437500
iteration 193: loss 0.669 0.367188 0.429688
iteration 194: loss 0.693 0.351562 0.445312
iteration 195: loss 0.734 0.335938 0.492188
iteration 196: loss 0.758 0.296875 0.437500
iteration 197: loss 0.707 0.179688 0.460938
iteration 198: loss 0.749 0.242188 0.476562
iteration 199: loss 0.628 0.304688 0.531250
iteration 200: loss 0.715 0.203125 0.539062
iteration 201: loss 0.728 0.343750 0.492188
iteration 202: loss 1.025 0.367188 0.468750
iteration 203: loss 0.697 0.304688 0.492188
iteration 204: loss 0.588 0.265625 0.554688
iteration 205: loss 0.759 0.335938 0.460938
iteration 206: loss 0.722 0.343750 0.484375
iteration 207: loss 0.813 0.343750 0.445312
iteration 208: loss 0.728 0.359375 0.468750
iteration 209: loss 0.722 0.328125 0.437500
iteration 210: loss 0.949 0.257812 0.343750
iteration 211: loss 0.789 0.289062 0.476562
iteration 212: loss 0.782 0.320312 0.398438
iteration 213: loss 0.707 0.296875 0.445312
iteration 214: loss 0.630 0.257812 0.453125
iteration 215: loss 0.822 0.320312 0.414062
iteration 216: loss 0.755 0.343750 0.429688
iteration 217: loss 0.793 0.382812 0.492188
iteration 218: loss 0.715 0.289062 0.500000
iteration 219: loss 0.780 0.328125 0.507812
iteration 220: loss 0.678 0.390625 0.515625
iteration 221: loss 0.834 0.242188 0.406250
iteration 222: loss 0.724 0.351562 0.398438
iteration 223: loss 0.777 0.296875 0.453125
iteration 224: loss 0.823 0.273438 0.398438
iteration 225: loss 0.968 0.257812 0.421875
iteration 226: loss 0.787 0.351562 0.437500
iteration 227: loss 0.665 0.304688 0.500000
iteration 228: loss 0.697 0.343750 0.515625
iteration 229: loss 0.780 0.304688 0.437500
iteration 230: loss 0.681 0.320312 0.539062
iteration 231: loss 0.661 0.234375 0.531250
iteration 232: loss 0.721 0.296875 0.414062
iteration 233: loss 0.865 0.335938 0.414062
iteration 234: loss 0.780 0.335938 0.421875
iteration 235: loss 0.720 0.289062 0.500000
iteration 236: loss 0.622 0.296875 0.554688
iteration 237: loss 0.778 0.328125 0.429688
iteration 238: loss 0.793 0.250000 0.492188
iteration 239: loss 0.802 0.351562 0.460938
iteration 240: loss 0.637 0.312500 0.484375
iteration 241: loss 0.646 0.335938 0.484375
iteration 242: loss 0.870 0.320312 0.468750
iteration 243: loss 0.638 0.296875 0.531250
iteration 244: loss 0.751 0.351562 0.460938
iteration 245: loss 0.777 0.312500 0.429688
iteration 246: loss 0.563 0.343750 0.515625
iteration 247: loss 0.792 0.343750 0.421875
iteration 248: loss 0.808 0.304688 0.468750
iteration 249: loss 0.703 0.289062 0.476562
iteration 250: loss 0.764 0.351562 0.437500
iteration 251: loss 0.676 0.312500 0.429688
iteration 252: loss 0.701 0.257812 0.492188
iteration 253: loss 0.699 0.351562 0.421875
iteration 254: loss 0.756 0.335938 0.539062
iteration 255: loss 0.780 0.273438 0.484375
iteration 256: loss 0.739 0.304688 0.460938
iteration 257: loss 0.811 0.304688 0.492188
iteration 258: loss 0.595 0.328125 0.507812
iteration 259: loss 0.708 0.281250 0.468750
iteration 260: loss 0.586 0.328125 0.507812
iteration 261: loss 0.790 0.289062 0.507812
iteration 262: loss 0.913 0.296875 0.414062
iteration 263: loss 0.839 0.265625 0.484375
iteration 264: loss 0.983 0.234375 0.421875
iteration 265: loss 0.465 0.281250 0.546875
iteration 266: loss 0.782 0.351562 0.453125
iteration 267: loss 0.740 0.281250 0.476562
iteration 268: loss 0.719 0.343750 0.476562
iteration 269: loss 0.785 0.343750 0.453125
iteration 270: loss 0.566 0.273438 0.531250
iteration 271: loss 0.916 0.273438 0.421875
iteration 272: loss 0.830 0.304688 0.460938
iteration 273: loss 0.934 0.250000 0.468750
iteration 274: loss 0.688 0.289062 0.507812
iteration 275: loss 0.869 0.242188 0.406250
iteration 276: loss 0.839 0.367188 0.468750
iteration 277: loss 0.737 0.320312 0.507812
iteration 278: loss 0.615 0.328125 0.531250
iteration 279: loss 0.764 0.273438 0.453125
iteration 280: loss 0.710 0.289062 0.500000
iteration 281: loss 0.704 0.414062 0.523438
iteration 282: loss 0.779 0.367188 0.468750
iteration 283: loss 0.678 0.351562 0.546875
iteration 284: loss 0.979 0.359375 0.421875
iteration 285: loss 1.067 0.359375 0.484375
iteration 286: loss 0.881 0.250000 0.531250
iteration 287: loss 0.958 0.281250 0.429688
iteration 288: loss 0.711 0.296875 0.492188
iteration 289: loss 0.754 0.382812 0.507812
iteration 290: loss 0.909 0.273438 0.382812
iteration 291: loss 0.813 0.281250 0.414062
iteration 292: loss 0.668 0.296875 0.515625
iteration 293: loss 0.609 0.328125 0.515625
iteration 294: loss 1.120 0.343750 0.359375
iteration 295: loss 0.880 0.320312 0.468750
iteration 296: loss 0.951 0.265625 0.453125
iteration 297: loss 1.032 0.281250 0.414062
iteration 298: loss 0.805 0.304688 0.351562
iteration 299: loss 0.791 0.296875 0.445312
iteration 300: loss 0.923 0.320312 0.375000
iteration 301: loss 0.845 0.312500 0.414062
iteration 302: loss 0.873 0.289062 0.414062
iteration 303: loss 0.838 0.242188 0.390625
iteration 304: loss 0.880 0.304688 0.492188
iteration 305: loss 0.737 0.320312 0.421875
iteration 306: loss 0.717 0.312500 0.476562
iteration 307: loss 0.880 0.320312 0.398438
iteration 308: loss 0.821 0.359375 0.437500
iteration 309: loss 1.068 0.289062 0.398438
iteration 310: loss 0.894 0.257812 0.414062
iteration 311: loss 0.792 0.312500 0.414062
iteration 312: loss 0.708 0.312500 0.523438
iteration 313: loss 0.729 0.296875 0.445312
iteration 314: loss 0.753 0.257812 0.453125
iteration 315: loss 0.706 0.312500 0.421875
iteration 316: loss 0.733 0.242188 0.421875
iteration 317: loss 0.786 0.312500 0.429688
iteration 318: loss 0.759 0.281250 0.398438
iteration 319: loss 0.654 0.304688 0.500000
iteration 320: loss 0.882 0.320312 0.437500
iteration 321: loss 0.818 0.296875 0.500000
iteration 322: loss 0.717 0.273438 0.484375
iteration 323: loss 0.707 0.281250 0.484375
iteration 324: loss 0.755 0.320312 0.460938
iteration 325: loss 0.779 0.328125 0.406250
iteration 326: loss 0.701 0.343750 0.468750
iteration 327: loss 0.865 0.312500 0.398438
iteration 328: loss 0.684 0.320312 0.453125
iteration 329: loss 0.748 0.312500 0.445312
iteration 330: loss 0.799 0.281250 0.445312
iteration 331: loss 0.890 0.289062 0.414062
iteration 332: loss 0.854 0.289062 0.398438
iteration 333: loss 1.001 0.273438 0.390625
iteration 334: loss 0.720 0.390625 0.507812
iteration 335: loss 0.801 0.281250 0.437500
iteration 336: loss 0.787 0.335938 0.437500
iteration 337: loss 0.693 0.289062 0.453125
iteration 338: loss 0.854 0.265625 0.406250
iteration 339: loss 0.748 0.343750 0.500000
iteration 340: loss 0.721 0.343750 0.515625
iteration 341: loss 0.819 0.343750 0.460938
iteration 342: loss 0.600 0.289062 0.546875
iteration 343: loss 0.654 0.289062 0.515625
iteration 344: loss 0.843 0.343750 0.437500
iteration 345: loss 0.797 0.328125 0.390625
iteration 346: loss 0.843 0.382812 0.429688
iteration 347: loss 0.617 0.328125 0.500000
iteration 348: loss 0.850 0.359375 0.429688
iteration 349: loss 0.680 0.328125 0.468750
iteration 350: loss 0.850 0.328125 0.414062
iteration 351: loss 0.820 0.390625 0.414062
iteration 352: loss 0.769 0.289062 0.476562
iteration 353: loss 0.735 0.367188 0.468750
iteration 354: loss 0.846 0.296875 0.421875
iteration 355: loss 0.739 0.281250 0.453125
iteration 356: loss 0.732 0.375000 0.484375
iteration 357: loss 0.738 0.250000 0.453125
iteration 358: loss 0.820 0.250000 0.437500
iteration 359: loss 0.674 0.320312 0.507812
iteration 360: loss 0.731 0.257812 0.429688
iteration 361: loss 0.811 0.281250 0.414062
iteration 362: loss 0.772 0.289062 0.421875
iteration 363: loss 0.588 0.320312 0.531250
iteration 364: loss 0.649 0.296875 0.453125
iteration 365: loss 0.844 0.296875 0.390625
iteration 366: loss 0.794 0.328125 0.476562
iteration 367: loss 0.689 0.351562 0.429688
iteration 368: loss 0.730 0.312500 0.414062
iteration 369: loss 0.679 0.351562 0.468750
iteration 370: loss 0.688 0.265625 0.492188
iteration 371: loss 0.611 0.281250 0.492188
iteration 372: loss 0.781 0.273438 0.507812
iteration 373: loss 0.668 0.328125 0.500000
iteration 374: loss 0.872 0.343750 0.445312
iteration 375: loss 0.859 0.242188 0.453125
iteration 376: loss 0.742 0.343750 0.492188
iteration 377: loss 0.736 0.289062 0.437500
iteration 378: loss 0.634 0.320312 0.468750
iteration 379: loss 0.678 0.328125 0.500000
iteration 380: loss 0.661 0.328125 0.460938
iteration 381: loss 0.738 0.312500 0.437500
iteration 382: loss 0.925 0.320312 0.500000
iteration 383: loss 0.724 0.312500 0.468750
iteration 384: loss 0.691 0.343750 0.453125
iteration 385: loss 0.821 0.351562 0.414062
iteration 386: loss 0.849 0.281250 0.429688
iteration 387: loss 0.912 0.343750 0.382812
iteration 388: loss 0.856 0.218750 0.414062
iteration 389: loss 0.582 0.304688 0.507812
iteration 390: loss 0.871 0.312500 0.390625
iteration 391: loss 0.789 0.367188 0.515625
iteration 392: loss 0.841 0.273438 0.398438
iteration 393: loss 0.681 0.234375 0.460938
iteration 394: loss 0.592 0.273438 0.507812
iteration 395: loss 0.947 0.304688 0.359375
iteration 396: loss 0.782 0.328125 0.406250
iteration 397: loss 0.689 0.257812 0.445312
iteration 398: loss 0.580 0.335938 0.476562
iteration 399: loss 0.829 0.296875 0.437500
iteration 400: loss 0.904 0.320312 0.453125
iteration 401: loss 1.134 0.320312 0.445312
iteration 402: loss 0.727 0.328125 0.531250
iteration 403: loss 0.742 0.375000 0.515625
iteration 404: loss 0.795 0.343750 0.445312
iteration 405: loss 0.817 0.281250 0.421875
iteration 406: loss 0.775 0.312500 0.484375
iteration 407: loss 0.653 0.304688 0.500000
iteration 408: loss 1.011 0.320312 0.453125
iteration 409: loss 0.850 0.296875 0.468750
iteration 410: loss 0.695 0.359375 0.484375
iteration 411: loss 0.803 0.312500 0.414062
iteration 412: loss 0.808 0.289062 0.492188
iteration 413: loss 0.837 0.273438 0.445312
iteration 414: loss 0.715 0.320312 0.445312
iteration 415: loss 0.856 0.320312 0.421875
iteration 416: loss 0.595 0.257812 0.523438
iteration 417: loss 0.919 0.335938 0.398438
iteration 418: loss 0.720 0.289062 0.468750
iteration 419: loss 0.622 0.375000 0.460938
iteration 420: loss 0.694 0.343750 0.523438
iteration 421: loss 0.923 0.296875 0.476562
iteration 422: loss 0.849 0.218750 0.460938
iteration 423: loss 0.822 0.367188 0.445312
iteration 424: loss 0.850 0.296875 0.492188
iteration 425: loss 0.991 0.359375 0.421875
iteration 426: loss 0.739 0.273438 0.398438
iteration 427: loss 0.843 0.351562 0.414062
iteration 428: loss 0.752 0.296875 0.523438
iteration 429: loss 0.751 0.351562 0.515625
iteration 430: loss 0.805 0.328125 0.492188
iteration 431: loss 0.821 0.312500 0.453125
iteration 432: loss 0.770 0.304688 0.460938
iteration 433: loss 0.702 0.304688 0.414062
iteration 434: loss 0.709 0.273438 0.421875
iteration 435: loss 0.885 0.312500 0.453125
iteration 436: loss 0.939 0.335938 0.398438
iteration 437: loss 0.949 0.359375 0.375000
iteration 438: loss 0.805 0.242188 0.421875
iteration 439: loss 0.721 0.281250 0.460938
iteration 440: loss 0.735 0.328125 0.406250
iteration 441: loss 0.649 0.320312 0.476562
iteration 442: loss 0.833 0.304688 0.453125
iteration 443: loss 0.974 0.320312 0.398438
iteration 444: loss 0.774 0.296875 0.476562
iteration 445: loss 0.943 0.296875 0.406250
iteration 446: loss 0.858 0.250000 0.453125
iteration 447: loss 0.953 0.273438 0.367188
iteration 448: loss 0.794 0.250000 0.429688
iteration 449: loss 0.953 0.320312 0.398438
iteration 450: loss 0.678 0.359375 0.460938
iteration 451: loss 0.833 0.382812 0.453125
iteration 452: loss 0.684 0.289062 0.492188
iteration 453: loss 0.717 0.367188 0.460938
iteration 454: loss 0.693 0.281250 0.453125
iteration 455: loss 1.040 0.375000 0.351562
iteration 456: loss 0.667 0.390625 0.453125
iteration 457: loss 0.713 0.328125 0.476562
iteration 458: loss 0.650 0.296875 0.453125
iteration 459: loss 0.688 0.250000 0.476562
iteration 460: loss 0.691 0.289062 0.507812
iteration 461: loss 0.963 0.304688 0.312500
iteration 462: loss 0.621 0.367188 0.515625
iteration 463: loss 0.712 0.328125 0.507812
iteration 464: loss 0.938 0.367188 0.460938
iteration 465: loss 0.875 0.343750 0.414062
iteration 466: loss 0.861 0.296875 0.445312
iteration 467: loss 0.814 0.265625 0.437500
iteration 468: loss 0.780 0.367188 0.437500
iteration 469: loss 0.892 0.304688 0.492188
iteration 470: loss 0.776 0.265625 0.476562
iteration 471: loss 0.921 0.273438 0.406250
iteration 472: loss 0.819 0.265625 0.437500
iteration 473: loss 0.551 0.210938 0.500000
iteration 474: loss 0.890 0.312500 0.406250
iteration 475: loss 0.759 0.312500 0.421875
iteration 476: loss 0.826 0.367188 0.468750
iteration 477: loss 0.831 0.250000 0.414062
iteration 478: loss 0.818 0.304688 0.484375
iteration 479: loss 0.780 0.382812 0.445312
iteration 480: loss 0.788 0.375000 0.500000
iteration 481: loss 0.848 0.226562 0.437500
iteration 482: loss 0.632 0.335938 0.437500
iteration 483: loss 0.742 0.359375 0.421875
iteration 484: loss 0.727 0.343750 0.445312
iteration 485: loss 0.819 0.257812 0.414062
iteration 486: loss 0.795 0.257812 0.460938
iteration 487: loss 0.899 0.273438 0.320312
iteration 488: loss 0.673 0.257812 0.476562
iteration 489: loss 0.703 0.265625 0.492188
iteration 490: loss 0.565 0.312500 0.539062
iteration 491: loss 0.694 0.304688 0.468750
iteration 492: loss 0.692 0.320312 0.507812
iteration 493: loss 1.091 0.242188 0.367188
iteration 494: loss 0.897 0.304688 0.367188
iteration 495: loss 0.806 0.273438 0.453125
iteration 496: loss 0.942 0.242188 0.390625
iteration 497: loss 0.714 0.273438 0.453125
iteration 498: loss 0.741 0.359375 0.445312
iteration 499: loss 0.955 0.304688 0.382812
iteration 500: loss 0.709 0.296875 0.445312
iteration 501: loss 0.651 0.320312 0.515625
iteration 502: loss 0.548 0.312500 0.460938
iteration 503: loss 0.960 0.312500 0.421875
iteration 504: loss 0.633 0.414062 0.429688
iteration 505: loss 0.845 0.289062 0.414062
iteration 506: loss 0.695 0.367188 0.492188
iteration 507: loss 0.684 0.273438 0.476562
iteration 508: loss 0.715 0.210938 0.382812
iteration 509: loss 0.738 0.351562 0.468750
iteration 510: loss 0.811 0.281250 0.367188
iteration 511: loss 0.872 0.265625 0.398438
iteration 512: loss 0.946 0.289062 0.367188
iteration 513: loss 0.611 0.375000 0.453125
iteration 514: loss 0.784 0.335938 0.453125
iteration 515: loss 0.707 0.296875 0.445312
iteration 516: loss 0.757 0.351562 0.445312
iteration 517: loss 0.677 0.296875 0.484375
iteration 518: loss 0.745 0.304688 0.523438
iteration 519: loss 0.825 0.250000 0.468750
iteration 520: loss 0.879 0.289062 0.382812
iteration 521: loss 0.657 0.320312 0.515625
iteration 522: loss 0.890 0.289062 0.453125
iteration 523: loss 0.754 0.320312 0.468750
iteration 524: loss 0.666 0.226562 0.453125
iteration 525: loss 0.610 0.281250 0.476562
iteration 526: loss 0.731 0.265625 0.445312
iteration 527: loss 0.725 0.343750 0.539062
iteration 528: loss 0.994 0.343750 0.445312
iteration 529: loss 0.837 0.257812 0.445312
iteration 530: loss 0.672 0.328125 0.523438
iteration 531: loss 0.665 0.320312 0.539062
iteration 532: loss 0.661 0.359375 0.460938
iteration 533: loss 0.711 0.367188 0.406250
iteration 534: loss 0.745 0.343750 0.507812
iteration 535: loss 0.716 0.289062 0.390625
iteration 536: loss 0.819 0.359375 0.445312
iteration 537: loss 0.668 0.320312 0.445312
iteration 538: loss 0.898 0.375000 0.468750
iteration 539: loss 0.732 0.304688 0.382812
iteration 540: loss 0.725 0.257812 0.500000
iteration 541: loss 0.885 0.312500 0.398438
iteration 542: loss 0.857 0.265625 0.437500
iteration 543: loss 0.924 0.328125 0.414062
iteration 544: loss 0.658 0.343750 0.468750
iteration 545: loss 0.705 0.335938 0.429688
iteration 546: loss 0.636 0.304688 0.453125
iteration 547: loss 0.832 0.320312 0.476562
iteration 548: loss 0.861 0.359375 0.476562
iteration 549: loss 0.964 0.265625 0.468750
iteration 550: loss 0.640 0.242188 0.515625
iteration 551: loss 0.841 0.375000 0.445312
iteration 552: loss 0.757 0.281250 0.437500
iteration 553: loss 0.707 0.304688 0.515625
iteration 554: loss 0.801 0.265625 0.343750
iteration 555: loss 0.774 0.367188 0.414062
iteration 556: loss 0.959 0.320312 0.515625
iteration 557: loss 0.852 0.296875 0.445312
iteration 558: loss 0.611 0.289062 0.523438
iteration 559: loss 0.752 0.304688 0.437500
iteration 560: loss 0.871 0.328125 0.484375
iteration 561: loss 0.716 0.335938 0.476562
iteration 562: loss 0.765 0.296875 0.460938
iteration 563: loss 0.871 0.257812 0.453125
iteration 564: loss 0.967 0.335938 0.445312
iteration 565: loss 0.854 0.351562 0.468750
iteration 566: loss 0.726 0.250000 0.460938
iteration 567: loss 0.734 0.312500 0.367188
iteration 568: loss 0.748 0.273438 0.437500
iteration 569: loss 0.731 0.289062 0.515625
iteration 570: loss 0.798 0.382812 0.468750
iteration 571: loss 0.661 0.375000 0.546875
iteration 572: loss 0.937 0.304688 0.476562
iteration 573: loss 0.729 0.359375 0.453125
iteration 574: loss 0.677 0.265625 0.515625
iteration 575: loss 0.577 0.250000 0.453125
iteration 576: loss 0.797 0.265625 0.359375
iteration 577: loss 0.661 0.312500 0.500000
iteration 578: loss 0.642 0.296875 0.476562
iteration 579: loss 0.702 0.328125 0.476562
iteration 580: loss 0.840 0.250000 0.476562
iteration 581: loss 0.928 0.289062 0.429688
iteration 582: loss 0.741 0.406250 0.500000
iteration 583: loss 0.776 0.328125 0.515625
iteration 584: loss 0.825 0.367188 0.453125
iteration 585: loss 0.777 0.296875 0.421875
iteration 586: loss 0.721 0.359375 0.468750
iteration 587: loss 0.754 0.257812 0.460938
iteration 588: loss 0.805 0.281250 0.390625
iteration 589: loss 0.807 0.281250 0.406250
iteration 590: loss 0.746 0.312500 0.468750
iteration 591: loss 0.802 0.320312 0.515625
iteration 592: loss 0.873 0.367188 0.492188
iteration 593: loss 0.706 0.289062 0.492188
iteration 594: loss 0.730 0.296875 0.468750
iteration 595: loss 0.490 0.335938 0.609375
iteration 596: loss 0.676 0.242188 0.468750
iteration 597: loss 0.864 0.335938 0.351562
iteration 598: loss 0.791 0.281250 0.453125
iteration 599: loss 0.679 0.328125 0.429688
iteration 600: loss 0.802 0.335938 0.453125
iteration 601: loss 0.595 0.343750 0.507812
iteration 602: loss 0.717 0.234375 0.492188
iteration 603: loss 0.635 0.312500 0.546875
iteration 604: loss 0.800 0.312500 0.453125
iteration 605: loss 0.872 0.273438 0.445312
iteration 606: loss 0.886 0.312500 0.429688
iteration 607: loss 0.847 0.328125 0.414062
iteration 608: loss 0.802 0.257812 0.382812
iteration 609: loss 0.631 0.304688 0.476562
iteration 610: loss 0.718 0.335938 0.406250
iteration 611: loss 0.639 0.312500 0.429688
iteration 612: loss 0.634 0.312500 0.515625
iteration 613: loss 0.855 0.281250 0.468750
iteration 614: loss 0.802 0.234375 0.492188
iteration 615: loss 0.664 0.281250 0.492188
iteration 616: loss 0.710 0.289062 0.523438
iteration 617: loss 0.819 0.296875 0.382812
iteration 618: loss 0.666 0.281250 0.460938
iteration 619: loss 0.604 0.304688 0.406250
iteration 620: loss 0.774 0.335938 0.500000
iteration 621: loss 0.620 0.367188 0.492188
iteration 622: loss 0.780 0.273438 0.437500
iteration 623: loss 0.795 0.265625 0.445312
iteration 624: loss 0.878 0.289062 0.421875
iteration 625: loss 0.599 0.335938 0.554688
iteration 626: loss 0.700 0.281250 0.507812
iteration 627: loss 0.774 0.210938 0.406250
iteration 628: loss 0.735 0.296875 0.421875
iteration 629: loss 0.788 0.296875 0.398438
iteration 630: loss 0.785 0.343750 0.445312
iteration 631: loss 0.619 0.328125 0.476562
iteration 632: loss 0.792 0.382812 0.437500
iteration 633: loss 0.727 0.289062 0.476562
iteration 634: loss 0.819 0.296875 0.421875
iteration 635: loss 0.682 0.343750 0.460938
iteration 636: loss 0.646 0.335938 0.500000
iteration 637: loss 0.796 0.343750 0.515625
iteration 638: loss 0.688 0.312500 0.460938
iteration 639: loss 0.716 0.328125 0.445312
iteration 640: loss 0.880 0.335938 0.453125
iteration 641: loss 0.580 0.398438 0.500000
iteration 642: loss 0.944 0.320312 0.406250
iteration 643: loss 0.598 0.304688 0.546875
iteration 644: loss 0.850 0.335938 0.429688
iteration 645: loss 0.716 0.335938 0.484375
iteration 646: loss 0.808 0.296875 0.484375
iteration 647: loss 0.831 0.328125 0.429688
iteration 648: loss 0.655 0.328125 0.445312
iteration 649: loss 0.693 0.328125 0.453125
iteration 650: loss 0.697 0.273438 0.445312
iteration 651: loss 0.778 0.304688 0.453125
iteration 652: loss 0.945 0.343750 0.445312
iteration 653: loss 0.640 0.289062 0.460938
iteration 654: loss 0.794 0.367188 0.429688
iteration 655: loss 0.741 0.312500 0.453125
iteration 656: loss 0.652 0.257812 0.500000
iteration 657: loss 0.901 0.273438 0.429688
iteration 658: loss 0.763 0.320312 0.468750
iteration 659: loss 0.733 0.375000 0.500000
iteration 660: loss 0.920 0.296875 0.406250
iteration 661: loss 0.704 0.304688 0.476562
iteration 662: loss 0.782 0.281250 0.429688
iteration 663: loss 0.773 0.343750 0.476562
iteration 664: loss 0.586 0.265625 0.515625
iteration 665: loss 0.703 0.265625 0.523438
iteration 666: loss 0.645 0.273438 0.515625
iteration 667: loss 0.771 0.281250 0.382812
iteration 668: loss 0.734 0.281250 0.484375
iteration 669: loss 0.712 0.281250 0.546875
iteration 670: loss 0.930 0.281250 0.367188
iteration 671: loss 0.713 0.312500 0.445312
iteration 672: loss 0.800 0.304688 0.406250
iteration 673: loss 1.054 0.320312 0.359375
iteration 674: loss 0.895 0.328125 0.398438
iteration 675: loss 0.814 0.304688 0.335938
iteration 676: loss 0.670 0.273438 0.390625
iteration 677: loss 0.700 0.296875 0.523438
iteration 678: loss 0.795 0.296875 0.414062
iteration 679: loss 0.726 0.281250 0.507812
iteration 680: loss 0.731 0.382812 0.539062
iteration 681: loss 0.934 0.296875 0.453125
iteration 682: loss 0.790 0.304688 0.476562
iteration 683: loss 0.837 0.382812 0.414062
iteration 684: loss 0.831 0.335938 0.445312
iteration 685: loss 0.686 0.320312 0.468750
iteration 686: loss 0.804 0.335938 0.507812
iteration 687: loss 0.732 0.320312 0.468750
iteration 688: loss 0.793 0.265625 0.484375
iteration 689: loss 0.856 0.273438 0.445312
iteration 690: loss 0.778 0.320312 0.523438
iteration 691: loss 0.823 0.289062 0.429688
iteration 692: loss 0.741 0.257812 0.406250
iteration 693: loss 0.654 0.351562 0.554688
iteration 694: loss 0.856 0.312500 0.429688
iteration 695: loss 0.726 0.250000 0.421875
iteration 696: loss 0.782 0.328125 0.539062
iteration 697: loss 0.901 0.242188 0.523438
iteration 698: loss 0.759 0.312500 0.437500
iteration 699: loss 0.916 0.273438 0.414062
iteration 700: loss 0.648 0.296875 0.507812
iteration 701: loss 0.856 0.304688 0.406250
iteration 702: loss 0.733 0.265625 0.460938
iteration 703: loss 0.709 0.328125 0.460938
iteration 704: loss 0.909 0.328125 0.437500
iteration 705: loss 0.908 0.335938 0.429688
iteration 706: loss 0.834 0.304688 0.460938
iteration 707: loss 0.740 0.265625 0.453125
iteration 708: loss 0.965 0.343750 0.367188
iteration 709: loss 0.662 0.375000 0.500000
iteration 710: loss 0.787 0.257812 0.468750
iteration 711: loss 0.670 0.312500 0.468750
iteration 712: loss 0.842 0.257812 0.414062
iteration 713: loss 0.826 0.304688 0.398438
iteration 714: loss 0.888 0.273438 0.398438
iteration 715: loss 0.943 0.273438 0.406250
iteration 716: loss 0.771 0.265625 0.437500
iteration 717: loss 0.872 0.335938 0.500000
iteration 718: loss 0.705 0.218750 0.453125
iteration 719: loss 0.862 0.304688 0.398438
iteration 720: loss 0.798 0.328125 0.414062
iteration 721: loss 0.816 0.367188 0.476562
iteration 722: loss 0.900 0.273438 0.414062
iteration 723: loss 0.784 0.398438 0.460938
iteration 724: loss 0.846 0.351562 0.453125
iteration 725: loss 0.598 0.382812 0.500000
iteration 726: loss 0.780 0.296875 0.500000
iteration 727: loss 0.906 0.359375 0.406250
iteration 728: loss 0.722 0.343750 0.531250
iteration 729: loss 0.738 0.382812 0.445312
iteration 730: loss 0.788 0.281250 0.445312
iteration 731: loss 0.624 0.226562 0.484375
iteration 732: loss 0.725 0.335938 0.468750
iteration 733: loss 0.763 0.296875 0.445312
iteration 734: loss 0.797 0.375000 0.437500
iteration 735: loss 0.767 0.328125 0.429688
iteration 736: loss 0.670 0.320312 0.492188
iteration 737: loss 0.751 0.312500 0.484375
iteration 738: loss 0.590 0.343750 0.500000
iteration 739: loss 0.687 0.289062 0.515625
iteration 740: loss 0.738 0.312500 0.500000
iteration 741: loss 0.783 0.304688 0.453125
iteration 742: loss 0.684 0.218750 0.453125
iteration 743: loss 0.736 0.273438 0.429688
iteration 744: loss 0.628 0.296875 0.531250
iteration 745: loss 0.647 0.242188 0.460938
iteration 746: loss 0.763 0.281250 0.437500
iteration 747: loss 0.774 0.367188 0.414062
iteration 748: loss 0.612 0.320312 0.515625
iteration 749: loss 0.572 0.351562 0.476562
iteration 750: loss 0.688 0.265625 0.476562
iteration 751: loss 0.769 0.273438 0.453125
iteration 752: loss 0.839 0.406250 0.406250
iteration 753: loss 0.693 0.367188 0.476562
iteration 754: loss 0.740 0.328125 0.484375
iteration 755: loss 0.896 0.265625 0.382812
iteration 756: loss 0.779 0.359375 0.453125
iteration 757: loss 0.609 0.304688 0.476562
iteration 758: loss 0.614 0.273438 0.437500
iteration 759: loss 0.868 0.257812 0.406250
iteration 760: loss 0.770 0.242188 0.414062
iteration 761: loss 0.764 0.265625 0.445312
iteration 762: loss 0.650 0.273438 0.445312
iteration 763: loss 1.014 0.351562 0.367188
iteration 764: loss 0.633 0.367188 0.460938
iteration 765: loss 0.729 0.304688 0.492188
iteration 766: loss 0.703 0.328125 0.460938
iteration 767: loss 0.838 0.312500 0.500000
iteration 768: loss 0.680 0.343750 0.468750
iteration 769: loss 0.774 0.335938 0.460938
iteration 770: loss 0.593 0.312500 0.492188
iteration 771: loss 0.774 0.296875 0.453125
iteration 772: loss 0.647 0.304688 0.429688
iteration 773: loss 0.657 0.328125 0.500000
iteration 774: loss 0.652 0.242188 0.460938
iteration 775: loss 0.811 0.343750 0.390625
iteration 776: loss 0.726 0.312500 0.367188
iteration 777: loss 0.700 0.242188 0.476562
iteration 778: loss 0.787 0.335938 0.437500
iteration 779: loss 0.704 0.320312 0.492188
iteration 780: loss 0.757 0.242188 0.468750
iteration 781: loss 0.636 0.257812 0.539062
iteration 782: loss 0.636 0.312500 0.546875
iteration 783: loss 0.866 0.351562 0.367188
iteration 784: loss 0.731 0.304688 0.460938
iteration 785: loss 0.746 0.273438 0.468750
iteration 786: loss 0.660 0.265625 0.492188
iteration 787: loss 0.585 0.289062 0.484375
iteration 788: loss 0.625 0.367188 0.484375
iteration 789: loss 0.709 0.398438 0.468750
iteration 790: loss 0.683 0.281250 0.460938
iteration 791: loss 0.692 0.335938 0.531250
iteration 792: loss 0.590 0.335938 0.500000
iteration 793: loss 0.777 0.242188 0.460938
iteration 794: loss 0.795 0.296875 0.398438
iteration 795: loss 0.752 0.289062 0.500000
iteration 796: loss 0.702 0.296875 0.453125
iteration 797: loss 0.664 0.343750 0.476562
iteration 798: loss 0.851 0.265625 0.429688
iteration 799: loss 0.604 0.312500 0.460938
iteration 800: loss 0.703 0.296875 0.476562
iteration 801: loss 0.646 0.320312 0.460938
iteration 802: loss 0.631 0.273438 0.500000
iteration 803: loss 0.703 0.289062 0.476562
iteration 804: loss 0.554 0.289062 0.570312
iteration 805: loss 0.860 0.414062 0.484375
iteration 806: loss 0.674 0.343750 0.500000
iteration 807: loss 0.678 0.320312 0.476562
iteration 808: loss 0.772 0.296875 0.437500
iteration 809: loss 0.739 0.281250 0.500000
iteration 810: loss 0.670 0.375000 0.414062
iteration 811: loss 0.841 0.296875 0.398438
iteration 812: loss 0.617 0.367188 0.500000
iteration 813: loss 0.620 0.343750 0.492188
iteration 814: loss 0.853 0.281250 0.398438
iteration 815: loss 0.941 0.382812 0.421875
iteration 816: loss 0.741 0.304688 0.539062
iteration 817: loss 0.705 0.273438 0.539062
iteration 818: loss 0.732 0.257812 0.453125
iteration 819: loss 0.624 0.226562 0.539062
iteration 820: loss 0.730 0.359375 0.445312
iteration 821: loss 0.757 0.273438 0.468750
iteration 822: loss 0.831 0.382812 0.398438
iteration 823: loss 0.831 0.320312 0.429688
iteration 824: loss 0.590 0.359375 0.453125
iteration 825: loss 0.768 0.343750 0.406250
iteration 826: loss 0.741 0.343750 0.468750
iteration 827: loss 1.256 0.289062 0.367188
iteration 828: loss 0.860 0.382812 0.437500
iteration 829: loss 0.787 0.335938 0.437500
iteration 830: loss 0.759 0.296875 0.406250
iteration 831: loss 0.593 0.304688 0.492188
iteration 832: loss 0.806 0.304688 0.476562
iteration 833: loss 0.709 0.265625 0.507812
iteration 834: loss 0.797 0.390625 0.484375
iteration 835: loss 0.838 0.304688 0.523438
iteration 836: loss 0.892 0.273438 0.492188
iteration 837: loss 0.751 0.453125 0.460938
iteration 838: loss 0.951 0.304688 0.437500
iteration 839: loss 0.712 0.296875 0.460938
iteration 840: loss 0.885 0.343750 0.421875
iteration 841: loss 0.843 0.289062 0.429688
iteration 842: loss 0.757 0.273438 0.429688
iteration 843: loss 0.708 0.367188 0.460938
iteration 844: loss 0.803 0.265625 0.437500
iteration 845: loss 0.922 0.281250 0.437500
iteration 846: loss 0.890 0.359375 0.382812
iteration 847: loss 0.640 0.304688 0.523438
iteration 848: loss 0.791 0.343750 0.492188
iteration 849: loss 0.788 0.320312 0.523438
iteration 850: loss 0.802 0.289062 0.515625
iteration 851: loss 0.778 0.328125 0.492188
iteration 852: loss 0.616 0.320312 0.539062
iteration 853: loss 0.732 0.273438 0.429688
iteration 854: loss 0.848 0.296875 0.398438
iteration 855: loss 0.818 0.289062 0.445312
iteration 856: loss 0.761 0.257812 0.414062
iteration 857: loss 0.935 0.351562 0.460938
iteration 858: loss 0.725 0.312500 0.500000
iteration 859: loss 0.674 0.289062 0.484375
iteration 860: loss 0.767 0.351562 0.531250
iteration 861: loss 0.678 0.312500 0.500000
iteration 862: loss 0.980 0.406250 0.390625
iteration 863: loss 0.744 0.242188 0.476562
iteration 864: loss 0.749 0.367188 0.398438
iteration 865: loss 0.648 0.328125 0.453125
iteration 866: loss 0.837 0.320312 0.476562
iteration 867: loss 0.706 0.250000 0.492188
iteration 868: loss 0.780 0.281250 0.500000
iteration 869: loss 0.776 0.289062 0.437500
iteration 870: loss 0.757 0.257812 0.429688
iteration 871: loss 0.763 0.312500 0.453125
iteration 872: loss 1.030 0.359375 0.437500
iteration 873: loss 0.708 0.367188 0.484375
iteration 874: loss 0.780 0.328125 0.398438
iteration 875: loss 0.700 0.414062 0.453125
iteration 876: loss 0.548 0.296875 0.531250
iteration 877: loss 0.817 0.367188 0.445312
iteration 878: loss 0.752 0.359375 0.468750
iteration 879: loss 0.758 0.382812 0.500000
iteration 880: loss 0.713 0.312500 0.453125
iteration 881: loss 0.844 0.289062 0.390625
iteration 882: loss 0.693 0.289062 0.445312
iteration 883: loss 0.766 0.273438 0.390625
iteration 884: loss 0.702 0.320312 0.515625
iteration 885: loss 0.865 0.289062 0.343750
iteration 886: loss 0.666 0.335938 0.468750
iteration 887: loss 0.736 0.335938 0.453125
iteration 888: loss 0.627 0.242188 0.429688
iteration 889: loss 0.712 0.320312 0.484375
iteration 890: loss 0.759 0.296875 0.515625
iteration 891: loss 0.545 0.359375 0.476562
iteration 892: loss 0.758 0.289062 0.437500
iteration 893: loss 0.629 0.382812 0.523438
iteration 894: loss 0.569 0.406250 0.523438
iteration 895: loss 0.675 0.343750 0.484375
iteration 896: loss 0.862 0.289062 0.437500
iteration 897: loss 0.630 0.312500 0.468750
iteration 898: loss 0.823 0.359375 0.406250
iteration 899: loss 0.842 0.281250 0.359375
iteration 900: loss 0.775 0.367188 0.468750
iteration 901: loss 0.824 0.343750 0.390625
iteration 902: loss 0.660 0.343750 0.476562
iteration 903: loss 0.693 0.250000 0.468750
iteration 904: loss 0.807 0.359375 0.484375
iteration 905: loss 0.633 0.250000 0.500000
iteration 906: loss 0.795 0.273438 0.453125
iteration 907: loss 0.647 0.359375 0.492188
iteration 908: loss 0.791 0.296875 0.437500
iteration 909: loss 0.672 0.304688 0.460938
iteration 910: loss 0.851 0.351562 0.406250
iteration 911: loss 0.622 0.304688 0.453125
iteration 912: loss 0.742 0.328125 0.468750
iteration 913: loss 0.722 0.273438 0.460938
iteration 914: loss 0.723 0.281250 0.484375
iteration 915: loss 0.718 0.281250 0.476562
iteration 916: loss 0.749 0.335938 0.429688
iteration 917: loss 0.974 0.273438 0.437500
iteration 918: loss 0.928 0.367188 0.406250
iteration 919: loss 0.804 0.312500 0.429688
iteration 920: loss 0.709 0.304688 0.414062
iteration 921: loss 0.590 0.343750 0.554688
iteration 922: loss 0.683 0.390625 0.484375
iteration 923: loss 0.892 0.257812 0.398438
iteration 924: loss 0.797 0.406250 0.375000
iteration 925: loss 0.581 0.257812 0.531250
iteration 926: loss 0.629 0.406250 0.468750
iteration 927: loss 0.776 0.320312 0.453125
iteration 928: loss 0.633 0.367188 0.515625
iteration 929: loss 0.648 0.429688 0.546875
iteration 930: loss 0.731 0.343750 0.460938
iteration 931: loss 0.539 0.351562 0.546875
iteration 932: loss 0.671 0.304688 0.484375
iteration 933: loss 0.760 0.312500 0.500000
iteration 934: loss 0.563 0.421875 0.460938
iteration 935: loss 0.760 0.312500 0.468750
iteration 936: loss 0.775 0.273438 0.429688
iteration 937: loss 0.761 0.320312 0.453125
iteration 938: loss 0.724 0.359375 0.476562
iteration 939: loss 0.823 0.312500 0.406250
iteration 940: loss 0.805 0.351562 0.468750
iteration 941: loss 0.723 0.312500 0.500000
iteration 942: loss 0.885 0.390625 0.476562
iteration 943: loss 0.756 0.273438 0.460938
iteration 944: loss 0.683 0.390625 0.468750
iteration 945: loss 0.670 0.265625 0.492188
iteration 946: loss 0.650 0.289062 0.453125
iteration 947: loss 0.793 0.296875 0.460938
iteration 948: loss 0.842 0.320312 0.343750
iteration 949: loss 0.756 0.304688 0.460938
iteration 950: loss 0.549 0.281250 0.460938
iteration 951: loss 0.723 0.343750 0.421875
iteration 952: loss 0.703 0.296875 0.484375
iteration 953: loss 0.765 0.296875 0.468750
iteration 954: loss 0.853 0.273438 0.406250
iteration 955: loss 0.839 0.351562 0.507812
iteration 956: loss 0.877 0.367188 0.398438
iteration 957: loss 0.685 0.335938 0.468750
iteration 958: loss 0.792 0.265625 0.406250
iteration 959: loss 0.746 0.351562 0.390625
iteration 960: loss 0.780 0.335938 0.375000
iteration 961: loss 0.568 0.351562 0.523438
iteration 962: loss 0.726 0.367188 0.437500
iteration 963: loss 0.713 0.312500 0.414062
iteration 964: loss 0.718 0.351562 0.484375
iteration 965: loss 0.616 0.281250 0.500000
iteration 966: loss 0.859 0.367188 0.437500
iteration 967: loss 0.726 0.359375 0.476562
iteration 968: loss 0.628 0.343750 0.507812
iteration 969: loss 0.843 0.281250 0.468750
iteration 970: loss 0.631 0.320312 0.468750
iteration 971: loss 0.595 0.304688 0.460938
iteration 972: loss 0.664 0.390625 0.468750
iteration 973: loss 0.700 0.343750 0.460938
iteration 974: loss 0.695 0.351562 0.492188
iteration 975: loss 0.732 0.281250 0.421875
iteration 976: loss 0.723 0.257812 0.500000
iteration 977: loss 0.716 0.304688 0.437500
iteration 978: loss 0.692 0.289062 0.398438
iteration 979: loss 0.697 0.312500 0.468750
iteration 980: loss 0.703 0.312500 0.484375
iteration 981: loss 0.640 0.335938 0.468750
iteration 982: loss 0.711 0.312500 0.437500
iteration 983: loss 0.670 0.312500 0.500000
iteration 984: loss 0.830 0.359375 0.476562
iteration 985: loss 0.698 0.304688 0.429688
iteration 986: loss 0.818 0.343750 0.382812
iteration 987: loss 0.683 0.351562 0.492188
iteration 988: loss 0.757 0.335938 0.414062
iteration 989: loss 0.633 0.343750 0.515625
iteration 990: loss 0.594 0.257812 0.515625
iteration 991: loss 0.693 0.351562 0.484375
iteration 992: loss 0.733 0.406250 0.445312
iteration 993: loss 0.859 0.289062 0.421875
iteration 994: loss 0.858 0.328125 0.445312
iteration 995: loss 0.692 0.375000 0.460938
iteration 996: loss 0.794 0.335938 0.429688
iteration 997: loss 0.736 0.281250 0.453125
iteration 998: loss 0.619 0.382812 0.453125
iteration 999: loss 0.792 0.335938 0.382812
epoch 7: training: 0.351562 validation: 0.218750
iteration 0: loss 0.654 0.296875 0.406250
iteration 1: loss 0.613 0.335938 0.476562
iteration 2: loss 0.745 0.281250 0.453125
iteration 3: loss 0.815 0.250000 0.437500
iteration 4: loss 0.476 0.304688 0.546875
iteration 5: loss 0.760 0.351562 0.453125
iteration 6: loss 0.703 0.304688 0.468750
iteration 7: loss 0.736 0.343750 0.492188
iteration 8: loss 0.672 0.328125 0.484375
iteration 9: loss 0.710 0.242188 0.453125
iteration 10: loss 0.803 0.281250 0.492188
iteration 11: loss 0.793 0.328125 0.484375
iteration 12: loss 0.668 0.335938 0.445312
iteration 13: loss 0.663 0.343750 0.437500
iteration 14: loss 0.690 0.460938 0.437500
iteration 15: loss 0.621 0.273438 0.476562
iteration 16: loss 0.781 0.359375 0.445312
iteration 17: loss 0.737 0.320312 0.429688
iteration 18: loss 0.802 0.281250 0.421875
iteration 19: loss 0.774 0.304688 0.468750
iteration 20: loss 0.731 0.312500 0.468750
iteration 21: loss 0.805 0.304688 0.398438
iteration 22: loss 0.815 0.343750 0.437500
iteration 23: loss 0.717 0.273438 0.453125
iteration 24: loss 0.646 0.265625 0.484375
iteration 25: loss 0.891 0.367188 0.445312
iteration 26: loss 0.748 0.312500 0.382812
iteration 27: loss 0.506 0.296875 0.554688
iteration 28: loss 0.863 0.335938 0.414062
iteration 29: loss 0.680 0.312500 0.468750
iteration 30: loss 0.836 0.320312 0.507812
iteration 31: loss 0.656 0.367188 0.468750
iteration 32: loss 0.911 0.320312 0.398438
iteration 33: loss 0.629 0.289062 0.507812
iteration 34: loss 0.677 0.296875 0.515625
iteration 35: loss 0.767 0.304688 0.445312
iteration 36: loss 0.695 0.281250 0.445312
iteration 37: loss 0.546 0.312500 0.492188
iteration 38: loss 0.866 0.343750 0.398438
iteration 39: loss 0.797 0.335938 0.460938
iteration 40: loss 0.679 0.351562 0.507812
iteration 41: loss 0.794 0.343750 0.437500
iteration 42: loss 0.556 0.265625 0.515625
iteration 43: loss 0.665 0.234375 0.562500
iteration 44: loss 0.684 0.335938 0.492188
iteration 45: loss 0.790 0.304688 0.476562
iteration 46: loss 0.750 0.289062 0.429688
iteration 47: loss 0.653 0.335938 0.437500
iteration 48: loss 0.773 0.250000 0.375000
iteration 49: loss 0.776 0.343750 0.500000
iteration 50: loss 0.710 0.351562 0.429688
iteration 51: loss 0.773 0.328125 0.515625
iteration 52: loss 0.591 0.281250 0.554688
iteration 53: loss 0.445 0.304688 0.617188
iteration 54: loss 0.652 0.398438 0.546875
iteration 55: loss 0.715 0.203125 0.500000
iteration 56: loss 0.753 0.390625 0.500000
iteration 57: loss 0.689 0.312500 0.500000
iteration 58: loss 0.701 0.250000 0.421875
iteration 59: loss 0.747 0.265625 0.414062
iteration 60: loss 0.793 0.273438 0.359375
iteration 61: loss 0.695 0.375000 0.421875
iteration 62: loss 0.794 0.304688 0.437500
iteration 63: loss 0.827 0.257812 0.406250
iteration 64: loss 0.426 0.312500 0.539062
iteration 65: loss 0.760 0.304688 0.484375
iteration 66: loss 0.736 0.351562 0.468750
iteration 67: loss 0.702 0.328125 0.460938
iteration 68: loss 0.738 0.312500 0.507812
iteration 69: loss 0.704 0.273438 0.484375
iteration 70: loss 0.689 0.343750 0.421875
iteration 71: loss 0.655 0.265625 0.453125
iteration 72: loss 0.723 0.304688 0.390625
iteration 73: loss 0.708 0.265625 0.460938
iteration 74: loss 0.716 0.320312 0.484375
iteration 75: loss 0.862 0.250000 0.414062
iteration 76: loss 0.887 0.312500 0.476562
iteration 77: loss 0.586 0.304688 0.500000
iteration 78: loss 0.706 0.343750 0.515625
iteration 79: loss 0.777 0.367188 0.437500
iteration 80: loss 0.899 0.187500 0.421875
iteration 81: loss 0.602 0.320312 0.562500
iteration 82: loss 0.631 0.281250 0.500000
iteration 83: loss 0.902 0.335938 0.390625
iteration 84: loss 0.733 0.351562 0.398438
iteration 85: loss 0.592 0.328125 0.500000
iteration 86: loss 0.813 0.296875 0.476562
iteration 87: loss 0.835 0.351562 0.375000
iteration 88: loss 0.556 0.335938 0.523438
iteration 89: loss 0.589 0.304688 0.531250
iteration 90: loss 0.920 0.257812 0.484375
iteration 91: loss 0.613 0.304688 0.484375
iteration 92: loss 0.772 0.359375 0.453125
iteration 93: loss 0.686 0.351562 0.500000
iteration 94: loss 0.782 0.242188 0.492188
iteration 95: loss 0.896 0.367188 0.335938
iteration 96: loss 0.749 0.375000 0.398438
iteration 97: loss 0.785 0.296875 0.484375
iteration 98: loss 0.871 0.335938 0.437500
iteration 99: loss 0.675 0.343750 0.406250
iteration 100: loss 0.623 0.242188 0.437500
iteration 101: loss 0.614 0.289062 0.531250
iteration 102: loss 0.622 0.296875 0.523438
iteration 103: loss 0.647 0.335938 0.492188
iteration 104: loss 0.866 0.343750 0.414062
iteration 105: loss 0.593 0.320312 0.531250
iteration 106: loss 0.629 0.367188 0.523438
iteration 107: loss 0.571 0.390625 0.460938
iteration 108: loss 0.643 0.273438 0.445312
iteration 109: loss 0.610 0.335938 0.453125
iteration 110: loss 0.659 0.312500 0.429688
iteration 111: loss 0.797 0.312500 0.359375
iteration 112: loss 0.691 0.312500 0.476562
iteration 113: loss 0.672 0.289062 0.476562
iteration 114: loss 0.865 0.304688 0.468750
iteration 115: loss 0.609 0.296875 0.484375
iteration 116: loss 0.740 0.343750 0.437500
iteration 117: loss 0.776 0.351562 0.468750
iteration 118: loss 0.664 0.296875 0.445312
iteration 119: loss 0.763 0.289062 0.429688
iteration 120: loss 0.729 0.289062 0.437500
iteration 121: loss 0.684 0.289062 0.453125
iteration 122: loss 0.723 0.375000 0.437500
iteration 123: loss 0.731 0.289062 0.460938
iteration 124: loss 0.675 0.250000 0.468750
iteration 125: loss 0.739 0.296875 0.523438
iteration 126: loss 0.833 0.273438 0.484375
iteration 127: loss 0.772 0.296875 0.437500
iteration 128: loss 0.742 0.265625 0.351562
iteration 129: loss 0.667 0.312500 0.421875
iteration 130: loss 0.531 0.359375 0.476562
iteration 131: loss 0.725 0.296875 0.460938
iteration 132: loss 0.684 0.281250 0.460938
iteration 133: loss 0.706 0.320312 0.460938
iteration 134: loss 0.591 0.320312 0.445312
iteration 135: loss 0.577 0.375000 0.492188
iteration 136: loss 0.600 0.203125 0.468750
iteration 137: loss 0.701 0.273438 0.406250
iteration 138: loss 0.632 0.257812 0.453125
iteration 139: loss 0.637 0.351562 0.484375
iteration 140: loss 0.700 0.281250 0.406250
iteration 141: loss 0.714 0.328125 0.468750
iteration 142: loss 0.641 0.210938 0.468750
iteration 143: loss 0.619 0.453125 0.445312
iteration 144: loss 0.683 0.375000 0.445312
iteration 145: loss 0.611 0.328125 0.453125
iteration 146: loss 0.780 0.265625 0.343750
iteration 147: loss 0.736 0.328125 0.460938
iteration 148: loss 0.694 0.273438 0.468750
iteration 149: loss 0.567 0.382812 0.453125
iteration 150: loss 0.719 0.296875 0.468750
iteration 151: loss 0.592 0.257812 0.523438
iteration 152: loss 0.745 0.351562 0.460938
iteration 153: loss 0.643 0.289062 0.453125
iteration 154: loss 0.588 0.335938 0.445312
iteration 155: loss 0.759 0.250000 0.414062
iteration 156: loss 0.801 0.312500 0.414062
iteration 157: loss 0.816 0.375000 0.312500
iteration 158: loss 0.729 0.296875 0.421875
iteration 159: loss 0.608 0.250000 0.515625
iteration 160: loss 0.665 0.351562 0.492188
iteration 161: loss 0.643 0.242188 0.453125
iteration 162: loss 0.735 0.312500 0.476562
iteration 163: loss 0.769 0.335938 0.429688
iteration 164: loss 0.632 0.296875 0.531250
iteration 165: loss 0.744 0.312500 0.453125
iteration 166: loss 0.808 0.257812 0.492188
iteration 167: loss 0.976 0.312500 0.398438
iteration 168: loss 0.744 0.265625 0.429688
iteration 169: loss 0.823 0.359375 0.421875
iteration 170: loss 0.725 0.304688 0.437500
iteration 171: loss 0.725 0.304688 0.460938
iteration 172: loss 0.665 0.312500 0.437500
iteration 173: loss 0.632 0.296875 0.453125
iteration 174: loss 0.738 0.328125 0.468750
iteration 175: loss 0.742 0.242188 0.406250
iteration 176: loss 0.780 0.351562 0.460938
iteration 177: loss 0.752 0.281250 0.453125
iteration 178: loss 0.871 0.328125 0.414062
iteration 179: loss 0.726 0.343750 0.429688
iteration 180: loss 0.741 0.296875 0.437500
iteration 181: loss 0.830 0.296875 0.429688
iteration 182: loss 0.695 0.265625 0.429688
iteration 183: loss 0.682 0.335938 0.460938
iteration 184: loss 0.429 0.250000 0.601562
iteration 185: loss 0.632 0.281250 0.515625
iteration 186: loss 0.684 0.359375 0.476562
iteration 187: loss 0.723 0.320312 0.437500
iteration 188: loss 0.756 0.265625 0.390625
iteration 189: loss 0.875 0.312500 0.398438
iteration 190: loss 0.772 0.289062 0.398438
iteration 191: loss 0.778 0.312500 0.453125
iteration 192: loss 0.724 0.304688 0.437500
iteration 193: loss 0.837 0.304688 0.460938
iteration 194: loss 0.633 0.343750 0.468750
iteration 195: loss 0.887 0.289062 0.421875
iteration 196: loss 0.774 0.289062 0.382812
iteration 197: loss 0.797 0.429688 0.421875
iteration 198: loss 0.713 0.250000 0.484375
iteration 199: loss 0.705 0.328125 0.476562
iteration 200: loss 0.759 0.320312 0.484375
iteration 201: loss 0.767 0.304688 0.437500
iteration 202: loss 0.722 0.296875 0.398438
iteration 203: loss 0.792 0.281250 0.437500
iteration 204: loss 0.861 0.296875 0.367188
iteration 205: loss 0.700 0.304688 0.468750
iteration 206: loss 0.863 0.328125 0.468750
iteration 207: loss 0.642 0.320312 0.484375
iteration 208: loss 0.602 0.296875 0.445312
iteration 209: loss 0.717 0.328125 0.429688
iteration 210: loss 0.860 0.289062 0.429688
iteration 211: loss 0.740 0.335938 0.484375
iteration 212: loss 0.644 0.312500 0.484375
iteration 213: loss 0.926 0.257812 0.453125
iteration 214: loss 0.648 0.242188 0.546875
iteration 215: loss 0.682 0.273438 0.406250
iteration 216: loss 0.625 0.273438 0.468750
iteration 217: loss 0.836 0.296875 0.414062
iteration 218: loss 0.698 0.320312 0.437500
iteration 219: loss 0.752 0.312500 0.453125
iteration 220: loss 0.521 0.304688 0.507812
iteration 221: loss 0.727 0.273438 0.531250
iteration 222: loss 0.613 0.320312 0.460938
iteration 223: loss 0.932 0.273438 0.335938
iteration 224: loss 0.523 0.312500 0.531250
iteration 225: loss 0.735 0.265625 0.414062
iteration 226: loss 0.658 0.335938 0.500000
iteration 227: loss 0.611 0.328125 0.507812
iteration 228: loss 0.822 0.328125 0.468750
iteration 229: loss 0.752 0.367188 0.414062
iteration 230: loss 0.538 0.289062 0.429688
iteration 231: loss 0.614 0.328125 0.453125
iteration 232: loss 0.931 0.242188 0.429688
iteration 233: loss 0.501 0.335938 0.492188
iteration 234: loss 0.644 0.320312 0.460938
iteration 235: loss 0.607 0.312500 0.531250
iteration 236: loss 0.860 0.320312 0.429688
iteration 237: loss 0.700 0.265625 0.406250
iteration 238: loss 0.666 0.406250 0.539062
iteration 239: loss 0.735 0.296875 0.437500
iteration 240: loss 0.620 0.312500 0.492188
iteration 241: loss 0.853 0.273438 0.398438
iteration 242: loss 0.690 0.289062 0.484375
iteration 243: loss 0.600 0.351562 0.476562
iteration 244: loss 0.615 0.320312 0.500000
iteration 245: loss 0.559 0.320312 0.476562
iteration 246: loss 0.775 0.343750 0.460938
iteration 247: loss 0.640 0.351562 0.375000
iteration 248: loss 0.694 0.265625 0.445312
iteration 249: loss 0.854 0.328125 0.398438
iteration 250: loss 0.789 0.281250 0.460938
iteration 251: loss 0.674 0.320312 0.468750
iteration 252: loss 0.695 0.289062 0.468750
iteration 253: loss 0.693 0.265625 0.468750
iteration 254: loss 0.765 0.367188 0.492188
iteration 255: loss 0.883 0.312500 0.421875
iteration 256: loss 0.737 0.359375 0.445312
iteration 257: loss 0.729 0.250000 0.453125
iteration 258: loss 0.844 0.273438 0.367188
iteration 259: loss 0.840 0.289062 0.421875
iteration 260: loss 0.682 0.250000 0.429688
iteration 261: loss 0.626 0.406250 0.453125
iteration 262: loss 0.886 0.265625 0.390625
iteration 263: loss 0.600 0.304688 0.492188
iteration 264: loss 0.666 0.281250 0.437500
iteration 265: loss 0.825 0.289062 0.437500
iteration 266: loss 0.767 0.382812 0.390625
iteration 267: loss 0.557 0.281250 0.429688
iteration 268: loss 0.499 0.273438 0.445312
iteration 269: loss 0.683 0.359375 0.476562
iteration 270: loss 0.861 0.382812 0.453125
iteration 271: loss 0.840 0.328125 0.390625
iteration 272: loss 0.693 0.320312 0.460938
iteration 273: loss 0.619 0.359375 0.507812
iteration 274: loss 0.657 0.281250 0.500000
iteration 275: loss 0.597 0.265625 0.445312
iteration 276: loss 0.792 0.265625 0.468750
iteration 277: loss 0.650 0.320312 0.468750
iteration 278: loss 0.559 0.382812 0.507812
iteration 279: loss 0.723 0.273438 0.429688
iteration 280: loss 0.690 0.304688 0.437500
iteration 281: loss 0.526 0.304688 0.453125
iteration 282: loss 0.654 0.414062 0.421875
iteration 283: loss 0.560 0.257812 0.500000
iteration 284: loss 0.729 0.242188 0.398438
iteration 285: loss 0.548 0.304688 0.539062
iteration 286: loss 0.651 0.343750 0.476562
iteration 287: loss 0.715 0.367188 0.523438
iteration 288: loss 0.556 0.289062 0.484375
iteration 289: loss 0.719 0.296875 0.492188
iteration 290: loss 0.598 0.335938 0.531250
iteration 291: loss 0.744 0.281250 0.468750
iteration 292: loss 0.608 0.265625 0.453125
iteration 293: loss 0.686 0.320312 0.437500
iteration 294: loss 0.711 0.335938 0.492188
iteration 295: loss 0.704 0.304688 0.492188
iteration 296: loss 0.449 0.304688 0.523438
iteration 297: loss 0.790 0.304688 0.429688
iteration 298: loss 0.581 0.281250 0.445312
iteration 299: loss 0.638 0.281250 0.507812
iteration 300: loss 0.633 0.242188 0.515625
iteration 301: loss 0.731 0.351562 0.445312
iteration 302: loss 0.779 0.320312 0.437500
iteration 303: loss 0.535 0.257812 0.468750
iteration 304: loss 0.612 0.312500 0.492188
iteration 305: loss 0.883 0.273438 0.343750
iteration 306: loss 0.937 0.234375 0.445312
iteration 307: loss 0.721 0.343750 0.437500
iteration 308: loss 0.491 0.367188 0.531250
iteration 309: loss 0.540 0.390625 0.500000
iteration 310: loss 0.679 0.406250 0.476562
iteration 311: loss 0.732 0.351562 0.500000
iteration 312: loss 0.613 0.304688 0.492188
iteration 313: loss 0.611 0.359375 0.570312
iteration 314: loss 0.751 0.359375 0.500000
iteration 315: loss 0.726 0.281250 0.414062
iteration 316: loss 0.650 0.328125 0.437500
iteration 317: loss 0.744 0.234375 0.421875
iteration 318: loss 0.752 0.289062 0.453125
iteration 319: loss 0.803 0.289062 0.367188
iteration 320: loss 0.720 0.312500 0.421875
iteration 321: loss 0.597 0.328125 0.460938
iteration 322: loss 0.592 0.296875 0.453125
iteration 323: loss 0.660 0.265625 0.484375
iteration 324: loss 0.775 0.242188 0.406250
iteration 325: loss 0.691 0.375000 0.437500
iteration 326: loss 0.649 0.304688 0.476562
iteration 327: loss 0.689 0.328125 0.445312
iteration 328: loss 0.635 0.304688 0.554688
iteration 329: loss 0.578 0.312500 0.507812
iteration 330: loss 0.719 0.242188 0.445312
iteration 331: loss 0.614 0.265625 0.546875
iteration 332: loss 0.743 0.312500 0.523438
iteration 333: loss 0.675 0.320312 0.468750
iteration 334: loss 0.673 0.312500 0.476562
iteration 335: loss 0.703 0.328125 0.523438
iteration 336: loss 0.834 0.328125 0.453125
iteration 337: loss 0.747 0.328125 0.429688
iteration 338: loss 0.674 0.304688 0.507812
iteration 339: loss 0.655 0.312500 0.500000
iteration 340: loss 0.938 0.265625 0.343750
iteration 341: loss 0.703 0.429688 0.484375
iteration 342: loss 0.703 0.328125 0.421875
iteration 343: loss 0.791 0.382812 0.437500
iteration 344: loss 0.743 0.296875 0.414062
iteration 345: loss 0.725 0.289062 0.421875
iteration 346: loss 0.890 0.273438 0.312500
iteration 347: loss 0.631 0.273438 0.546875
iteration 348: loss 0.619 0.257812 0.546875
iteration 349: loss 0.575 0.257812 0.523438
iteration 350: loss 0.710 0.265625 0.398438
iteration 351: loss 0.714 0.335938 0.507812
iteration 352: loss 0.540 0.390625 0.515625
iteration 353: loss 0.604 0.320312 0.492188
iteration 354: loss 0.717 0.429688 0.445312
iteration 355: loss 0.664 0.328125 0.476562
iteration 356: loss 0.703 0.312500 0.460938
iteration 357: loss 0.489 0.250000 0.531250
iteration 358: loss 0.649 0.289062 0.468750
iteration 359: loss 0.654 0.343750 0.531250
iteration 360: loss 0.735 0.242188 0.437500
iteration 361: loss 0.875 0.328125 0.453125
iteration 362: loss 0.890 0.359375 0.398438
iteration 363: loss 0.891 0.328125 0.343750
iteration 364: loss 0.934 0.359375 0.382812
iteration 365: loss 0.738 0.328125 0.500000
iteration 366: loss 0.750 0.328125 0.476562
iteration 367: loss 0.662 0.296875 0.453125
iteration 368: loss 0.655 0.296875 0.460938
iteration 369: loss 0.857 0.296875 0.406250
iteration 370: loss 0.791 0.359375 0.367188
iteration 371: loss 0.712 0.304688 0.453125
iteration 372: loss 0.849 0.359375 0.468750
iteration 373: loss 1.014 0.367188 0.414062
iteration 374: loss 0.688 0.328125 0.476562
iteration 375: loss 0.756 0.218750 0.476562
iteration 376: loss 0.665 0.328125 0.531250
iteration 377: loss 0.843 0.320312 0.421875
iteration 378: loss 0.780 0.335938 0.421875
iteration 379: loss 0.674 0.281250 0.492188
iteration 380: loss 0.682 0.281250 0.421875
iteration 381: loss 0.626 0.320312 0.468750
iteration 382: loss 0.704 0.296875 0.460938
iteration 383: loss 0.591 0.296875 0.484375
iteration 384: loss 0.740 0.273438 0.468750
iteration 385: loss 0.759 0.320312 0.429688
iteration 386: loss 0.860 0.257812 0.414062
iteration 387: loss 0.728 0.296875 0.476562
iteration 388: loss 0.537 0.328125 0.500000
iteration 389: loss 0.671 0.289062 0.445312
iteration 390: loss 0.930 0.265625 0.437500
iteration 391: loss 0.839 0.265625 0.382812
iteration 392: loss 0.820 0.328125 0.406250
iteration 393: loss 0.714 0.367188 0.445312
iteration 394: loss 0.746 0.273438 0.445312
iteration 395: loss 0.749 0.273438 0.398438
iteration 396: loss 0.756 0.367188 0.445312
iteration 397: loss 0.616 0.343750 0.453125
iteration 398: loss 0.619 0.382812 0.453125
iteration 399: loss 0.828 0.320312 0.429688
iteration 400: loss 0.686 0.351562 0.445312
iteration 401: loss 0.689 0.304688 0.460938
iteration 402: loss 0.699 0.289062 0.492188
iteration 403: loss 0.738 0.335938 0.398438
iteration 404: loss 0.860 0.273438 0.367188
iteration 405: loss 0.835 0.281250 0.492188
iteration 406: loss 0.687 0.257812 0.445312
iteration 407: loss 0.768 0.289062 0.398438
iteration 408: loss 0.721 0.234375 0.406250
iteration 409: loss 0.732 0.296875 0.460938
iteration 410: loss 0.665 0.250000 0.445312
iteration 411: loss 0.672 0.210938 0.421875
iteration 412: loss 0.762 0.328125 0.492188
iteration 413: loss 0.732 0.351562 0.476562
iteration 414: loss 0.638 0.359375 0.476562
iteration 415: loss 0.553 0.367188 0.562500
iteration 416: loss 0.713 0.281250 0.421875
iteration 417: loss 0.748 0.320312 0.460938
iteration 418: loss 0.607 0.257812 0.484375
iteration 419: loss 0.889 0.335938 0.367188
iteration 420: loss 0.861 0.359375 0.421875
iteration 421: loss 0.543 0.328125 0.476562
iteration 422: loss 0.704 0.359375 0.414062
iteration 423: loss 0.748 0.351562 0.414062
iteration 424: loss 0.761 0.343750 0.476562
iteration 425: loss 0.560 0.328125 0.554688
iteration 426: loss 0.693 0.304688 0.484375
iteration 427: loss 0.882 0.359375 0.453125
iteration 428: loss 0.663 0.312500 0.476562
iteration 429: loss 0.834 0.250000 0.453125
iteration 430: loss 0.601 0.304688 0.351562
iteration 431: loss 0.707 0.328125 0.453125
iteration 432: loss 0.687 0.320312 0.492188
iteration 433: loss 0.682 0.414062 0.453125
iteration 434: loss 0.742 0.335938 0.390625
iteration 435: loss 0.643 0.320312 0.507812
iteration 436: loss 0.726 0.343750 0.476562
iteration 437: loss 0.892 0.265625 0.414062
iteration 438: loss 0.786 0.375000 0.359375
iteration 439: loss 0.770 0.273438 0.515625
iteration 440: loss 0.736 0.328125 0.468750
iteration 441: loss 0.761 0.257812 0.476562
iteration 442: loss 0.640 0.281250 0.476562
iteration 443: loss 0.643 0.296875 0.445312
iteration 444: loss 0.715 0.234375 0.468750
iteration 445: loss 0.768 0.304688 0.460938
iteration 446: loss 0.766 0.296875 0.414062
iteration 447: loss 0.788 0.296875 0.546875
iteration 448: loss 0.729 0.312500 0.453125
iteration 449: loss 0.728 0.359375 0.375000
iteration 450: loss 0.724 0.328125 0.484375
iteration 451: loss 0.806 0.312500 0.414062
iteration 452: loss 0.740 0.328125 0.453125
iteration 453: loss 0.603 0.359375 0.414062
iteration 454: loss 0.677 0.281250 0.437500
iteration 455: loss 0.763 0.328125 0.500000
iteration 456: loss 0.707 0.289062 0.492188
iteration 457: loss 0.883 0.304688 0.445312
iteration 458: loss 0.896 0.273438 0.421875
iteration 459: loss 0.755 0.296875 0.421875
iteration 460: loss 0.670 0.281250 0.421875
iteration 461: loss 0.641 0.320312 0.507812
iteration 462: loss 0.687 0.382812 0.500000
iteration 463: loss 0.759 0.289062 0.445312
iteration 464: loss 0.754 0.335938 0.476562
iteration 465: loss 0.840 0.304688 0.453125
iteration 466: loss 0.773 0.265625 0.468750
iteration 467: loss 0.665 0.304688 0.507812
iteration 468: loss 0.682 0.296875 0.460938
iteration 469: loss 0.813 0.250000 0.414062
iteration 470: loss 0.927 0.273438 0.335938
iteration 471: loss 0.586 0.367188 0.546875
iteration 472: loss 0.725 0.296875 0.492188
iteration 473: loss 0.689 0.375000 0.468750
iteration 474: loss 0.694 0.257812 0.476562
iteration 475: loss 0.740 0.304688 0.421875
iteration 476: loss 0.659 0.312500 0.445312
iteration 477: loss 0.740 0.320312 0.429688
iteration 478: loss 0.827 0.312500 0.335938
iteration 479: loss 0.669 0.304688 0.390625
iteration 480: loss 0.672 0.343750 0.445312
iteration 481: loss 0.750 0.304688 0.421875
iteration 482: loss 0.594 0.304688 0.500000
iteration 483: loss 0.680 0.320312 0.515625
iteration 484: loss 0.762 0.328125 0.476562
iteration 485: loss 0.728 0.304688 0.445312
iteration 486: loss 0.702 0.304688 0.484375
iteration 487: loss 0.678 0.296875 0.460938
iteration 488: loss 0.709 0.398438 0.429688
iteration 489: loss 0.568 0.273438 0.492188
iteration 490: loss 0.734 0.304688 0.460938
iteration 491: loss 0.771 0.312500 0.429688
iteration 492: loss 0.610 0.289062 0.468750
iteration 493: loss 0.701 0.320312 0.445312
iteration 494: loss 0.601 0.304688 0.507812
iteration 495: loss 0.655 0.226562 0.523438
iteration 496: loss 0.869 0.351562 0.390625
iteration 497: loss 0.751 0.296875 0.390625
iteration 498: loss 0.866 0.312500 0.500000
iteration 499: loss 0.780 0.320312 0.453125
iteration 500: loss 0.692 0.250000 0.421875
iteration 501: loss 0.769 0.265625 0.421875
iteration 502: loss 0.793 0.312500 0.414062
iteration 503: loss 0.689 0.273438 0.460938
iteration 504: loss 0.653 0.289062 0.492188
iteration 505: loss 0.765 0.320312 0.453125
iteration 506: loss 0.760 0.320312 0.390625
iteration 507: loss 0.663 0.250000 0.445312
iteration 508: loss 0.730 0.296875 0.406250
iteration 509: loss 0.543 0.320312 0.492188
iteration 510: loss 0.778 0.289062 0.437500
iteration 511: loss 0.876 0.335938 0.406250
iteration 512: loss 0.856 0.250000 0.460938
iteration 513: loss 0.774 0.351562 0.406250
iteration 514: loss 0.702 0.343750 0.429688
iteration 515: loss 0.641 0.296875 0.492188
iteration 516: loss 0.692 0.242188 0.460938
iteration 517: loss 0.690 0.320312 0.445312
iteration 518: loss 0.675 0.250000 0.460938
iteration 519: loss 0.691 0.296875 0.468750
iteration 520: loss 0.836 0.265625 0.406250
iteration 521: loss 0.805 0.296875 0.468750
iteration 522: loss 0.625 0.335938 0.468750
iteration 523: loss 0.679 0.320312 0.414062
iteration 524: loss 0.724 0.335938 0.421875
iteration 525: loss 0.716 0.351562 0.460938
iteration 526: loss 0.795 0.289062 0.390625
iteration 527: loss 0.771 0.304688 0.421875
iteration 528: loss 0.713 0.304688 0.507812
iteration 529: loss 0.707 0.343750 0.500000
iteration 530: loss 0.603 0.257812 0.468750
iteration 531: loss 0.748 0.328125 0.445312
iteration 532: loss 0.690 0.257812 0.375000
iteration 533: loss 0.724 0.281250 0.437500
iteration 534: loss 0.710 0.296875 0.429688
iteration 535: loss 0.877 0.359375 0.453125
iteration 536: loss 0.623 0.304688 0.554688
iteration 537: loss 0.681 0.343750 0.453125
iteration 538: loss 0.739 0.367188 0.468750
iteration 539: loss 0.702 0.335938 0.445312
iteration 540: loss 0.758 0.312500 0.468750
iteration 541: loss 0.802 0.281250 0.429688
iteration 542: loss 0.662 0.390625 0.515625
iteration 543: loss 0.583 0.320312 0.531250
iteration 544: loss 0.725 0.320312 0.421875
iteration 545: loss 0.952 0.304688 0.343750
iteration 546: loss 0.633 0.367188 0.421875
iteration 547: loss 0.580 0.335938 0.492188
iteration 548: loss 0.659 0.328125 0.453125
iteration 549: loss 0.651 0.320312 0.492188
iteration 550: loss 0.738 0.312500 0.500000
iteration 551: loss 0.761 0.343750 0.390625
iteration 552: loss 0.626 0.273438 0.429688
iteration 553: loss 0.627 0.265625 0.406250
iteration 554: loss 0.786 0.242188 0.367188
iteration 555: loss 0.693 0.359375 0.406250
iteration 556: loss 0.683 0.351562 0.476562
iteration 557: loss 0.664 0.312500 0.460938
iteration 558: loss 0.778 0.234375 0.476562
iteration 559: loss 0.706 0.335938 0.515625
iteration 560: loss 0.610 0.320312 0.500000
iteration 561: loss 0.667 0.398438 0.515625
iteration 562: loss 0.707 0.289062 0.531250
iteration 563: loss 0.717 0.281250 0.445312
iteration 564: loss 0.704 0.257812 0.500000
iteration 565: loss 0.729 0.296875 0.445312
iteration 566: loss 0.612 0.351562 0.507812
iteration 567: loss 0.793 0.359375 0.421875
iteration 568: loss 0.717 0.359375 0.476562
iteration 569: loss 0.956 0.296875 0.351562
iteration 570: loss 0.752 0.351562 0.429688
iteration 571: loss 0.808 0.304688 0.460938
iteration 572: loss 0.773 0.273438 0.453125
iteration 573: loss 0.697 0.398438 0.468750
iteration 574: loss 0.865 0.289062 0.406250
iteration 575: loss 0.696 0.289062 0.460938
iteration 576: loss 0.628 0.335938 0.492188
iteration 577: loss 0.825 0.273438 0.328125
iteration 578: loss 0.632 0.335938 0.453125
iteration 579: loss 0.599 0.320312 0.507812
iteration 580: loss 0.684 0.367188 0.476562
iteration 581: loss 0.746 0.281250 0.460938
iteration 582: loss 0.689 0.328125 0.460938
iteration 583: loss 0.811 0.367188 0.453125
iteration 584: loss 0.692 0.328125 0.453125
iteration 585: loss 0.715 0.289062 0.523438
iteration 586: loss 0.746 0.335938 0.429688
iteration 587: loss 0.805 0.312500 0.421875
iteration 588: loss 0.549 0.320312 0.523438
iteration 589: loss 0.532 0.367188 0.492188
iteration 590: loss 0.585 0.335938 0.460938
iteration 591: loss 0.757 0.375000 0.429688
iteration 592: loss 0.624 0.320312 0.507812
iteration 593: loss 0.685 0.320312 0.453125
iteration 594: loss 0.799 0.406250 0.492188
iteration 595: loss 0.643 0.273438 0.507812
iteration 596: loss 0.621 0.328125 0.453125
iteration 597: loss 0.632 0.257812 0.507812
iteration 598: loss 0.737 0.296875 0.390625
iteration 599: loss 0.787 0.304688 0.437500
iteration 600: loss 0.648 0.289062 0.546875
iteration 601: loss 0.796 0.304688 0.390625
iteration 602: loss 0.978 0.320312 0.476562
iteration 603: loss 0.711 0.250000 0.484375
iteration 604: loss 0.531 0.289062 0.546875
iteration 605: loss 0.730 0.281250 0.523438
iteration 606: loss 0.722 0.320312 0.445312
iteration 607: loss 0.677 0.304688 0.468750
iteration 608: loss 0.796 0.328125 0.437500
iteration 609: loss 0.708 0.273438 0.492188
iteration 610: loss 0.701 0.242188 0.445312
iteration 611: loss 0.765 0.281250 0.398438
iteration 612: loss 0.626 0.312500 0.445312
iteration 613: loss 0.692 0.320312 0.398438
iteration 614: loss 0.692 0.273438 0.468750
iteration 615: loss 0.721 0.296875 0.460938
iteration 616: loss 0.758 0.281250 0.445312
iteration 617: loss 0.749 0.320312 0.437500
iteration 618: loss 0.699 0.320312 0.476562
iteration 619: loss 0.718 0.398438 0.429688
iteration 620: loss 0.553 0.273438 0.515625
iteration 621: loss 0.873 0.289062 0.468750
iteration 622: loss 0.878 0.312500 0.375000
iteration 623: loss 0.518 0.406250 0.531250
iteration 624: loss 0.653 0.281250 0.578125
iteration 625: loss 0.693 0.367188 0.507812
iteration 626: loss 0.807 0.281250 0.429688
iteration 627: loss 0.761 0.289062 0.406250
iteration 628: loss 0.628 0.359375 0.445312
iteration 629: loss 0.786 0.265625 0.460938
iteration 630: loss 0.831 0.257812 0.437500
iteration 631: loss 0.709 0.296875 0.445312
iteration 632: loss 0.662 0.265625 0.468750
iteration 633: loss 0.729 0.328125 0.484375
iteration 634: loss 0.719 0.335938 0.414062
iteration 635: loss 0.524 0.304688 0.578125
iteration 636: loss 0.644 0.273438 0.507812
iteration 637: loss 0.649 0.250000 0.500000
iteration 638: loss 0.637 0.289062 0.468750
iteration 639: loss 0.570 0.226562 0.492188
iteration 640: loss 0.818 0.281250 0.421875
iteration 641: loss 0.685 0.367188 0.445312
iteration 642: loss 0.496 0.203125 0.500000
iteration 643: loss 0.706 0.367188 0.406250
iteration 644: loss 0.539 0.273438 0.460938
iteration 645: loss 0.827 0.312500 0.445312
iteration 646: loss 0.874 0.273438 0.382812
iteration 647: loss 0.742 0.289062 0.515625
iteration 648: loss 0.703 0.296875 0.468750
iteration 649: loss 0.580 0.304688 0.476562
iteration 650: loss 0.579 0.265625 0.437500
iteration 651: loss 0.687 0.234375 0.429688
iteration 652: loss 0.589 0.281250 0.437500
iteration 653: loss 0.596 0.335938 0.437500
iteration 654: loss 0.749 0.296875 0.367188
iteration 655: loss 0.776 0.281250 0.421875
iteration 656: loss 0.723 0.312500 0.335938
iteration 657: loss 0.722 0.320312 0.398438
iteration 658: loss 0.547 0.304688 0.546875
iteration 659: loss 0.767 0.289062 0.406250
iteration 660: loss 0.730 0.304688 0.484375
iteration 661: loss 0.858 0.289062 0.476562
iteration 662: loss 0.841 0.328125 0.507812
iteration 663: loss 0.917 0.289062 0.398438
iteration 664: loss 0.684 0.312500 0.406250
iteration 665: loss 0.756 0.343750 0.460938
iteration 666: loss 0.649 0.289062 0.453125
iteration 667: loss 0.709 0.265625 0.484375
iteration 668: loss 0.867 0.304688 0.375000
iteration 669: loss 0.805 0.242188 0.437500
iteration 670: loss 0.725 0.304688 0.445312
iteration 671: loss 0.568 0.281250 0.476562
iteration 672: loss 0.617 0.351562 0.484375
iteration 673: loss 0.553 0.328125 0.492188
iteration 674: loss 0.778 0.289062 0.453125
iteration 675: loss 0.765 0.304688 0.515625
iteration 676: loss 0.628 0.367188 0.546875
iteration 677: loss 0.637 0.289062 0.492188
iteration 678: loss 0.778 0.257812 0.382812
iteration 679: loss 0.812 0.367188 0.390625
iteration 680: loss 0.752 0.250000 0.445312
iteration 681: loss 0.701 0.250000 0.523438
iteration 682: loss 0.760 0.320312 0.453125
iteration 683: loss 0.835 0.312500 0.375000
iteration 684: loss 0.829 0.242188 0.429688
iteration 685: loss 0.897 0.289062 0.398438
iteration 686: loss 0.734 0.273438 0.429688
iteration 687: loss 0.724 0.304688 0.421875
iteration 688: loss 0.685 0.312500 0.453125
iteration 689: loss 0.560 0.351562 0.515625
iteration 690: loss 0.586 0.320312 0.531250
iteration 691: loss 0.752 0.359375 0.531250
iteration 692: loss 0.684 0.281250 0.515625
iteration 693: loss 0.630 0.304688 0.492188
iteration 694: loss 0.720 0.296875 0.476562
iteration 695: loss 0.759 0.289062 0.460938
iteration 696: loss 0.570 0.320312 0.476562
iteration 697: loss 0.788 0.312500 0.484375
iteration 698: loss 0.902 0.281250 0.468750
iteration 699: loss 0.741 0.265625 0.445312
iteration 700: loss 0.766 0.312500 0.375000
iteration 701: loss 0.655 0.343750 0.453125
iteration 702: loss 0.597 0.320312 0.421875
iteration 703: loss 0.752 0.375000 0.398438
iteration 704: loss 0.661 0.320312 0.554688
iteration 705: loss 0.798 0.296875 0.445312
iteration 706: loss 0.828 0.398438 0.468750
iteration 707: loss 0.632 0.265625 0.546875
iteration 708: loss 0.609 0.351562 0.437500
iteration 709: loss 0.725 0.296875 0.546875
iteration 710: loss 0.670 0.359375 0.460938
iteration 711: loss 0.590 0.304688 0.546875
iteration 712: loss 0.802 0.335938 0.421875
iteration 713: loss 0.744 0.375000 0.484375
iteration 714: loss 0.939 0.367188 0.382812
iteration 715: loss 0.791 0.328125 0.406250
iteration 716: loss 0.684 0.226562 0.484375
iteration 717: loss 0.787 0.304688 0.398438
iteration 718: loss 0.744 0.289062 0.382812
iteration 719: loss 0.903 0.273438 0.437500
iteration 720: loss 0.848 0.289062 0.460938
iteration 721: loss 0.755 0.250000 0.429688
iteration 722: loss 0.657 0.375000 0.492188
iteration 723: loss 0.766 0.328125 0.445312
iteration 724: loss 0.744 0.359375 0.468750
iteration 725: loss 0.701 0.296875 0.421875
iteration 726: loss 0.573 0.328125 0.460938
iteration 727: loss 0.654 0.281250 0.554688
iteration 728: loss 0.708 0.335938 0.437500
iteration 729: loss 0.744 0.257812 0.484375
iteration 730: loss 0.687 0.304688 0.523438
iteration 731: loss 0.894 0.351562 0.398438
iteration 732: loss 0.782 0.359375 0.500000
iteration 733: loss 0.703 0.289062 0.515625
iteration 734: loss 0.682 0.328125 0.476562
iteration 735: loss 0.640 0.242188 0.445312
iteration 736: loss 0.702 0.273438 0.476562
iteration 737: loss 0.647 0.304688 0.468750
iteration 738: loss 0.905 0.320312 0.367188
iteration 739: loss 0.577 0.289062 0.554688
iteration 740: loss 0.530 0.296875 0.531250
iteration 741: loss 0.698 0.304688 0.453125
iteration 742: loss 0.596 0.351562 0.429688
iteration 743: loss 0.810 0.296875 0.421875
iteration 744: loss 0.592 0.351562 0.476562
iteration 745: loss 0.637 0.359375 0.531250
iteration 746: loss 0.599 0.343750 0.453125
iteration 747: loss 0.645 0.359375 0.500000
iteration 748: loss 0.678 0.226562 0.460938
iteration 749: loss 0.775 0.320312 0.375000
iteration 750: loss 0.687 0.250000 0.414062
iteration 751: loss 0.592 0.296875 0.460938
iteration 752: loss 0.803 0.335938 0.406250
iteration 753: loss 0.784 0.242188 0.460938
iteration 754: loss 0.664 0.382812 0.476562
iteration 755: loss 0.596 0.335938 0.460938
iteration 756: loss 0.716 0.281250 0.492188
iteration 757: loss 0.662 0.265625 0.492188
iteration 758: loss 0.742 0.328125 0.468750
iteration 759: loss 0.540 0.242188 0.507812
iteration 760: loss 0.866 0.289062 0.429688
iteration 761: loss 0.729 0.335938 0.515625
iteration 762: loss 0.762 0.273438 0.445312
iteration 763: loss 0.906 0.304688 0.398438
iteration 764: loss 0.770 0.242188 0.375000
iteration 765: loss 0.542 0.320312 0.531250
iteration 766: loss 0.616 0.304688 0.484375
iteration 767: loss 0.609 0.320312 0.515625
iteration 768: loss 0.737 0.257812 0.445312
iteration 769: loss 0.646 0.265625 0.484375
iteration 770: loss 0.740 0.375000 0.414062
iteration 771: loss 0.754 0.273438 0.468750
iteration 772: loss 0.604 0.351562 0.460938
iteration 773: loss 0.636 0.273438 0.515625
iteration 774: loss 0.673 0.328125 0.437500
iteration 775: loss 0.752 0.289062 0.382812
iteration 776: loss 0.677 0.367188 0.476562
iteration 777: loss 0.628 0.289062 0.562500
iteration 778: loss 0.634 0.226562 0.531250
iteration 779: loss 0.799 0.304688 0.414062
iteration 780: loss 0.682 0.304688 0.492188
iteration 781: loss 0.530 0.304688 0.531250
iteration 782: loss 0.704 0.335938 0.453125
iteration 783: loss 0.740 0.210938 0.421875
iteration 784: loss 0.646 0.367188 0.476562
iteration 785: loss 0.675 0.281250 0.468750
iteration 786: loss 0.596 0.257812 0.515625
iteration 787: loss 0.710 0.304688 0.437500
iteration 788: loss 0.716 0.296875 0.507812
iteration 789: loss 0.712 0.289062 0.390625
iteration 790: loss 0.520 0.351562 0.476562
iteration 791: loss 0.732 0.289062 0.476562
iteration 792: loss 0.707 0.320312 0.429688
iteration 793: loss 0.773 0.343750 0.406250
iteration 794: loss 0.744 0.359375 0.414062
iteration 795: loss 0.810 0.390625 0.460938
iteration 796: loss 0.655 0.296875 0.460938
iteration 797: loss 0.635 0.351562 0.468750
iteration 798: loss 0.695 0.226562 0.460938
iteration 799: loss 0.804 0.335938 0.453125
iteration 800: loss 0.762 0.382812 0.414062
iteration 801: loss 0.928 0.289062 0.421875
iteration 802: loss 0.734 0.312500 0.484375
iteration 803: loss 0.686 0.312500 0.460938
iteration 804: loss 0.697 0.335938 0.453125
iteration 805: loss 0.749 0.304688 0.476562
iteration 806: loss 0.731 0.328125 0.539062
iteration 807: loss 0.811 0.335938 0.429688
iteration 808: loss 0.670 0.375000 0.453125
iteration 809: loss 0.718 0.296875 0.406250
iteration 810: loss 0.664 0.328125 0.492188
iteration 811: loss 0.876 0.250000 0.382812
iteration 812: loss 0.632 0.351562 0.476562
iteration 813: loss 0.499 0.320312 0.484375
iteration 814: loss 0.588 0.335938 0.515625
iteration 815: loss 0.620 0.289062 0.476562
iteration 816: loss 0.716 0.343750 0.429688
iteration 817: loss 0.708 0.335938 0.507812
iteration 818: loss 0.948 0.289062 0.335938
iteration 819: loss 0.688 0.320312 0.453125
iteration 820: loss 0.638 0.289062 0.460938
iteration 821: loss 0.537 0.312500 0.484375
iteration 822: loss 0.617 0.328125 0.484375
iteration 823: loss 0.721 0.296875 0.414062
iteration 824: loss 0.756 0.296875 0.414062
iteration 825: loss 0.571 0.304688 0.492188
iteration 826: loss 0.727 0.312500 0.421875
iteration 827: loss 0.715 0.359375 0.460938
iteration 828: loss 0.804 0.312500 0.406250
iteration 829: loss 0.838 0.367188 0.398438
iteration 830: loss 0.639 0.312500 0.476562
iteration 831: loss 0.814 0.250000 0.421875
iteration 832: loss 0.675 0.265625 0.507812
iteration 833: loss 0.696 0.375000 0.453125
iteration 834: loss 0.591 0.351562 0.507812
iteration 835: loss 0.739 0.296875 0.476562
iteration 836: loss 0.638 0.343750 0.421875
iteration 837: loss 0.609 0.320312 0.500000
iteration 838: loss 0.626 0.273438 0.468750
iteration 839: loss 0.676 0.289062 0.507812
iteration 840: loss 0.760 0.312500 0.453125
iteration 841: loss 0.659 0.320312 0.500000
iteration 842: loss 0.758 0.281250 0.390625
iteration 843: loss 0.682 0.343750 0.414062
iteration 844: loss 0.788 0.273438 0.367188
iteration 845: loss 0.553 0.296875 0.468750
iteration 846: loss 0.559 0.289062 0.562500
iteration 847: loss 0.705 0.234375 0.507812
iteration 848: loss 0.777 0.265625 0.406250
iteration 849: loss 0.685 0.304688 0.492188
iteration 850: loss 0.875 0.281250 0.429688
iteration 851: loss 0.749 0.281250 0.421875
iteration 852: loss 0.715 0.343750 0.414062
iteration 853: loss 0.642 0.289062 0.429688
iteration 854: loss 0.591 0.265625 0.453125
iteration 855: loss 0.763 0.265625 0.445312
iteration 856: loss 0.781 0.312500 0.484375
iteration 857: loss 0.664 0.351562 0.468750
iteration 858: loss 0.802 0.335938 0.453125
iteration 859: loss 0.794 0.265625 0.515625
iteration 860: loss 0.809 0.351562 0.468750
iteration 861: loss 0.572 0.328125 0.515625
iteration 862: loss 0.582 0.328125 0.492188
iteration 863: loss 0.488 0.273438 0.523438
iteration 864: loss 0.614 0.304688 0.476562
iteration 865: loss 0.563 0.351562 0.500000
iteration 866: loss 0.576 0.359375 0.492188
iteration 867: loss 0.649 0.351562 0.546875
iteration 868: loss 0.644 0.289062 0.460938
iteration 869: loss 0.521 0.335938 0.492188
iteration 870: loss 0.774 0.375000 0.414062
iteration 871: loss 0.629 0.281250 0.468750
iteration 872: loss 0.741 0.328125 0.507812
iteration 873: loss 0.532 0.296875 0.554688
iteration 874: loss 0.801 0.312500 0.453125
iteration 875: loss 0.754 0.312500 0.320312
iteration 876: loss 0.726 0.296875 0.445312
iteration 877: loss 0.672 0.382812 0.500000
iteration 878: loss 0.556 0.335938 0.531250
iteration 879: loss 0.546 0.335938 0.476562
iteration 880: loss 0.750 0.351562 0.421875
iteration 881: loss 0.806 0.320312 0.492188
iteration 882: loss 0.719 0.257812 0.523438
iteration 883: loss 0.679 0.375000 0.484375
iteration 884: loss 0.696 0.312500 0.453125
iteration 885: loss 0.889 0.281250 0.382812
iteration 886: loss 0.801 0.218750 0.367188
iteration 887: loss 0.661 0.359375 0.421875
iteration 888: loss 0.665 0.289062 0.531250
iteration 889: loss 0.731 0.296875 0.460938
iteration 890: loss 0.565 0.296875 0.515625
iteration 891: loss 0.589 0.265625 0.593750
iteration 892: loss 0.659 0.382812 0.476562
iteration 893: loss 0.695 0.335938 0.484375
iteration 894: loss 0.781 0.351562 0.414062
iteration 895: loss 0.638 0.250000 0.460938
iteration 896: loss 0.725 0.281250 0.500000
iteration 897: loss 0.764 0.257812 0.460938
iteration 898: loss 0.652 0.359375 0.476562
iteration 899: loss 0.766 0.312500 0.414062
iteration 900: loss 0.813 0.304688 0.429688
iteration 901: loss 0.990 0.359375 0.421875
iteration 902: loss 0.898 0.335938 0.476562
iteration 903: loss 0.781 0.296875 0.507812
iteration 904: loss 0.825 0.265625 0.445312
iteration 905: loss 0.696 0.335938 0.437500
iteration 906: loss 0.534 0.250000 0.523438
iteration 907: loss 0.707 0.320312 0.390625
iteration 908: loss 0.682 0.296875 0.437500
iteration 909: loss 0.733 0.265625 0.390625
iteration 910: loss 0.813 0.296875 0.343750
iteration 911: loss 0.721 0.265625 0.421875
iteration 912: loss 0.794 0.281250 0.421875
iteration 913: loss 0.761 0.406250 0.460938
iteration 914: loss 0.763 0.351562 0.453125
iteration 915: loss 0.586 0.367188 0.531250
iteration 916: loss 0.699 0.273438 0.421875
iteration 917: loss 0.445 0.257812 0.531250
iteration 918: loss 0.733 0.289062 0.429688
iteration 919: loss 0.630 0.296875 0.484375
iteration 920: loss 0.789 0.296875 0.460938
iteration 921: loss 0.774 0.281250 0.398438
iteration 922: loss 0.657 0.343750 0.492188
iteration 923: loss 0.704 0.281250 0.500000
iteration 924: loss 0.733 0.273438 0.476562
iteration 925: loss 0.505 0.359375 0.531250
iteration 926: loss 0.797 0.257812 0.453125
iteration 927: loss 0.762 0.320312 0.414062
iteration 928: loss 0.681 0.312500 0.476562
iteration 929: loss 0.830 0.375000 0.460938
iteration 930: loss 0.675 0.335938 0.460938
iteration 931: loss 0.728 0.320312 0.492188
iteration 932: loss 0.808 0.351562 0.468750
iteration 933: loss 0.701 0.312500 0.414062
iteration 934: loss 0.872 0.273438 0.429688
iteration 935: loss 0.735 0.335938 0.390625
iteration 936: loss 0.889 0.296875 0.359375
iteration 937: loss 0.640 0.351562 0.460938
iteration 938: loss 0.604 0.359375 0.492188
iteration 939: loss 0.565 0.351562 0.515625
iteration 940: loss 0.649 0.328125 0.523438
iteration 941: loss 0.720 0.359375 0.398438
iteration 942: loss 0.577 0.304688 0.492188
iteration 943: loss 0.676 0.281250 0.507812
iteration 944: loss 0.620 0.359375 0.468750
iteration 945: loss 0.658 0.335938 0.468750
iteration 946: loss 0.712 0.312500 0.414062
iteration 947: loss 0.682 0.320312 0.445312
iteration 948: loss 0.648 0.218750 0.398438
iteration 949: loss 0.704 0.343750 0.421875
iteration 950: loss 0.675 0.320312 0.453125
iteration 951: loss 0.856 0.351562 0.437500
iteration 952: loss 0.729 0.320312 0.406250
iteration 953: loss 0.760 0.281250 0.468750
iteration 954: loss 0.761 0.304688 0.468750
iteration 955: loss 0.736 0.296875 0.476562
iteration 956: loss 0.701 0.328125 0.429688
iteration 957: loss 0.770 0.328125 0.421875
iteration 958: loss 0.877 0.281250 0.367188
iteration 959: loss 0.716 0.304688 0.437500
iteration 960: loss 0.479 0.312500 0.531250
iteration 961: loss 0.660 0.335938 0.468750
iteration 962: loss 0.813 0.335938 0.382812
iteration 963: loss 0.635 0.367188 0.468750
iteration 964: loss 0.878 0.250000 0.406250
iteration 965: loss 0.758 0.390625 0.382812
iteration 966: loss 0.619 0.343750 0.515625
iteration 967: loss 0.683 0.351562 0.429688
iteration 968: loss 0.737 0.343750 0.429688
iteration 969: loss 0.739 0.367188 0.453125
iteration 970: loss 0.544 0.320312 0.476562
iteration 971: loss 0.726 0.273438 0.398438
iteration 972: loss 0.579 0.210938 0.531250
iteration 973: loss 0.726 0.289062 0.460938
iteration 974: loss 0.615 0.296875 0.445312
iteration 975: loss 0.671 0.320312 0.484375
iteration 976: loss 0.781 0.273438 0.484375
iteration 977: loss 0.784 0.312500 0.398438
iteration 978: loss 0.693 0.281250 0.445312
iteration 979: loss 0.670 0.250000 0.476562
iteration 980: loss 0.702 0.343750 0.507812
iteration 981: loss 0.773 0.312500 0.429688
iteration 982: loss 0.675 0.250000 0.414062
iteration 983: loss 0.651 0.312500 0.429688
iteration 984: loss 0.675 0.351562 0.429688
iteration 985: loss 0.780 0.304688 0.390625
iteration 986: loss 0.700 0.320312 0.398438
iteration 987: loss 0.588 0.304688 0.507812
iteration 988: loss 0.729 0.296875 0.429688
iteration 989: loss 0.767 0.343750 0.414062
iteration 990: loss 0.704 0.296875 0.492188
iteration 991: loss 0.737 0.304688 0.484375
iteration 992: loss 0.758 0.359375 0.492188
iteration 993: loss 0.724 0.328125 0.437500
iteration 994: loss 0.744 0.351562 0.429688
iteration 995: loss 0.689 0.242188 0.414062
iteration 996: loss 0.815 0.265625 0.406250
iteration 997: loss 0.728 0.328125 0.445312
iteration 998: loss 0.780 0.304688 0.421875
iteration 999: loss 0.590 0.343750 0.468750
epoch 8: training: 0.281250 validation: 0.289062
iteration 0: loss 0.596 0.398438 0.468750
iteration 1: loss 0.869 0.328125 0.351562
iteration 2: loss 0.749 0.304688 0.460938
iteration 3: loss 0.736 0.335938 0.453125
iteration 4: loss 0.588 0.296875 0.500000
iteration 5: loss 0.667 0.312500 0.515625
iteration 6: loss 0.771 0.265625 0.437500
iteration 7: loss 0.822 0.320312 0.382812
iteration 8: loss 0.568 0.281250 0.414062
iteration 9: loss 0.710 0.351562 0.484375
iteration 10: loss 0.734 0.335938 0.390625
iteration 11: loss 0.519 0.273438 0.539062
iteration 12: loss 0.688 0.234375 0.390625
iteration 13: loss 0.641 0.351562 0.476562
iteration 14: loss 0.518 0.296875 0.492188
iteration 15: loss 0.676 0.359375 0.507812
iteration 16: loss 0.626 0.312500 0.515625
iteration 17: loss 0.754 0.304688 0.515625
iteration 18: loss 0.622 0.257812 0.515625
iteration 19: loss 0.686 0.257812 0.492188
iteration 20: loss 0.577 0.265625 0.539062
iteration 21: loss 0.664 0.296875 0.500000
iteration 22: loss 0.777 0.328125 0.382812
iteration 23: loss 0.656 0.257812 0.476562
iteration 24: loss 0.595 0.242188 0.453125
iteration 25: loss 0.610 0.257812 0.460938
iteration 26: loss 0.668 0.390625 0.406250
iteration 27: loss 0.648 0.382812 0.515625
iteration 28: loss 0.597 0.296875 0.468750
iteration 29: loss 0.823 0.351562 0.453125
iteration 30: loss 0.684 0.265625 0.414062
iteration 31: loss 0.603 0.281250 0.507812
iteration 32: loss 0.827 0.351562 0.406250
iteration 33: loss 0.787 0.304688 0.367188
iteration 34: loss 0.599 0.304688 0.460938
iteration 35: loss 0.722 0.257812 0.406250
iteration 36: loss 0.727 0.312500 0.476562
iteration 37: loss 0.848 0.320312 0.398438
iteration 38: loss 0.709 0.312500 0.421875
iteration 39: loss 0.665 0.281250 0.406250
iteration 40: loss 0.753 0.289062 0.460938
iteration 41: loss 0.630 0.265625 0.484375
iteration 42: loss 0.709 0.328125 0.492188
iteration 43: loss 0.875 0.304688 0.437500
iteration 44: loss 0.623 0.320312 0.500000
iteration 45: loss 0.756 0.328125 0.421875
iteration 46: loss 0.621 0.296875 0.468750
iteration 47: loss 0.728 0.304688 0.476562
iteration 48: loss 0.680 0.320312 0.437500
iteration 49: loss 0.693 0.367188 0.460938
iteration 50: loss 0.723 0.343750 0.476562
iteration 51: loss 0.657 0.242188 0.484375
iteration 52: loss 0.644 0.328125 0.460938
iteration 53: loss 0.668 0.296875 0.421875
iteration 54: loss 0.704 0.265625 0.429688
iteration 55: loss 0.574 0.343750 0.476562
iteration 56: loss 0.692 0.390625 0.531250
iteration 57: loss 0.638 0.375000 0.468750
iteration 58: loss 0.736 0.351562 0.414062
iteration 59: loss 0.588 0.375000 0.507812
iteration 60: loss 0.527 0.281250 0.585938
iteration 61: loss 0.717 0.289062 0.476562
iteration 62: loss 0.775 0.312500 0.484375
iteration 63: loss 0.743 0.343750 0.476562
iteration 64: loss 0.609 0.289062 0.476562
iteration 65: loss 0.608 0.289062 0.500000
iteration 66: loss 0.690 0.304688 0.429688
iteration 67: loss 0.668 0.320312 0.421875
iteration 68: loss 0.622 0.265625 0.476562
iteration 69: loss 0.763 0.304688 0.460938
iteration 70: loss 0.655 0.273438 0.421875
iteration 71: loss 0.671 0.257812 0.468750
iteration 72: loss 0.729 0.273438 0.437500
iteration 73: loss 0.636 0.328125 0.492188
iteration 74: loss 0.603 0.257812 0.539062
iteration 75: loss 0.771 0.242188 0.468750
iteration 76: loss 0.690 0.304688 0.414062
iteration 77: loss 0.763 0.328125 0.445312
iteration 78: loss 0.649 0.312500 0.460938
iteration 79: loss 0.662 0.273438 0.492188
iteration 80: loss 0.771 0.273438 0.492188
iteration 81: loss 0.717 0.304688 0.507812
iteration 82: loss 0.710 0.335938 0.500000
iteration 83: loss 0.677 0.335938 0.492188
iteration 84: loss 0.770 0.328125 0.382812
iteration 85: loss 0.630 0.296875 0.484375
iteration 86: loss 0.575 0.289062 0.507812
iteration 87: loss 0.694 0.250000 0.453125
iteration 88: loss 0.621 0.367188 0.515625
iteration 89: loss 0.553 0.273438 0.570312
iteration 90: loss 0.736 0.351562 0.445312
iteration 91: loss 0.683 0.335938 0.453125
iteration 92: loss 0.711 0.390625 0.492188
iteration 93: loss 0.780 0.343750 0.421875
iteration 94: loss 0.700 0.289062 0.468750
iteration 95: loss 0.608 0.281250 0.492188
iteration 96: loss 0.690 0.304688 0.468750
iteration 97: loss 0.713 0.328125 0.460938
iteration 98: loss 0.627 0.359375 0.406250
iteration 99: loss 0.708 0.265625 0.414062
iteration 100: loss 0.645 0.312500 0.414062
iteration 101: loss 0.721 0.296875 0.437500
iteration 102: loss 0.642 0.359375 0.476562
iteration 103: loss 0.822 0.359375 0.367188
iteration 104: loss 0.692 0.304688 0.437500
iteration 105: loss 0.509 0.250000 0.546875
iteration 106: loss 0.702 0.351562 0.460938
iteration 107: loss 0.761 0.281250 0.414062
iteration 108: loss 0.642 0.343750 0.468750
iteration 109: loss 0.547 0.335938 0.585938
iteration 110: loss 0.590 0.328125 0.429688
iteration 111: loss 0.697 0.390625 0.460938
iteration 112: loss 0.739 0.367188 0.367188
iteration 113: loss 0.660 0.312500 0.445312
iteration 114: loss 0.579 0.304688 0.484375
iteration 115: loss 0.508 0.367188 0.531250
iteration 116: loss 0.560 0.242188 0.515625
iteration 117: loss 0.681 0.226562 0.390625
iteration 118: loss 0.604 0.281250 0.468750
iteration 119: loss 0.589 0.273438 0.484375
iteration 120: loss 0.604 0.304688 0.476562
iteration 121: loss 0.783 0.289062 0.398438
iteration 122: loss 0.702 0.281250 0.390625
iteration 123: loss 0.671 0.351562 0.429688
iteration 124: loss 0.621 0.304688 0.492188
iteration 125: loss 0.623 0.375000 0.460938
iteration 126: loss 0.737 0.210938 0.445312
iteration 127: loss 0.601 0.289062 0.460938
iteration 128: loss 0.713 0.312500 0.414062
iteration 129: loss 0.582 0.406250 0.539062
iteration 130: loss 0.794 0.320312 0.562500
iteration 131: loss 0.786 0.367188 0.453125
iteration 132: loss 0.712 0.250000 0.507812
iteration 133: loss 0.724 0.273438 0.453125
iteration 134: loss 0.724 0.312500 0.414062
iteration 135: loss 0.698 0.289062 0.437500
iteration 136: loss 0.790 0.304688 0.437500
iteration 137: loss 0.542 0.343750 0.523438
iteration 138: loss 0.820 0.312500 0.492188
iteration 139: loss 0.605 0.289062 0.539062
iteration 140: loss 0.650 0.195312 0.484375
iteration 141: loss 0.719 0.312500 0.453125
iteration 142: loss 0.640 0.281250 0.429688
iteration 143: loss 0.764 0.273438 0.390625
iteration 144: loss 0.537 0.257812 0.523438
iteration 145: loss 0.739 0.390625 0.468750
iteration 146: loss 0.567 0.289062 0.484375
iteration 147: loss 0.723 0.312500 0.445312
iteration 148: loss 0.790 0.296875 0.382812
iteration 149: loss 0.744 0.312500 0.476562
iteration 150: loss 0.711 0.226562 0.437500
iteration 151: loss 0.663 0.273438 0.406250
iteration 152: loss 0.594 0.281250 0.484375
iteration 153: loss 0.740 0.250000 0.500000
iteration 154: loss 0.598 0.320312 0.515625
iteration 155: loss 0.844 0.328125 0.351562
iteration 156: loss 0.698 0.226562 0.453125
iteration 157: loss 0.626 0.304688 0.515625
iteration 158: loss 0.626 0.289062 0.468750
iteration 159: loss 0.605 0.281250 0.515625
iteration 160: loss 0.524 0.343750 0.476562
iteration 161: loss 0.694 0.351562 0.484375
iteration 162: loss 0.803 0.312500 0.460938
iteration 163: loss 0.701 0.359375 0.398438
iteration 164: loss 0.565 0.390625 0.476562
iteration 165: loss 0.663 0.273438 0.468750
iteration 166: loss 0.777 0.257812 0.445312
iteration 167: loss 0.742 0.328125 0.437500
iteration 168: loss 0.666 0.343750 0.468750
iteration 169: loss 0.765 0.343750 0.476562
iteration 170: loss 0.697 0.312500 0.500000
iteration 171: loss 0.791 0.273438 0.421875
iteration 172: loss 0.777 0.304688 0.398438
iteration 173: loss 0.766 0.289062 0.429688
iteration 174: loss 0.705 0.218750 0.453125
iteration 175: loss 0.640 0.296875 0.476562
iteration 176: loss 0.737 0.382812 0.445312
iteration 177: loss 0.516 0.328125 0.531250
iteration 178: loss 0.692 0.304688 0.460938
iteration 179: loss 0.559 0.335938 0.515625
iteration 180: loss 0.791 0.328125 0.437500
iteration 181: loss 0.809 0.273438 0.531250
iteration 182: loss 0.716 0.273438 0.507812
iteration 183: loss 0.761 0.242188 0.531250
iteration 184: loss 0.686 0.328125 0.445312
iteration 185: loss 0.540 0.312500 0.523438
iteration 186: loss 0.839 0.250000 0.421875
iteration 187: loss 0.660 0.296875 0.406250
iteration 188: loss 0.674 0.351562 0.437500
iteration 189: loss 0.729 0.234375 0.390625
iteration 190: loss 0.590 0.289062 0.460938
iteration 191: loss 0.739 0.351562 0.460938
iteration 192: loss 0.881 0.289062 0.429688
iteration 193: loss 0.740 0.273438 0.476562
iteration 194: loss 0.648 0.289062 0.476562
iteration 195: loss 0.669 0.234375 0.445312
iteration 196: loss 0.720 0.343750 0.460938
iteration 197: loss 0.620 0.296875 0.445312
iteration 198: loss 0.734 0.359375 0.437500
iteration 199: loss 0.687 0.296875 0.429688
iteration 200: loss 0.755 0.382812 0.437500
iteration 201: loss 0.640 0.234375 0.406250
iteration 202: loss 0.587 0.328125 0.492188
iteration 203: loss 0.564 0.320312 0.437500
iteration 204: loss 0.697 0.257812 0.500000
iteration 205: loss 0.613 0.335938 0.523438
iteration 206: loss 0.485 0.296875 0.546875
iteration 207: loss 0.834 0.148438 0.445312
iteration 208: loss 0.720 0.281250 0.437500
iteration 209: loss 0.591 0.281250 0.453125
iteration 210: loss 0.691 0.265625 0.398438
iteration 211: loss 0.772 0.281250 0.398438
iteration 212: loss 0.615 0.320312 0.414062
iteration 213: loss 0.820 0.296875 0.437500
iteration 214: loss 0.702 0.226562 0.445312
iteration 215: loss 0.743 0.242188 0.359375
iteration 216: loss 0.558 0.234375 0.421875
iteration 217: loss 0.728 0.289062 0.476562
iteration 218: loss 0.664 0.312500 0.492188
iteration 219: loss 0.741 0.289062 0.476562
iteration 220: loss 0.530 0.320312 0.554688
iteration 221: loss 0.767 0.406250 0.406250
iteration 222: loss 0.771 0.335938 0.437500
iteration 223: loss 0.601 0.257812 0.500000
iteration 224: loss 0.783 0.320312 0.437500
iteration 225: loss 0.680 0.250000 0.484375
iteration 226: loss 0.885 0.304688 0.359375
iteration 227: loss 0.553 0.343750 0.453125
iteration 228: loss 0.697 0.281250 0.484375
iteration 229: loss 0.627 0.304688 0.406250
iteration 230: loss 0.702 0.335938 0.476562
iteration 231: loss 0.584 0.335938 0.484375
iteration 232: loss 0.734 0.320312 0.468750
iteration 233: loss 0.810 0.289062 0.453125
iteration 234: loss 0.689 0.335938 0.460938
iteration 235: loss 0.728 0.328125 0.500000
iteration 236: loss 0.732 0.296875 0.390625
iteration 237: loss 0.692 0.304688 0.468750
iteration 238: loss 0.644 0.335938 0.484375
iteration 239: loss 0.697 0.257812 0.445312
iteration 240: loss 0.751 0.296875 0.359375
iteration 241: loss 0.645 0.328125 0.414062
iteration 242: loss 0.641 0.281250 0.476562
iteration 243: loss 0.643 0.375000 0.445312
iteration 244: loss 0.795 0.250000 0.390625
iteration 245: loss 0.610 0.343750 0.453125
iteration 246: loss 0.533 0.328125 0.476562
iteration 247: loss 0.671 0.250000 0.476562
iteration 248: loss 0.620 0.335938 0.421875
iteration 249: loss 0.750 0.320312 0.398438
iteration 250: loss 0.641 0.250000 0.382812
iteration 251: loss 0.565 0.304688 0.445312
iteration 252: loss 0.692 0.242188 0.414062
iteration 253: loss 0.799 0.242188 0.445312
iteration 254: loss 0.617 0.328125 0.468750
iteration 255: loss 0.626 0.289062 0.523438
iteration 256: loss 0.537 0.312500 0.523438
iteration 257: loss 0.628 0.359375 0.523438
iteration 258: loss 0.671 0.312500 0.468750
iteration 259: loss 0.640 0.367188 0.445312
iteration 260: loss 0.517 0.335938 0.546875
iteration 261: loss 0.670 0.328125 0.460938
iteration 262: loss 0.605 0.375000 0.460938
iteration 263: loss 0.665 0.367188 0.414062
iteration 264: loss 0.656 0.335938 0.492188
iteration 265: loss 0.475 0.242188 0.507812
iteration 266: loss 0.726 0.296875 0.460938
iteration 267: loss 0.612 0.250000 0.421875
iteration 268: loss 0.671 0.320312 0.437500
iteration 269: loss 0.623 0.406250 0.539062
iteration 270: loss 0.637 0.398438 0.507812
iteration 271: loss 0.793 0.289062 0.421875
iteration 272: loss 0.612 0.359375 0.492188
iteration 273: loss 0.706 0.273438 0.437500
iteration 274: loss 0.679 0.289062 0.453125
iteration 275: loss 0.682 0.296875 0.445312
iteration 276: loss 0.714 0.320312 0.476562
iteration 277: loss 0.727 0.281250 0.468750
iteration 278: loss 0.678 0.281250 0.484375
iteration 279: loss 0.714 0.296875 0.468750
iteration 280: loss 0.748 0.281250 0.375000
iteration 281: loss 0.608 0.390625 0.546875
iteration 282: loss 0.671 0.265625 0.453125
iteration 283: loss 0.549 0.289062 0.476562
iteration 284: loss 0.567 0.289062 0.515625
iteration 285: loss 0.560 0.281250 0.507812
iteration 286: loss 0.644 0.289062 0.507812
iteration 287: loss 0.716 0.304688 0.453125
iteration 288: loss 0.670 0.304688 0.500000
iteration 289: loss 0.832 0.335938 0.453125
iteration 290: loss 0.698 0.281250 0.500000
iteration 291: loss 0.574 0.296875 0.460938
iteration 292: loss 0.532 0.304688 0.507812
iteration 293: loss 0.651 0.320312 0.445312
iteration 294: loss 0.692 0.304688 0.492188
iteration 295: loss 0.885 0.265625 0.375000
iteration 296: loss 0.784 0.343750 0.414062
iteration 297: loss 0.564 0.296875 0.460938
iteration 298: loss 0.702 0.335938 0.414062
iteration 299: loss 0.648 0.343750 0.531250
iteration 300: loss 0.681 0.304688 0.421875
iteration 301: loss 0.551 0.335938 0.500000
iteration 302: loss 0.590 0.257812 0.476562
iteration 303: loss 0.570 0.304688 0.484375
iteration 304: loss 0.620 0.296875 0.500000
iteration 305: loss 0.777 0.250000 0.414062
iteration 306: loss 0.587 0.304688 0.507812
iteration 307: loss 0.696 0.289062 0.437500
iteration 308: loss 0.690 0.289062 0.414062
iteration 309: loss 0.738 0.335938 0.429688
iteration 310: loss 0.691 0.359375 0.492188
iteration 311: loss 0.689 0.312500 0.492188
iteration 312: loss 0.750 0.343750 0.437500
iteration 313: loss 0.664 0.320312 0.429688
iteration 314: loss 0.590 0.359375 0.460938
iteration 315: loss 0.782 0.273438 0.375000
iteration 316: loss 0.732 0.382812 0.429688
iteration 317: loss 0.636 0.359375 0.500000
iteration 318: loss 0.620 0.304688 0.500000
iteration 319: loss 0.820 0.296875 0.437500
iteration 320: loss 0.732 0.281250 0.445312
iteration 321: loss 0.852 0.281250 0.476562
iteration 322: loss 0.754 0.273438 0.359375
iteration 323: loss 0.531 0.367188 0.593750
iteration 324: loss 0.631 0.382812 0.484375
iteration 325: loss 0.510 0.281250 0.523438
iteration 326: loss 0.746 0.359375 0.398438
iteration 327: loss 0.607 0.367188 0.476562
iteration 328: loss 0.631 0.351562 0.460938
iteration 329: loss 0.595 0.281250 0.507812
iteration 330: loss 0.759 0.296875 0.468750
iteration 331: loss 0.638 0.328125 0.445312
iteration 332: loss 0.779 0.351562 0.468750
iteration 333: loss 0.487 0.351562 0.539062
iteration 334: loss 0.553 0.289062 0.515625
iteration 335: loss 0.591 0.250000 0.468750
iteration 336: loss 0.711 0.312500 0.453125
iteration 337: loss 0.667 0.328125 0.507812
iteration 338: loss 0.710 0.367188 0.421875
iteration 339: loss 0.731 0.312500 0.445312
iteration 340: loss 0.633 0.250000 0.445312
iteration 341: loss 0.637 0.257812 0.445312
iteration 342: loss 0.809 0.335938 0.437500
iteration 343: loss 0.579 0.289062 0.515625
iteration 344: loss 0.734 0.289062 0.500000
iteration 345: loss 0.597 0.289062 0.539062
iteration 346: loss 0.631 0.242188 0.484375
iteration 347: loss 0.735 0.375000 0.406250
iteration 348: loss 0.672 0.343750 0.507812
iteration 349: loss 0.620 0.289062 0.453125
iteration 350: loss 0.644 0.328125 0.476562
iteration 351: loss 0.652 0.328125 0.453125
iteration 352: loss 0.715 0.343750 0.437500
iteration 353: loss 0.556 0.367188 0.585938
iteration 354: loss 0.618 0.343750 0.460938
iteration 355: loss 0.678 0.289062 0.484375
iteration 356: loss 0.696 0.421875 0.484375
iteration 357: loss 0.802 0.289062 0.437500
iteration 358: loss 0.535 0.343750 0.476562
iteration 359: loss 0.706 0.375000 0.445312
iteration 360: loss 0.720 0.218750 0.445312
iteration 361: loss 0.766 0.375000 0.460938
iteration 362: loss 0.560 0.226562 0.531250
iteration 363: loss 0.612 0.320312 0.460938
iteration 364: loss 0.661 0.296875 0.460938
iteration 365: loss 0.666 0.289062 0.453125
iteration 366: loss 0.677 0.312500 0.546875
iteration 367: loss 0.707 0.335938 0.476562
iteration 368: loss 0.606 0.289062 0.500000
iteration 369: loss 0.718 0.312500 0.429688
iteration 370: loss 0.602 0.273438 0.539062
iteration 371: loss 0.594 0.390625 0.492188
iteration 372: loss 0.643 0.296875 0.476562
iteration 373: loss 0.766 0.304688 0.468750
iteration 374: loss 0.589 0.273438 0.539062
iteration 375: loss 0.662 0.304688 0.476562
iteration 376: loss 0.530 0.273438 0.500000
iteration 377: loss 0.726 0.289062 0.398438
iteration 378: loss 0.635 0.281250 0.453125
iteration 379: loss 0.735 0.304688 0.476562
iteration 380: loss 0.471 0.289062 0.546875
iteration 381: loss 0.675 0.335938 0.453125
iteration 382: loss 0.759 0.328125 0.468750
iteration 383: loss 0.634 0.273438 0.523438
iteration 384: loss 0.658 0.335938 0.476562
iteration 385: loss 0.615 0.218750 0.453125
iteration 386: loss 0.716 0.351562 0.414062
iteration 387: loss 0.831 0.289062 0.367188
iteration 388: loss 0.634 0.343750 0.460938
iteration 389: loss 0.564 0.312500 0.445312
iteration 390: loss 0.667 0.265625 0.484375
iteration 391: loss 0.729 0.335938 0.414062
iteration 392: loss 0.679 0.320312 0.476562
iteration 393: loss 0.570 0.320312 0.515625
iteration 394: loss 0.527 0.312500 0.484375
iteration 395: loss 0.596 0.320312 0.515625
iteration 396: loss 0.820 0.382812 0.367188
iteration 397: loss 0.786 0.265625 0.390625
iteration 398: loss 0.677 0.335938 0.507812
iteration 399: loss 0.668 0.320312 0.429688
iteration 400: loss 0.664 0.312500 0.406250
iteration 401: loss 0.664 0.210938 0.507812
iteration 402: loss 0.634 0.296875 0.507812
iteration 403: loss 0.594 0.335938 0.453125
iteration 404: loss 0.626 0.273438 0.460938
iteration 405: loss 0.583 0.351562 0.507812
iteration 406: loss 0.737 0.265625 0.398438
iteration 407: loss 0.693 0.382812 0.453125
iteration 408: loss 0.573 0.382812 0.460938
iteration 409: loss 0.596 0.406250 0.429688
iteration 410: loss 0.619 0.304688 0.546875
iteration 411: loss 0.710 0.265625 0.406250
iteration 412: loss 0.626 0.398438 0.460938
iteration 413: loss 0.706 0.265625 0.507812
iteration 414: loss 0.569 0.328125 0.515625
iteration 415: loss 0.551 0.320312 0.445312
iteration 416: loss 0.537 0.281250 0.468750
iteration 417: loss 0.625 0.312500 0.437500
iteration 418: loss 0.505 0.289062 0.492188
iteration 419: loss 0.651 0.250000 0.476562
iteration 420: loss 0.738 0.328125 0.390625
iteration 421: loss 0.724 0.250000 0.468750
iteration 422: loss 0.695 0.296875 0.445312
iteration 423: loss 0.806 0.273438 0.468750
iteration 424: loss 0.647 0.296875 0.492188
iteration 425: loss 0.680 0.328125 0.507812
iteration 426: loss 0.579 0.273438 0.523438
iteration 427: loss 0.578 0.351562 0.507812
iteration 428: loss 0.718 0.335938 0.500000
iteration 429: loss 0.652 0.328125 0.382812
iteration 430: loss 0.727 0.312500 0.437500
iteration 431: loss 0.727 0.312500 0.453125
iteration 432: loss 0.714 0.312500 0.437500
iteration 433: loss 0.760 0.335938 0.406250
iteration 434: loss 0.591 0.218750 0.484375
iteration 435: loss 0.660 0.250000 0.476562
iteration 436: loss 0.762 0.296875 0.476562
iteration 437: loss 0.547 0.328125 0.460938
iteration 438: loss 0.723 0.312500 0.429688
iteration 439: loss 0.743 0.242188 0.437500
iteration 440: loss 0.799 0.335938 0.437500
iteration 441: loss 0.673 0.289062 0.492188
iteration 442: loss 0.681 0.382812 0.453125
iteration 443: loss 0.610 0.312500 0.460938
iteration 444: loss 0.664 0.414062 0.460938
iteration 445: loss 0.837 0.257812 0.375000
iteration 446: loss 0.617 0.328125 0.476562
iteration 447: loss 0.711 0.250000 0.437500
iteration 448: loss 0.628 0.304688 0.484375
iteration 449: loss 0.828 0.250000 0.492188
iteration 450: loss 0.547 0.203125 0.531250
iteration 451: loss 0.683 0.250000 0.476562
iteration 452: loss 0.733 0.312500 0.515625
iteration 453: loss 0.817 0.312500 0.468750
iteration 454: loss 0.695 0.234375 0.492188
iteration 455: loss 0.736 0.320312 0.460938
iteration 456: loss 0.603 0.359375 0.492188
iteration 457: loss 0.731 0.328125 0.476562
iteration 458: loss 0.803 0.296875 0.414062
iteration 459: loss 0.763 0.328125 0.453125
iteration 460: loss 0.623 0.335938 0.421875
iteration 461: loss 0.763 0.250000 0.468750
iteration 462: loss 0.620 0.335938 0.500000
iteration 463: loss 0.712 0.335938 0.453125
iteration 464: loss 0.716 0.234375 0.476562
iteration 465: loss 0.705 0.281250 0.500000
iteration 466: loss 0.628 0.320312 0.492188
iteration 467: loss 0.599 0.296875 0.437500
iteration 468: loss 0.447 0.320312 0.562500
iteration 469: loss 0.650 0.312500 0.453125
iteration 470: loss 0.708 0.226562 0.460938
iteration 471: loss 0.593 0.242188 0.492188
iteration 472: loss 0.877 0.304688 0.507812
iteration 473: loss 0.691 0.265625 0.453125
iteration 474: loss 0.679 0.273438 0.453125
iteration 475: loss 0.751 0.320312 0.453125
iteration 476: loss 0.697 0.242188 0.445312
iteration 477: loss 0.704 0.289062 0.406250
iteration 478: loss 0.664 0.343750 0.445312
iteration 479: loss 0.641 0.343750 0.492188
iteration 480: loss 0.630 0.343750 0.468750
iteration 481: loss 0.617 0.320312 0.500000
iteration 482: loss 0.606 0.335938 0.515625
iteration 483: loss 0.624 0.335938 0.507812
iteration 484: loss 0.548 0.312500 0.437500
iteration 485: loss 0.734 0.304688 0.429688
iteration 486: loss 0.662 0.312500 0.406250
iteration 487: loss 0.628 0.257812 0.460938
iteration 488: loss 0.646 0.335938 0.484375
iteration 489: loss 0.591 0.296875 0.460938
iteration 490: loss 0.561 0.304688 0.476562
iteration 491: loss 0.676 0.367188 0.421875
iteration 492: loss 0.649 0.320312 0.476562
iteration 493: loss 0.715 0.289062 0.429688
iteration 494: loss 0.663 0.351562 0.531250
iteration 495: loss 0.679 0.226562 0.484375
iteration 496: loss 0.768 0.375000 0.468750
iteration 497: loss 0.581 0.289062 0.421875
iteration 498: loss 0.596 0.273438 0.468750
iteration 499: loss 0.746 0.242188 0.492188
iteration 500: loss 0.672 0.304688 0.468750
iteration 501: loss 0.774 0.320312 0.460938
iteration 502: loss 0.805 0.328125 0.367188
iteration 503: loss 0.769 0.312500 0.406250
iteration 504: loss 0.569 0.375000 0.523438
iteration 505: loss 0.687 0.312500 0.445312
iteration 506: loss 0.611 0.367188 0.484375
iteration 507: loss 0.726 0.273438 0.484375
iteration 508: loss 0.795 0.328125 0.421875
iteration 509: loss 0.601 0.164062 0.492188
iteration 510: loss 0.589 0.257812 0.437500
iteration 511: loss 0.713 0.234375 0.398438
iteration 512: loss 0.751 0.304688 0.406250
iteration 513: loss 0.589 0.312500 0.414062
iteration 514: loss 0.682 0.281250 0.531250
iteration 515: loss 0.621 0.367188 0.507812
iteration 516: loss 0.545 0.367188 0.523438
iteration 517: loss 0.753 0.312500 0.515625
iteration 518: loss 0.650 0.390625 0.523438
iteration 519: loss 0.621 0.328125 0.484375
iteration 520: loss 0.642 0.343750 0.515625
iteration 521: loss 0.746 0.320312 0.414062
iteration 522: loss 0.697 0.359375 0.468750
iteration 523: loss 0.745 0.328125 0.406250
iteration 524: loss 0.797 0.265625 0.445312
iteration 525: loss 0.710 0.343750 0.453125
iteration 526: loss 0.629 0.289062 0.406250
iteration 527: loss 0.626 0.273438 0.453125
iteration 528: loss 0.564 0.335938 0.484375
iteration 529: loss 0.720 0.304688 0.437500
iteration 530: loss 0.580 0.328125 0.484375
iteration 531: loss 0.709 0.343750 0.398438
iteration 532: loss 0.611 0.335938 0.453125
iteration 533: loss 0.643 0.265625 0.531250
iteration 534: loss 0.746 0.265625 0.507812
iteration 535: loss 0.623 0.281250 0.437500
iteration 536: loss 0.734 0.257812 0.406250
iteration 537: loss 0.536 0.242188 0.492188
iteration 538: loss 0.709 0.281250 0.460938
iteration 539: loss 0.527 0.375000 0.531250
iteration 540: loss 0.601 0.398438 0.531250
iteration 541: loss 0.846 0.273438 0.406250
iteration 542: loss 0.665 0.375000 0.484375
iteration 543: loss 0.524 0.335938 0.507812
iteration 544: loss 0.767 0.226562 0.375000
iteration 545: loss 0.614 0.359375 0.492188
iteration 546: loss 0.668 0.359375 0.445312
iteration 547: loss 0.622 0.257812 0.437500
iteration 548: loss 0.710 0.250000 0.429688
iteration 549: loss 0.728 0.250000 0.421875
iteration 550: loss 0.688 0.304688 0.429688
iteration 551: loss 0.649 0.226562 0.468750
iteration 552: loss 0.498 0.289062 0.546875
iteration 553: loss 0.500 0.320312 0.492188
iteration 554: loss 0.756 0.320312 0.390625
iteration 555: loss 0.689 0.265625 0.523438
iteration 556: loss 0.627 0.265625 0.445312
iteration 557: loss 0.636 0.343750 0.468750
iteration 558: loss 0.630 0.328125 0.492188
iteration 559: loss 0.772 0.304688 0.437500
iteration 560: loss 0.676 0.265625 0.382812
iteration 561: loss 0.572 0.273438 0.468750
iteration 562: loss 0.569 0.304688 0.484375
iteration 563: loss 0.733 0.312500 0.375000
iteration 564: loss 0.643 0.304688 0.453125
iteration 565: loss 0.652 0.296875 0.468750
iteration 566: loss 0.577 0.289062 0.500000
iteration 567: loss 0.701 0.328125 0.421875
iteration 568: loss 0.627 0.343750 0.500000
iteration 569: loss 0.723 0.250000 0.460938
iteration 570: loss 0.686 0.312500 0.429688
iteration 571: loss 0.650 0.234375 0.429688
iteration 572: loss 0.614 0.343750 0.476562
iteration 573: loss 0.494 0.304688 0.484375
iteration 574: loss 0.620 0.312500 0.445312
iteration 575: loss 0.666 0.304688 0.476562
iteration 576: loss 0.684 0.289062 0.500000
iteration 577: loss 0.663 0.328125 0.445312
iteration 578: loss 0.868 0.328125 0.398438
iteration 579: loss 0.552 0.335938 0.500000
iteration 580: loss 0.564 0.351562 0.468750
iteration 581: loss 0.726 0.390625 0.437500
iteration 582: loss 0.812 0.429688 0.367188
iteration 583: loss 0.733 0.304688 0.468750
iteration 584: loss 0.732 0.257812 0.453125
iteration 585: loss 0.793 0.328125 0.390625
iteration 586: loss 0.593 0.367188 0.523438
iteration 587: loss 0.616 0.312500 0.507812
iteration 588: loss 0.486 0.226562 0.500000
iteration 589: loss 0.613 0.359375 0.500000
iteration 590: loss 0.790 0.320312 0.421875
iteration 591: loss 0.722 0.312500 0.429688
iteration 592: loss 0.700 0.335938 0.476562
iteration 593: loss 0.790 0.343750 0.476562
iteration 594: loss 0.687 0.359375 0.484375
iteration 595: loss 0.612 0.320312 0.460938
iteration 596: loss 0.690 0.296875 0.460938
iteration 597: loss 0.651 0.312500 0.453125
iteration 598: loss 0.815 0.289062 0.437500
iteration 599: loss 0.700 0.304688 0.515625
iteration 600: loss 0.528 0.265625 0.554688
iteration 601: loss 0.708 0.273438 0.382812
iteration 602: loss 0.733 0.335938 0.429688
iteration 603: loss 0.783 0.273438 0.398438
iteration 604: loss 0.671 0.296875 0.468750
iteration 605: loss 0.605 0.226562 0.468750
iteration 606: loss 0.653 0.281250 0.523438
iteration 607: loss 0.616 0.359375 0.476562
iteration 608: loss 0.887 0.335938 0.367188
iteration 609: loss 0.630 0.351562 0.500000
iteration 610: loss 0.626 0.320312 0.546875
iteration 611: loss 0.886 0.351562 0.406250
iteration 612: loss 0.719 0.335938 0.445312
iteration 613: loss 0.705 0.296875 0.476562
iteration 614: loss 0.605 0.312500 0.414062
iteration 615: loss 0.635 0.359375 0.445312
iteration 616: loss 0.566 0.343750 0.515625
iteration 617: loss 0.645 0.312500 0.476562
iteration 618: loss 0.677 0.343750 0.476562
iteration 619: loss 0.649 0.320312 0.507812
iteration 620: loss 0.697 0.359375 0.507812
iteration 621: loss 0.762 0.304688 0.460938
iteration 622: loss 0.605 0.250000 0.500000
iteration 623: loss 0.692 0.335938 0.468750
iteration 624: loss 0.545 0.335938 0.539062
iteration 625: loss 0.789 0.265625 0.460938
iteration 626: loss 0.602 0.273438 0.500000
iteration 627: loss 0.612 0.382812 0.437500
iteration 628: loss 0.781 0.312500 0.367188
iteration 629: loss 0.739 0.273438 0.398438
iteration 630: loss 0.725 0.351562 0.484375
iteration 631: loss 0.735 0.320312 0.523438
iteration 632: loss 0.784 0.367188 0.539062
iteration 633: loss 0.622 0.273438 0.492188
iteration 634: loss 0.636 0.312500 0.515625
iteration 635: loss 0.552 0.289062 0.484375
iteration 636: loss 0.736 0.335938 0.476562
iteration 637: loss 0.714 0.351562 0.515625
iteration 638: loss 0.692 0.242188 0.437500
iteration 639: loss 0.596 0.304688 0.476562
iteration 640: loss 0.705 0.320312 0.375000
iteration 641: loss 0.674 0.281250 0.429688
iteration 642: loss 0.746 0.328125 0.390625
iteration 643: loss 0.823 0.273438 0.359375
iteration 644: loss 0.760 0.296875 0.406250
iteration 645: loss 0.674 0.265625 0.500000
iteration 646: loss 0.624 0.328125 0.500000
iteration 647: loss 0.563 0.281250 0.585938
iteration 648: loss 0.691 0.304688 0.445312
iteration 649: loss 0.618 0.273438 0.468750
iteration 650: loss 0.564 0.335938 0.476562
iteration 651: loss 0.577 0.320312 0.546875
iteration 652: loss 0.928 0.359375 0.437500
iteration 653: loss 0.668 0.304688 0.515625
iteration 654: loss 0.625 0.328125 0.500000
iteration 655: loss 0.739 0.273438 0.390625
iteration 656: loss 0.658 0.320312 0.460938
iteration 657: loss 0.657 0.210938 0.507812
iteration 658: loss 0.913 0.257812 0.398438
iteration 659: loss 0.729 0.250000 0.460938
iteration 660: loss 0.679 0.320312 0.500000
iteration 661: loss 0.879 0.304688 0.398438
iteration 662: loss 0.727 0.351562 0.500000
iteration 663: loss 0.736 0.335938 0.406250
iteration 664: loss 0.652 0.312500 0.500000
iteration 665: loss 0.638 0.265625 0.468750
iteration 666: loss 0.545 0.359375 0.531250
iteration 667: loss 0.672 0.328125 0.468750
iteration 668: loss 0.744 0.343750 0.437500
iteration 669: loss 0.715 0.367188 0.453125
iteration 670: loss 0.550 0.312500 0.492188
iteration 671: loss 0.755 0.265625 0.460938
iteration 672: loss 0.717 0.335938 0.429688
iteration 673: loss 0.683 0.296875 0.445312
iteration 674: loss 0.653 0.335938 0.437500
iteration 675: loss 0.606 0.343750 0.492188
iteration 676: loss 0.685 0.343750 0.390625
iteration 677: loss 0.517 0.281250 0.453125
iteration 678: loss 0.675 0.281250 0.421875
iteration 679: loss 0.919 0.304688 0.437500
iteration 680: loss 0.731 0.304688 0.453125
iteration 681: loss 0.797 0.367188 0.484375
iteration 682: loss 0.561 0.328125 0.484375
iteration 683: loss 0.463 0.304688 0.531250
iteration 684: loss 0.598 0.351562 0.484375
iteration 685: loss 0.666 0.335938 0.515625
iteration 686: loss 0.651 0.195312 0.468750
iteration 687: loss 0.716 0.312500 0.445312
iteration 688: loss 0.618 0.289062 0.484375
iteration 689: loss 0.637 0.304688 0.492188
iteration 690: loss 0.550 0.343750 0.500000
iteration 691: loss 0.655 0.312500 0.414062
iteration 692: loss 0.656 0.289062 0.484375
iteration 693: loss 0.555 0.304688 0.539062
iteration 694: loss 0.685 0.351562 0.453125
iteration 695: loss 0.760 0.367188 0.398438
iteration 696: loss 0.580 0.351562 0.507812
iteration 697: loss 0.688 0.320312 0.445312
iteration 698: loss 0.506 0.328125 0.414062
iteration 699: loss 0.606 0.414062 0.414062
iteration 700: loss 0.556 0.320312 0.476562
iteration 701: loss 0.601 0.312500 0.484375
iteration 702: loss 0.565 0.273438 0.515625
iteration 703: loss 0.616 0.289062 0.437500
iteration 704: loss 0.706 0.281250 0.484375
iteration 705: loss 0.604 0.312500 0.437500
iteration 706: loss 0.591 0.304688 0.507812
iteration 707: loss 0.658 0.343750 0.445312
iteration 708: loss 0.571 0.312500 0.476562
iteration 709: loss 0.803 0.289062 0.406250
iteration 710: loss 0.715 0.335938 0.445312
iteration 711: loss 0.700 0.296875 0.437500
iteration 712: loss 0.716 0.351562 0.445312
iteration 713: loss 0.709 0.335938 0.468750
iteration 714: loss 0.693 0.343750 0.460938
iteration 715: loss 0.714 0.351562 0.390625
iteration 716: loss 0.745 0.289062 0.507812
iteration 717: loss 0.833 0.312500 0.390625
iteration 718: loss 0.785 0.304688 0.429688
iteration 719: loss 0.724 0.375000 0.468750
iteration 720: loss 0.673 0.351562 0.492188
iteration 721: loss 0.573 0.367188 0.492188
iteration 722: loss 0.869 0.304688 0.445312
iteration 723: loss 0.727 0.320312 0.414062
iteration 724: loss 0.697 0.343750 0.429688
iteration 725: loss 0.729 0.343750 0.414062
iteration 726: loss 0.794 0.296875 0.351562
iteration 727: loss 0.672 0.257812 0.476562
iteration 728: loss 0.645 0.273438 0.445312
iteration 729: loss 0.758 0.242188 0.453125
iteration 730: loss 0.642 0.312500 0.484375
iteration 731: loss 0.695 0.257812 0.414062
iteration 732: loss 0.586 0.390625 0.507812
iteration 733: loss 0.710 0.281250 0.460938
iteration 734: loss 0.642 0.273438 0.421875
iteration 735: loss 0.856 0.328125 0.343750
iteration 736: loss 0.684 0.296875 0.476562
iteration 737: loss 0.584 0.320312 0.492188
iteration 738: loss 0.601 0.296875 0.476562
iteration 739: loss 0.618 0.265625 0.460938
iteration 740: loss 0.763 0.414062 0.437500
iteration 741: loss 0.592 0.273438 0.515625
iteration 742: loss 0.693 0.390625 0.539062
iteration 743: loss 0.712 0.281250 0.421875
iteration 744: loss 0.541 0.304688 0.460938
iteration 745: loss 0.719 0.289062 0.468750
iteration 746: loss 0.707 0.312500 0.429688
iteration 747: loss 0.651 0.304688 0.468750
iteration 748: loss 0.531 0.312500 0.500000
iteration 749: loss 0.612 0.359375 0.414062
iteration 750: loss 0.631 0.304688 0.515625
iteration 751: loss 0.602 0.296875 0.468750
iteration 752: loss 0.567 0.281250 0.453125
iteration 753: loss 0.620 0.343750 0.414062
iteration 754: loss 0.691 0.289062 0.382812
iteration 755: loss 0.606 0.273438 0.406250
iteration 756: loss 0.676 0.210938 0.507812
iteration 757: loss 0.622 0.312500 0.429688
iteration 758: loss 0.593 0.343750 0.437500
iteration 759: loss 0.596 0.312500 0.453125
iteration 760: loss 0.610 0.281250 0.414062
iteration 761: loss 0.601 0.351562 0.429688
iteration 762: loss 0.624 0.289062 0.429688
iteration 763: loss 0.624 0.351562 0.429688
iteration 764: loss 0.629 0.328125 0.460938
iteration 765: loss 0.689 0.343750 0.484375
iteration 766: loss 0.623 0.304688 0.460938
iteration 767: loss 0.713 0.304688 0.375000
iteration 768: loss 0.742 0.257812 0.445312
iteration 769: loss 0.598 0.382812 0.460938
iteration 770: loss 0.596 0.289062 0.500000
iteration 771: loss 0.624 0.312500 0.460938
iteration 772: loss 0.764 0.265625 0.414062
iteration 773: loss 0.727 0.343750 0.382812
iteration 774: loss 0.577 0.312500 0.507812
iteration 775: loss 0.582 0.257812 0.453125
iteration 776: loss 0.581 0.265625 0.453125
iteration 777: loss 0.599 0.359375 0.515625
iteration 778: loss 0.661 0.320312 0.476562
iteration 779: loss 0.562 0.273438 0.546875
iteration 780: loss 0.656 0.273438 0.523438
iteration 781: loss 0.601 0.257812 0.476562
iteration 782: loss 0.568 0.328125 0.476562
iteration 783: loss 0.634 0.273438 0.453125
iteration 784: loss 0.638 0.312500 0.414062
iteration 785: loss 0.776 0.343750 0.500000
iteration 786: loss 0.665 0.335938 0.453125
iteration 787: loss 0.855 0.242188 0.375000
iteration 788: loss 0.679 0.281250 0.398438
iteration 789: loss 0.676 0.304688 0.437500
iteration 790: loss 0.613 0.265625 0.468750
iteration 791: loss 0.542 0.328125 0.492188
iteration 792: loss 0.701 0.328125 0.507812
iteration 793: loss 0.641 0.273438 0.453125
iteration 794: loss 0.760 0.296875 0.484375
iteration 795: loss 0.643 0.273438 0.523438
iteration 796: loss 0.745 0.296875 0.421875
iteration 797: loss 0.551 0.203125 0.492188
iteration 798: loss 0.654 0.328125 0.421875
iteration 799: loss 0.650 0.312500 0.406250
iteration 800: loss 0.535 0.312500 0.500000
iteration 801: loss 0.568 0.335938 0.453125
iteration 802: loss 0.463 0.304688 0.546875
iteration 803: loss 0.697 0.320312 0.414062
iteration 804: loss 0.692 0.320312 0.414062
iteration 805: loss 0.573 0.351562 0.484375
iteration 806: loss 0.591 0.289062 0.437500
iteration 807: loss 0.534 0.335938 0.500000
iteration 808: loss 0.567 0.320312 0.414062
iteration 809: loss 0.630 0.257812 0.421875
iteration 810: loss 0.402 0.234375 0.578125
iteration 811: loss 0.655 0.296875 0.453125
iteration 812: loss 0.585 0.289062 0.414062
iteration 813: loss 0.565 0.242188 0.507812
iteration 814: loss 0.533 0.335938 0.515625
iteration 815: loss 0.624 0.320312 0.414062
iteration 816: loss 0.603 0.281250 0.476562
iteration 817: loss 0.614 0.304688 0.453125
iteration 818: loss 0.687 0.343750 0.375000
iteration 819: loss 0.589 0.281250 0.460938
iteration 820: loss 0.618 0.390625 0.453125
iteration 821: loss 0.688 0.304688 0.429688
iteration 822: loss 0.575 0.312500 0.484375
iteration 823: loss 0.615 0.328125 0.500000
iteration 824: loss 0.590 0.320312 0.554688
iteration 825: loss 0.544 0.281250 0.507812
iteration 826: loss 0.584 0.367188 0.453125
iteration 827: loss 0.707 0.367188 0.445312
iteration 828: loss 0.645 0.304688 0.445312
iteration 829: loss 0.668 0.320312 0.382812
iteration 830: loss 0.679 0.296875 0.398438
iteration 831: loss 0.643 0.242188 0.460938
iteration 832: loss 0.446 0.218750 0.492188
iteration 833: loss 0.588 0.250000 0.460938
iteration 834: loss 0.595 0.257812 0.492188
iteration 835: loss 0.642 0.320312 0.468750
iteration 836: loss 0.466 0.289062 0.531250
iteration 837: loss 0.699 0.304688 0.421875
iteration 838: loss 0.654 0.328125 0.398438
iteration 839: loss 0.633 0.335938 0.453125
iteration 840: loss 0.663 0.250000 0.460938
iteration 841: loss 0.654 0.367188 0.476562
iteration 842: loss 0.671 0.367188 0.460938
iteration 843: loss 0.676 0.335938 0.500000
iteration 844: loss 0.718 0.210938 0.492188
iteration 845: loss 0.610 0.359375 0.500000
iteration 846: loss 0.546 0.296875 0.507812
iteration 847: loss 0.937 0.343750 0.453125
iteration 848: loss 0.623 0.296875 0.476562
iteration 849: loss 0.690 0.242188 0.429688
iteration 850: loss 0.647 0.265625 0.398438
iteration 851: loss 0.828 0.367188 0.406250
iteration 852: loss 0.700 0.296875 0.414062
iteration 853: loss 0.635 0.304688 0.453125
iteration 854: loss 0.454 0.312500 0.500000
iteration 855: loss 0.613 0.312500 0.484375
iteration 856: loss 0.721 0.289062 0.398438
iteration 857: loss 0.446 0.320312 0.468750
iteration 858: loss 0.615 0.304688 0.531250
iteration 859: loss 0.655 0.320312 0.476562
iteration 860: loss 0.631 0.320312 0.507812
iteration 861: loss 0.482 0.273438 0.523438
iteration 862: loss 0.657 0.234375 0.460938
iteration 863: loss 0.777 0.289062 0.406250
iteration 864: loss 0.662 0.304688 0.484375
iteration 865: loss 0.751 0.265625 0.421875
iteration 866: loss 0.650 0.351562 0.460938
iteration 867: loss 0.701 0.320312 0.484375
iteration 868: loss 0.683 0.296875 0.453125
iteration 869: loss 0.705 0.281250 0.453125
iteration 870: loss 0.708 0.414062 0.453125
iteration 871: loss 0.590 0.320312 0.492188
iteration 872: loss 0.662 0.226562 0.476562
iteration 873: loss 0.443 0.351562 0.562500
iteration 874: loss 0.614 0.328125 0.468750
iteration 875: loss 0.750 0.343750 0.445312
iteration 876: loss 0.674 0.328125 0.476562
iteration 877: loss 0.774 0.273438 0.429688
iteration 878: loss 0.667 0.320312 0.453125
iteration 879: loss 0.809 0.328125 0.429688
iteration 880: loss 0.627 0.242188 0.429688
iteration 881: loss 0.737 0.328125 0.390625
iteration 882: loss 0.604 0.343750 0.515625
iteration 883: loss 0.468 0.390625 0.515625
iteration 884: loss 0.621 0.312500 0.500000
iteration 885: loss 0.641 0.312500 0.523438
iteration 886: loss 0.524 0.304688 0.531250
iteration 887: loss 0.685 0.312500 0.484375
iteration 888: loss 0.826 0.289062 0.429688
iteration 889: loss 0.750 0.320312 0.476562
iteration 890: loss 0.735 0.304688 0.398438
iteration 891: loss 0.732 0.375000 0.406250
iteration 892: loss 0.659 0.289062 0.468750
iteration 893: loss 0.792 0.265625 0.445312
iteration 894: loss 0.694 0.195312 0.515625
iteration 895: loss 0.635 0.367188 0.507812
iteration 896: loss 0.811 0.367188 0.421875
iteration 897: loss 0.760 0.289062 0.429688
iteration 898: loss 0.679 0.265625 0.421875
iteration 899: loss 0.738 0.359375 0.414062
iteration 900: loss 0.537 0.375000 0.484375
iteration 901: loss 0.710 0.257812 0.367188
iteration 902: loss 0.758 0.335938 0.406250
iteration 903: loss 0.685 0.304688 0.460938
iteration 904: loss 0.649 0.289062 0.484375
iteration 905: loss 0.783 0.312500 0.468750
iteration 906: loss 0.788 0.328125 0.468750
iteration 907: loss 0.632 0.257812 0.507812
iteration 908: loss 0.581 0.351562 0.421875
iteration 909: loss 0.698 0.296875 0.476562
iteration 910: loss 0.828 0.335938 0.445312
iteration 911: loss 0.647 0.289062 0.546875
iteration 912: loss 0.664 0.257812 0.453125
iteration 913: loss 0.686 0.320312 0.468750
iteration 914: loss 0.755 0.312500 0.445312
iteration 915: loss 0.638 0.250000 0.429688
iteration 916: loss 0.668 0.328125 0.468750
iteration 917: loss 0.654 0.265625 0.445312
iteration 918: loss 0.660 0.320312 0.468750
iteration 919: loss 0.663 0.343750 0.492188
iteration 920: loss 0.695 0.289062 0.484375
iteration 921: loss 0.759 0.273438 0.460938
iteration 922: loss 0.588 0.281250 0.460938
iteration 923: loss 0.716 0.335938 0.429688
iteration 924: loss 0.731 0.335938 0.492188
iteration 925: loss 0.677 0.304688 0.476562
iteration 926: loss 0.655 0.335938 0.468750
iteration 927: loss 0.797 0.320312 0.390625
iteration 928: loss 0.644 0.328125 0.531250
iteration 929: loss 0.737 0.289062 0.468750
iteration 930: loss 0.639 0.179688 0.484375
iteration 931: loss 0.795 0.265625 0.421875
iteration 932: loss 0.692 0.250000 0.492188
iteration 933: loss 0.798 0.328125 0.468750
iteration 934: loss 0.529 0.273438 0.539062
iteration 935: loss 0.741 0.296875 0.421875
iteration 936: loss 0.722 0.304688 0.445312
iteration 937: loss 0.702 0.257812 0.367188
iteration 938: loss 0.567 0.296875 0.523438
iteration 939: loss 0.636 0.296875 0.453125
iteration 940: loss 0.634 0.328125 0.476562
iteration 941: loss 0.734 0.335938 0.429688
iteration 942: loss 0.733 0.257812 0.421875
iteration 943: loss 0.782 0.312500 0.460938
iteration 944: loss 0.786 0.398438 0.468750
iteration 945: loss 0.826 0.375000 0.406250
iteration 946: loss 0.681 0.343750 0.468750
iteration 947: loss 0.627 0.289062 0.460938
iteration 948: loss 0.749 0.296875 0.328125
iteration 949: loss 0.623 0.281250 0.445312
iteration 950: loss 0.717 0.335938 0.468750
iteration 951: loss 0.916 0.390625 0.445312
iteration 952: loss 0.795 0.335938 0.406250
iteration 953: loss 0.761 0.312500 0.453125
iteration 954: loss 0.783 0.242188 0.421875
iteration 955: loss 0.645 0.359375 0.531250
iteration 956: loss 0.875 0.328125 0.359375
iteration 957: loss 0.699 0.281250 0.507812
iteration 958: loss 0.709 0.242188 0.437500
iteration 959: loss 0.795 0.304688 0.523438
iteration 960: loss 0.623 0.281250 0.492188
iteration 961: loss 0.822 0.304688 0.492188
iteration 962: loss 0.788 0.343750 0.468750
iteration 963: loss 0.681 0.335938 0.468750
iteration 964: loss 0.692 0.304688 0.445312
iteration 965: loss 0.675 0.320312 0.500000
iteration 966: loss 0.776 0.296875 0.437500
iteration 967: loss 0.681 0.296875 0.507812
iteration 968: loss 0.577 0.296875 0.500000
iteration 969: loss 0.771 0.351562 0.421875
iteration 970: loss 0.721 0.281250 0.445312
iteration 971: loss 0.791 0.351562 0.476562
iteration 972: loss 0.678 0.273438 0.492188
iteration 973: loss 0.809 0.304688 0.406250
iteration 974: loss 0.669 0.273438 0.367188
iteration 975: loss 0.730 0.304688 0.445312
iteration 976: loss 0.766 0.289062 0.460938
iteration 977: loss 0.643 0.351562 0.421875
iteration 978: loss 0.587 0.304688 0.382812
iteration 979: loss 0.725 0.281250 0.476562
iteration 980: loss 0.711 0.281250 0.476562
iteration 981: loss 0.817 0.390625 0.343750
iteration 982: loss 0.690 0.312500 0.445312
iteration 983: loss 0.525 0.257812 0.546875
iteration 984: loss 0.707 0.242188 0.476562
iteration 985: loss 0.612 0.265625 0.523438
iteration 986: loss 0.657 0.335938 0.500000
iteration 987: loss 0.724 0.210938 0.453125
iteration 988: loss 0.692 0.289062 0.492188
iteration 989: loss 0.906 0.312500 0.367188
iteration 990: loss 0.577 0.242188 0.484375
iteration 991: loss 0.726 0.312500 0.359375
iteration 992: loss 0.738 0.367188 0.468750
iteration 993: loss 0.722 0.250000 0.437500
iteration 994: loss 0.557 0.304688 0.484375
iteration 995: loss 0.627 0.234375 0.429688
iteration 996: loss 0.719 0.367188 0.375000
iteration 997: loss 0.748 0.257812 0.390625
iteration 998: loss 0.564 0.328125 0.414062
iteration 999: loss 0.691 0.406250 0.476562
epoch 9: training: 0.265625 validation: 0.265625
iteration 0: loss 0.765 0.304688 0.437500
iteration 1: loss 0.667 0.367188 0.484375
iteration 2: loss 0.578 0.351562 0.437500
iteration 3: loss 0.543 0.312500 0.539062
iteration 4: loss 0.575 0.367188 0.445312
iteration 5: loss 0.629 0.320312 0.500000
iteration 6: loss 0.595 0.296875 0.523438
iteration 7: loss 0.712 0.304688 0.406250
iteration 8: loss 0.639 0.351562 0.468750
iteration 9: loss 0.696 0.273438 0.468750
iteration 10: loss 0.657 0.328125 0.484375
iteration 11: loss 0.584 0.367188 0.429688
iteration 12: loss 0.553 0.265625 0.515625
iteration 13: loss 0.731 0.226562 0.445312
iteration 14: loss 0.812 0.296875 0.312500
iteration 15: loss 0.653 0.320312 0.476562
iteration 16: loss 0.722 0.343750 0.453125
iteration 17: loss 0.601 0.375000 0.437500
iteration 18: loss 0.660 0.375000 0.460938
iteration 19: loss 0.547 0.304688 0.500000
iteration 20: loss 0.732 0.304688 0.523438
iteration 21: loss 0.846 0.343750 0.390625
iteration 22: loss 0.656 0.351562 0.531250
iteration 23: loss 0.602 0.250000 0.601562
iteration 24: loss 0.574 0.265625 0.468750
iteration 25: loss 0.771 0.296875 0.390625
iteration 26: loss 0.639 0.304688 0.437500
iteration 27: loss 0.928 0.312500 0.328125
iteration 28: loss 0.748 0.304688 0.453125
iteration 29: loss 0.611 0.273438 0.460938
iteration 30: loss 0.796 0.296875 0.382812
iteration 31: loss 0.622 0.296875 0.406250
iteration 32: loss 0.645 0.304688 0.492188
iteration 33: loss 0.717 0.250000 0.421875
iteration 34: loss 0.624 0.320312 0.484375
iteration 35: loss 0.690 0.351562 0.531250
iteration 36: loss 0.660 0.296875 0.492188
iteration 37: loss 0.584 0.304688 0.500000
iteration 38: loss 0.701 0.304688 0.445312
iteration 39: loss 0.651 0.265625 0.484375
iteration 40: loss 0.625 0.273438 0.539062
iteration 41: loss 0.651 0.304688 0.500000
iteration 42: loss 0.489 0.281250 0.531250
iteration 43: loss 0.670 0.343750 0.500000
iteration 44: loss 0.547 0.351562 0.546875
iteration 45: loss 0.567 0.382812 0.476562
iteration 46: loss 0.656 0.335938 0.453125
iteration 47: loss 0.725 0.273438 0.523438
iteration 48: loss 0.625 0.296875 0.468750
iteration 49: loss 0.809 0.320312 0.445312
iteration 50: loss 0.909 0.273438 0.382812
iteration 51: loss 0.663 0.257812 0.476562
iteration 52: loss 0.703 0.328125 0.429688
iteration 53: loss 0.613 0.250000 0.445312
iteration 54: loss 0.612 0.429688 0.468750
iteration 55: loss 0.797 0.296875 0.335938
iteration 56: loss 0.741 0.250000 0.398438
iteration 57: loss 0.699 0.296875 0.445312
iteration 58: loss 0.762 0.382812 0.406250
iteration 59: loss 0.571 0.312500 0.531250
iteration 60: loss 0.670 0.257812 0.445312
iteration 61: loss 0.628 0.359375 0.515625
iteration 62: loss 0.615 0.320312 0.500000
iteration 63: loss 0.813 0.250000 0.398438
iteration 64: loss 0.546 0.234375 0.515625
iteration 65: loss 0.706 0.328125 0.507812
iteration 66: loss 0.764 0.335938 0.421875
iteration 67: loss 0.655 0.296875 0.531250
iteration 68: loss 0.637 0.312500 0.507812
iteration 69: loss 0.726 0.445312 0.515625
iteration 70: loss 0.737 0.281250 0.492188
iteration 71: loss 0.771 0.351562 0.390625
iteration 72: loss 0.793 0.351562 0.398438
iteration 73: loss 0.693 0.359375 0.390625
iteration 74: loss 0.664 0.281250 0.468750
iteration 75: loss 0.688 0.304688 0.437500
iteration 76: loss 0.532 0.343750 0.476562
iteration 77: loss 0.638 0.257812 0.398438
iteration 78: loss 0.735 0.265625 0.398438
iteration 79: loss 0.500 0.359375 0.585938
iteration 80: loss 0.620 0.289062 0.507812
iteration 81: loss 0.730 0.328125 0.390625
iteration 82: loss 0.668 0.343750 0.414062
iteration 83: loss 0.695 0.343750 0.453125
iteration 84: loss 0.558 0.296875 0.492188
iteration 85: loss 0.507 0.343750 0.476562
iteration 86: loss 0.567 0.296875 0.500000
iteration 87: loss 0.660 0.250000 0.437500
iteration 88: loss 0.565 0.242188 0.507812
iteration 89: loss 0.932 0.320312 0.421875
iteration 90: loss 0.628 0.242188 0.460938
iteration 91: loss 0.644 0.304688 0.484375
iteration 92: loss 0.568 0.296875 0.539062
iteration 93: loss 0.527 0.281250 0.500000
iteration 94: loss 0.717 0.273438 0.421875
iteration 95: loss 0.757 0.320312 0.398438
iteration 96: loss 0.547 0.312500 0.507812
iteration 97: loss 0.445 0.320312 0.500000
iteration 98: loss 0.538 0.242188 0.492188
iteration 99: loss 0.570 0.265625 0.515625
iteration 100: loss 0.594 0.304688 0.484375
iteration 101: loss 0.777 0.351562 0.445312
iteration 102: loss 0.585 0.289062 0.476562
iteration 103: loss 0.704 0.351562 0.429688
iteration 104: loss 0.648 0.304688 0.390625
iteration 105: loss 0.775 0.312500 0.382812
iteration 106: loss 0.729 0.289062 0.484375
iteration 107: loss 0.589 0.289062 0.453125
iteration 108: loss 0.799 0.335938 0.460938
iteration 109: loss 0.621 0.281250 0.484375
iteration 110: loss 0.690 0.398438 0.476562
iteration 111: loss 0.742 0.335938 0.476562
iteration 112: loss 0.806 0.304688 0.468750
iteration 113: loss 0.617 0.304688 0.445312
iteration 114: loss 0.668 0.273438 0.406250
iteration 115: loss 0.703 0.296875 0.406250
iteration 116: loss 0.771 0.312500 0.429688
iteration 117: loss 0.721 0.312500 0.429688
iteration 118: loss 0.639 0.289062 0.437500
iteration 119: loss 0.549 0.281250 0.523438
iteration 120: loss 0.508 0.289062 0.531250
iteration 121: loss 0.642 0.312500 0.382812
iteration 122: loss 0.566 0.281250 0.468750
iteration 123: loss 0.595 0.312500 0.453125
iteration 124: loss 0.663 0.257812 0.421875
iteration 125: loss 0.688 0.320312 0.453125
iteration 126: loss 0.602 0.265625 0.437500
iteration 127: loss 0.599 0.320312 0.421875
iteration 128: loss 0.598 0.273438 0.484375
iteration 129: loss 0.595 0.359375 0.492188
iteration 130: loss 0.673 0.328125 0.445312
iteration 131: loss 0.759 0.257812 0.406250
iteration 132: loss 0.560 0.289062 0.523438
iteration 133: loss 0.657 0.226562 0.445312
iteration 134: loss 0.711 0.289062 0.429688
iteration 135: loss 0.572 0.226562 0.445312
iteration 136: loss 0.685 0.273438 0.421875
iteration 137: loss 0.543 0.289062 0.523438
iteration 138: loss 0.747 0.382812 0.468750
iteration 139: loss 0.758 0.273438 0.453125
iteration 140: loss 0.715 0.312500 0.468750
iteration 141: loss 0.594 0.382812 0.453125
iteration 142: loss 0.604 0.320312 0.507812
iteration 143: loss 0.613 0.296875 0.476562
iteration 144: loss 0.868 0.281250 0.437500
iteration 145: loss 0.665 0.328125 0.445312
iteration 146: loss 0.661 0.414062 0.382812
iteration 147: loss 0.675 0.312500 0.414062
iteration 148: loss 0.631 0.273438 0.476562
iteration 149: loss 0.654 0.289062 0.437500
iteration 150: loss 0.580 0.320312 0.453125
iteration 151: loss 0.798 0.335938 0.375000
iteration 152: loss 0.647 0.226562 0.515625
iteration 153: loss 0.712 0.328125 0.437500
iteration 154: loss 0.682 0.328125 0.437500
iteration 155: loss 0.718 0.265625 0.398438
iteration 156: loss 0.548 0.343750 0.492188
iteration 157: loss 0.715 0.304688 0.406250
iteration 158: loss 0.627 0.304688 0.437500
iteration 159: loss 0.816 0.328125 0.382812
iteration 160: loss 0.577 0.265625 0.523438
iteration 161: loss 0.859 0.265625 0.390625
iteration 162: loss 0.779 0.320312 0.406250
iteration 163: loss 0.571 0.304688 0.546875
iteration 164: loss 0.541 0.273438 0.437500
iteration 165: loss 0.759 0.281250 0.398438
iteration 166: loss 0.745 0.289062 0.476562
iteration 167: loss 0.819 0.304688 0.484375
iteration 168: loss 0.656 0.281250 0.507812
iteration 169: loss 0.809 0.343750 0.406250
iteration 170: loss 0.552 0.328125 0.460938
iteration 171: loss 0.570 0.304688 0.546875
iteration 172: loss 0.673 0.328125 0.484375
iteration 173: loss 0.631 0.320312 0.500000
iteration 174: loss 0.871 0.328125 0.398438
iteration 175: loss 0.608 0.289062 0.507812
iteration 176: loss 0.725 0.375000 0.476562
iteration 177: loss 0.709 0.312500 0.523438
iteration 178: loss 0.577 0.281250 0.523438
iteration 179: loss 0.671 0.367188 0.437500
iteration 180: loss 0.674 0.351562 0.500000
iteration 181: loss 0.695 0.234375 0.484375
iteration 182: loss 0.559 0.351562 0.484375
iteration 183: loss 0.446 0.281250 0.515625
iteration 184: loss 0.514 0.335938 0.468750
iteration 185: loss 0.608 0.359375 0.460938
iteration 186: loss 0.582 0.343750 0.429688
iteration 187: loss 0.582 0.242188 0.414062
iteration 188: loss 0.793 0.382812 0.359375
iteration 189: loss 0.560 0.375000 0.578125
iteration 190: loss 0.544 0.312500 0.515625
iteration 191: loss 0.609 0.320312 0.421875
iteration 192: loss 0.512 0.375000 0.500000
iteration 193: loss 0.635 0.359375 0.445312
iteration 194: loss 0.710 0.312500 0.437500
iteration 195: loss 0.595 0.257812 0.445312
iteration 196: loss 0.662 0.296875 0.421875
iteration 197: loss 0.588 0.351562 0.406250
iteration 198: loss 0.558 0.273438 0.500000
iteration 199: loss 0.730 0.304688 0.468750
iteration 200: loss 0.590 0.296875 0.523438
iteration 201: loss 0.757 0.320312 0.437500
iteration 202: loss 0.727 0.335938 0.460938
iteration 203: loss 0.563 0.375000 0.570312
iteration 204: loss 0.657 0.234375 0.484375
iteration 205: loss 0.625 0.304688 0.507812
iteration 206: loss 0.666 0.320312 0.453125
iteration 207: loss 0.645 0.320312 0.421875
iteration 208: loss 0.546 0.328125 0.515625
iteration 209: loss 0.608 0.335938 0.523438
iteration 210: loss 0.666 0.250000 0.468750
iteration 211: loss 0.714 0.359375 0.484375
iteration 212: loss 0.695 0.375000 0.460938
iteration 213: loss 0.617 0.296875 0.484375
iteration 214: loss 0.558 0.335938 0.492188
iteration 215: loss 0.663 0.320312 0.437500
iteration 216: loss 0.641 0.304688 0.484375
iteration 217: loss 0.570 0.281250 0.546875
iteration 218: loss 0.775 0.328125 0.500000
iteration 219: loss 0.588 0.468750 0.546875
iteration 220: loss 0.671 0.304688 0.460938
iteration 221: loss 0.581 0.367188 0.507812
iteration 222: loss 0.614 0.375000 0.484375
iteration 223: loss 0.620 0.343750 0.468750
iteration 224: loss 0.830 0.273438 0.445312
iteration 225: loss 0.874 0.351562 0.343750
iteration 226: loss 0.575 0.312500 0.406250
iteration 227: loss 0.597 0.281250 0.445312
iteration 228: loss 0.570 0.273438 0.507812
iteration 229: loss 0.610 0.328125 0.445312
iteration 230: loss 0.745 0.242188 0.484375
iteration 231: loss 0.694 0.343750 0.445312
iteration 232: loss 0.697 0.328125 0.476562
iteration 233: loss 0.728 0.250000 0.398438
iteration 234: loss 0.537 0.312500 0.445312
iteration 235: loss 0.640 0.281250 0.507812
iteration 236: loss 0.741 0.242188 0.343750
iteration 237: loss 0.463 0.429688 0.492188
iteration 238: loss 0.643 0.320312 0.453125
iteration 239: loss 0.579 0.398438 0.468750
iteration 240: loss 0.635 0.273438 0.539062
iteration 241: loss 0.842 0.226562 0.398438
iteration 242: loss 0.569 0.367188 0.476562
iteration 243: loss 0.671 0.203125 0.453125
iteration 244: loss 0.689 0.382812 0.421875
iteration 245: loss 0.675 0.351562 0.460938
iteration 246: loss 0.670 0.265625 0.507812
iteration 247: loss 0.626 0.289062 0.570312
iteration 248: loss 0.559 0.257812 0.492188
iteration 249: loss 0.670 0.250000 0.390625
iteration 250: loss 0.658 0.312500 0.468750
iteration 251: loss 0.614 0.320312 0.484375
iteration 252: loss 0.702 0.250000 0.476562
iteration 253: loss 0.777 0.273438 0.429688
iteration 254: loss 0.644 0.187500 0.429688
iteration 255: loss 0.635 0.250000 0.468750
iteration 256: loss 0.750 0.273438 0.398438
iteration 257: loss 0.750 0.296875 0.453125
iteration 258: loss 0.682 0.273438 0.515625
iteration 259: loss 0.624 0.367188 0.453125
iteration 260: loss 0.481 0.257812 0.500000
iteration 261: loss 0.622 0.320312 0.429688
iteration 262: loss 0.575 0.304688 0.437500
iteration 263: loss 0.737 0.289062 0.382812
iteration 264: loss 0.619 0.328125 0.453125
iteration 265: loss 0.658 0.351562 0.507812
iteration 266: loss 0.701 0.351562 0.414062
iteration 267: loss 0.671 0.304688 0.484375
iteration 268: loss 0.662 0.273438 0.500000
iteration 269: loss 0.553 0.351562 0.468750
iteration 270: loss 0.608 0.281250 0.500000
iteration 271: loss 0.722 0.343750 0.414062
iteration 272: loss 0.692 0.359375 0.460938
iteration 273: loss 0.679 0.242188 0.484375
iteration 274: loss 0.723 0.257812 0.468750
iteration 275: loss 0.770 0.351562 0.437500
iteration 276: loss 0.697 0.343750 0.437500
iteration 277: loss 0.686 0.328125 0.414062
iteration 278: loss 0.560 0.320312 0.445312
iteration 279: loss 0.697 0.289062 0.468750
iteration 280: loss 0.693 0.320312 0.500000
iteration 281: loss 0.665 0.281250 0.476562
iteration 282: loss 0.816 0.320312 0.437500
iteration 283: loss 0.667 0.328125 0.484375
iteration 284: loss 0.497 0.335938 0.468750
iteration 285: loss 0.599 0.281250 0.445312
iteration 286: loss 0.742 0.289062 0.429688
iteration 287: loss 0.641 0.281250 0.476562
iteration 288: loss 0.729 0.296875 0.398438
iteration 289: loss 0.610 0.289062 0.445312
iteration 290: loss 0.568 0.289062 0.531250
iteration 291: loss 0.637 0.304688 0.484375
iteration 292: loss 0.621 0.335938 0.460938
iteration 293: loss 0.622 0.265625 0.500000
iteration 294: loss 0.656 0.335938 0.500000
iteration 295: loss 0.802 0.335938 0.421875
iteration 296: loss 0.606 0.265625 0.445312
iteration 297: loss 0.691 0.343750 0.398438
iteration 298: loss 0.740 0.328125 0.460938
iteration 299: loss 0.615 0.296875 0.445312
iteration 300: loss 0.568 0.328125 0.445312
iteration 301: loss 0.684 0.390625 0.414062
iteration 302: loss 0.544 0.343750 0.531250
iteration 303: loss 0.713 0.320312 0.500000
iteration 304: loss 0.666 0.320312 0.492188
iteration 305: loss 0.588 0.320312 0.453125
iteration 306: loss 0.561 0.328125 0.492188
iteration 307: loss 0.606 0.296875 0.492188
iteration 308: loss 0.560 0.273438 0.515625
iteration 309: loss 0.566 0.328125 0.476562
iteration 310: loss 0.607 0.335938 0.476562
iteration 311: loss 0.707 0.281250 0.445312
iteration 312: loss 0.645 0.289062 0.445312
iteration 313: loss 0.626 0.281250 0.382812
iteration 314: loss 0.540 0.304688 0.507812
iteration 315: loss 0.627 0.296875 0.445312
iteration 316: loss 0.583 0.226562 0.484375
iteration 317: loss 0.720 0.257812 0.421875
iteration 318: loss 0.754 0.335938 0.445312
iteration 319: loss 0.618 0.273438 0.554688
iteration 320: loss 0.789 0.328125 0.476562
iteration 321: loss 0.708 0.218750 0.453125
iteration 322: loss 0.673 0.257812 0.492188
iteration 323: loss 0.822 0.382812 0.445312
iteration 324: loss 0.579 0.296875 0.476562
iteration 325: loss 0.592 0.304688 0.570312
iteration 326: loss 0.696 0.289062 0.445312
iteration 327: loss 0.587 0.351562 0.429688
iteration 328: loss 0.688 0.296875 0.414062
iteration 329: loss 0.693 0.281250 0.437500
iteration 330: loss 0.692 0.304688 0.445312
iteration 331: loss 0.558 0.343750 0.484375
iteration 332: loss 0.712 0.296875 0.437500
iteration 333: loss 0.549 0.281250 0.507812
iteration 334: loss 0.584 0.257812 0.484375
iteration 335: loss 0.699 0.250000 0.523438
iteration 336: loss 0.557 0.304688 0.515625
iteration 337: loss 0.704 0.218750 0.406250
iteration 338: loss 0.699 0.367188 0.445312
iteration 339: loss 0.690 0.375000 0.414062
iteration 340: loss 0.718 0.250000 0.484375
iteration 341: loss 0.789 0.273438 0.429688
iteration 342: loss 0.740 0.359375 0.445312
iteration 343: loss 0.709 0.328125 0.476562
iteration 344: loss 0.627 0.320312 0.500000
iteration 345: loss 0.738 0.351562 0.453125
iteration 346: loss 0.660 0.367188 0.500000
iteration 347: loss 0.651 0.289062 0.390625
iteration 348: loss 0.757 0.351562 0.492188
iteration 349: loss 0.521 0.281250 0.531250
iteration 350: loss 0.625 0.328125 0.523438
iteration 351: loss 0.647 0.289062 0.484375
iteration 352: loss 0.643 0.359375 0.507812
iteration 353: loss 0.724 0.304688 0.492188
iteration 354: loss 0.611 0.351562 0.460938
iteration 355: loss 0.630 0.320312 0.468750
iteration 356: loss 0.595 0.367188 0.546875
iteration 357: loss 0.705 0.304688 0.429688
iteration 358: loss 0.590 0.343750 0.460938
iteration 359: loss 0.587 0.304688 0.460938
iteration 360: loss 0.662 0.250000 0.445312
iteration 361: loss 0.649 0.320312 0.500000
iteration 362: loss 0.595 0.265625 0.546875
iteration 363: loss 0.698 0.242188 0.437500
iteration 364: loss 0.692 0.312500 0.523438
iteration 365: loss 0.641 0.281250 0.453125
iteration 366: loss 0.698 0.281250 0.429688
iteration 367: loss 0.599 0.273438 0.421875
iteration 368: loss 0.642 0.296875 0.507812
iteration 369: loss 0.734 0.367188 0.445312
iteration 370: loss 0.759 0.398438 0.453125
iteration 371: loss 0.568 0.273438 0.515625
iteration 372: loss 0.686 0.273438 0.429688
iteration 373: loss 0.633 0.320312 0.507812
iteration 374: loss 0.602 0.343750 0.468750
iteration 375: loss 0.558 0.320312 0.492188
iteration 376: loss 0.558 0.328125 0.492188
iteration 377: loss 0.762 0.335938 0.375000
iteration 378: loss 0.609 0.304688 0.500000
iteration 379: loss 0.721 0.265625 0.421875
iteration 380: loss 0.641 0.320312 0.492188
iteration 381: loss 0.834 0.375000 0.429688
iteration 382: loss 0.604 0.328125 0.507812
iteration 383: loss 0.523 0.328125 0.578125
iteration 384: loss 0.604 0.328125 0.484375
iteration 385: loss 0.671 0.312500 0.468750
iteration 386: loss 0.679 0.273438 0.476562
iteration 387: loss 0.704 0.257812 0.429688
iteration 388: loss 0.556 0.179688 0.554688
iteration 389: loss 0.571 0.398438 0.492188
iteration 390: loss 0.546 0.367188 0.515625
iteration 391: loss 0.777 0.296875 0.390625
iteration 392: loss 0.789 0.359375 0.414062
iteration 393: loss 0.705 0.320312 0.445312
iteration 394: loss 0.685 0.390625 0.437500
iteration 395: loss 0.695 0.328125 0.445312
iteration 396: loss 0.683 0.234375 0.492188
iteration 397: loss 0.607 0.312500 0.515625
iteration 398: loss 0.762 0.273438 0.453125
iteration 399: loss 0.707 0.265625 0.500000
iteration 400: loss 0.737 0.390625 0.429688
iteration 401: loss 0.611 0.289062 0.468750
iteration 402: loss 0.469 0.335938 0.484375
iteration 403: loss 0.734 0.312500 0.414062
iteration 404: loss 0.616 0.328125 0.429688
iteration 405: loss 0.655 0.328125 0.437500
iteration 406: loss 0.646 0.296875 0.406250
iteration 407: loss 0.608 0.304688 0.476562
iteration 408: loss 0.715 0.312500 0.429688
iteration 409: loss 0.659 0.296875 0.453125
iteration 410: loss 0.654 0.273438 0.460938
iteration 411: loss 0.656 0.265625 0.453125
iteration 412: loss 0.478 0.335938 0.554688
iteration 413: loss 0.685 0.250000 0.414062
iteration 414: loss 0.545 0.328125 0.507812
iteration 415: loss 0.543 0.304688 0.460938
iteration 416: loss 0.485 0.304688 0.539062
iteration 417: loss 0.728 0.273438 0.421875
iteration 418: loss 0.885 0.250000 0.398438
iteration 419: loss 0.680 0.312500 0.460938
iteration 420: loss 0.595 0.257812 0.460938
iteration 421: loss 0.640 0.289062 0.468750
iteration 422: loss 0.631 0.257812 0.414062
iteration 423: loss 0.618 0.320312 0.421875
iteration 424: loss 0.794 0.304688 0.429688
iteration 425: loss 0.653 0.281250 0.437500
iteration 426: loss 0.562 0.312500 0.492188
iteration 427: loss 0.555 0.296875 0.484375
iteration 428: loss 0.568 0.265625 0.460938
iteration 429: loss 0.603 0.312500 0.414062
iteration 430: loss 0.627 0.304688 0.445312
iteration 431: loss 0.541 0.343750 0.554688
iteration 432: loss 0.681 0.351562 0.460938
iteration 433: loss 0.510 0.320312 0.578125
iteration 434: loss 0.912 0.289062 0.421875
iteration 435: loss 0.718 0.226562 0.507812
iteration 436: loss 0.629 0.273438 0.460938
iteration 437: loss 0.741 0.335938 0.476562
iteration 438: loss 0.607 0.320312 0.453125
iteration 439: loss 0.554 0.289062 0.539062
iteration 440: loss 0.584 0.234375 0.515625
iteration 441: loss 0.659 0.328125 0.382812
iteration 442: loss 0.612 0.335938 0.421875
iteration 443: loss 0.688 0.304688 0.382812
iteration 444: loss 0.800 0.375000 0.484375
iteration 445: loss 0.609 0.437500 0.578125
iteration 446: loss 0.695 0.375000 0.445312
iteration 447: loss 0.581 0.335938 0.507812
iteration 448: loss 0.651 0.312500 0.421875
iteration 449: loss 0.682 0.320312 0.429688
iteration 450: loss 0.665 0.312500 0.421875
iteration 451: loss 0.650 0.351562 0.453125
iteration 452: loss 0.637 0.289062 0.484375
iteration 453: loss 0.751 0.296875 0.398438
iteration 454: loss 0.592 0.289062 0.437500
iteration 455: loss 0.655 0.250000 0.398438
iteration 456: loss 0.626 0.234375 0.445312
iteration 457: loss 0.658 0.343750 0.460938
iteration 458: loss 0.715 0.304688 0.429688
iteration 459: loss 0.740 0.257812 0.359375
iteration 460: loss 0.805 0.289062 0.328125
iteration 461: loss 0.668 0.210938 0.429688
iteration 462: loss 0.574 0.320312 0.476562
iteration 463: loss 0.468 0.367188 0.507812
iteration 464: loss 0.609 0.335938 0.539062
iteration 465: loss 0.702 0.281250 0.476562
iteration 466: loss 0.738 0.304688 0.500000
iteration 467: loss 0.633 0.281250 0.460938
iteration 468: loss 0.704 0.296875 0.500000
iteration 469: loss 0.637 0.460938 0.460938
iteration 470: loss 0.706 0.265625 0.500000
iteration 471: loss 0.629 0.312500 0.414062
iteration 472: loss 0.677 0.273438 0.476562
iteration 473: loss 0.615 0.312500 0.484375
iteration 474: loss 0.617 0.335938 0.500000
iteration 475: loss 0.548 0.351562 0.507812
iteration 476: loss 0.709 0.359375 0.515625
iteration 477: loss 0.657 0.250000 0.437500
iteration 478: loss 0.782 0.359375 0.390625
iteration 479: loss 0.592 0.320312 0.468750
iteration 480: loss 0.392 0.242188 0.539062
iteration 481: loss 0.672 0.265625 0.460938
iteration 482: loss 0.509 0.312500 0.492188
iteration 483: loss 0.605 0.289062 0.460938
iteration 484: loss 0.571 0.343750 0.492188
iteration 485: loss 0.787 0.367188 0.453125
iteration 486: loss 0.707 0.304688 0.414062
iteration 487: loss 0.614 0.312500 0.453125
iteration 488: loss 0.660 0.265625 0.476562
iteration 489: loss 0.675 0.265625 0.460938
iteration 490: loss 0.586 0.289062 0.507812
iteration 491: loss 0.661 0.281250 0.476562
iteration 492: loss 0.667 0.351562 0.390625
iteration 493: loss 0.631 0.289062 0.429688
iteration 494: loss 0.723 0.320312 0.390625
iteration 495: loss 0.609 0.273438 0.468750
iteration 496: loss 0.900 0.257812 0.390625
iteration 497: loss 0.790 0.296875 0.468750
iteration 498: loss 0.548 0.226562 0.507812
iteration 499: loss 0.624 0.328125 0.500000
iteration 500: loss 0.641 0.289062 0.414062
iteration 501: loss 0.587 0.304688 0.468750
iteration 502: loss 0.512 0.320312 0.507812
iteration 503: loss 0.579 0.265625 0.468750
iteration 504: loss 0.609 0.281250 0.515625
iteration 505: loss 0.681 0.257812 0.453125
iteration 506: loss 0.647 0.273438 0.468750
iteration 507: loss 0.500 0.343750 0.531250
iteration 508: loss 0.689 0.296875 0.445312
iteration 509: loss 0.628 0.304688 0.484375
iteration 510: loss 0.632 0.289062 0.437500
iteration 511: loss 0.573 0.242188 0.492188
iteration 512: loss 0.599 0.375000 0.437500
iteration 513: loss 0.802 0.328125 0.351562
iteration 514: loss 0.607 0.304688 0.468750
iteration 515: loss 0.627 0.328125 0.531250
iteration 516: loss 0.775 0.234375 0.484375
iteration 517: loss 0.693 0.320312 0.445312
iteration 518: loss 0.655 0.273438 0.539062
iteration 519: loss 0.716 0.265625 0.476562
iteration 520: loss 0.791 0.320312 0.375000
iteration 521: loss 0.681 0.250000 0.367188
iteration 522: loss 0.535 0.312500 0.507812
iteration 523: loss 0.608 0.296875 0.460938
iteration 524: loss 0.698 0.296875 0.421875
iteration 525: loss 0.671 0.242188 0.437500
iteration 526: loss 0.634 0.195312 0.515625
iteration 527: loss 0.653 0.296875 0.523438
iteration 528: loss 0.573 0.351562 0.476562
iteration 529: loss 0.607 0.312500 0.429688
iteration 530: loss 0.594 0.281250 0.515625
iteration 531: loss 0.688 0.273438 0.445312
iteration 532: loss 0.518 0.414062 0.445312
iteration 533: loss 0.625 0.343750 0.437500
iteration 534: loss 0.602 0.296875 0.453125
iteration 535: loss 0.748 0.351562 0.421875
iteration 536: loss 0.710 0.250000 0.453125
iteration 537: loss 0.603 0.320312 0.507812
iteration 538: loss 0.533 0.250000 0.484375
iteration 539: loss 0.531 0.398438 0.546875
iteration 540: loss 0.718 0.328125 0.421875
iteration 541: loss 0.724 0.335938 0.468750
iteration 542: loss 0.592 0.343750 0.453125
iteration 543: loss 0.731 0.304688 0.421875
iteration 544: loss 0.582 0.320312 0.445312
iteration 545: loss 0.413 0.343750 0.554688
iteration 546: loss 0.490 0.312500 0.507812
iteration 547: loss 0.522 0.328125 0.453125
iteration 548: loss 0.545 0.257812 0.601562
iteration 549: loss 0.664 0.351562 0.468750
iteration 550: loss 0.557 0.234375 0.421875
iteration 551: loss 0.544 0.351562 0.492188
iteration 552: loss 0.625 0.289062 0.500000
iteration 553: loss 0.579 0.273438 0.500000
iteration 554: loss 0.647 0.273438 0.453125
iteration 555: loss 0.625 0.343750 0.492188
iteration 556: loss 0.596 0.296875 0.523438
iteration 557: loss 0.629 0.359375 0.460938
iteration 558: loss 0.767 0.343750 0.476562
iteration 559: loss 0.750 0.328125 0.453125
iteration 560: loss 0.648 0.296875 0.414062
iteration 561: loss 0.658 0.289062 0.367188
iteration 562: loss 0.723 0.265625 0.421875
iteration 563: loss 0.663 0.265625 0.429688
iteration 564: loss 0.735 0.335938 0.437500
iteration 565: loss 0.605 0.335938 0.429688
iteration 566: loss 0.701 0.265625 0.367188
iteration 567: loss 0.733 0.335938 0.429688
iteration 568: loss 0.629 0.335938 0.515625
iteration 569: loss 0.488 0.335938 0.531250
iteration 570: loss 0.624 0.296875 0.500000
iteration 571: loss 0.744 0.343750 0.398438
iteration 572: loss 0.658 0.296875 0.453125
iteration 573: loss 0.615 0.320312 0.476562
iteration 574: loss 0.639 0.335938 0.515625
iteration 575: loss 0.562 0.390625 0.484375
iteration 576: loss 0.554 0.367188 0.453125
iteration 577: loss 0.452 0.289062 0.546875
iteration 578: loss 0.517 0.335938 0.476562
iteration 579: loss 0.695 0.257812 0.406250
iteration 580: loss 0.694 0.312500 0.468750
iteration 581: loss 0.745 0.367188 0.460938
iteration 582: loss 0.656 0.328125 0.429688
iteration 583: loss 0.614 0.320312 0.453125
iteration 584: loss 0.599 0.265625 0.492188
iteration 585: loss 0.663 0.250000 0.476562
iteration 586: loss 0.618 0.367188 0.523438
iteration 587: loss 0.678 0.328125 0.453125
iteration 588: loss 0.582 0.343750 0.554688
iteration 589: loss 0.761 0.210938 0.390625
iteration 590: loss 0.683 0.375000 0.468750
iteration 591: loss 0.732 0.343750 0.476562
iteration 592: loss 0.607 0.375000 0.460938
iteration 593: loss 0.564 0.289062 0.468750
iteration 594: loss 0.581 0.304688 0.398438
iteration 595: loss 0.613 0.375000 0.500000
iteration 596: loss 0.820 0.257812 0.429688
iteration 597: loss 0.656 0.289062 0.468750
iteration 598: loss 0.484 0.304688 0.515625
iteration 599: loss 0.672 0.218750 0.453125
iteration 600: loss 0.546 0.382812 0.531250
iteration 601: loss 0.565 0.289062 0.531250
iteration 602: loss 0.739 0.289062 0.421875
iteration 603: loss 0.819 0.234375 0.390625
iteration 604: loss 0.605 0.335938 0.437500
iteration 605: loss 0.621 0.273438 0.468750
iteration 606: loss 0.669 0.296875 0.500000
iteration 607: loss 0.649 0.296875 0.531250
iteration 608: loss 0.621 0.320312 0.476562
iteration 609: loss 0.710 0.289062 0.492188
iteration 610: loss 0.828 0.312500 0.437500
iteration 611: loss 0.442 0.312500 0.562500
iteration 612: loss 0.695 0.289062 0.445312
iteration 613: loss 0.781 0.328125 0.437500
iteration 614: loss 0.629 0.359375 0.484375
iteration 615: loss 0.588 0.359375 0.500000
iteration 616: loss 0.691 0.289062 0.445312
iteration 617: loss 0.561 0.304688 0.453125
iteration 618: loss 0.519 0.234375 0.507812
iteration 619: loss 0.670 0.343750 0.437500
iteration 620: loss 0.740 0.335938 0.453125
iteration 621: loss 0.762 0.320312 0.390625
iteration 622: loss 0.528 0.273438 0.554688
iteration 623: loss 0.552 0.359375 0.445312
iteration 624: loss 0.609 0.328125 0.453125
iteration 625: loss 0.594 0.281250 0.492188
iteration 626: loss 0.531 0.335938 0.437500
iteration 627: loss 0.694 0.242188 0.484375
iteration 628: loss 0.621 0.281250 0.468750
iteration 629: loss 0.750 0.335938 0.500000
iteration 630: loss 0.753 0.320312 0.429688
iteration 631: loss 0.717 0.281250 0.476562
iteration 632: loss 0.565 0.257812 0.539062
iteration 633: loss 0.700 0.265625 0.414062
iteration 634: loss 0.613 0.359375 0.492188
iteration 635: loss 0.645 0.320312 0.460938
iteration 636: loss 0.585 0.273438 0.437500
iteration 637: loss 0.626 0.304688 0.484375
iteration 638: loss 0.698 0.359375 0.421875
iteration 639: loss 0.582 0.281250 0.453125
iteration 640: loss 0.672 0.375000 0.414062
iteration 641: loss 0.693 0.335938 0.484375
iteration 642: loss 0.694 0.273438 0.398438
iteration 643: loss 0.651 0.304688 0.453125
iteration 644: loss 0.524 0.312500 0.492188
iteration 645: loss 0.654 0.351562 0.445312
iteration 646: loss 0.637 0.296875 0.453125
iteration 647: loss 0.777 0.265625 0.453125
iteration 648: loss 0.662 0.320312 0.414062
iteration 649: loss 0.543 0.398438 0.468750
iteration 650: loss 0.539 0.367188 0.468750
iteration 651: loss 0.768 0.320312 0.453125
iteration 652: loss 0.692 0.367188 0.523438
iteration 653: loss 0.546 0.320312 0.523438
iteration 654: loss 0.791 0.312500 0.421875
iteration 655: loss 0.647 0.242188 0.468750
iteration 656: loss 0.823 0.335938 0.421875
iteration 657: loss 0.643 0.210938 0.484375
iteration 658: loss 0.657 0.281250 0.476562
iteration 659: loss 0.677 0.265625 0.445312
iteration 660: loss 0.728 0.296875 0.437500
iteration 661: loss 0.690 0.335938 0.476562
iteration 662: loss 0.548 0.296875 0.437500
iteration 663: loss 0.778 0.296875 0.414062
iteration 664: loss 0.716 0.312500 0.390625
iteration 665: loss 0.597 0.398438 0.429688
iteration 666: loss 0.662 0.312500 0.437500
iteration 667: loss 0.659 0.312500 0.453125
iteration 668: loss 0.627 0.390625 0.492188
iteration 669: loss 0.655 0.257812 0.554688
iteration 670: loss 0.565 0.289062 0.539062
iteration 671: loss 0.695 0.273438 0.515625
iteration 672: loss 0.788 0.351562 0.429688
iteration 673: loss 0.763 0.281250 0.414062
iteration 674: loss 0.603 0.296875 0.445312
iteration 675: loss 0.609 0.304688 0.453125
iteration 676: loss 0.603 0.335938 0.437500
iteration 677: loss 0.683 0.273438 0.445312
iteration 678: loss 0.689 0.312500 0.414062
iteration 679: loss 0.708 0.335938 0.468750
iteration 680: loss 0.621 0.312500 0.492188
iteration 681: loss 0.665 0.312500 0.484375
iteration 682: loss 0.613 0.351562 0.476562
iteration 683: loss 0.640 0.328125 0.554688
iteration 684: loss 0.607 0.312500 0.460938
iteration 685: loss 0.723 0.312500 0.460938
iteration 686: loss 0.561 0.343750 0.460938
iteration 687: loss 0.675 0.351562 0.476562
iteration 688: loss 0.658 0.273438 0.460938
iteration 689: loss 0.563 0.273438 0.500000
iteration 690: loss 0.621 0.296875 0.492188
iteration 691: loss 0.605 0.289062 0.468750
iteration 692: loss 0.619 0.289062 0.429688
iteration 693: loss 0.711 0.335938 0.445312
iteration 694: loss 0.675 0.320312 0.484375
iteration 695: loss 0.634 0.289062 0.468750
iteration 696: loss 0.761 0.265625 0.398438
iteration 697: loss 0.684 0.367188 0.515625
iteration 698: loss 0.702 0.281250 0.414062
iteration 699: loss 0.669 0.289062 0.445312
iteration 700: loss 0.719 0.343750 0.453125
iteration 701: loss 0.683 0.351562 0.390625
iteration 702: loss 0.523 0.328125 0.507812
iteration 703: loss 0.680 0.312500 0.445312
iteration 704: loss 0.617 0.242188 0.421875
iteration 705: loss 0.744 0.312500 0.414062
iteration 706: loss 0.609 0.265625 0.406250
iteration 707: loss 0.621 0.281250 0.492188
iteration 708: loss 0.680 0.281250 0.414062
iteration 709: loss 0.667 0.296875 0.437500
iteration 710: loss 0.569 0.320312 0.445312
iteration 711: loss 0.634 0.242188 0.515625
iteration 712: loss 0.843 0.296875 0.390625
iteration 713: loss 0.591 0.304688 0.468750
iteration 714: loss 0.698 0.296875 0.414062
iteration 715: loss 0.504 0.367188 0.484375
iteration 716: loss 0.657 0.296875 0.421875
iteration 717: loss 0.695 0.312500 0.437500
iteration 718: loss 0.636 0.281250 0.484375
iteration 719: loss 0.587 0.343750 0.429688
iteration 720: loss 0.653 0.351562 0.476562
iteration 721: loss 0.695 0.351562 0.375000
iteration 722: loss 0.643 0.312500 0.484375
iteration 723: loss 0.667 0.296875 0.437500
iteration 724: loss 0.701 0.289062 0.460938
iteration 725: loss 0.761 0.289062 0.367188
iteration 726: loss 0.787 0.296875 0.382812
iteration 727: loss 0.591 0.320312 0.406250
iteration 728: loss 0.554 0.273438 0.500000
iteration 729: loss 0.536 0.296875 0.460938
iteration 730: loss 0.556 0.265625 0.500000
iteration 731: loss 0.677 0.281250 0.515625
iteration 732: loss 0.640 0.226562 0.500000
iteration 733: loss 0.643 0.289062 0.492188
iteration 734: loss 0.652 0.343750 0.406250
iteration 735: loss 0.760 0.273438 0.375000
iteration 736: loss 0.672 0.257812 0.390625
iteration 737: loss 0.528 0.320312 0.476562
iteration 738: loss 0.645 0.265625 0.437500
iteration 739: loss 0.623 0.265625 0.460938
iteration 740: loss 0.632 0.320312 0.468750
iteration 741: loss 0.671 0.382812 0.453125
iteration 742: loss 0.656 0.273438 0.445312
iteration 743: loss 0.635 0.312500 0.484375
iteration 744: loss 0.551 0.289062 0.484375
iteration 745: loss 0.648 0.210938 0.515625
iteration 746: loss 0.636 0.375000 0.453125
iteration 747: loss 0.687 0.273438 0.460938
iteration 748: loss 0.699 0.296875 0.507812
iteration 749: loss 0.553 0.359375 0.500000
iteration 750: loss 0.696 0.234375 0.515625
iteration 751: loss 0.685 0.281250 0.398438
iteration 752: loss 0.691 0.273438 0.367188
iteration 753: loss 0.597 0.273438 0.460938
iteration 754: loss 0.722 0.289062 0.476562
iteration 755: loss 0.704 0.234375 0.484375
iteration 756: loss 0.700 0.265625 0.367188
iteration 757: loss 0.551 0.320312 0.500000
iteration 758: loss 0.611 0.367188 0.476562
iteration 759: loss 0.491 0.273438 0.531250
iteration 760: loss 0.656 0.273438 0.476562
iteration 761: loss 0.681 0.257812 0.500000
iteration 762: loss 0.704 0.351562 0.390625
iteration 763: loss 0.736 0.312500 0.367188
iteration 764: loss 0.636 0.320312 0.406250
iteration 765: loss 0.631 0.304688 0.414062
iteration 766: loss 0.800 0.312500 0.468750
iteration 767: loss 0.656 0.296875 0.445312
iteration 768: loss 0.569 0.375000 0.500000
iteration 769: loss 0.576 0.359375 0.492188
iteration 770: loss 0.703 0.257812 0.468750
iteration 771: loss 0.663 0.250000 0.515625
iteration 772: loss 0.656 0.304688 0.437500
iteration 773: loss 0.617 0.335938 0.492188
iteration 774: loss 0.612 0.304688 0.500000
iteration 775: loss 0.681 0.289062 0.437500
iteration 776: loss 0.559 0.296875 0.468750
iteration 777: loss 0.532 0.273438 0.492188
iteration 778: loss 0.601 0.398438 0.476562
iteration 779: loss 0.552 0.312500 0.492188
iteration 780: loss 0.697 0.289062 0.375000
iteration 781: loss 0.666 0.390625 0.406250
iteration 782: loss 0.644 0.250000 0.515625
iteration 783: loss 0.572 0.328125 0.453125
iteration 784: loss 0.631 0.257812 0.421875
iteration 785: loss 0.715 0.328125 0.445312
iteration 786: loss 0.646 0.250000 0.460938
iteration 787: loss 0.598 0.375000 0.492188
iteration 788: loss 0.631 0.281250 0.492188
iteration 789: loss 0.488 0.328125 0.500000
iteration 790: loss 0.466 0.242188 0.554688
iteration 791: loss 0.657 0.328125 0.500000
iteration 792: loss 0.625 0.273438 0.484375
iteration 793: loss 0.755 0.257812 0.476562
iteration 794: loss 0.736 0.312500 0.398438
iteration 795: loss 0.732 0.281250 0.445312
iteration 796: loss 0.651 0.273438 0.460938
iteration 797: loss 0.740 0.304688 0.476562
iteration 798: loss 0.758 0.320312 0.460938
iteration 799: loss 0.582 0.304688 0.437500
iteration 800: loss 0.702 0.312500 0.390625
iteration 801: loss 0.578 0.343750 0.500000
iteration 802: loss 0.682 0.335938 0.437500
iteration 803: loss 0.570 0.265625 0.468750
iteration 804: loss 0.604 0.351562 0.507812
iteration 805: loss 0.709 0.281250 0.484375
iteration 806: loss 0.675 0.320312 0.406250
iteration 807: loss 0.649 0.328125 0.515625
iteration 808: loss 0.788 0.304688 0.406250
iteration 809: loss 0.845 0.335938 0.382812
iteration 810: loss 0.655 0.328125 0.406250
iteration 811: loss 0.489 0.273438 0.539062
iteration 812: loss 0.488 0.296875 0.507812
iteration 813: loss 0.664 0.312500 0.507812
iteration 814: loss 0.495 0.312500 0.523438
iteration 815: loss 0.514 0.242188 0.539062
iteration 816: loss 0.650 0.335938 0.445312
iteration 817: loss 0.651 0.289062 0.421875
iteration 818: loss 0.627 0.335938 0.531250
iteration 819: loss 0.591 0.273438 0.453125
iteration 820: loss 0.605 0.296875 0.445312
iteration 821: loss 0.661 0.304688 0.453125
iteration 822: loss 0.641 0.296875 0.445312
iteration 823: loss 0.703 0.226562 0.429688
iteration 824: loss 0.707 0.335938 0.476562
iteration 825: loss 0.592 0.296875 0.437500
iteration 826: loss 0.632 0.281250 0.468750
iteration 827: loss 0.821 0.257812 0.382812
iteration 828: loss 0.841 0.312500 0.429688
iteration 829: loss 0.769 0.367188 0.406250
iteration 830: loss 0.547 0.296875 0.429688
iteration 831: loss 0.581 0.304688 0.414062
iteration 832: loss 0.707 0.250000 0.382812
iteration 833: loss 0.598 0.289062 0.453125
iteration 834: loss 0.694 0.257812 0.460938
iteration 835: loss 0.633 0.328125 0.484375
iteration 836: loss 0.680 0.312500 0.445312
iteration 837: loss 0.614 0.304688 0.546875
iteration 838: loss 0.607 0.281250 0.453125
iteration 839: loss 0.839 0.320312 0.468750
iteration 840: loss 0.635 0.328125 0.476562
iteration 841: loss 0.608 0.312500 0.429688
iteration 842: loss 0.763 0.242188 0.437500
iteration 843: loss 0.702 0.320312 0.421875
iteration 844: loss 0.760 0.312500 0.414062
iteration 845: loss 0.732 0.289062 0.453125
iteration 846: loss 0.723 0.257812 0.437500
iteration 847: loss 0.596 0.351562 0.453125
iteration 848: loss 0.689 0.296875 0.421875
iteration 849: loss 0.523 0.171875 0.578125
iteration 850: loss 0.566 0.320312 0.500000
iteration 851: loss 0.727 0.351562 0.437500
iteration 852: loss 0.584 0.351562 0.539062
iteration 853: loss 0.702 0.296875 0.500000
iteration 854: loss 0.571 0.289062 0.468750
iteration 855: loss 0.473 0.312500 0.570312
iteration 856: loss 0.557 0.320312 0.515625
iteration 857: loss 0.654 0.296875 0.492188
iteration 858: loss 0.677 0.265625 0.460938
iteration 859: loss 0.597 0.312500 0.468750
iteration 860: loss 0.722 0.296875 0.484375
iteration 861: loss 0.661 0.296875 0.429688
iteration 862: loss 0.582 0.390625 0.414062
iteration 863: loss 0.804 0.421875 0.398438
iteration 864: loss 0.497 0.335938 0.500000
iteration 865: loss 0.748 0.304688 0.398438
iteration 866: loss 0.575 0.250000 0.507812
iteration 867: loss 0.702 0.312500 0.429688
iteration 868: loss 0.607 0.296875 0.554688
iteration 869: loss 0.662 0.296875 0.484375
iteration 870: loss 0.574 0.265625 0.570312
iteration 871: loss 0.664 0.359375 0.429688
iteration 872: loss 0.468 0.281250 0.476562
iteration 873: loss 0.694 0.296875 0.406250
iteration 874: loss 0.625 0.320312 0.445312
iteration 875: loss 0.534 0.359375 0.539062
iteration 876: loss 0.555 0.304688 0.468750
iteration 877: loss 0.533 0.257812 0.531250
iteration 878: loss 0.634 0.304688 0.468750
iteration 879: loss 0.575 0.312500 0.492188
iteration 880: loss 0.601 0.320312 0.484375
iteration 881: loss 0.669 0.257812 0.406250
iteration 882: loss 0.581 0.289062 0.453125
iteration 883: loss 0.446 0.335938 0.554688
iteration 884: loss 0.635 0.351562 0.484375
iteration 885: loss 0.500 0.218750 0.437500
iteration 886: loss 0.589 0.289062 0.476562
iteration 887: loss 0.608 0.296875 0.468750
iteration 888: loss 0.509 0.359375 0.515625
iteration 889: loss 0.594 0.289062 0.531250
iteration 890: loss 0.646 0.304688 0.468750
iteration 891: loss 0.635 0.210938 0.484375
iteration 892: loss 0.591 0.312500 0.507812
iteration 893: loss 0.688 0.351562 0.437500
iteration 894: loss 0.759 0.234375 0.468750
iteration 895: loss 0.717 0.281250 0.406250
iteration 896: loss 0.555 0.359375 0.453125
iteration 897: loss 0.698 0.265625 0.421875
iteration 898: loss 0.536 0.320312 0.492188
iteration 899: loss 0.719 0.234375 0.390625
iteration 900: loss 0.508 0.296875 0.554688
iteration 901: loss 0.799 0.328125 0.453125
iteration 902: loss 0.624 0.367188 0.476562
iteration 903: loss 0.499 0.359375 0.562500
iteration 904: loss 0.562 0.273438 0.539062
iteration 905: loss 0.883 0.351562 0.421875
iteration 906: loss 0.627 0.265625 0.492188
iteration 907: loss 0.719 0.250000 0.406250
iteration 908: loss 0.678 0.289062 0.445312
iteration 909: loss 0.541 0.328125 0.445312
iteration 910: loss 0.672 0.273438 0.453125
iteration 911: loss 0.711 0.250000 0.390625
iteration 912: loss 0.664 0.320312 0.406250
iteration 913: loss 0.529 0.312500 0.453125
iteration 914: loss 0.594 0.398438 0.414062
iteration 915: loss 0.757 0.351562 0.460938
iteration 916: loss 0.673 0.273438 0.445312
iteration 917: loss 0.598 0.320312 0.453125
iteration 918: loss 0.476 0.296875 0.578125
iteration 919: loss 0.614 0.335938 0.500000
iteration 920: loss 0.649 0.312500 0.500000
iteration 921: loss 0.517 0.312500 0.476562
iteration 922: loss 0.557 0.328125 0.453125
iteration 923: loss 0.509 0.312500 0.453125
iteration 924: loss 0.521 0.265625 0.437500
iteration 925: loss 0.662 0.304688 0.414062
iteration 926: loss 0.561 0.289062 0.460938
iteration 927: loss 0.798 0.296875 0.476562
iteration 928: loss 0.717 0.281250 0.453125
iteration 929: loss 0.664 0.367188 0.476562
iteration 930: loss 0.562 0.335938 0.492188
iteration 931: loss 0.820 0.359375 0.359375
iteration 932: loss 0.874 0.257812 0.351562
iteration 933: loss 0.610 0.343750 0.460938
iteration 934: loss 0.583 0.312500 0.468750
iteration 935: loss 0.729 0.273438 0.414062
iteration 936: loss 0.624 0.257812 0.554688
iteration 937: loss 0.632 0.265625 0.437500
iteration 938: loss 0.716 0.273438 0.382812
iteration 939: loss 0.778 0.343750 0.382812
iteration 940: loss 0.848 0.273438 0.414062
iteration 941: loss 0.623 0.328125 0.484375
iteration 942: loss 0.646 0.375000 0.437500
iteration 943: loss 0.496 0.281250 0.484375
iteration 944: loss 0.529 0.312500 0.492188
iteration 945: loss 0.672 0.289062 0.453125
iteration 946: loss 0.664 0.320312 0.437500
iteration 947: loss 0.528 0.289062 0.445312
iteration 948: loss 0.627 0.328125 0.437500
iteration 949: loss 0.751 0.359375 0.445312
iteration 950: loss 0.737 0.320312 0.460938
iteration 951: loss 0.511 0.289062 0.523438
iteration 952: loss 0.548 0.281250 0.570312
iteration 953: loss 0.810 0.257812 0.367188
iteration 954: loss 0.615 0.304688 0.531250
iteration 955: loss 0.595 0.218750 0.437500
iteration 956: loss 0.594 0.257812 0.476562
iteration 957: loss 0.795 0.289062 0.304688
iteration 958: loss 0.766 0.335938 0.390625
iteration 959: loss 0.787 0.375000 0.445312
iteration 960: loss 0.566 0.250000 0.453125
iteration 961: loss 0.631 0.320312 0.500000
iteration 962: loss 0.640 0.273438 0.476562
iteration 963: loss 0.726 0.343750 0.406250
iteration 964: loss 0.506 0.281250 0.500000
iteration 965: loss 0.586 0.226562 0.414062
iteration 966: loss 0.739 0.296875 0.414062
iteration 967: loss 0.670 0.312500 0.460938
iteration 968: loss 0.717 0.281250 0.468750
iteration 969: loss 0.611 0.289062 0.390625
iteration 970: loss 0.533 0.218750 0.453125
iteration 971: loss 0.675 0.273438 0.421875
iteration 972: loss 0.620 0.304688 0.515625
iteration 973: loss 0.572 0.312500 0.515625
iteration 974: loss 0.755 0.375000 0.460938
iteration 975: loss 0.685 0.328125 0.445312
iteration 976: loss 0.442 0.265625 0.554688
iteration 977: loss 0.635 0.296875 0.445312
iteration 978: loss 0.614 0.273438 0.500000
iteration 979: loss 0.679 0.304688 0.414062
iteration 980: loss 0.699 0.257812 0.429688
iteration 981: loss 0.654 0.335938 0.507812
iteration 982: loss 0.522 0.250000 0.507812
iteration 983: loss 0.538 0.312500 0.468750
iteration 984: loss 0.783 0.335938 0.367188
iteration 985: loss 0.611 0.328125 0.500000
iteration 986: loss 0.559 0.320312 0.492188
iteration 987: loss 0.612 0.351562 0.484375
iteration 988: loss 0.773 0.351562 0.460938
iteration 989: loss 0.804 0.351562 0.453125
iteration 990: loss 0.639 0.367188 0.484375
iteration 991: loss 0.674 0.312500 0.421875
iteration 992: loss 0.745 0.296875 0.421875
iteration 993: loss 0.609 0.382812 0.453125
iteration 994: loss 0.507 0.320312 0.539062
iteration 995: loss 0.580 0.250000 0.531250
iteration 996: loss 0.555 0.218750 0.539062
iteration 997: loss 0.550 0.359375 0.554688
iteration 998: loss 0.621 0.343750 0.507812
iteration 999: loss 0.598 0.289062 0.515625
epoch 10: training: 0.343750 validation: 0.203125
iteration 0: loss 0.719 0.335938 0.437500
iteration 1: loss 0.608 0.257812 0.492188
iteration 2: loss 0.663 0.351562 0.468750
iteration 3: loss 0.562 0.265625 0.492188
iteration 4: loss 0.702 0.273438 0.453125
iteration 5: loss 0.634 0.328125 0.445312
iteration 6: loss 0.647 0.273438 0.445312
iteration 7: loss 0.509 0.328125 0.531250
iteration 8: loss 0.511 0.296875 0.492188
iteration 9: loss 0.678 0.304688 0.429688
iteration 10: loss 0.718 0.343750 0.398438
iteration 11: loss 0.589 0.367188 0.429688
iteration 12: loss 0.680 0.289062 0.390625
iteration 13: loss 0.649 0.367188 0.375000
iteration 14: loss 0.604 0.281250 0.515625
iteration 15: loss 0.551 0.234375 0.492188
iteration 16: loss 0.586 0.304688 0.500000
iteration 17: loss 0.428 0.320312 0.546875
iteration 18: loss 0.616 0.289062 0.382812
iteration 19: loss 0.687 0.289062 0.421875
iteration 20: loss 0.677 0.343750 0.460938
iteration 21: loss 0.733 0.257812 0.421875
iteration 22: loss 0.701 0.328125 0.492188
iteration 23: loss 0.638 0.281250 0.406250
iteration 24: loss 0.459 0.304688 0.500000
iteration 25: loss 0.511 0.304688 0.421875
iteration 26: loss 0.589 0.312500 0.414062
iteration 27: loss 0.518 0.328125 0.554688
iteration 28: loss 0.575 0.328125 0.500000
iteration 29: loss 0.653 0.289062 0.507812
iteration 30: loss 0.587 0.320312 0.484375
iteration 31: loss 0.572 0.328125 0.445312
iteration 32: loss 0.594 0.312500 0.476562
iteration 33: loss 0.878 0.304688 0.406250
iteration 34: loss 0.752 0.304688 0.421875
iteration 35: loss 0.647 0.242188 0.468750
iteration 36: loss 0.657 0.335938 0.429688
iteration 37: loss 0.653 0.328125 0.460938
iteration 38: loss 0.678 0.375000 0.468750
iteration 39: loss 0.720 0.351562 0.460938
iteration 40: loss 0.689 0.296875 0.492188
iteration 41: loss 0.747 0.296875 0.515625
iteration 42: loss 0.616 0.281250 0.484375
iteration 43: loss 0.514 0.320312 0.492188
iteration 44: loss 0.553 0.273438 0.539062
iteration 45: loss 0.781 0.406250 0.460938
iteration 46: loss 0.638 0.273438 0.445312
iteration 47: loss 0.742 0.359375 0.437500
iteration 48: loss 0.726 0.257812 0.375000
iteration 49: loss 0.589 0.281250 0.515625
iteration 50: loss 0.787 0.218750 0.406250
iteration 51: loss 0.672 0.312500 0.468750
iteration 52: loss 0.582 0.359375 0.460938
iteration 53: loss 0.608 0.289062 0.437500
iteration 54: loss 0.681 0.320312 0.398438
iteration 55: loss 0.554 0.289062 0.468750
iteration 56: loss 0.567 0.257812 0.445312
iteration 57: loss 0.743 0.273438 0.476562
iteration 58: loss 0.670 0.367188 0.445312
iteration 59: loss 0.644 0.195312 0.414062
iteration 60: loss 0.517 0.335938 0.484375
iteration 61: loss 0.630 0.273438 0.484375
iteration 62: loss 0.678 0.343750 0.445312
iteration 63: loss 0.553 0.273438 0.492188
iteration 64: loss 0.539 0.289062 0.492188
iteration 65: loss 0.624 0.273438 0.539062
iteration 66: loss 0.549 0.281250 0.492188
iteration 67: loss 0.546 0.296875 0.554688
iteration 68: loss 0.666 0.359375 0.476562
iteration 69: loss 0.488 0.296875 0.523438
iteration 70: loss 0.594 0.273438 0.429688
iteration 71: loss 0.538 0.296875 0.460938
iteration 72: loss 0.638 0.265625 0.351562
iteration 73: loss 0.469 0.265625 0.515625
iteration 74: loss 0.676 0.296875 0.468750
iteration 75: loss 0.537 0.312500 0.453125
iteration 76: loss 0.618 0.296875 0.445312
iteration 77: loss 0.595 0.257812 0.453125
iteration 78: loss 0.487 0.312500 0.523438
iteration 79: loss 0.526 0.437500 0.406250
iteration 80: loss 0.725 0.273438 0.390625
iteration 81: loss 0.476 0.296875 0.460938
iteration 82: loss 0.679 0.328125 0.406250
iteration 83: loss 0.591 0.335938 0.507812
iteration 84: loss 0.579 0.304688 0.484375
iteration 85: loss 0.687 0.367188 0.421875
iteration 86: loss 0.814 0.273438 0.414062
iteration 87: loss 0.613 0.289062 0.468750
iteration 88: loss 0.586 0.343750 0.453125
iteration 89: loss 0.592 0.265625 0.429688
iteration 90: loss 0.646 0.335938 0.375000
iteration 91: loss 0.703 0.320312 0.476562
iteration 92: loss 0.660 0.312500 0.421875
iteration 93: loss 0.500 0.257812 0.500000
iteration 94: loss 0.576 0.328125 0.507812
iteration 95: loss 0.646 0.312500 0.437500
iteration 96: loss 0.508 0.468750 0.500000
iteration 97: loss 0.764 0.257812 0.492188
iteration 98: loss 0.773 0.289062 0.429688
iteration 99: loss 0.666 0.289062 0.468750
iteration 100: loss 0.563 0.250000 0.460938
iteration 101: loss 0.583 0.265625 0.515625
iteration 102: loss 0.600 0.343750 0.445312
iteration 103: loss 0.603 0.312500 0.546875
iteration 104: loss 0.697 0.304688 0.445312
iteration 105: loss 0.584 0.351562 0.460938
iteration 106: loss 0.517 0.273438 0.460938
iteration 107: loss 0.545 0.234375 0.476562
iteration 108: loss 0.785 0.367188 0.359375
iteration 109: loss 0.809 0.320312 0.429688
iteration 110: loss 0.639 0.320312 0.437500
iteration 111: loss 0.775 0.328125 0.437500
iteration 112: loss 0.489 0.226562 0.460938
iteration 113: loss 0.631 0.257812 0.429688
iteration 114: loss 0.769 0.335938 0.406250
iteration 115: loss 0.686 0.328125 0.406250
iteration 116: loss 0.523 0.296875 0.484375
iteration 117: loss 0.624 0.320312 0.476562
iteration 118: loss 0.646 0.250000 0.476562
iteration 119: loss 0.668 0.312500 0.414062
iteration 120: loss 0.550 0.320312 0.453125
iteration 121: loss 0.506 0.320312 0.531250
iteration 122: loss 0.816 0.281250 0.398438
iteration 123: loss 0.564 0.343750 0.484375
iteration 124: loss 0.515 0.304688 0.523438
iteration 125: loss 0.492 0.328125 0.468750
iteration 126: loss 0.756 0.273438 0.437500
iteration 127: loss 0.604 0.250000 0.492188
iteration 128: loss 0.608 0.289062 0.468750
iteration 129: loss 0.905 0.320312 0.359375
iteration 130: loss 0.710 0.250000 0.476562
iteration 131: loss 0.728 0.351562 0.445312
iteration 132: loss 0.545 0.296875 0.546875
iteration 133: loss 0.639 0.265625 0.437500
iteration 134: loss 0.638 0.273438 0.437500
iteration 135: loss 0.675 0.265625 0.421875
iteration 136: loss 0.705 0.296875 0.453125
iteration 137: loss 0.549 0.289062 0.484375
iteration 138: loss 0.679 0.335938 0.437500
iteration 139: loss 0.844 0.257812 0.421875
iteration 140: loss 0.698 0.257812 0.468750
iteration 141: loss 0.558 0.242188 0.445312
iteration 142: loss 0.532 0.312500 0.468750
iteration 143: loss 0.582 0.296875 0.500000
iteration 144: loss 0.628 0.234375 0.468750
iteration 145: loss 0.604 0.328125 0.453125
iteration 146: loss 0.694 0.320312 0.437500
iteration 147: loss 0.651 0.265625 0.437500
iteration 148: loss 0.770 0.359375 0.445312
iteration 149: loss 0.544 0.359375 0.437500
iteration 150: loss 0.729 0.343750 0.429688
iteration 151: loss 0.843 0.335938 0.468750
iteration 152: loss 0.612 0.265625 0.492188
iteration 153: loss 0.822 0.281250 0.312500
iteration 154: loss 0.503 0.257812 0.492188
iteration 155: loss 0.615 0.328125 0.476562
iteration 156: loss 0.598 0.289062 0.460938
iteration 157: loss 0.685 0.335938 0.468750
iteration 158: loss 0.666 0.289062 0.398438
iteration 159: loss 0.606 0.304688 0.476562
iteration 160: loss 0.597 0.328125 0.468750
iteration 161: loss 0.667 0.421875 0.437500
iteration 162: loss 0.562 0.335938 0.492188
iteration 163: loss 0.585 0.304688 0.476562
iteration 164: loss 0.684 0.250000 0.421875
iteration 165: loss 0.520 0.265625 0.507812
iteration 166: loss 0.664 0.250000 0.437500
iteration 167: loss 0.606 0.335938 0.421875
iteration 168: loss 0.534 0.250000 0.460938
iteration 169: loss 0.560 0.320312 0.476562
iteration 170: loss 0.799 0.203125 0.390625
iteration 171: loss 0.498 0.296875 0.500000
iteration 172: loss 0.528 0.312500 0.468750
iteration 173: loss 0.573 0.320312 0.507812
iteration 174: loss 0.692 0.304688 0.507812
iteration 175: loss 0.433 0.289062 0.531250
iteration 176: loss 0.636 0.312500 0.507812
iteration 177: loss 0.618 0.265625 0.429688
iteration 178: loss 0.669 0.250000 0.414062
iteration 179: loss 0.691 0.289062 0.390625
iteration 180: loss 0.589 0.265625 0.453125
iteration 181: loss 0.529 0.296875 0.507812
iteration 182: loss 0.810 0.335938 0.375000
iteration 183: loss 0.678 0.296875 0.484375
iteration 184: loss 0.655 0.289062 0.453125
iteration 185: loss 0.533 0.359375 0.515625
iteration 186: loss 0.710 0.273438 0.445312
iteration 187: loss 0.686 0.296875 0.445312
iteration 188: loss 0.647 0.257812 0.414062
iteration 189: loss 0.755 0.320312 0.367188
iteration 190: loss 0.542 0.343750 0.523438
iteration 191: loss 0.665 0.273438 0.460938
iteration 192: loss 0.524 0.320312 0.468750
iteration 193: loss 0.608 0.296875 0.476562
iteration 194: loss 0.650 0.226562 0.453125
iteration 195: loss 0.521 0.328125 0.546875
iteration 196: loss 0.606 0.312500 0.484375
iteration 197: loss 0.652 0.250000 0.406250
iteration 198: loss 0.613 0.335938 0.546875
iteration 199: loss 0.598 0.335938 0.414062
iteration 200: loss 0.610 0.343750 0.421875
iteration 201: loss 0.578 0.296875 0.429688
iteration 202: loss 0.662 0.312500 0.445312
iteration 203: loss 0.668 0.273438 0.468750
iteration 204: loss 0.519 0.320312 0.484375
iteration 205: loss 0.503 0.296875 0.476562
iteration 206: loss 0.627 0.429688 0.476562
iteration 207: loss 0.583 0.250000 0.500000
iteration 208: loss 0.673 0.296875 0.445312
iteration 209: loss 0.712 0.273438 0.476562
iteration 210: loss 0.537 0.320312 0.476562
iteration 211: loss 0.517 0.320312 0.476562
iteration 212: loss 0.733 0.234375 0.445312
iteration 213: loss 0.689 0.289062 0.414062
iteration 214: loss 0.591 0.281250 0.539062
iteration 215: loss 0.413 0.343750 0.578125
iteration 216: loss 0.794 0.312500 0.445312
iteration 217: loss 0.716 0.312500 0.500000
iteration 218: loss 0.762 0.296875 0.367188
iteration 219: loss 0.534 0.312500 0.554688
iteration 220: loss 0.781 0.328125 0.437500
iteration 221: loss 0.710 0.273438 0.500000
iteration 222: loss 0.612 0.398438 0.453125
iteration 223: loss 0.498 0.281250 0.507812
iteration 224: loss 0.590 0.351562 0.484375
iteration 225: loss 0.533 0.320312 0.476562
iteration 226: loss 0.672 0.304688 0.484375
iteration 227: loss 0.698 0.351562 0.468750
iteration 228: loss 0.577 0.304688 0.523438
iteration 229: loss 0.732 0.265625 0.445312
iteration 230: loss 0.502 0.320312 0.507812
iteration 231: loss 0.744 0.250000 0.437500
iteration 232: loss 0.550 0.289062 0.500000
iteration 233: loss 0.680 0.359375 0.500000
iteration 234: loss 0.607 0.335938 0.437500
iteration 235: loss 0.647 0.320312 0.460938
iteration 236: loss 0.657 0.296875 0.445312
iteration 237: loss 0.662 0.359375 0.468750
iteration 238: loss 0.586 0.367188 0.460938
iteration 239: loss 0.764 0.320312 0.421875
iteration 240: loss 0.754 0.250000 0.367188
iteration 241: loss 0.495 0.281250 0.546875
iteration 242: loss 0.780 0.257812 0.429688
iteration 243: loss 0.735 0.265625 0.390625
iteration 244: loss 0.590 0.328125 0.484375
iteration 245: loss 0.655 0.359375 0.492188
iteration 246: loss 0.780 0.281250 0.351562
iteration 247: loss 0.633 0.257812 0.398438
iteration 248: loss 0.657 0.250000 0.437500
iteration 249: loss 0.687 0.304688 0.429688
iteration 250: loss 0.600 0.281250 0.437500
iteration 251: loss 0.557 0.328125 0.492188
iteration 252: loss 0.580 0.226562 0.515625
iteration 253: loss 0.696 0.367188 0.421875
iteration 254: loss 0.596 0.281250 0.492188
iteration 255: loss 0.644 0.320312 0.468750
iteration 256: loss 0.509 0.312500 0.515625
iteration 257: loss 0.492 0.351562 0.554688
iteration 258: loss 0.502 0.296875 0.531250
iteration 259: loss 0.618 0.414062 0.468750
iteration 260: loss 0.715 0.281250 0.500000
iteration 261: loss 0.696 0.328125 0.460938
iteration 262: loss 0.469 0.234375 0.515625
iteration 263: loss 0.551 0.328125 0.492188
iteration 264: loss 0.623 0.312500 0.515625
iteration 265: loss 0.524 0.320312 0.429688
iteration 266: loss 0.652 0.335938 0.460938
iteration 267: loss 0.631 0.218750 0.484375
iteration 268: loss 0.623 0.335938 0.476562
iteration 269: loss 0.535 0.296875 0.500000
iteration 270: loss 0.592 0.226562 0.507812
iteration 271: loss 0.708 0.359375 0.375000
iteration 272: loss 0.579 0.398438 0.500000
iteration 273: loss 0.771 0.226562 0.375000
iteration 274: loss 0.490 0.304688 0.484375
iteration 275: loss 0.588 0.304688 0.468750
iteration 276: loss 0.636 0.273438 0.429688
iteration 277: loss 0.586 0.281250 0.476562
iteration 278: loss 0.637 0.265625 0.445312
iteration 279: loss 0.743 0.328125 0.437500
iteration 280: loss 0.558 0.289062 0.484375
iteration 281: loss 0.616 0.226562 0.460938
iteration 282: loss 0.708 0.296875 0.367188
iteration 283: loss 0.549 0.289062 0.515625
iteration 284: loss 0.626 0.320312 0.460938
iteration 285: loss 0.631 0.406250 0.437500
iteration 286: loss 0.572 0.226562 0.460938
iteration 287: loss 0.624 0.343750 0.562500
iteration 288: loss 0.744 0.257812 0.484375
iteration 289: loss 0.632 0.335938 0.460938
iteration 290: loss 0.662 0.359375 0.429688
iteration 291: loss 0.721 0.312500 0.437500
iteration 292: loss 0.813 0.296875 0.312500
iteration 293: loss 0.683 0.289062 0.414062
iteration 294: loss 0.691 0.367188 0.468750
iteration 295: loss 0.442 0.257812 0.585938
iteration 296: loss 0.597 0.375000 0.476562
iteration 297: loss 0.486 0.304688 0.476562
iteration 298: loss 0.578 0.312500 0.468750
iteration 299: loss 0.553 0.343750 0.460938
iteration 300: loss 0.687 0.328125 0.437500
iteration 301: loss 0.690 0.273438 0.460938
iteration 302: loss 0.632 0.351562 0.445312
iteration 303: loss 0.521 0.281250 0.507812
iteration 304: loss 0.711 0.367188 0.468750
iteration 305: loss 0.632 0.250000 0.484375
iteration 306: loss 0.651 0.218750 0.484375
iteration 307: loss 0.676 0.359375 0.484375
iteration 308: loss 0.616 0.250000 0.460938
iteration 309: loss 0.629 0.335938 0.515625
iteration 310: loss 0.594 0.304688 0.468750
iteration 311: loss 0.667 0.289062 0.468750
iteration 312: loss 0.571 0.320312 0.468750
iteration 313: loss 0.605 0.312500 0.507812
iteration 314: loss 0.580 0.328125 0.507812
iteration 315: loss 0.808 0.312500 0.476562
iteration 316: loss 0.599 0.343750 0.460938
iteration 317: loss 0.647 0.289062 0.429688
iteration 318: loss 0.536 0.398438 0.406250
iteration 319: loss 0.645 0.273438 0.421875
iteration 320: loss 0.410 0.304688 0.578125
iteration 321: loss 0.716 0.281250 0.414062
iteration 322: loss 0.541 0.359375 0.484375
iteration 323: loss 0.497 0.382812 0.476562
iteration 324: loss 0.573 0.335938 0.507812
iteration 325: loss 0.597 0.257812 0.468750
iteration 326: loss 0.636 0.359375 0.406250
iteration 327: loss 0.671 0.289062 0.468750
iteration 328: loss 0.570 0.296875 0.468750
iteration 329: loss 0.726 0.343750 0.406250
iteration 330: loss 0.472 0.375000 0.476562
iteration 331: loss 0.640 0.304688 0.421875
iteration 332: loss 0.669 0.328125 0.445312
iteration 333: loss 0.676 0.296875 0.484375
iteration 334: loss 0.555 0.281250 0.476562
iteration 335: loss 0.637 0.257812 0.429688
iteration 336: loss 0.569 0.390625 0.453125
iteration 337: loss 0.803 0.359375 0.375000
iteration 338: loss 0.715 0.296875 0.414062
iteration 339: loss 0.691 0.289062 0.437500
iteration 340: loss 0.642 0.265625 0.484375
iteration 341: loss 0.574 0.328125 0.523438
iteration 342: loss 0.792 0.289062 0.421875
iteration 343: loss 0.676 0.398438 0.382812
iteration 344: loss 0.634 0.312500 0.460938
iteration 345: loss 0.650 0.343750 0.414062
iteration 346: loss 0.751 0.296875 0.445312
iteration 347: loss 0.477 0.453125 0.554688
iteration 348: loss 0.790 0.304688 0.445312
iteration 349: loss 0.621 0.257812 0.515625
iteration 350: loss 0.693 0.312500 0.460938
iteration 351: loss 0.660 0.281250 0.476562
iteration 352: loss 0.639 0.320312 0.429688
iteration 353: loss 0.471 0.265625 0.570312
iteration 354: loss 0.531 0.312500 0.492188
iteration 355: loss 0.707 0.257812 0.468750
iteration 356: loss 0.527 0.265625 0.460938
iteration 357: loss 0.646 0.296875 0.476562
iteration 358: loss 0.625 0.312500 0.453125
iteration 359: loss 0.579 0.242188 0.476562
iteration 360: loss 0.647 0.343750 0.437500
iteration 361: loss 0.637 0.304688 0.515625
iteration 362: loss 0.610 0.351562 0.500000
iteration 363: loss 0.718 0.281250 0.414062
iteration 364: loss 0.647 0.281250 0.523438
iteration 365: loss 0.526 0.382812 0.437500
iteration 366: loss 0.668 0.273438 0.429688
iteration 367: loss 0.551 0.367188 0.445312
iteration 368: loss 0.570 0.281250 0.445312
iteration 369: loss 0.670 0.273438 0.437500
iteration 370: loss 0.573 0.343750 0.468750
iteration 371: loss 0.663 0.320312 0.453125
iteration 372: loss 0.777 0.281250 0.375000
iteration 373: loss 0.760 0.351562 0.414062
iteration 374: loss 0.664 0.296875 0.429688
iteration 375: loss 0.689 0.265625 0.507812
iteration 376: loss 0.694 0.320312 0.429688
iteration 377: loss 0.460 0.296875 0.546875
iteration 378: loss 0.722 0.351562 0.468750
iteration 379: loss 0.667 0.281250 0.476562
iteration 380: loss 0.701 0.406250 0.460938
iteration 381: loss 0.683 0.335938 0.382812
iteration 382: loss 0.648 0.367188 0.406250
iteration 383: loss 0.641 0.320312 0.484375
iteration 384: loss 0.769 0.289062 0.406250
iteration 385: loss 0.573 0.335938 0.390625
iteration 386: loss 0.630 0.335938 0.375000
iteration 387: loss 0.690 0.296875 0.421875
iteration 388: loss 0.758 0.398438 0.414062
iteration 389: loss 0.608 0.335938 0.492188
iteration 390: loss 0.622 0.296875 0.453125
iteration 391: loss 0.687 0.281250 0.382812
iteration 392: loss 0.714 0.296875 0.468750
iteration 393: loss 0.616 0.281250 0.437500
iteration 394: loss 0.592 0.320312 0.445312
iteration 395: loss 0.656 0.296875 0.429688
iteration 396: loss 0.560 0.335938 0.476562
iteration 397: loss 0.579 0.328125 0.468750
iteration 398: loss 0.480 0.281250 0.554688
iteration 399: loss 0.878 0.312500 0.437500
iteration 400: loss 0.594 0.281250 0.460938
iteration 401: loss 0.785 0.312500 0.453125
iteration 402: loss 0.640 0.273438 0.515625
iteration 403: loss 0.730 0.335938 0.445312
iteration 404: loss 0.640 0.210938 0.476562
iteration 405: loss 0.670 0.367188 0.375000
iteration 406: loss 0.783 0.367188 0.398438
iteration 407: loss 0.666 0.281250 0.453125
iteration 408: loss 0.683 0.281250 0.437500
iteration 409: loss 0.708 0.257812 0.453125
iteration 410: loss 0.583 0.351562 0.531250
iteration 411: loss 0.759 0.234375 0.460938
iteration 412: loss 0.625 0.242188 0.554688
iteration 413: loss 0.631 0.312500 0.492188
iteration 414: loss 0.734 0.328125 0.437500
iteration 415: loss 0.540 0.218750 0.554688
iteration 416: loss 0.728 0.273438 0.390625
iteration 417: loss 0.678 0.328125 0.492188
iteration 418: loss 0.589 0.296875 0.492188
iteration 419: loss 0.463 0.343750 0.546875
iteration 420: loss 0.721 0.304688 0.437500
iteration 421: loss 0.572 0.304688 0.492188
iteration 422: loss 0.613 0.257812 0.531250
iteration 423: loss 0.777 0.281250 0.445312
iteration 424: loss 0.660 0.281250 0.414062
iteration 425: loss 0.604 0.312500 0.398438
iteration 426: loss 0.589 0.265625 0.500000
iteration 427: loss 0.621 0.312500 0.500000
iteration 428: loss 0.567 0.367188 0.554688
iteration 429: loss 0.534 0.304688 0.531250
iteration 430: loss 0.737 0.335938 0.453125
iteration 431: loss 0.693 0.281250 0.523438
iteration 432: loss 0.570 0.320312 0.476562
iteration 433: loss 0.616 0.296875 0.500000
iteration 434: loss 0.692 0.398438 0.390625
iteration 435: loss 0.628 0.304688 0.437500
iteration 436: loss 0.596 0.320312 0.523438
iteration 437: loss 0.620 0.234375 0.507812
iteration 438: loss 0.585 0.312500 0.531250
iteration 439: loss 0.749 0.320312 0.429688
iteration 440: loss 0.802 0.304688 0.507812
iteration 441: loss 0.740 0.304688 0.429688
iteration 442: loss 0.784 0.273438 0.406250
iteration 443: loss 0.812 0.296875 0.429688
iteration 444: loss 0.612 0.312500 0.421875
iteration 445: loss 0.618 0.343750 0.484375
iteration 446: loss 0.716 0.250000 0.468750
iteration 447: loss 0.642 0.281250 0.492188
iteration 448: loss 0.553 0.296875 0.515625
iteration 449: loss 0.637 0.375000 0.468750
iteration 450: loss 0.641 0.328125 0.468750
iteration 451: loss 0.675 0.218750 0.445312
iteration 452: loss 0.642 0.296875 0.429688
iteration 453: loss 0.483 0.289062 0.507812
iteration 454: loss 0.628 0.343750 0.437500
iteration 455: loss 0.712 0.312500 0.421875
iteration 456: loss 0.630 0.312500 0.437500
iteration 457: loss 0.632 0.304688 0.460938
iteration 458: loss 0.508 0.312500 0.554688
iteration 459: loss 0.793 0.281250 0.460938
iteration 460: loss 0.500 0.375000 0.507812
iteration 461: loss 0.774 0.335938 0.500000
iteration 462: loss 0.663 0.304688 0.429688
iteration 463: loss 0.747 0.320312 0.359375
iteration 464: loss 0.802 0.296875 0.429688
iteration 465: loss 0.549 0.250000 0.429688
iteration 466: loss 0.575 0.289062 0.468750
iteration 467: loss 0.698 0.351562 0.429688
iteration 468: loss 0.653 0.359375 0.484375
iteration 469: loss 0.581 0.343750 0.468750
iteration 470: loss 0.669 0.281250 0.492188
iteration 471: loss 0.545 0.242188 0.507812
iteration 472: loss 0.681 0.296875 0.429688
iteration 473: loss 0.696 0.304688 0.429688
iteration 474: loss 0.651 0.273438 0.437500
iteration 475: loss 0.515 0.328125 0.492188
iteration 476: loss 0.700 0.296875 0.460938
iteration 477: loss 0.694 0.312500 0.476562
iteration 478: loss 0.654 0.296875 0.414062
iteration 479: loss 0.706 0.289062 0.445312
iteration 480: loss 0.578 0.281250 0.492188
iteration 481: loss 0.778 0.359375 0.429688
iteration 482: loss 0.734 0.304688 0.398438
iteration 483: loss 0.618 0.296875 0.429688
iteration 484: loss 0.585 0.328125 0.468750
iteration 485: loss 0.653 0.265625 0.468750
iteration 486: loss 0.571 0.304688 0.476562
iteration 487: loss 0.649 0.312500 0.453125
iteration 488: loss 0.593 0.328125 0.406250
iteration 489: loss 0.601 0.273438 0.507812
iteration 490: loss 0.749 0.351562 0.429688
iteration 491: loss 0.740 0.265625 0.484375
iteration 492: loss 0.695 0.234375 0.429688
iteration 493: loss 0.483 0.250000 0.476562
iteration 494: loss 0.541 0.289062 0.539062
iteration 495: loss 0.743 0.320312 0.429688
iteration 496: loss 0.913 0.304688 0.382812
iteration 497: loss 0.776 0.351562 0.328125
iteration 498: loss 0.680 0.257812 0.375000
iteration 499: loss 0.569 0.281250 0.460938
iteration 500: loss 0.698 0.296875 0.437500
iteration 501: loss 0.588 0.351562 0.523438
iteration 502: loss 0.675 0.343750 0.468750
iteration 503: loss 0.485 0.273438 0.570312
iteration 504: loss 0.629 0.257812 0.468750
iteration 505: loss 0.528 0.296875 0.492188
iteration 506: loss 0.600 0.351562 0.429688
iteration 507: loss 0.654 0.242188 0.460938
iteration 508: loss 0.548 0.328125 0.492188
iteration 509: loss 0.611 0.312500 0.546875
iteration 510: loss 0.551 0.304688 0.523438
iteration 511: loss 0.646 0.304688 0.453125
iteration 512: loss 0.501 0.343750 0.507812
iteration 513: loss 0.624 0.328125 0.437500
iteration 514: loss 0.615 0.257812 0.500000
iteration 515: loss 0.701 0.242188 0.437500
iteration 516: loss 0.661 0.312500 0.453125
iteration 517: loss 0.630 0.367188 0.484375
iteration 518: loss 0.490 0.382812 0.468750
iteration 519: loss 0.469 0.289062 0.476562
iteration 520: loss 0.526 0.304688 0.468750
iteration 521: loss 0.636 0.296875 0.382812
iteration 522: loss 0.563 0.304688 0.554688
iteration 523: loss 0.634 0.382812 0.492188
iteration 524: loss 0.639 0.273438 0.476562
iteration 525: loss 0.493 0.281250 0.500000
iteration 526: loss 0.712 0.375000 0.382812
iteration 527: loss 0.525 0.343750 0.453125
iteration 528: loss 0.523 0.304688 0.523438
iteration 529: loss 0.615 0.335938 0.476562
iteration 530: loss 0.557 0.390625 0.460938
iteration 531: loss 0.652 0.281250 0.484375
iteration 532: loss 0.580 0.281250 0.460938
iteration 533: loss 0.570 0.296875 0.500000
iteration 534: loss 0.580 0.296875 0.492188
iteration 535: loss 0.701 0.281250 0.460938
iteration 536: loss 0.635 0.304688 0.375000
iteration 537: loss 0.544 0.296875 0.476562
iteration 538: loss 0.511 0.367188 0.531250
iteration 539: loss 0.707 0.242188 0.429688
iteration 540: loss 0.698 0.289062 0.468750
iteration 541: loss 0.533 0.351562 0.500000
iteration 542: loss 0.463 0.312500 0.507812
iteration 543: loss 0.621 0.273438 0.398438
iteration 544: loss 0.613 0.382812 0.445312
iteration 545: loss 0.639 0.367188 0.460938
iteration 546: loss 0.546 0.335938 0.476562
iteration 547: loss 0.604 0.367188 0.421875
iteration 548: loss 0.553 0.312500 0.468750
iteration 549: loss 0.616 0.398438 0.492188
iteration 550: loss 0.649 0.351562 0.539062
iteration 551: loss 0.600 0.304688 0.453125
iteration 552: loss 0.541 0.273438 0.539062
iteration 553: loss 0.536 0.320312 0.515625
iteration 554: loss 0.551 0.351562 0.453125
iteration 555: loss 0.643 0.242188 0.375000
iteration 556: loss 0.558 0.320312 0.468750
iteration 557: loss 0.501 0.312500 0.507812
iteration 558: loss 0.546 0.320312 0.476562
iteration 559: loss 0.478 0.289062 0.453125
iteration 560: loss 0.403 0.367188 0.539062
iteration 561: loss 0.584 0.335938 0.507812
iteration 562: loss 0.728 0.304688 0.492188
iteration 563: loss 0.745 0.257812 0.429688
iteration 564: loss 0.587 0.234375 0.515625
iteration 565: loss 0.554 0.320312 0.476562
iteration 566: loss 0.595 0.242188 0.468750
iteration 567: loss 0.555 0.304688 0.492188
iteration 568: loss 0.481 0.289062 0.523438
iteration 569: loss 0.549 0.328125 0.476562
iteration 570: loss 0.584 0.257812 0.453125
iteration 571: loss 0.644 0.351562 0.468750
iteration 572: loss 0.674 0.320312 0.476562
iteration 573: loss 0.531 0.304688 0.445312
iteration 574: loss 0.556 0.296875 0.476562
iteration 575: loss 0.506 0.273438 0.539062
iteration 576: loss 0.397 0.296875 0.539062
iteration 577: loss 0.569 0.343750 0.445312
iteration 578: loss 0.540 0.312500 0.476562
iteration 579: loss 0.536 0.265625 0.468750
iteration 580: loss 0.410 0.343750 0.609375
iteration 581: loss 0.658 0.296875 0.492188
iteration 582: loss 0.670 0.359375 0.453125
iteration 583: loss 0.618 0.265625 0.453125
iteration 584: loss 0.543 0.281250 0.437500
iteration 585: loss 0.599 0.265625 0.453125
iteration 586: loss 0.702 0.398438 0.359375
iteration 587: loss 0.531 0.296875 0.460938
iteration 588: loss 0.725 0.265625 0.406250
iteration 589: loss 0.695 0.335938 0.492188
iteration 590: loss 0.639 0.273438 0.507812
iteration 591: loss 0.602 0.406250 0.507812
iteration 592: loss 0.607 0.320312 0.523438
iteration 593: loss 0.699 0.296875 0.460938
iteration 594: loss 0.654 0.289062 0.375000
iteration 595: loss 0.550 0.351562 0.492188
iteration 596: loss 0.698 0.273438 0.390625
iteration 597: loss 0.581 0.296875 0.507812
iteration 598: loss 0.657 0.250000 0.429688
iteration 599: loss 0.638 0.343750 0.429688
iteration 600: loss 0.569 0.335938 0.437500
iteration 601: loss 0.665 0.335938 0.453125
iteration 602: loss 0.542 0.242188 0.468750
iteration 603: loss 0.594 0.382812 0.445312
iteration 604: loss 0.836 0.234375 0.437500
iteration 605: loss 0.641 0.289062 0.484375
iteration 606: loss 0.636 0.351562 0.468750
iteration 607: loss 0.552 0.265625 0.445312
iteration 608: loss 0.464 0.328125 0.515625
iteration 609: loss 0.611 0.250000 0.500000
iteration 610: loss 0.699 0.304688 0.429688
iteration 611: loss 0.674 0.242188 0.468750
iteration 612: loss 0.719 0.421875 0.398438
iteration 613: loss 0.716 0.359375 0.421875
iteration 614: loss 0.643 0.335938 0.507812
iteration 615: loss 0.695 0.351562 0.398438
iteration 616: loss 0.473 0.328125 0.523438
iteration 617: loss 0.489 0.257812 0.500000
iteration 618: loss 0.635 0.273438 0.453125
iteration 619: loss 0.869 0.351562 0.367188
iteration 620: loss 0.751 0.304688 0.460938
iteration 621: loss 0.534 0.250000 0.437500
iteration 622: loss 0.670 0.281250 0.437500
iteration 623: loss 0.624 0.312500 0.500000
iteration 624: loss 0.647 0.226562 0.437500
iteration 625: loss 0.672 0.359375 0.406250
iteration 626: loss 0.642 0.242188 0.484375
iteration 627: loss 0.489 0.265625 0.507812
iteration 628: loss 0.588 0.250000 0.453125
iteration 629: loss 0.564 0.273438 0.484375
iteration 630: loss 0.544 0.328125 0.546875
iteration 631: loss 0.686 0.281250 0.453125
iteration 632: loss 0.490 0.265625 0.546875
iteration 633: loss 0.623 0.281250 0.437500
iteration 634: loss 0.562 0.281250 0.437500
iteration 635: loss 0.512 0.273438 0.476562
iteration 636: loss 0.534 0.242188 0.429688
iteration 637: loss 0.552 0.242188 0.421875
iteration 638: loss 0.655 0.273438 0.390625
iteration 639: loss 0.733 0.328125 0.328125
iteration 640: loss 0.606 0.320312 0.414062
iteration 641: loss 0.667 0.312500 0.453125
iteration 642: loss 0.620 0.335938 0.453125
iteration 643: loss 0.611 0.320312 0.445312
iteration 644: loss 0.654 0.328125 0.445312
iteration 645: loss 0.577 0.304688 0.507812
iteration 646: loss 0.482 0.312500 0.531250
iteration 647: loss 0.697 0.296875 0.375000
iteration 648: loss 0.680 0.328125 0.460938
iteration 649: loss 0.682 0.320312 0.421875
iteration 650: loss 0.548 0.335938 0.484375
iteration 651: loss 0.600 0.351562 0.437500
iteration 652: loss 0.697 0.367188 0.460938
iteration 653: loss 0.514 0.312500 0.531250
iteration 654: loss 0.647 0.437500 0.468750
iteration 655: loss 0.548 0.351562 0.539062
iteration 656: loss 0.725 0.281250 0.460938
iteration 657: loss 0.523 0.320312 0.492188
iteration 658: loss 0.607 0.312500 0.406250
iteration 659: loss 0.787 0.320312 0.382812
iteration 660: loss 0.637 0.320312 0.460938
iteration 661: loss 0.592 0.281250 0.539062
iteration 662: loss 0.643 0.320312 0.507812
iteration 663: loss 0.598 0.406250 0.445312
iteration 664: loss 0.604 0.257812 0.500000
iteration 665: loss 0.689 0.273438 0.476562
iteration 666: loss 0.586 0.250000 0.453125
iteration 667: loss 0.528 0.312500 0.468750
iteration 668: loss 0.788 0.296875 0.367188
iteration 669: loss 0.621 0.281250 0.523438
iteration 670: loss 0.522 0.265625 0.523438
iteration 671: loss 0.677 0.250000 0.437500
iteration 672: loss 0.576 0.359375 0.539062
iteration 673: loss 0.580 0.242188 0.523438
iteration 674: loss 0.594 0.296875 0.507812
iteration 675: loss 0.551 0.312500 0.500000
iteration 676: loss 0.742 0.328125 0.484375
iteration 677: loss 0.647 0.335938 0.500000
iteration 678: loss 0.663 0.320312 0.500000
iteration 679: loss 0.658 0.382812 0.429688
iteration 680: loss 0.575 0.343750 0.507812
iteration 681: loss 0.608 0.226562 0.414062
iteration 682: loss 0.589 0.312500 0.476562
iteration 683: loss 0.672 0.273438 0.406250
iteration 684: loss 0.581 0.320312 0.414062
iteration 685: loss 0.701 0.375000 0.437500
iteration 686: loss 0.698 0.304688 0.382812
iteration 687: loss 0.492 0.335938 0.492188
iteration 688: loss 0.526 0.250000 0.445312
iteration 689: loss 0.573 0.335938 0.429688
iteration 690: loss 0.706 0.328125 0.398438
iteration 691: loss 0.631 0.296875 0.453125
iteration 692: loss 0.576 0.281250 0.515625
iteration 693: loss 0.525 0.296875 0.437500
iteration 694: loss 0.583 0.359375 0.453125
iteration 695: loss 0.556 0.289062 0.468750
iteration 696: loss 0.698 0.328125 0.460938
iteration 697: loss 0.625 0.312500 0.421875
iteration 698: loss 0.766 0.320312 0.421875
iteration 699: loss 0.626 0.328125 0.460938
iteration 700: loss 0.610 0.367188 0.507812
iteration 701: loss 0.572 0.335938 0.476562
iteration 702: loss 0.554 0.281250 0.445312
iteration 703: loss 0.864 0.320312 0.468750
iteration 704: loss 0.716 0.304688 0.468750
iteration 705: loss 0.525 0.343750 0.554688
iteration 706: loss 0.674 0.304688 0.429688
iteration 707: loss 0.522 0.320312 0.507812
iteration 708: loss 0.583 0.382812 0.453125
iteration 709: loss 0.715 0.367188 0.421875
iteration 710: loss 0.607 0.265625 0.500000
iteration 711: loss 0.695 0.289062 0.398438
iteration 712: loss 0.654 0.312500 0.445312
iteration 713: loss 0.661 0.390625 0.437500
iteration 714: loss 0.648 0.250000 0.476562
iteration 715: loss 0.639 0.328125 0.492188
iteration 716: loss 0.633 0.312500 0.429688
iteration 717: loss 0.611 0.320312 0.429688
iteration 718: loss 0.604 0.289062 0.437500
iteration 719: loss 0.550 0.390625 0.531250
iteration 720: loss 0.665 0.281250 0.460938
iteration 721: loss 0.550 0.257812 0.406250
iteration 722: loss 0.644 0.226562 0.429688
iteration 723: loss 0.610 0.296875 0.398438
iteration 724: loss 0.595 0.414062 0.523438
iteration 725: loss 0.700 0.343750 0.390625
iteration 726: loss 0.634 0.304688 0.468750
iteration 727: loss 0.645 0.257812 0.406250
iteration 728: loss 0.598 0.328125 0.476562
iteration 729: loss 0.515 0.367188 0.476562
iteration 730: loss 0.581 0.359375 0.507812
iteration 731: loss 0.645 0.343750 0.406250
iteration 732: loss 0.627 0.343750 0.414062
iteration 733: loss 0.726 0.304688 0.445312
iteration 734: loss 0.709 0.265625 0.390625
iteration 735: loss 0.610 0.273438 0.406250
iteration 736: loss 0.645 0.273438 0.476562
iteration 737: loss 0.589 0.273438 0.429688
iteration 738: loss 0.539 0.335938 0.492188
iteration 739: loss 0.549 0.328125 0.453125
iteration 740: loss 0.651 0.265625 0.453125
iteration 741: loss 0.572 0.312500 0.507812
iteration 742: loss 0.591 0.273438 0.484375
iteration 743: loss 0.648 0.234375 0.468750
iteration 744: loss 0.606 0.320312 0.500000
iteration 745: loss 0.703 0.343750 0.421875
iteration 746: loss 0.450 0.328125 0.539062
iteration 747: loss 0.691 0.335938 0.437500
iteration 748: loss 0.498 0.250000 0.523438
iteration 749: loss 0.555 0.265625 0.507812
iteration 750: loss 0.704 0.312500 0.460938
iteration 751: loss 0.477 0.320312 0.500000
iteration 752: loss 0.495 0.289062 0.468750
iteration 753: loss 0.628 0.335938 0.453125
iteration 754: loss 0.563 0.312500 0.453125
iteration 755: loss 0.615 0.242188 0.476562
iteration 756: loss 0.560 0.304688 0.492188
iteration 757: loss 0.555 0.304688 0.515625
iteration 758: loss 0.538 0.257812 0.453125
iteration 759: loss 0.617 0.359375 0.500000
iteration 760: loss 0.655 0.320312 0.414062
iteration 761: loss 0.756 0.375000 0.390625
iteration 762: loss 0.595 0.234375 0.484375
iteration 763: loss 0.543 0.289062 0.468750
iteration 764: loss 0.581 0.289062 0.445312
iteration 765: loss 0.473 0.312500 0.492188
iteration 766: loss 0.711 0.281250 0.468750
iteration 767: loss 0.664 0.304688 0.382812
iteration 768: loss 0.562 0.367188 0.460938
iteration 769: loss 0.701 0.296875 0.437500
iteration 770: loss 0.663 0.273438 0.414062
iteration 771: loss 0.552 0.257812 0.484375
iteration 772: loss 0.626 0.312500 0.476562
iteration 773: loss 0.634 0.343750 0.476562
iteration 774: loss 0.674 0.273438 0.429688
iteration 775: loss 0.487 0.265625 0.578125
iteration 776: loss 0.568 0.398438 0.531250
iteration 777: loss 0.505 0.335938 0.492188
iteration 778: loss 0.548 0.265625 0.507812
iteration 779: loss 0.644 0.320312 0.437500
iteration 780: loss 0.668 0.312500 0.437500
iteration 781: loss 0.518 0.367188 0.429688
iteration 782: loss 0.587 0.312500 0.476562
iteration 783: loss 0.601 0.320312 0.460938
iteration 784: loss 0.696 0.281250 0.453125
iteration 785: loss 0.582 0.351562 0.523438
iteration 786: loss 0.602 0.289062 0.421875
iteration 787: loss 0.810 0.304688 0.437500
iteration 788: loss 0.573 0.242188 0.476562
iteration 789: loss 0.501 0.265625 0.523438
iteration 790: loss 0.571 0.320312 0.429688
iteration 791: loss 0.572 0.281250 0.507812
iteration 792: loss 0.497 0.320312 0.500000
iteration 793: loss 0.793 0.250000 0.390625
iteration 794: loss 0.651 0.335938 0.453125
iteration 795: loss 0.555 0.304688 0.453125
iteration 796: loss 0.616 0.390625 0.437500
iteration 797: loss 0.550 0.304688 0.460938
iteration 798: loss 0.525 0.281250 0.484375
iteration 799: loss 0.623 0.289062 0.414062
iteration 800: loss 0.561 0.265625 0.484375
iteration 801: loss 0.708 0.312500 0.429688
iteration 802: loss 0.599 0.273438 0.406250
iteration 803: loss 0.690 0.359375 0.406250
iteration 804: loss 0.612 0.281250 0.476562
iteration 805: loss 0.597 0.281250 0.453125
iteration 806: loss 0.524 0.312500 0.546875
iteration 807: loss 0.633 0.304688 0.539062
iteration 808: loss 0.795 0.359375 0.382812
iteration 809: loss 0.626 0.289062 0.484375
iteration 810: loss 0.584 0.257812 0.421875
iteration 811: loss 0.635 0.343750 0.421875
iteration 812: loss 0.497 0.312500 0.468750
iteration 813: loss 0.572 0.351562 0.343750
iteration 814: loss 0.400 0.304688 0.539062
iteration 815: loss 0.797 0.289062 0.507812
iteration 816: loss 0.635 0.343750 0.570312
iteration 817: loss 0.584 0.328125 0.468750
iteration 818: loss 0.635 0.250000 0.460938
iteration 819: loss 0.574 0.281250 0.453125
iteration 820: loss 0.545 0.296875 0.531250
iteration 821: loss 0.654 0.304688 0.453125
iteration 822: loss 0.495 0.281250 0.515625
iteration 823: loss 0.611 0.382812 0.468750
iteration 824: loss 0.673 0.273438 0.429688
iteration 825: loss 0.568 0.320312 0.492188
iteration 826: loss 0.635 0.289062 0.515625
iteration 827: loss 0.869 0.273438 0.367188
iteration 828: loss 0.656 0.289062 0.429688
iteration 829: loss 0.636 0.312500 0.429688
iteration 830: loss 0.675 0.312500 0.468750
iteration 831: loss 0.639 0.343750 0.500000
iteration 832: loss 0.732 0.343750 0.476562
iteration 833: loss 0.588 0.296875 0.515625
iteration 834: loss 0.689 0.296875 0.453125
iteration 835: loss 0.731 0.257812 0.468750
iteration 836: loss 0.631 0.398438 0.453125
iteration 837: loss 0.622 0.265625 0.414062
iteration 838: loss 0.599 0.289062 0.382812
iteration 839: loss 0.583 0.265625 0.554688
iteration 840: loss 0.803 0.226562 0.492188
iteration 841: loss 0.507 0.273438 0.476562
iteration 842: loss 0.521 0.257812 0.460938
iteration 843: loss 0.499 0.265625 0.468750
iteration 844: loss 0.582 0.390625 0.539062
iteration 845: loss 0.726 0.343750 0.578125
iteration 846: loss 0.659 0.265625 0.468750
iteration 847: loss 0.688 0.343750 0.484375
iteration 848: loss 0.629 0.289062 0.445312
iteration 849: loss 0.569 0.273438 0.367188
iteration 850: loss 0.503 0.257812 0.515625
iteration 851: loss 0.547 0.289062 0.468750
iteration 852: loss 0.639 0.250000 0.468750
iteration 853: loss 0.709 0.273438 0.484375
iteration 854: loss 0.595 0.320312 0.507812
iteration 855: loss 0.649 0.382812 0.453125
iteration 856: loss 0.615 0.226562 0.406250
iteration 857: loss 0.642 0.281250 0.429688
iteration 858: loss 0.537 0.312500 0.476562
iteration 859: loss 0.568 0.343750 0.515625
iteration 860: loss 0.498 0.367188 0.539062
iteration 861: loss 0.764 0.320312 0.468750
iteration 862: loss 0.651 0.250000 0.468750
iteration 863: loss 0.509 0.296875 0.554688
iteration 864: loss 0.746 0.351562 0.460938
iteration 865: loss 0.643 0.304688 0.421875
iteration 866: loss 0.516 0.343750 0.515625
iteration 867: loss 0.819 0.281250 0.359375
iteration 868: loss 0.587 0.289062 0.453125
iteration 869: loss 0.495 0.210938 0.546875
iteration 870: loss 0.538 0.296875 0.484375
iteration 871: loss 0.565 0.265625 0.500000
iteration 872: loss 0.673 0.250000 0.523438
iteration 873: loss 0.687 0.320312 0.390625
iteration 874: loss 0.622 0.312500 0.398438
iteration 875: loss 0.558 0.296875 0.484375
iteration 876: loss 0.619 0.289062 0.460938
iteration 877: loss 0.477 0.289062 0.554688
iteration 878: loss 0.597 0.242188 0.414062
iteration 879: loss 0.681 0.343750 0.375000
iteration 880: loss 0.592 0.304688 0.382812
iteration 881: loss 0.606 0.304688 0.484375
iteration 882: loss 0.688 0.367188 0.515625
iteration 883: loss 0.763 0.328125 0.500000
iteration 884: loss 0.552 0.273438 0.453125
iteration 885: loss 0.579 0.335938 0.421875
iteration 886: loss 0.548 0.312500 0.414062
iteration 887: loss 0.662 0.343750 0.515625
iteration 888: loss 0.622 0.257812 0.539062
iteration 889: loss 0.565 0.265625 0.445312
iteration 890: loss 0.693 0.273438 0.367188
iteration 891: loss 0.873 0.296875 0.351562
iteration 892: loss 0.596 0.304688 0.429688
iteration 893: loss 0.645 0.250000 0.468750
iteration 894: loss 0.514 0.320312 0.539062
iteration 895: loss 0.532 0.367188 0.554688
iteration 896: loss 0.465 0.375000 0.515625
iteration 897: loss 0.605 0.257812 0.421875
iteration 898: loss 0.610 0.343750 0.492188
iteration 899: loss 0.761 0.250000 0.406250
iteration 900: loss 0.586 0.335938 0.523438
iteration 901: loss 0.559 0.367188 0.445312
iteration 902: loss 0.699 0.312500 0.421875
iteration 903: loss 0.551 0.273438 0.398438
iteration 904: loss 0.551 0.320312 0.437500
iteration 905: loss 0.607 0.250000 0.421875
iteration 906: loss 0.649 0.312500 0.437500
iteration 907: loss 0.629 0.281250 0.500000
iteration 908: loss 0.652 0.335938 0.429688
iteration 909: loss 0.650 0.375000 0.539062
iteration 910: loss 0.582 0.343750 0.500000
iteration 911: loss 0.638 0.343750 0.523438
iteration 912: loss 0.514 0.218750 0.609375
iteration 913: loss 0.742 0.304688 0.500000
iteration 914: loss 0.492 0.203125 0.593750
iteration 915: loss 0.657 0.265625 0.476562
iteration 916: loss 0.594 0.289062 0.484375
iteration 917: loss 0.605 0.367188 0.375000
iteration 918: loss 0.686 0.351562 0.437500
iteration 919: loss 0.630 0.335938 0.460938
iteration 920: loss 0.680 0.375000 0.476562
iteration 921: loss 0.581 0.289062 0.445312
iteration 922: loss 0.554 0.242188 0.429688
iteration 923: loss 0.547 0.265625 0.492188
iteration 924: loss 0.685 0.359375 0.476562
iteration 925: loss 0.649 0.320312 0.390625
iteration 926: loss 0.536 0.312500 0.492188
iteration 927: loss 0.631 0.304688 0.445312
iteration 928: loss 0.633 0.304688 0.437500
iteration 929: loss 0.653 0.312500 0.484375
iteration 930: loss 0.726 0.367188 0.390625
iteration 931: loss 0.761 0.359375 0.414062
iteration 932: loss 0.841 0.296875 0.335938
iteration 933: loss 0.682 0.328125 0.421875
iteration 934: loss 0.641 0.367188 0.398438
iteration 935: loss 0.773 0.304688 0.367188
iteration 936: loss 0.612 0.335938 0.429688
iteration 937: loss 0.676 0.242188 0.398438
iteration 938: loss 0.724 0.296875 0.421875
iteration 939: loss 0.700 0.335938 0.507812
iteration 940: loss 0.611 0.265625 0.500000
iteration 941: loss 0.768 0.351562 0.382812
iteration 942: loss 0.722 0.250000 0.421875
iteration 943: loss 0.720 0.304688 0.476562
iteration 944: loss 0.532 0.312500 0.429688
iteration 945: loss 0.597 0.296875 0.468750
iteration 946: loss 0.589 0.304688 0.453125
iteration 947: loss 0.695 0.312500 0.421875
iteration 948: loss 0.552 0.203125 0.468750
iteration 949: loss 0.654 0.328125 0.468750
iteration 950: loss 0.642 0.312500 0.437500
iteration 951: loss 0.464 0.367188 0.515625
iteration 952: loss 0.671 0.273438 0.437500
iteration 953: loss 0.681 0.296875 0.453125
iteration 954: loss 0.745 0.367188 0.367188
iteration 955: loss 0.699 0.257812 0.382812
iteration 956: loss 0.521 0.351562 0.523438
iteration 957: loss 0.617 0.320312 0.382812
iteration 958: loss 0.740 0.289062 0.375000
iteration 959: loss 0.731 0.351562 0.398438
iteration 960: loss 0.584 0.273438 0.476562
iteration 961: loss 0.625 0.320312 0.492188
iteration 962: loss 0.458 0.304688 0.531250
iteration 963: loss 0.696 0.312500 0.500000
iteration 964: loss 0.500 0.273438 0.531250
iteration 965: loss 0.567 0.351562 0.515625
iteration 966: loss 0.632 0.242188 0.429688
iteration 967: loss 0.486 0.281250 0.578125
iteration 968: loss 0.571 0.257812 0.398438
iteration 969: loss 0.461 0.328125 0.460938
iteration 970: loss 0.565 0.335938 0.445312
iteration 971: loss 0.691 0.296875 0.476562
iteration 972: loss 0.688 0.343750 0.476562
iteration 973: loss 0.694 0.328125 0.421875
iteration 974: loss 0.558 0.265625 0.515625
iteration 975: loss 0.520 0.328125 0.515625
iteration 976: loss 0.638 0.320312 0.445312
iteration 977: loss 0.704 0.320312 0.398438
iteration 978: loss 0.644 0.359375 0.398438
iteration 979: loss 0.636 0.312500 0.445312
iteration 980: loss 0.607 0.250000 0.476562
iteration 981: loss 0.542 0.312500 0.531250
iteration 982: loss 0.657 0.304688 0.476562
iteration 983: loss 0.712 0.289062 0.437500
iteration 984: loss 0.621 0.250000 0.515625
iteration 985: loss 0.699 0.335938 0.390625
iteration 986: loss 0.575 0.250000 0.515625
iteration 987: loss 0.586 0.304688 0.484375
iteration 988: loss 0.661 0.265625 0.421875
iteration 989: loss 0.610 0.281250 0.484375
iteration 990: loss 0.419 0.257812 0.585938
iteration 991: loss 0.666 0.328125 0.500000
iteration 992: loss 0.565 0.257812 0.546875
iteration 993: loss 0.633 0.234375 0.460938
iteration 994: loss 0.616 0.359375 0.437500
iteration 995: loss 0.652 0.312500 0.468750
iteration 996: loss 0.561 0.328125 0.500000
iteration 997: loss 0.595 0.234375 0.437500
iteration 998: loss 0.533 0.273438 0.507812
iteration 999: loss 0.644 0.359375 0.429688
epoch 11: training: 0.328125 validation: 0.203125
iteration 0: loss 0.616 0.351562 0.460938
iteration 1: loss 0.519 0.375000 0.539062
iteration 2: loss 0.576 0.335938 0.484375
iteration 3: loss 0.574 0.289062 0.523438
iteration 4: loss 0.713 0.343750 0.445312
iteration 5: loss 0.572 0.304688 0.507812
iteration 6: loss 0.628 0.296875 0.390625
iteration 7: loss 0.715 0.250000 0.437500
iteration 8: loss 0.588 0.289062 0.453125
iteration 9: loss 0.557 0.242188 0.531250
iteration 10: loss 0.576 0.359375 0.523438
iteration 11: loss 0.554 0.289062 0.437500
iteration 12: loss 0.693 0.226562 0.406250
iteration 13: loss 0.581 0.265625 0.484375
iteration 14: loss 0.605 0.242188 0.476562
iteration 15: loss 0.619 0.359375 0.531250
iteration 16: loss 0.574 0.351562 0.546875
iteration 17: loss 0.454 0.328125 0.546875
iteration 18: loss 0.712 0.265625 0.445312
iteration 19: loss 0.751 0.289062 0.437500
iteration 20: loss 0.680 0.242188 0.453125
iteration 21: loss 0.786 0.289062 0.429688
iteration 22: loss 0.446 0.343750 0.515625
iteration 23: loss 0.674 0.234375 0.429688
iteration 24: loss 0.550 0.328125 0.507812
iteration 25: loss 0.593 0.359375 0.398438
iteration 26: loss 0.662 0.226562 0.492188
iteration 27: loss 0.687 0.351562 0.460938
iteration 28: loss 0.623 0.289062 0.421875
iteration 29: loss 0.559 0.304688 0.515625
iteration 30: loss 0.680 0.312500 0.437500
iteration 31: loss 0.568 0.320312 0.507812
iteration 32: loss 0.610 0.328125 0.437500
iteration 33: loss 0.417 0.351562 0.554688
iteration 34: loss 0.635 0.265625 0.468750
iteration 35: loss 0.630 0.390625 0.453125
iteration 36: loss 0.463 0.257812 0.531250
iteration 37: loss 0.428 0.343750 0.507812
iteration 38: loss 0.649 0.367188 0.421875
iteration 39: loss 0.728 0.406250 0.445312
iteration 40: loss 0.625 0.328125 0.468750
iteration 41: loss 0.555 0.320312 0.468750
iteration 42: loss 0.789 0.242188 0.437500
iteration 43: loss 0.738 0.335938 0.445312
iteration 44: loss 0.620 0.320312 0.468750
iteration 45: loss 0.632 0.367188 0.523438
iteration 46: loss 0.553 0.289062 0.539062
iteration 47: loss 0.683 0.328125 0.406250
iteration 48: loss 0.656 0.273438 0.476562
iteration 49: loss 0.522 0.335938 0.507812
iteration 50: loss 0.653 0.210938 0.429688
iteration 51: loss 0.692 0.281250 0.484375
iteration 52: loss 0.698 0.343750 0.421875
iteration 53: loss 0.650 0.296875 0.484375
iteration 54: loss 0.708 0.265625 0.429688
iteration 55: loss 0.593 0.296875 0.406250
iteration 56: loss 0.601 0.304688 0.445312
iteration 57: loss 0.700 0.312500 0.460938
iteration 58: loss 0.699 0.257812 0.468750
iteration 59: loss 0.804 0.320312 0.359375
iteration 60: loss 0.565 0.320312 0.507812
iteration 61: loss 0.721 0.273438 0.398438
iteration 62: loss 0.578 0.289062 0.445312
iteration 63: loss 0.573 0.226562 0.453125
iteration 64: loss 0.618 0.351562 0.476562
iteration 65: loss 0.607 0.343750 0.453125
iteration 66: loss 0.596 0.242188 0.492188
iteration 67: loss 0.624 0.320312 0.507812
iteration 68: loss 0.614 0.289062 0.460938
iteration 69: loss 0.624 0.343750 0.500000
iteration 70: loss 0.546 0.226562 0.484375
iteration 71: loss 0.610 0.312500 0.421875
iteration 72: loss 0.581 0.335938 0.453125
iteration 73: loss 0.687 0.367188 0.468750
iteration 74: loss 0.712 0.320312 0.390625
iteration 75: loss 0.574 0.343750 0.492188
iteration 76: loss 0.547 0.320312 0.500000
iteration 77: loss 0.618 0.242188 0.554688
iteration 78: loss 0.573 0.218750 0.453125
iteration 79: loss 0.470 0.273438 0.531250
iteration 80: loss 0.612 0.281250 0.406250
iteration 81: loss 0.608 0.328125 0.531250
iteration 82: loss 0.631 0.375000 0.453125
iteration 83: loss 0.562 0.382812 0.523438
iteration 84: loss 0.727 0.351562 0.421875
iteration 85: loss 0.594 0.390625 0.484375
iteration 86: loss 0.665 0.312500 0.468750
iteration 87: loss 0.641 0.296875 0.429688
iteration 88: loss 0.706 0.335938 0.429688
iteration 89: loss 0.705 0.359375 0.437500
iteration 90: loss 0.576 0.328125 0.500000
iteration 91: loss 0.602 0.296875 0.460938
iteration 92: loss 0.649 0.281250 0.437500
iteration 93: loss 0.583 0.390625 0.515625
iteration 94: loss 0.642 0.289062 0.437500
iteration 95: loss 0.687 0.289062 0.367188
iteration 96: loss 0.629 0.312500 0.460938
iteration 97: loss 0.532 0.375000 0.507812
iteration 98: loss 0.547 0.335938 0.460938
iteration 99: loss 0.561 0.226562 0.460938
iteration 100: loss 0.653 0.273438 0.414062
iteration 101: loss 0.559 0.343750 0.460938
iteration 102: loss 0.650 0.320312 0.421875
iteration 103: loss 0.702 0.343750 0.437500
iteration 104: loss 0.586 0.296875 0.500000
iteration 105: loss 0.643 0.242188 0.492188
iteration 106: loss 0.495 0.328125 0.562500
iteration 107: loss 0.646 0.265625 0.445312
iteration 108: loss 0.524 0.289062 0.476562
iteration 109: loss 0.595 0.328125 0.476562
iteration 110: loss 0.752 0.289062 0.429688
iteration 111: loss 0.579 0.257812 0.382812
iteration 112: loss 0.481 0.265625 0.500000
iteration 113: loss 0.522 0.320312 0.507812
iteration 114: loss 0.568 0.296875 0.453125
iteration 115: loss 0.533 0.250000 0.523438
iteration 116: loss 0.565 0.289062 0.398438
iteration 117: loss 0.595 0.312500 0.429688
iteration 118: loss 0.704 0.351562 0.375000
iteration 119: loss 0.613 0.335938 0.445312
iteration 120: loss 0.713 0.289062 0.421875
iteration 121: loss 0.661 0.296875 0.523438
iteration 122: loss 0.650 0.343750 0.437500
iteration 123: loss 0.513 0.265625 0.523438
iteration 124: loss 0.521 0.335938 0.476562
iteration 125: loss 0.489 0.289062 0.531250
iteration 126: loss 0.655 0.265625 0.429688
iteration 127: loss 0.560 0.312500 0.468750
iteration 128: loss 0.596 0.343750 0.523438
iteration 129: loss 0.500 0.312500 0.507812
iteration 130: loss 0.611 0.257812 0.437500
iteration 131: loss 0.673 0.257812 0.468750
iteration 132: loss 0.509 0.312500 0.476562
iteration 133: loss 0.521 0.375000 0.492188
iteration 134: loss 0.561 0.281250 0.515625
iteration 135: loss 0.518 0.289062 0.445312
iteration 136: loss 0.599 0.320312 0.468750
iteration 137: loss 0.591 0.367188 0.437500
iteration 138: loss 0.670 0.273438 0.429688
iteration 139: loss 0.455 0.335938 0.515625
iteration 140: loss 0.696 0.304688 0.460938
iteration 141: loss 0.663 0.273438 0.429688
iteration 142: loss 0.504 0.351562 0.460938
iteration 143: loss 0.644 0.343750 0.476562
iteration 144: loss 0.476 0.359375 0.515625
iteration 145: loss 0.516 0.343750 0.523438
iteration 146: loss 0.676 0.328125 0.445312
iteration 147: loss 0.643 0.367188 0.421875
iteration 148: loss 0.592 0.257812 0.453125
iteration 149: loss 0.560 0.296875 0.445312
iteration 150: loss 0.623 0.367188 0.421875
iteration 151: loss 0.653 0.265625 0.429688
iteration 152: loss 0.620 0.289062 0.437500
iteration 153: loss 0.661 0.359375 0.437500
iteration 154: loss 0.626 0.273438 0.445312
iteration 155: loss 0.701 0.250000 0.390625
iteration 156: loss 0.681 0.296875 0.453125
iteration 157: loss 0.713 0.343750 0.382812
iteration 158: loss 0.420 0.289062 0.546875
iteration 159: loss 0.525 0.359375 0.460938
iteration 160: loss 0.659 0.257812 0.437500
iteration 161: loss 0.709 0.226562 0.437500
iteration 162: loss 0.587 0.359375 0.492188
iteration 163: loss 0.548 0.320312 0.507812
iteration 164: loss 0.568 0.257812 0.492188
iteration 165: loss 0.614 0.304688 0.375000
iteration 166: loss 0.669 0.257812 0.406250
iteration 167: loss 0.590 0.281250 0.398438
iteration 168: loss 0.531 0.312500 0.515625
iteration 169: loss 0.595 0.242188 0.460938
iteration 170: loss 0.557 0.304688 0.531250
iteration 171: loss 0.644 0.367188 0.429688
iteration 172: loss 0.719 0.343750 0.421875
iteration 173: loss 0.574 0.328125 0.437500
iteration 174: loss 0.739 0.367188 0.406250
iteration 175: loss 0.623 0.320312 0.406250
iteration 176: loss 0.574 0.289062 0.460938
iteration 177: loss 0.587 0.335938 0.492188
iteration 178: loss 0.533 0.250000 0.523438
iteration 179: loss 0.691 0.328125 0.398438
iteration 180: loss 0.578 0.328125 0.468750
iteration 181: loss 0.744 0.312500 0.335938
iteration 182: loss 0.618 0.312500 0.445312
iteration 183: loss 0.598 0.273438 0.429688
iteration 184: loss 0.633 0.359375 0.390625
iteration 185: loss 0.458 0.343750 0.570312
iteration 186: loss 0.661 0.257812 0.515625
iteration 187: loss 0.800 0.281250 0.437500
iteration 188: loss 0.534 0.289062 0.500000
iteration 189: loss 0.434 0.273438 0.531250
iteration 190: loss 0.661 0.273438 0.406250
iteration 191: loss 0.760 0.335938 0.375000
iteration 192: loss 0.584 0.351562 0.429688
iteration 193: loss 0.529 0.281250 0.531250
iteration 194: loss 0.588 0.312500 0.484375
iteration 195: loss 0.681 0.335938 0.460938
iteration 196: loss 0.579 0.281250 0.484375
iteration 197: loss 0.670 0.296875 0.468750
iteration 198: loss 0.579 0.210938 0.500000
iteration 199: loss 0.581 0.296875 0.468750
iteration 200: loss 0.621 0.312500 0.406250
iteration 201: loss 0.634 0.281250 0.437500
iteration 202: loss 0.712 0.375000 0.390625
iteration 203: loss 0.622 0.304688 0.507812
iteration 204: loss 0.533 0.273438 0.484375
iteration 205: loss 0.594 0.312500 0.460938
iteration 206: loss 0.511 0.289062 0.507812
iteration 207: loss 0.613 0.257812 0.453125
iteration 208: loss 0.479 0.296875 0.453125
iteration 209: loss 0.584 0.343750 0.460938
iteration 210: loss 0.561 0.367188 0.429688
iteration 211: loss 0.518 0.296875 0.539062
iteration 212: loss 0.560 0.390625 0.546875
iteration 213: loss 0.579 0.320312 0.414062
iteration 214: loss 0.583 0.296875 0.492188
iteration 215: loss 0.732 0.250000 0.453125
iteration 216: loss 0.558 0.304688 0.507812
iteration 217: loss 0.731 0.304688 0.484375
iteration 218: loss 0.458 0.265625 0.523438
iteration 219: loss 0.837 0.343750 0.289062
iteration 220: loss 0.601 0.304688 0.468750
iteration 221: loss 0.535 0.257812 0.492188
iteration 222: loss 0.646 0.320312 0.476562
iteration 223: loss 0.455 0.273438 0.562500
iteration 224: loss 0.615 0.320312 0.492188
iteration 225: loss 0.579 0.367188 0.507812
iteration 226: loss 0.517 0.320312 0.484375
iteration 227: loss 0.437 0.320312 0.476562
iteration 228: loss 0.526 0.312500 0.476562
iteration 229: loss 0.631 0.250000 0.359375
iteration 230: loss 0.623 0.226562 0.421875
iteration 231: loss 0.503 0.265625 0.421875
iteration 232: loss 0.586 0.320312 0.445312
iteration 233: loss 0.699 0.335938 0.398438
iteration 234: loss 0.543 0.312500 0.476562
iteration 235: loss 0.563 0.234375 0.500000
iteration 236: loss 0.577 0.273438 0.453125
iteration 237: loss 0.552 0.250000 0.507812
iteration 238: loss 0.493 0.250000 0.484375
iteration 239: loss 0.697 0.382812 0.437500
iteration 240: loss 0.564 0.382812 0.476562
iteration 241: loss 0.557 0.375000 0.414062
iteration 242: loss 0.634 0.328125 0.429688
iteration 243: loss 0.579 0.296875 0.476562
iteration 244: loss 0.724 0.359375 0.390625
iteration 245: loss 0.554 0.367188 0.460938
iteration 246: loss 0.539 0.320312 0.468750
iteration 247: loss 0.567 0.296875 0.468750
iteration 248: loss 0.586 0.296875 0.429688
iteration 249: loss 0.656 0.296875 0.398438
iteration 250: loss 0.607 0.343750 0.484375
iteration 251: loss 0.649 0.367188 0.484375
iteration 252: loss 0.642 0.257812 0.468750
iteration 253: loss 0.532 0.289062 0.453125
iteration 254: loss 0.567 0.335938 0.546875
iteration 255: loss 0.590 0.343750 0.507812
iteration 256: loss 0.624 0.257812 0.476562
iteration 257: loss 0.746 0.289062 0.445312
iteration 258: loss 0.767 0.312500 0.484375
iteration 259: loss 0.560 0.281250 0.484375
iteration 260: loss 0.574 0.296875 0.484375
iteration 261: loss 0.750 0.375000 0.445312
iteration 262: loss 0.688 0.343750 0.414062
iteration 263: loss 0.473 0.312500 0.507812
iteration 264: loss 0.605 0.304688 0.468750
iteration 265: loss 0.492 0.265625 0.523438
iteration 266: loss 0.609 0.351562 0.484375
iteration 267: loss 0.638 0.312500 0.390625
iteration 268: loss 0.511 0.335938 0.531250
iteration 269: loss 0.485 0.312500 0.484375
iteration 270: loss 0.624 0.273438 0.453125
iteration 271: loss 0.570 0.242188 0.515625
iteration 272: loss 0.559 0.304688 0.554688
iteration 273: loss 0.588 0.367188 0.500000
iteration 274: loss 0.796 0.289062 0.414062
iteration 275: loss 0.642 0.273438 0.414062
iteration 276: loss 0.722 0.328125 0.421875
iteration 277: loss 0.634 0.281250 0.414062
iteration 278: loss 0.664 0.296875 0.453125
iteration 279: loss 0.618 0.281250 0.484375
iteration 280: loss 0.503 0.304688 0.476562
iteration 281: loss 0.707 0.304688 0.414062
iteration 282: loss 0.674 0.320312 0.460938
iteration 283: loss 0.530 0.335938 0.515625
iteration 284: loss 0.525 0.312500 0.515625
iteration 285: loss 0.652 0.382812 0.460938
iteration 286: loss 0.777 0.304688 0.445312
iteration 287: loss 0.660 0.265625 0.437500
iteration 288: loss 0.589 0.304688 0.429688
iteration 289: loss 0.688 0.328125 0.507812
iteration 290: loss 0.485 0.250000 0.515625
iteration 291: loss 0.568 0.296875 0.492188
iteration 292: loss 0.620 0.328125 0.437500
iteration 293: loss 0.671 0.257812 0.437500
iteration 294: loss 0.456 0.343750 0.484375
iteration 295: loss 0.647 0.328125 0.414062
iteration 296: loss 0.507 0.289062 0.507812
iteration 297: loss 0.778 0.289062 0.390625
iteration 298: loss 0.445 0.265625 0.515625
iteration 299: loss 0.665 0.304688 0.429688
iteration 300: loss 0.768 0.312500 0.429688
iteration 301: loss 0.679 0.367188 0.453125
iteration 302: loss 0.644 0.242188 0.476562
iteration 303: loss 0.686 0.250000 0.453125
iteration 304: loss 0.559 0.320312 0.554688
iteration 305: loss 0.557 0.351562 0.578125
iteration 306: loss 0.658 0.281250 0.468750
iteration 307: loss 0.778 0.351562 0.437500
iteration 308: loss 0.776 0.281250 0.390625
iteration 309: loss 0.845 0.273438 0.421875
iteration 310: loss 0.561 0.257812 0.492188
iteration 311: loss 0.721 0.242188 0.468750
iteration 312: loss 0.596 0.335938 0.476562
iteration 313: loss 0.629 0.265625 0.531250
iteration 314: loss 0.651 0.289062 0.476562
iteration 315: loss 0.734 0.242188 0.453125
iteration 316: loss 0.793 0.273438 0.351562
iteration 317: loss 0.610 0.226562 0.460938
iteration 318: loss 0.551 0.343750 0.515625
iteration 319: loss 0.716 0.234375 0.500000
iteration 320: loss 0.731 0.289062 0.406250
iteration 321: loss 0.706 0.289062 0.382812
iteration 322: loss 0.566 0.406250 0.507812
iteration 323: loss 0.505 0.281250 0.468750
iteration 324: loss 0.633 0.250000 0.382812
iteration 325: loss 0.612 0.328125 0.492188
iteration 326: loss 0.662 0.359375 0.484375
iteration 327: loss 0.610 0.398438 0.460938
iteration 328: loss 0.532 0.289062 0.484375
iteration 329: loss 0.562 0.234375 0.492188
iteration 330: loss 0.538 0.343750 0.421875
iteration 331: loss 0.535 0.265625 0.398438
iteration 332: loss 0.494 0.296875 0.500000
iteration 333: loss 0.646 0.367188 0.445312
iteration 334: loss 0.583 0.304688 0.500000
iteration 335: loss 0.635 0.296875 0.468750
iteration 336: loss 0.682 0.281250 0.460938
iteration 337: loss 0.649 0.296875 0.453125
iteration 338: loss 0.534 0.257812 0.531250
iteration 339: loss 0.649 0.320312 0.421875
iteration 340: loss 0.695 0.304688 0.476562
iteration 341: loss 0.579 0.257812 0.484375
iteration 342: loss 0.588 0.312500 0.390625
iteration 343: loss 0.438 0.273438 0.515625
iteration 344: loss 0.769 0.226562 0.437500
iteration 345: loss 0.609 0.257812 0.484375
iteration 346: loss 0.788 0.257812 0.367188
iteration 347: loss 0.707 0.328125 0.437500
iteration 348: loss 0.530 0.304688 0.531250
iteration 349: loss 0.622 0.289062 0.453125
iteration 350: loss 0.439 0.328125 0.554688
iteration 351: loss 0.673 0.265625 0.414062
iteration 352: loss 0.593 0.312500 0.453125
iteration 353: loss 0.643 0.320312 0.468750
iteration 354: loss 0.524 0.265625 0.500000
iteration 355: loss 0.490 0.289062 0.531250
iteration 356: loss 0.575 0.335938 0.523438
iteration 357: loss 0.744 0.367188 0.375000
iteration 358: loss 0.535 0.273438 0.554688
iteration 359: loss 0.670 0.218750 0.390625
iteration 360: loss 0.767 0.312500 0.382812
iteration 361: loss 0.614 0.328125 0.476562
iteration 362: loss 0.642 0.359375 0.429688
iteration 363: loss 0.544 0.265625 0.515625
iteration 364: loss 0.645 0.320312 0.429688
iteration 365: loss 0.644 0.257812 0.414062
iteration 366: loss 0.540 0.250000 0.468750
iteration 367: loss 0.440 0.328125 0.570312
iteration 368: loss 0.723 0.359375 0.398438
iteration 369: loss 0.678 0.289062 0.445312
iteration 370: loss 0.674 0.312500 0.375000
iteration 371: loss 0.548 0.296875 0.437500
iteration 372: loss 0.479 0.289062 0.468750
iteration 373: loss 0.624 0.304688 0.500000
iteration 374: loss 0.703 0.265625 0.468750
iteration 375: loss 0.473 0.296875 0.570312
iteration 376: loss 0.558 0.335938 0.453125
iteration 377: loss 0.524 0.289062 0.468750
iteration 378: loss 0.452 0.296875 0.507812
iteration 379: loss 0.454 0.328125 0.523438
iteration 380: loss 0.650 0.281250 0.437500
iteration 381: loss 0.654 0.234375 0.437500
iteration 382: loss 0.566 0.226562 0.492188
iteration 383: loss 0.627 0.257812 0.414062
iteration 384: loss 0.598 0.289062 0.437500
iteration 385: loss 0.576 0.320312 0.531250
iteration 386: loss 0.496 0.273438 0.492188
iteration 387: loss 0.704 0.234375 0.390625
iteration 388: loss 0.556 0.343750 0.484375
iteration 389: loss 0.579 0.281250 0.429688
iteration 390: loss 0.648 0.328125 0.445312
iteration 391: loss 0.616 0.312500 0.468750
iteration 392: loss 0.596 0.234375 0.515625
iteration 393: loss 0.784 0.296875 0.414062
iteration 394: loss 0.531 0.312500 0.492188
iteration 395: loss 0.571 0.257812 0.515625
iteration 396: loss 0.570 0.265625 0.429688
iteration 397: loss 0.696 0.351562 0.414062
iteration 398: loss 0.522 0.398438 0.515625
iteration 399: loss 0.589 0.304688 0.437500
iteration 400: loss 0.556 0.273438 0.468750
iteration 401: loss 0.609 0.335938 0.414062
iteration 402: loss 0.590 0.304688 0.460938
iteration 403: loss 0.654 0.328125 0.375000
iteration 404: loss 0.477 0.242188 0.500000
iteration 405: loss 0.616 0.328125 0.507812
iteration 406: loss 0.532 0.382812 0.500000
iteration 407: loss 0.642 0.343750 0.507812
iteration 408: loss 0.645 0.257812 0.460938
iteration 409: loss 0.594 0.335938 0.468750
iteration 410: loss 0.575 0.210938 0.507812
iteration 411: loss 0.476 0.320312 0.531250
iteration 412: loss 0.670 0.304688 0.468750
iteration 413: loss 0.524 0.312500 0.507812
iteration 414: loss 0.650 0.328125 0.460938
iteration 415: loss 0.569 0.257812 0.484375
iteration 416: loss 0.584 0.375000 0.484375
iteration 417: loss 0.644 0.398438 0.421875
iteration 418: loss 0.566 0.320312 0.453125
iteration 419: loss 0.701 0.273438 0.468750
iteration 420: loss 0.645 0.242188 0.460938
iteration 421: loss 0.682 0.304688 0.460938
iteration 422: loss 0.500 0.265625 0.515625
iteration 423: loss 0.586 0.257812 0.492188
iteration 424: loss 0.509 0.273438 0.398438
iteration 425: loss 0.578 0.273438 0.468750
iteration 426: loss 0.628 0.328125 0.460938
iteration 427: loss 0.590 0.367188 0.476562
iteration 428: loss 0.559 0.312500 0.484375
iteration 429: loss 0.582 0.320312 0.507812
iteration 430: loss 0.704 0.312500 0.359375
iteration 431: loss 0.549 0.234375 0.476562
iteration 432: loss 0.530 0.242188 0.390625
iteration 433: loss 0.632 0.351562 0.406250
iteration 434: loss 0.628 0.406250 0.476562
iteration 435: loss 0.631 0.296875 0.476562
iteration 436: loss 0.684 0.351562 0.492188
iteration 437: loss 0.826 0.273438 0.390625
iteration 438: loss 0.712 0.304688 0.453125
iteration 439: loss 0.658 0.281250 0.476562
iteration 440: loss 0.611 0.234375 0.445312
iteration 441: loss 0.688 0.343750 0.390625
iteration 442: loss 0.581 0.328125 0.531250
iteration 443: loss 0.416 0.273438 0.570312
iteration 444: loss 0.530 0.320312 0.507812
iteration 445: loss 0.641 0.367188 0.468750
iteration 446: loss 0.685 0.351562 0.445312
iteration 447: loss 0.558 0.320312 0.507812
iteration 448: loss 0.710 0.265625 0.421875
iteration 449: loss 0.581 0.289062 0.492188
iteration 450: loss 0.726 0.234375 0.429688
iteration 451: loss 0.665 0.296875 0.398438
iteration 452: loss 0.768 0.257812 0.343750
iteration 453: loss 0.702 0.351562 0.421875
iteration 454: loss 0.535 0.289062 0.484375
iteration 455: loss 0.705 0.335938 0.492188
iteration 456: loss 0.663 0.351562 0.515625
iteration 457: loss 0.615 0.304688 0.523438
iteration 458: loss 0.538 0.335938 0.468750
iteration 459: loss 0.665 0.351562 0.445312
iteration 460: loss 0.549 0.328125 0.585938
iteration 461: loss 0.556 0.257812 0.507812
iteration 462: loss 0.465 0.359375 0.500000
iteration 463: loss 0.559 0.250000 0.500000
iteration 464: loss 0.558 0.343750 0.500000
iteration 465: loss 0.600 0.281250 0.429688
iteration 466: loss 0.544 0.304688 0.468750
iteration 467: loss 0.682 0.281250 0.453125
iteration 468: loss 0.547 0.304688 0.445312
iteration 469: loss 0.499 0.351562 0.492188
iteration 470: loss 0.699 0.257812 0.367188
iteration 471: loss 0.683 0.320312 0.453125
iteration 472: loss 0.720 0.265625 0.460938
iteration 473: loss 0.632 0.375000 0.468750
iteration 474: loss 0.711 0.304688 0.406250
iteration 475: loss 0.681 0.281250 0.539062
iteration 476: loss 0.638 0.273438 0.429688
iteration 477: loss 0.580 0.343750 0.453125
iteration 478: loss 0.521 0.328125 0.468750
iteration 479: loss 0.538 0.273438 0.500000
iteration 480: loss 0.575 0.359375 0.507812
iteration 481: loss 0.536 0.296875 0.507812
iteration 482: loss 0.596 0.343750 0.539062
iteration 483: loss 0.718 0.343750 0.437500
iteration 484: loss 0.622 0.351562 0.445312
iteration 485: loss 0.564 0.312500 0.492188
iteration 486: loss 0.520 0.328125 0.453125
iteration 487: loss 0.668 0.250000 0.375000
iteration 488: loss 0.715 0.343750 0.343750
iteration 489: loss 0.565 0.281250 0.484375
iteration 490: loss 0.549 0.414062 0.515625
iteration 491: loss 0.717 0.242188 0.476562
iteration 492: loss 0.547 0.296875 0.531250
iteration 493: loss 0.648 0.335938 0.375000
iteration 494: loss 0.633 0.234375 0.382812
iteration 495: loss 0.442 0.343750 0.546875
iteration 496: loss 0.503 0.351562 0.531250
iteration 497: loss 0.514 0.382812 0.523438
iteration 498: loss 0.700 0.359375 0.500000
iteration 499: loss 0.485 0.328125 0.492188
iteration 500: loss 0.594 0.289062 0.468750
iteration 501: loss 0.721 0.343750 0.421875
iteration 502: loss 0.621 0.359375 0.375000
iteration 503: loss 0.620 0.250000 0.445312
iteration 504: loss 0.532 0.320312 0.437500
iteration 505: loss 0.611 0.250000 0.429688
iteration 506: loss 0.685 0.312500 0.421875
iteration 507: loss 0.672 0.328125 0.453125
iteration 508: loss 0.546 0.375000 0.531250
iteration 509: loss 0.593 0.343750 0.460938
iteration 510: loss 0.577 0.234375 0.429688
iteration 511: loss 0.574 0.226562 0.468750
iteration 512: loss 0.458 0.359375 0.515625
iteration 513: loss 0.514 0.187500 0.445312
iteration 514: loss 0.676 0.312500 0.500000
iteration 515: loss 0.652 0.289062 0.437500
iteration 516: loss 0.670 0.289062 0.445312
iteration 517: loss 0.493 0.273438 0.507812
iteration 518: loss 0.597 0.226562 0.492188
iteration 519: loss 0.560 0.320312 0.460938
iteration 520: loss 0.559 0.343750 0.460938
iteration 521: loss 0.499 0.273438 0.500000
iteration 522: loss 0.576 0.226562 0.445312
iteration 523: loss 0.631 0.335938 0.414062
iteration 524: loss 0.428 0.343750 0.468750
iteration 525: loss 0.585 0.265625 0.476562
iteration 526: loss 0.579 0.289062 0.507812
iteration 527: loss 0.562 0.289062 0.484375
iteration 528: loss 0.569 0.304688 0.515625
iteration 529: loss 0.654 0.265625 0.476562
iteration 530: loss 0.688 0.429688 0.476562
iteration 531: loss 0.741 0.273438 0.406250
iteration 532: loss 0.593 0.328125 0.406250
iteration 533: loss 0.485 0.234375 0.492188
iteration 534: loss 0.474 0.289062 0.539062
iteration 535: loss 0.530 0.273438 0.492188
iteration 536: loss 0.673 0.304688 0.351562
iteration 537: loss 0.538 0.242188 0.515625
iteration 538: loss 0.791 0.312500 0.343750
iteration 539: loss 0.616 0.289062 0.421875
iteration 540: loss 0.654 0.328125 0.421875
iteration 541: loss 0.591 0.304688 0.406250
iteration 542: loss 0.665 0.281250 0.390625
iteration 543: loss 0.661 0.351562 0.421875
iteration 544: loss 0.693 0.257812 0.460938
iteration 545: loss 0.634 0.367188 0.484375
iteration 546: loss 0.578 0.312500 0.453125
iteration 547: loss 0.587 0.343750 0.523438
iteration 548: loss 0.481 0.406250 0.500000
iteration 549: loss 0.760 0.320312 0.445312
iteration 550: loss 0.520 0.296875 0.507812
iteration 551: loss 0.473 0.320312 0.546875
iteration 552: loss 0.561 0.375000 0.476562
iteration 553: loss 0.515 0.250000 0.453125
iteration 554: loss 0.590 0.296875 0.406250
iteration 555: loss 0.544 0.312500 0.445312
iteration 556: loss 0.452 0.312500 0.515625
iteration 557: loss 0.628 0.328125 0.437500
iteration 558: loss 0.555 0.296875 0.484375
iteration 559: loss 0.758 0.343750 0.437500
iteration 560: loss 0.733 0.343750 0.375000
iteration 561: loss 0.627 0.312500 0.500000
iteration 562: loss 0.628 0.242188 0.398438
iteration 563: loss 0.623 0.351562 0.398438
iteration 564: loss 0.543 0.234375 0.437500
iteration 565: loss 0.613 0.296875 0.445312
iteration 566: loss 0.586 0.289062 0.429688
iteration 567: loss 0.551 0.320312 0.421875
iteration 568: loss 0.555 0.289062 0.507812
iteration 569: loss 0.683 0.250000 0.476562
iteration 570: loss 0.504 0.367188 0.554688
iteration 571: loss 0.709 0.304688 0.476562
iteration 572: loss 0.755 0.273438 0.453125
iteration 573: loss 0.564 0.304688 0.507812
iteration 574: loss 0.549 0.234375 0.476562
iteration 575: loss 0.683 0.273438 0.460938
iteration 576: loss 0.537 0.304688 0.468750
iteration 577: loss 0.611 0.359375 0.460938
iteration 578: loss 0.562 0.351562 0.437500
iteration 579: loss 0.542 0.312500 0.515625
iteration 580: loss 0.576 0.257812 0.468750
iteration 581: loss 0.527 0.281250 0.460938
iteration 582: loss 0.566 0.304688 0.500000
iteration 583: loss 0.631 0.296875 0.468750
iteration 584: loss 0.555 0.226562 0.421875
iteration 585: loss 0.545 0.343750 0.468750
iteration 586: loss 0.555 0.320312 0.476562
iteration 587: loss 0.553 0.359375 0.515625
iteration 588: loss 0.622 0.304688 0.445312
iteration 589: loss 0.579 0.281250 0.476562
iteration 590: loss 0.515 0.328125 0.492188
iteration 591: loss 0.545 0.265625 0.453125
iteration 592: loss 0.584 0.390625 0.484375
iteration 593: loss 0.608 0.296875 0.484375
iteration 594: loss 0.652 0.367188 0.507812
iteration 595: loss 0.574 0.281250 0.562500
iteration 596: loss 0.649 0.226562 0.398438
iteration 597: loss 0.601 0.289062 0.429688
iteration 598: loss 0.453 0.273438 0.523438
iteration 599: loss 0.510 0.406250 0.492188
iteration 600: loss 0.596 0.273438 0.484375
iteration 601: loss 0.687 0.289062 0.429688
iteration 602: loss 0.446 0.320312 0.523438
iteration 603: loss 0.636 0.328125 0.398438
iteration 604: loss 0.678 0.296875 0.421875
iteration 605: loss 0.665 0.359375 0.445312
iteration 606: loss 0.758 0.351562 0.375000
iteration 607: loss 0.557 0.335938 0.507812
iteration 608: loss 0.469 0.281250 0.554688
iteration 609: loss 0.629 0.281250 0.476562
iteration 610: loss 0.599 0.265625 0.390625
iteration 611: loss 0.463 0.281250 0.492188
iteration 612: loss 0.443 0.328125 0.515625
iteration 613: loss 0.474 0.234375 0.539062
iteration 614: loss 0.536 0.359375 0.492188
iteration 615: loss 0.533 0.296875 0.492188
iteration 616: loss 0.578 0.281250 0.476562
iteration 617: loss 0.608 0.320312 0.406250
iteration 618: loss 0.589 0.406250 0.460938
iteration 619: loss 0.605 0.179688 0.390625
iteration 620: loss 0.719 0.304688 0.406250
iteration 621: loss 0.708 0.296875 0.367188
iteration 622: loss 0.532 0.296875 0.421875
iteration 623: loss 0.609 0.351562 0.500000
iteration 624: loss 0.535 0.281250 0.492188
iteration 625: loss 0.507 0.273438 0.570312
iteration 626: loss 0.665 0.304688 0.460938
iteration 627: loss 0.657 0.296875 0.437500
iteration 628: loss 0.614 0.273438 0.421875
iteration 629: loss 0.553 0.234375 0.406250
iteration 630: loss 0.649 0.335938 0.406250
iteration 631: loss 0.733 0.296875 0.390625
iteration 632: loss 0.563 0.335938 0.429688
iteration 633: loss 0.537 0.304688 0.500000
iteration 634: loss 0.572 0.273438 0.460938
iteration 635: loss 0.513 0.304688 0.484375
iteration 636: loss 0.553 0.203125 0.531250
iteration 637: loss 0.684 0.265625 0.429688
iteration 638: loss 0.737 0.312500 0.406250
iteration 639: loss 0.555 0.289062 0.398438
iteration 640: loss 0.576 0.328125 0.390625
iteration 641: loss 0.578 0.367188 0.382812
iteration 642: loss 0.698 0.289062 0.367188
iteration 643: loss 0.559 0.328125 0.492188
iteration 644: loss 0.537 0.250000 0.476562
iteration 645: loss 0.547 0.265625 0.492188
iteration 646: loss 0.663 0.281250 0.445312
iteration 647: loss 0.597 0.343750 0.453125
iteration 648: loss 0.468 0.343750 0.492188
iteration 649: loss 0.633 0.289062 0.429688
iteration 650: loss 0.402 0.359375 0.546875
iteration 651: loss 0.489 0.312500 0.492188
iteration 652: loss 0.587 0.320312 0.421875
iteration 653: loss 0.471 0.328125 0.531250
iteration 654: loss 0.488 0.281250 0.515625
iteration 655: loss 0.526 0.351562 0.500000
iteration 656: loss 0.632 0.289062 0.523438
iteration 657: loss 0.527 0.273438 0.445312
iteration 658: loss 0.503 0.312500 0.468750
iteration 659: loss 0.447 0.265625 0.460938
iteration 660: loss 0.575 0.289062 0.414062
iteration 661: loss 0.518 0.281250 0.507812
iteration 662: loss 0.503 0.343750 0.507812
iteration 663: loss 0.475 0.328125 0.515625
iteration 664: loss 0.542 0.312500 0.492188
iteration 665: loss 0.629 0.367188 0.390625
iteration 666: loss 0.710 0.351562 0.398438
iteration 667: loss 0.606 0.343750 0.414062
iteration 668: loss 0.543 0.296875 0.437500
iteration 669: loss 0.648 0.335938 0.421875
iteration 670: loss 0.569 0.351562 0.484375
iteration 671: loss 0.550 0.343750 0.476562
iteration 672: loss 0.738 0.273438 0.507812
iteration 673: loss 0.674 0.273438 0.500000
iteration 674: loss 0.575 0.304688 0.453125
iteration 675: loss 0.687 0.351562 0.476562
iteration 676: loss 0.610 0.273438 0.484375
iteration 677: loss 0.679 0.367188 0.453125
iteration 678: loss 0.561 0.382812 0.468750
iteration 679: loss 0.729 0.335938 0.453125
iteration 680: loss 0.590 0.296875 0.460938
iteration 681: loss 0.577 0.312500 0.492188
iteration 682: loss 0.624 0.335938 0.492188
iteration 683: loss 0.519 0.375000 0.539062
iteration 684: loss 0.652 0.242188 0.406250
iteration 685: loss 0.537 0.351562 0.507812
iteration 686: loss 0.868 0.312500 0.382812
iteration 687: loss 0.679 0.226562 0.429688
iteration 688: loss 0.664 0.257812 0.421875
iteration 689: loss 0.576 0.351562 0.429688
iteration 690: loss 0.684 0.265625 0.351562
iteration 691: loss 0.554 0.343750 0.453125
iteration 692: loss 0.644 0.375000 0.515625
iteration 693: loss 0.566 0.289062 0.445312
iteration 694: loss 0.541 0.289062 0.468750
iteration 695: loss 0.492 0.312500 0.453125
iteration 696: loss 0.568 0.289062 0.453125
iteration 697: loss 0.654 0.320312 0.437500
iteration 698: loss 0.595 0.304688 0.382812
iteration 699: loss 0.602 0.265625 0.484375
iteration 700: loss 0.609 0.320312 0.468750
iteration 701: loss 0.604 0.320312 0.445312
iteration 702: loss 0.565 0.351562 0.398438
iteration 703: loss 0.690 0.367188 0.382812
iteration 704: loss 0.583 0.296875 0.429688
iteration 705: loss 0.640 0.320312 0.460938
iteration 706: loss 0.663 0.343750 0.429688
iteration 707: loss 0.663 0.382812 0.359375
iteration 708: loss 0.482 0.296875 0.492188
iteration 709: loss 0.585 0.250000 0.445312
iteration 710: loss 0.533 0.281250 0.390625
iteration 711: loss 0.473 0.296875 0.531250
iteration 712: loss 0.639 0.273438 0.445312
iteration 713: loss 0.517 0.312500 0.492188
iteration 714: loss 0.560 0.328125 0.476562
iteration 715: loss 0.597 0.273438 0.421875
iteration 716: loss 0.593 0.289062 0.531250
iteration 717: loss 0.525 0.359375 0.515625
iteration 718: loss 0.510 0.343750 0.492188
iteration 719: loss 0.555 0.320312 0.492188
iteration 720: loss 0.631 0.281250 0.476562
iteration 721: loss 0.568 0.304688 0.460938
iteration 722: loss 0.667 0.273438 0.406250
iteration 723: loss 0.609 0.359375 0.515625
iteration 724: loss 0.532 0.312500 0.492188
iteration 725: loss 0.717 0.257812 0.398438
iteration 726: loss 0.584 0.304688 0.468750
iteration 727: loss 0.647 0.312500 0.414062
iteration 728: loss 0.539 0.296875 0.445312
iteration 729: loss 0.520 0.320312 0.460938
iteration 730: loss 0.607 0.328125 0.437500
iteration 731: loss 0.592 0.304688 0.421875
iteration 732: loss 0.520 0.257812 0.500000
iteration 733: loss 0.637 0.351562 0.445312
iteration 734: loss 0.622 0.351562 0.445312
iteration 735: loss 0.587 0.257812 0.507812
iteration 736: loss 0.492 0.296875 0.539062
iteration 737: loss 0.660 0.296875 0.421875
iteration 738: loss 0.523 0.320312 0.437500
iteration 739: loss 0.631 0.328125 0.414062
iteration 740: loss 0.677 0.289062 0.351562
iteration 741: loss 0.621 0.335938 0.531250
iteration 742: loss 0.631 0.257812 0.375000
iteration 743: loss 0.594 0.320312 0.406250
iteration 744: loss 0.530 0.320312 0.484375
iteration 745: loss 0.600 0.234375 0.429688
iteration 746: loss 0.674 0.265625 0.398438
iteration 747: loss 0.620 0.328125 0.453125
iteration 748: loss 0.489 0.257812 0.492188
iteration 749: loss 0.555 0.328125 0.507812
iteration 750: loss 0.620 0.296875 0.460938
iteration 751: loss 0.623 0.351562 0.453125
iteration 752: loss 0.576 0.296875 0.414062
iteration 753: loss 0.546 0.320312 0.453125
iteration 754: loss 0.381 0.312500 0.539062
iteration 755: loss 0.574 0.250000 0.437500
iteration 756: loss 0.474 0.296875 0.507812
iteration 757: loss 0.579 0.289062 0.460938
iteration 758: loss 0.604 0.375000 0.445312
iteration 759: loss 0.666 0.398438 0.421875
iteration 760: loss 0.431 0.304688 0.531250
iteration 761: loss 0.606 0.250000 0.445312
iteration 762: loss 0.625 0.218750 0.375000
iteration 763: loss 0.613 0.289062 0.484375
iteration 764: loss 0.546 0.289062 0.523438
iteration 765: loss 0.560 0.335938 0.445312
iteration 766: loss 0.507 0.312500 0.460938
iteration 767: loss 0.580 0.304688 0.460938
iteration 768: loss 0.494 0.320312 0.554688
iteration 769: loss 0.583 0.289062 0.515625
iteration 770: loss 0.602 0.304688 0.445312
iteration 771: loss 0.693 0.289062 0.343750
iteration 772: loss 0.657 0.312500 0.406250
iteration 773: loss 0.711 0.273438 0.414062
iteration 774: loss 0.597 0.250000 0.429688
iteration 775: loss 0.520 0.250000 0.492188
iteration 776: loss 0.571 0.234375 0.531250
iteration 777: loss 0.848 0.210938 0.414062
iteration 778: loss 0.635 0.367188 0.460938
iteration 779: loss 0.629 0.242188 0.445312
iteration 780: loss 0.640 0.375000 0.453125
iteration 781: loss 0.480 0.328125 0.492188
iteration 782: loss 0.634 0.328125 0.398438
iteration 783: loss 0.575 0.226562 0.429688
iteration 784: loss 0.625 0.304688 0.460938
iteration 785: loss 0.540 0.343750 0.484375
iteration 786: loss 0.545 0.375000 0.460938
iteration 787: loss 0.545 0.273438 0.492188
iteration 788: loss 0.576 0.335938 0.445312
iteration 789: loss 0.393 0.234375 0.570312
iteration 790: loss 0.651 0.289062 0.437500
iteration 791: loss 0.659 0.250000 0.468750
iteration 792: loss 0.643 0.328125 0.421875
iteration 793: loss 0.617 0.281250 0.500000
iteration 794: loss 0.586 0.367188 0.484375
iteration 795: loss 0.617 0.320312 0.484375
iteration 796: loss 0.681 0.289062 0.414062
iteration 797: loss 0.543 0.328125 0.500000
iteration 798: loss 0.570 0.265625 0.500000
iteration 799: loss 0.651 0.281250 0.492188
iteration 800: loss 0.576 0.304688 0.460938
iteration 801: loss 0.683 0.218750 0.492188
iteration 802: loss 0.597 0.203125 0.507812
iteration 803: loss 0.655 0.265625 0.445312
iteration 804: loss 0.617 0.257812 0.476562
iteration 805: loss 0.662 0.312500 0.406250
iteration 806: loss 0.520 0.242188 0.484375
iteration 807: loss 0.745 0.367188 0.406250
iteration 808: loss 0.862 0.250000 0.390625
iteration 809: loss 0.477 0.375000 0.546875
iteration 810: loss 0.709 0.257812 0.460938
iteration 811: loss 0.621 0.250000 0.445312
iteration 812: loss 0.595 0.257812 0.546875
iteration 813: loss 0.648 0.273438 0.468750
iteration 814: loss 0.616 0.296875 0.437500
iteration 815: loss 0.517 0.335938 0.539062
iteration 816: loss 0.670 0.328125 0.367188
iteration 817: loss 0.629 0.328125 0.500000
iteration 818: loss 0.528 0.312500 0.468750
iteration 819: loss 0.616 0.257812 0.429688
iteration 820: loss 0.576 0.242188 0.500000
iteration 821: loss 0.563 0.328125 0.460938
iteration 822: loss 0.601 0.289062 0.523438
iteration 823: loss 0.609 0.281250 0.421875
iteration 824: loss 0.528 0.203125 0.523438
iteration 825: loss 0.621 0.265625 0.453125
iteration 826: loss 0.661 0.320312 0.492188
iteration 827: loss 0.561 0.296875 0.515625
iteration 828: loss 0.638 0.304688 0.390625
iteration 829: loss 0.615 0.335938 0.460938
iteration 830: loss 0.481 0.367188 0.468750
iteration 831: loss 0.502 0.367188 0.523438
iteration 832: loss 0.600 0.265625 0.484375
iteration 833: loss 0.464 0.281250 0.523438
iteration 834: loss 0.650 0.312500 0.421875
iteration 835: loss 0.530 0.320312 0.617188
iteration 836: loss 0.702 0.312500 0.429688
iteration 837: loss 0.546 0.312500 0.437500
iteration 838: loss 0.582 0.335938 0.468750
iteration 839: loss 0.455 0.296875 0.515625
iteration 840: loss 0.584 0.304688 0.484375
iteration 841: loss 0.543 0.304688 0.460938
iteration 842: loss 0.405 0.265625 0.570312
iteration 843: loss 0.675 0.320312 0.484375
iteration 844: loss 0.607 0.367188 0.406250
iteration 845: loss 0.468 0.289062 0.468750
iteration 846: loss 0.457 0.312500 0.546875
iteration 847: loss 0.733 0.312500 0.500000
iteration 848: loss 0.702 0.281250 0.453125
iteration 849: loss 0.538 0.359375 0.515625
iteration 850: loss 0.679 0.351562 0.414062
iteration 851: loss 0.585 0.242188 0.445312
iteration 852: loss 0.449 0.273438 0.492188
iteration 853: loss 0.575 0.281250 0.531250
iteration 854: loss 0.543 0.312500 0.468750
iteration 855: loss 0.550 0.320312 0.554688
iteration 856: loss 0.483 0.257812 0.562500
iteration 857: loss 0.518 0.320312 0.507812
iteration 858: loss 0.416 0.312500 0.539062
iteration 859: loss 0.571 0.320312 0.476562
iteration 860: loss 0.682 0.242188 0.460938
iteration 861: loss 0.551 0.281250 0.492188
iteration 862: loss 0.609 0.296875 0.492188
iteration 863: loss 0.520 0.296875 0.531250
iteration 864: loss 0.726 0.265625 0.406250
iteration 865: loss 0.559 0.343750 0.437500
iteration 866: loss 0.522 0.335938 0.546875
iteration 867: loss 0.495 0.265625 0.531250
iteration 868: loss 0.506 0.382812 0.507812
iteration 869: loss 0.588 0.351562 0.515625
iteration 870: loss 0.562 0.343750 0.570312
iteration 871: loss 0.597 0.273438 0.421875
iteration 872: loss 0.699 0.343750 0.523438
iteration 873: loss 0.665 0.328125 0.437500
iteration 874: loss 0.671 0.320312 0.468750
iteration 875: loss 0.665 0.312500 0.531250
iteration 876: loss 0.455 0.218750 0.507812
iteration 877: loss 0.758 0.304688 0.382812
iteration 878: loss 0.604 0.250000 0.437500
iteration 879: loss 0.622 0.375000 0.421875
iteration 880: loss 0.555 0.289062 0.437500
iteration 881: loss 0.565 0.320312 0.539062
iteration 882: loss 0.661 0.304688 0.445312
iteration 883: loss 0.488 0.328125 0.570312
iteration 884: loss 0.565 0.234375 0.406250
iteration 885: loss 0.534 0.312500 0.523438
iteration 886: loss 0.567 0.296875 0.460938
iteration 887: loss 0.506 0.343750 0.484375
iteration 888: loss 0.630 0.281250 0.437500
iteration 889: loss 0.550 0.250000 0.531250
iteration 890: loss 0.616 0.289062 0.429688
iteration 891: loss 0.573 0.335938 0.445312
iteration 892: loss 0.565 0.289062 0.507812
iteration 893: loss 0.642 0.242188 0.445312
iteration 894: loss 0.486 0.296875 0.539062
iteration 895: loss 0.714 0.265625 0.429688
iteration 896: loss 0.648 0.304688 0.453125
iteration 897: loss 0.728 0.312500 0.375000
iteration 898: loss 0.652 0.382812 0.453125
iteration 899: loss 0.610 0.312500 0.421875
iteration 900: loss 0.671 0.289062 0.382812
iteration 901: loss 0.559 0.296875 0.492188
iteration 902: loss 0.650 0.359375 0.507812
iteration 903: loss 0.497 0.257812 0.523438
iteration 904: loss 0.542 0.320312 0.500000
iteration 905: loss 0.768 0.304688 0.414062
iteration 906: loss 0.425 0.296875 0.546875
iteration 907: loss 0.594 0.273438 0.484375
iteration 908: loss 0.663 0.328125 0.476562
iteration 909: loss 0.526 0.250000 0.531250
iteration 910: loss 0.543 0.375000 0.476562
iteration 911: loss 0.655 0.226562 0.468750
iteration 912: loss 0.791 0.367188 0.398438
iteration 913: loss 0.659 0.335938 0.445312
iteration 914: loss 0.675 0.296875 0.460938
iteration 915: loss 0.484 0.382812 0.468750
iteration 916: loss 0.609 0.343750 0.460938
iteration 917: loss 0.596 0.250000 0.445312
iteration 918: loss 0.549 0.367188 0.523438
iteration 919: loss 0.695 0.265625 0.359375
iteration 920: loss 0.505 0.289062 0.515625
iteration 921: loss 0.591 0.398438 0.484375
iteration 922: loss 0.569 0.281250 0.453125
iteration 923: loss 0.625 0.335938 0.453125
iteration 924: loss 0.765 0.273438 0.351562
iteration 925: loss 0.754 0.312500 0.343750
iteration 926: loss 0.560 0.304688 0.468750
iteration 927: loss 0.654 0.304688 0.406250
iteration 928: loss 0.463 0.320312 0.507812
iteration 929: loss 0.632 0.320312 0.453125
iteration 930: loss 0.550 0.296875 0.507812
iteration 931: loss 0.547 0.296875 0.460938
iteration 932: loss 0.574 0.328125 0.515625
iteration 933: loss 0.665 0.289062 0.500000
iteration 934: loss 0.555 0.250000 0.484375
iteration 935: loss 0.482 0.257812 0.476562
iteration 936: loss 0.584 0.265625 0.476562
iteration 937: loss 0.628 0.312500 0.500000
iteration 938: loss 0.679 0.335938 0.429688
iteration 939: loss 0.596 0.312500 0.453125
iteration 940: loss 0.519 0.312500 0.445312
iteration 941: loss 0.600 0.335938 0.523438
iteration 942: loss 0.617 0.304688 0.429688
iteration 943: loss 0.569 0.273438 0.500000
iteration 944: loss 0.554 0.250000 0.421875
iteration 945: loss 0.680 0.289062 0.398438
iteration 946: loss 0.727 0.367188 0.390625
iteration 947: loss 0.630 0.328125 0.468750
iteration 948: loss 0.643 0.257812 0.414062
iteration 949: loss 0.674 0.367188 0.460938
iteration 950: loss 0.433 0.289062 0.554688
iteration 951: loss 0.580 0.320312 0.507812
iteration 952: loss 0.597 0.289062 0.507812
iteration 953: loss 0.652 0.257812 0.460938
iteration 954: loss 0.614 0.289062 0.429688
iteration 955: loss 0.499 0.250000 0.515625
iteration 956: loss 0.610 0.328125 0.453125
iteration 957: loss 0.595 0.296875 0.507812
iteration 958: loss 0.461 0.328125 0.453125
iteration 959: loss 0.560 0.257812 0.500000
iteration 960: loss 0.524 0.289062 0.515625
iteration 961: loss 0.535 0.351562 0.515625
iteration 962: loss 0.564 0.335938 0.515625
iteration 963: loss 0.636 0.281250 0.445312
iteration 964: loss 0.496 0.335938 0.523438
iteration 965: loss 0.737 0.273438 0.398438
iteration 966: loss 0.697 0.234375 0.437500
iteration 967: loss 0.554 0.335938 0.445312
iteration 968: loss 0.566 0.343750 0.390625
iteration 969: loss 0.542 0.320312 0.468750
iteration 970: loss 0.565 0.304688 0.335938
iteration 971: loss 0.691 0.406250 0.359375
iteration 972: loss 0.528 0.304688 0.492188
iteration 973: loss 0.561 0.273438 0.468750
iteration 974: loss 0.540 0.257812 0.507812
iteration 975: loss 0.664 0.289062 0.453125
iteration 976: loss 0.380 0.335938 0.570312
iteration 977: loss 0.550 0.335938 0.507812
iteration 978: loss 0.534 0.328125 0.445312
iteration 979: loss 0.548 0.367188 0.492188
iteration 980: loss 0.554 0.257812 0.468750
iteration 981: loss 0.644 0.335938 0.500000
iteration 982: loss 0.592 0.281250 0.445312
iteration 983: loss 0.486 0.281250 0.460938
iteration 984: loss 0.560 0.250000 0.500000
iteration 985: loss 0.520 0.328125 0.476562
iteration 986: loss 0.506 0.250000 0.531250
iteration 987: loss 0.592 0.257812 0.507812
iteration 988: loss 0.585 0.312500 0.492188
iteration 989: loss 0.552 0.304688 0.492188
iteration 990: loss 0.559 0.304688 0.500000
iteration 991: loss 0.566 0.328125 0.453125
iteration 992: loss 0.540 0.335938 0.414062
iteration 993: loss 0.661 0.320312 0.382812
iteration 994: loss 0.532 0.304688 0.476562
iteration 995: loss 0.668 0.320312 0.445312
iteration 996: loss 0.618 0.312500 0.484375
iteration 997: loss 0.668 0.289062 0.421875
iteration 998: loss 0.634 0.335938 0.476562
iteration 999: loss 0.584 0.289062 0.468750
epoch 12: training: 0.281250 validation: 0.250000
iteration 0: loss 0.660 0.281250 0.429688
iteration 1: loss 0.704 0.281250 0.429688
iteration 2: loss 0.645 0.296875 0.460938
iteration 3: loss 0.668 0.289062 0.398438
iteration 4: loss 0.451 0.273438 0.515625
iteration 5: loss 0.522 0.375000 0.414062
iteration 6: loss 0.510 0.242188 0.484375
iteration 7: loss 0.563 0.320312 0.468750
iteration 8: loss 0.598 0.250000 0.492188
iteration 9: loss 0.570 0.265625 0.515625
iteration 10: loss 0.627 0.296875 0.484375
iteration 11: loss 0.588 0.367188 0.460938
iteration 12: loss 0.616 0.421875 0.460938
iteration 13: loss 0.558 0.289062 0.468750
iteration 14: loss 0.665 0.335938 0.429688
iteration 15: loss 0.587 0.320312 0.390625
iteration 16: loss 0.563 0.289062 0.468750
iteration 17: loss 0.696 0.242188 0.429688
iteration 18: loss 0.657 0.265625 0.406250
iteration 19: loss 0.519 0.281250 0.468750
iteration 20: loss 0.603 0.414062 0.437500
iteration 21: loss 0.624 0.304688 0.476562
iteration 22: loss 0.821 0.304688 0.429688
iteration 23: loss 0.691 0.304688 0.421875
iteration 24: loss 0.633 0.265625 0.460938
iteration 25: loss 0.519 0.296875 0.476562
iteration 26: loss 0.618 0.328125 0.453125
iteration 27: loss 0.547 0.250000 0.492188
iteration 28: loss 0.412 0.312500 0.585938
iteration 29: loss 0.608 0.351562 0.421875
iteration 30: loss 0.573 0.312500 0.492188
iteration 31: loss 0.470 0.265625 0.562500
iteration 32: loss 0.561 0.351562 0.460938
iteration 33: loss 0.556 0.320312 0.390625
iteration 34: loss 0.572 0.289062 0.468750
iteration 35: loss 0.637 0.320312 0.421875
iteration 36: loss 0.777 0.359375 0.398438
iteration 37: loss 0.578 0.296875 0.445312
iteration 38: loss 0.486 0.289062 0.429688
iteration 39: loss 0.644 0.312500 0.382812
iteration 40: loss 0.587 0.296875 0.421875
iteration 41: loss 0.610 0.328125 0.476562
iteration 42: loss 0.484 0.250000 0.484375
iteration 43: loss 0.632 0.273438 0.539062
iteration 44: loss 0.566 0.289062 0.507812
iteration 45: loss 0.822 0.312500 0.429688
iteration 46: loss 0.559 0.335938 0.539062
iteration 47: loss 0.607 0.312500 0.453125
iteration 48: loss 0.646 0.312500 0.460938
iteration 49: loss 0.613 0.296875 0.500000
iteration 50: loss 0.759 0.367188 0.414062
iteration 51: loss 0.597 0.265625 0.531250
iteration 52: loss 0.579 0.242188 0.492188
iteration 53: loss 0.796 0.367188 0.429688
iteration 54: loss 0.493 0.390625 0.531250
iteration 55: loss 0.476 0.265625 0.484375
iteration 56: loss 0.523 0.289062 0.460938
iteration 57: loss 0.517 0.281250 0.500000
iteration 58: loss 0.501 0.320312 0.476562
iteration 59: loss 0.729 0.281250 0.398438
iteration 60: loss 0.644 0.343750 0.445312
iteration 61: loss 0.597 0.273438 0.468750
iteration 62: loss 0.651 0.273438 0.421875
iteration 63: loss 0.597 0.265625 0.437500
iteration 64: loss 0.470 0.257812 0.531250
iteration 65: loss 0.659 0.304688 0.367188
iteration 66: loss 0.587 0.312500 0.531250
iteration 67: loss 0.613 0.320312 0.476562
iteration 68: loss 0.497 0.273438 0.476562
iteration 69: loss 0.596 0.328125 0.460938
iteration 70: loss 0.607 0.335938 0.421875
iteration 71: loss 0.484 0.367188 0.476562
iteration 72: loss 0.497 0.320312 0.492188
iteration 73: loss 0.511 0.320312 0.492188
iteration 74: loss 0.641 0.289062 0.507812
iteration 75: loss 0.508 0.304688 0.492188
iteration 76: loss 0.732 0.343750 0.460938
iteration 77: loss 0.516 0.289062 0.531250
iteration 78: loss 0.680 0.335938 0.414062
iteration 79: loss 0.682 0.289062 0.414062
iteration 80: loss 0.663 0.328125 0.468750
iteration 81: loss 0.584 0.328125 0.476562
iteration 82: loss 0.571 0.335938 0.429688
iteration 83: loss 0.539 0.343750 0.523438
iteration 84: loss 0.634 0.343750 0.492188
iteration 85: loss 0.628 0.328125 0.453125
iteration 86: loss 0.584 0.195312 0.460938
iteration 87: loss 0.564 0.242188 0.476562
iteration 88: loss 0.563 0.250000 0.476562
iteration 89: loss 0.525 0.296875 0.484375
iteration 90: loss 0.555 0.320312 0.429688
iteration 91: loss 0.595 0.320312 0.468750
iteration 92: loss 0.618 0.312500 0.468750
iteration 93: loss 0.531 0.289062 0.507812
iteration 94: loss 0.568 0.312500 0.492188
iteration 95: loss 0.532 0.320312 0.507812
iteration 96: loss 0.721 0.343750 0.382812
iteration 97: loss 0.504 0.320312 0.468750
iteration 98: loss 0.438 0.312500 0.531250
iteration 99: loss 0.527 0.304688 0.468750
iteration 100: loss 0.639 0.312500 0.437500
iteration 101: loss 0.537 0.281250 0.554688
iteration 102: loss 0.662 0.265625 0.445312
iteration 103: loss 0.625 0.304688 0.460938
iteration 104: loss 0.537 0.335938 0.515625
iteration 105: loss 0.501 0.304688 0.515625
iteration 106: loss 0.604 0.328125 0.437500
iteration 107: loss 0.615 0.367188 0.453125
iteration 108: loss 0.632 0.281250 0.500000
iteration 109: loss 0.579 0.328125 0.453125
iteration 110: loss 0.670 0.390625 0.453125
iteration 111: loss 0.522 0.273438 0.492188
iteration 112: loss 0.636 0.257812 0.414062
iteration 113: loss 0.476 0.226562 0.484375
iteration 114: loss 0.578 0.328125 0.515625
iteration 115: loss 0.618 0.250000 0.453125
iteration 116: loss 0.665 0.281250 0.429688
iteration 117: loss 0.614 0.343750 0.421875
iteration 118: loss 0.511 0.289062 0.460938
iteration 119: loss 0.461 0.320312 0.562500
iteration 120: loss 0.660 0.320312 0.460938
iteration 121: loss 0.858 0.390625 0.351562
iteration 122: loss 0.633 0.367188 0.437500
iteration 123: loss 0.570 0.320312 0.523438
iteration 124: loss 0.577 0.335938 0.468750
iteration 125: loss 0.541 0.320312 0.531250
iteration 126: loss 0.605 0.281250 0.445312
iteration 127: loss 0.696 0.320312 0.445312
iteration 128: loss 0.608 0.210938 0.375000
iteration 129: loss 0.570 0.296875 0.398438
iteration 130: loss 0.617 0.250000 0.421875
iteration 131: loss 0.620 0.257812 0.445312
iteration 132: loss 0.697 0.304688 0.437500
iteration 133: loss 0.666 0.265625 0.468750
iteration 134: loss 0.619 0.328125 0.421875
iteration 135: loss 0.826 0.289062 0.367188
iteration 136: loss 0.537 0.359375 0.476562
iteration 137: loss 0.567 0.367188 0.492188
iteration 138: loss 0.526 0.304688 0.539062
iteration 139: loss 0.710 0.382812 0.476562
iteration 140: loss 0.630 0.375000 0.460938
iteration 141: loss 0.599 0.304688 0.453125
iteration 142: loss 0.665 0.195312 0.492188
iteration 143: loss 0.641 0.351562 0.500000
iteration 144: loss 0.664 0.382812 0.421875
iteration 145: loss 0.624 0.390625 0.460938
iteration 146: loss 0.497 0.304688 0.507812
iteration 147: loss 0.599 0.304688 0.398438
iteration 148: loss 0.719 0.328125 0.398438
iteration 149: loss 0.548 0.320312 0.500000
iteration 150: loss 0.564 0.273438 0.531250
iteration 151: loss 0.563 0.273438 0.476562
iteration 152: loss 0.567 0.304688 0.507812
iteration 153: loss 0.518 0.289062 0.515625
iteration 154: loss 0.707 0.312500 0.515625
iteration 155: loss 0.657 0.304688 0.453125
iteration 156: loss 0.573 0.296875 0.507812
iteration 157: loss 0.658 0.296875 0.382812
iteration 158: loss 0.621 0.312500 0.453125
iteration 159: loss 0.621 0.242188 0.476562
iteration 160: loss 0.609 0.273438 0.453125
iteration 161: loss 0.512 0.328125 0.445312
iteration 162: loss 0.572 0.328125 0.531250
iteration 163: loss 0.613 0.250000 0.500000
iteration 164: loss 0.584 0.281250 0.453125
iteration 165: loss 0.772 0.289062 0.382812
iteration 166: loss 0.570 0.335938 0.429688
iteration 167: loss 0.585 0.312500 0.507812
iteration 168: loss 0.616 0.320312 0.414062
iteration 169: loss 0.605 0.328125 0.429688
iteration 170: loss 0.703 0.312500 0.406250
iteration 171: loss 0.596 0.289062 0.484375
iteration 172: loss 0.568 0.351562 0.468750
iteration 173: loss 0.614 0.281250 0.476562
iteration 174: loss 0.600 0.257812 0.429688
iteration 175: loss 0.560 0.281250 0.421875
iteration 176: loss 0.553 0.320312 0.398438
iteration 177: loss 0.609 0.335938 0.460938
iteration 178: loss 0.604 0.242188 0.421875
iteration 179: loss 0.582 0.289062 0.414062
iteration 180: loss 0.506 0.312500 0.507812
iteration 181: loss 0.512 0.390625 0.445312
iteration 182: loss 0.536 0.296875 0.500000
iteration 183: loss 0.518 0.281250 0.500000
iteration 184: loss 0.578 0.250000 0.445312
iteration 185: loss 0.557 0.320312 0.476562
iteration 186: loss 0.594 0.265625 0.390625
iteration 187: loss 0.564 0.320312 0.460938
iteration 188: loss 0.518 0.289062 0.531250
iteration 189: loss 0.580 0.273438 0.460938
iteration 190: loss 0.608 0.296875 0.460938
iteration 191: loss 0.410 0.304688 0.492188
iteration 192: loss 0.679 0.218750 0.398438
iteration 193: loss 0.445 0.367188 0.484375
iteration 194: loss 0.662 0.320312 0.453125
iteration 195: loss 0.565 0.359375 0.460938
iteration 196: loss 0.542 0.390625 0.492188
iteration 197: loss 0.539 0.328125 0.523438
iteration 198: loss 0.567 0.328125 0.476562
iteration 199: loss 0.564 0.335938 0.453125
iteration 200: loss 0.563 0.335938 0.437500
iteration 201: loss 0.447 0.304688 0.484375
iteration 202: loss 0.576 0.281250 0.460938
iteration 203: loss 0.626 0.289062 0.382812
iteration 204: loss 0.568 0.375000 0.476562
iteration 205: loss 0.506 0.273438 0.500000
iteration 206: loss 0.541 0.304688 0.437500
iteration 207: loss 0.594 0.335938 0.437500
iteration 208: loss 0.514 0.390625 0.445312
iteration 209: loss 0.532 0.296875 0.476562
iteration 210: loss 0.612 0.296875 0.484375
iteration 211: loss 0.625 0.390625 0.343750
iteration 212: loss 0.619 0.320312 0.421875
iteration 213: loss 0.534 0.343750 0.437500
iteration 214: loss 0.633 0.250000 0.445312
iteration 215: loss 0.685 0.343750 0.406250
iteration 216: loss 0.635 0.265625 0.398438
iteration 217: loss 0.477 0.250000 0.507812
iteration 218: loss 0.595 0.289062 0.492188
iteration 219: loss 0.550 0.226562 0.507812
iteration 220: loss 0.473 0.273438 0.500000
iteration 221: loss 0.533 0.312500 0.507812
iteration 222: loss 0.454 0.312500 0.523438
iteration 223: loss 0.549 0.367188 0.476562
iteration 224: loss 0.626 0.328125 0.414062
iteration 225: loss 0.554 0.250000 0.453125
iteration 226: loss 0.600 0.242188 0.453125
iteration 227: loss 0.472 0.289062 0.523438
iteration 228: loss 0.614 0.296875 0.382812
iteration 229: loss 0.626 0.234375 0.476562
iteration 230: loss 0.514 0.335938 0.445312
iteration 231: loss 0.616 0.351562 0.468750
iteration 232: loss 0.527 0.343750 0.453125
iteration 233: loss 0.616 0.296875 0.437500
iteration 234: loss 0.626 0.375000 0.468750
iteration 235: loss 0.632 0.375000 0.445312
iteration 236: loss 0.538 0.273438 0.484375
iteration 237: loss 0.607 0.265625 0.484375
iteration 238: loss 0.543 0.335938 0.554688
iteration 239: loss 0.582 0.289062 0.468750
iteration 240: loss 0.580 0.296875 0.453125
iteration 241: loss 0.640 0.281250 0.414062
iteration 242: loss 0.504 0.289062 0.484375
iteration 243: loss 0.559 0.320312 0.429688
iteration 244: loss 0.531 0.375000 0.476562
iteration 245: loss 0.441 0.304688 0.460938
iteration 246: loss 0.633 0.445312 0.390625
iteration 247: loss 0.561 0.359375 0.468750
iteration 248: loss 0.483 0.343750 0.445312
iteration 249: loss 0.709 0.335938 0.375000
iteration 250: loss 0.595 0.335938 0.406250
iteration 251: loss 0.550 0.328125 0.398438
iteration 252: loss 0.366 0.398438 0.578125
iteration 253: loss 0.517 0.304688 0.484375
iteration 254: loss 0.671 0.390625 0.500000
iteration 255: loss 0.569 0.320312 0.500000
iteration 256: loss 0.631 0.242188 0.445312
iteration 257: loss 0.570 0.296875 0.437500
iteration 258: loss 0.669 0.351562 0.421875
iteration 259: loss 0.517 0.335938 0.507812
iteration 260: loss 0.646 0.328125 0.406250
iteration 261: loss 0.536 0.265625 0.500000
iteration 262: loss 0.481 0.312500 0.531250
iteration 263: loss 0.451 0.375000 0.539062
iteration 264: loss 0.517 0.367188 0.484375
iteration 265: loss 0.577 0.304688 0.437500
iteration 266: loss 0.696 0.375000 0.398438
iteration 267: loss 0.611 0.328125 0.406250
iteration 268: loss 0.591 0.296875 0.398438
iteration 269: loss 0.628 0.281250 0.367188
iteration 270: loss 0.562 0.343750 0.437500
iteration 271: loss 0.516 0.304688 0.507812
iteration 272: loss 0.553 0.296875 0.515625
iteration 273: loss 0.587 0.250000 0.500000
iteration 274: loss 0.625 0.367188 0.476562
iteration 275: loss 0.554 0.312500 0.523438
iteration 276: loss 0.566 0.320312 0.453125
iteration 277: loss 0.485 0.312500 0.531250
iteration 278: loss 0.629 0.289062 0.421875
iteration 279: loss 0.497 0.234375 0.507812
iteration 280: loss 0.575 0.359375 0.429688
iteration 281: loss 0.575 0.273438 0.460938
iteration 282: loss 0.551 0.242188 0.500000
iteration 283: loss 0.478 0.289062 0.453125
iteration 284: loss 0.534 0.265625 0.484375
iteration 285: loss 0.509 0.281250 0.531250
iteration 286: loss 0.579 0.273438 0.468750
iteration 287: loss 0.481 0.320312 0.539062
iteration 288: loss 0.563 0.304688 0.390625
iteration 289: loss 0.538 0.359375 0.437500
iteration 290: loss 0.601 0.351562 0.460938
iteration 291: loss 0.518 0.343750 0.523438
iteration 292: loss 0.690 0.320312 0.515625
iteration 293: loss 0.607 0.289062 0.523438
iteration 294: loss 0.603 0.281250 0.398438
iteration 295: loss 0.568 0.312500 0.398438
iteration 296: loss 0.548 0.273438 0.484375
iteration 297: loss 0.630 0.320312 0.523438
iteration 298: loss 0.611 0.351562 0.492188
iteration 299: loss 0.661 0.273438 0.382812
iteration 300: loss 0.548 0.257812 0.406250
iteration 301: loss 0.485 0.281250 0.484375
iteration 302: loss 0.672 0.328125 0.421875
iteration 303: loss 0.623 0.226562 0.421875
iteration 304: loss 0.446 0.296875 0.546875
iteration 305: loss 0.686 0.289062 0.570312
iteration 306: loss 0.640 0.265625 0.507812
iteration 307: loss 0.548 0.250000 0.445312
iteration 308: loss 0.536 0.343750 0.382812
iteration 309: loss 0.560 0.281250 0.437500
iteration 310: loss 0.641 0.304688 0.429688
iteration 311: loss 0.654 0.257812 0.476562
iteration 312: loss 0.633 0.320312 0.468750
iteration 313: loss 0.796 0.304688 0.328125
iteration 314: loss 0.472 0.296875 0.523438
iteration 315: loss 0.705 0.320312 0.390625
iteration 316: loss 0.571 0.382812 0.437500
iteration 317: loss 0.518 0.273438 0.515625
iteration 318: loss 0.601 0.335938 0.445312
iteration 319: loss 0.555 0.312500 0.453125
iteration 320: loss 0.583 0.351562 0.429688
iteration 321: loss 0.629 0.281250 0.390625
iteration 322: loss 0.710 0.367188 0.406250
iteration 323: loss 0.547 0.312500 0.523438
iteration 324: loss 0.691 0.265625 0.367188
iteration 325: loss 0.525 0.367188 0.414062
iteration 326: loss 0.441 0.250000 0.562500
iteration 327: loss 0.596 0.304688 0.421875
iteration 328: loss 0.542 0.296875 0.523438
iteration 329: loss 0.588 0.328125 0.476562
iteration 330: loss 0.688 0.304688 0.445312
iteration 331: loss 0.652 0.375000 0.484375
iteration 332: loss 0.623 0.250000 0.492188
iteration 333: loss 0.722 0.296875 0.359375
iteration 334: loss 0.561 0.265625 0.507812
iteration 335: loss 0.491 0.312500 0.500000
iteration 336: loss 0.608 0.289062 0.445312
iteration 337: loss 0.472 0.343750 0.539062
iteration 338: loss 0.508 0.304688 0.539062
iteration 339: loss 0.484 0.304688 0.484375
iteration 340: loss 0.631 0.343750 0.375000
iteration 341: loss 0.639 0.257812 0.453125
iteration 342: loss 0.494 0.234375 0.523438
iteration 343: loss 0.469 0.359375 0.570312
iteration 344: loss 0.661 0.265625 0.500000
iteration 345: loss 0.561 0.265625 0.468750
iteration 346: loss 0.565 0.273438 0.429688
iteration 347: loss 0.564 0.343750 0.421875
iteration 348: loss 0.591 0.320312 0.437500
iteration 349: loss 0.549 0.250000 0.546875
iteration 350: loss 0.533 0.351562 0.492188
iteration 351: loss 0.600 0.304688 0.437500
iteration 352: loss 0.588 0.328125 0.460938
iteration 353: loss 0.517 0.234375 0.515625
iteration 354: loss 0.581 0.273438 0.468750
iteration 355: loss 0.614 0.312500 0.500000
iteration 356: loss 0.596 0.328125 0.460938
iteration 357: loss 0.564 0.359375 0.445312
iteration 358: loss 0.673 0.390625 0.406250
iteration 359: loss 0.531 0.257812 0.500000
iteration 360: loss 0.565 0.375000 0.507812
iteration 361: loss 0.581 0.312500 0.476562
iteration 362: loss 0.671 0.273438 0.468750
iteration 363: loss 0.761 0.351562 0.445312
iteration 364: loss 0.477 0.320312 0.445312
iteration 365: loss 0.622 0.296875 0.492188
iteration 366: loss 0.665 0.367188 0.476562
iteration 367: loss 0.596 0.320312 0.523438
iteration 368: loss 0.674 0.351562 0.453125
iteration 369: loss 0.666 0.312500 0.429688
iteration 370: loss 0.693 0.304688 0.437500
iteration 371: loss 0.553 0.257812 0.437500
iteration 372: loss 0.686 0.296875 0.484375
iteration 373: loss 0.658 0.343750 0.375000
iteration 374: loss 0.608 0.250000 0.421875
iteration 375: loss 0.510 0.320312 0.500000
iteration 376: loss 0.734 0.328125 0.460938
iteration 377: loss 0.598 0.257812 0.437500
iteration 378: loss 0.614 0.281250 0.492188
iteration 379: loss 0.600 0.390625 0.523438
iteration 380: loss 0.646 0.304688 0.375000
iteration 381: loss 0.467 0.304688 0.539062
iteration 382: loss 0.696 0.226562 0.476562
iteration 383: loss 0.555 0.437500 0.515625
iteration 384: loss 0.610 0.296875 0.453125
iteration 385: loss 0.631 0.328125 0.468750
iteration 386: loss 0.772 0.343750 0.437500
iteration 387: loss 0.545 0.335938 0.460938
iteration 388: loss 0.456 0.281250 0.531250
iteration 389: loss 0.637 0.289062 0.492188
iteration 390: loss 0.490 0.296875 0.546875
iteration 391: loss 0.626 0.289062 0.429688
iteration 392: loss 0.449 0.343750 0.570312
iteration 393: loss 0.614 0.281250 0.429688
iteration 394: loss 0.530 0.312500 0.460938
iteration 395: loss 0.750 0.273438 0.414062
iteration 396: loss 0.544 0.250000 0.492188
iteration 397: loss 0.564 0.289062 0.476562
iteration 398: loss 0.529 0.312500 0.453125
iteration 399: loss 0.526 0.351562 0.507812
iteration 400: loss 0.628 0.312500 0.429688
iteration 401: loss 0.508 0.289062 0.531250
iteration 402: loss 0.467 0.296875 0.492188
iteration 403: loss 0.400 0.265625 0.570312
iteration 404: loss 0.572 0.281250 0.500000
iteration 405: loss 0.604 0.398438 0.492188
iteration 406: loss 0.511 0.328125 0.546875
iteration 407: loss 0.512 0.281250 0.492188
iteration 408: loss 0.604 0.320312 0.476562
iteration 409: loss 0.504 0.304688 0.476562
iteration 410: loss 0.656 0.289062 0.429688
iteration 411: loss 0.520 0.218750 0.484375
iteration 412: loss 0.555 0.343750 0.398438
iteration 413: loss 0.592 0.312500 0.382812
iteration 414: loss 0.522 0.312500 0.492188
iteration 415: loss 0.523 0.296875 0.390625
iteration 416: loss 0.494 0.359375 0.484375
iteration 417: loss 0.645 0.281250 0.492188
iteration 418: loss 0.523 0.242188 0.476562
iteration 419: loss 0.635 0.351562 0.437500
iteration 420: loss 0.470 0.281250 0.484375
iteration 421: loss 0.472 0.281250 0.539062
iteration 422: loss 0.724 0.304688 0.429688
iteration 423: loss 0.646 0.257812 0.390625
iteration 424: loss 0.662 0.304688 0.421875
iteration 425: loss 0.562 0.335938 0.445312
iteration 426: loss 0.722 0.304688 0.390625
iteration 427: loss 0.674 0.257812 0.492188
iteration 428: loss 0.654 0.304688 0.539062
iteration 429: loss 0.554 0.250000 0.484375
iteration 430: loss 0.584 0.328125 0.406250
iteration 431: loss 0.609 0.390625 0.398438
iteration 432: loss 0.592 0.296875 0.421875
iteration 433: loss 0.581 0.367188 0.437500
iteration 434: loss 0.566 0.250000 0.554688
iteration 435: loss 0.573 0.351562 0.437500
iteration 436: loss 0.660 0.281250 0.515625
iteration 437: loss 0.603 0.312500 0.453125
iteration 438: loss 0.485 0.289062 0.484375
iteration 439: loss 0.540 0.304688 0.500000
iteration 440: loss 0.534 0.335938 0.476562
iteration 441: loss 0.526 0.210938 0.484375
iteration 442: loss 0.653 0.257812 0.421875
iteration 443: loss 0.579 0.296875 0.476562
iteration 444: loss 0.671 0.312500 0.421875
iteration 445: loss 0.456 0.335938 0.593750
iteration 446: loss 0.775 0.296875 0.476562
iteration 447: loss 0.600 0.257812 0.484375
iteration 448: loss 0.593 0.226562 0.453125
iteration 449: loss 0.563 0.296875 0.406250
iteration 450: loss 0.620 0.242188 0.429688
iteration 451: loss 0.580 0.312500 0.453125
iteration 452: loss 0.525 0.367188 0.523438
iteration 453: loss 0.728 0.343750 0.406250
iteration 454: loss 0.808 0.312500 0.367188
iteration 455: loss 0.609 0.242188 0.460938
iteration 456: loss 0.620 0.351562 0.429688
iteration 457: loss 0.436 0.367188 0.539062
iteration 458: loss 0.662 0.257812 0.414062
iteration 459: loss 0.551 0.320312 0.492188
iteration 460: loss 0.530 0.343750 0.445312
iteration 461: loss 0.493 0.250000 0.507812
iteration 462: loss 0.523 0.351562 0.460938
iteration 463: loss 0.531 0.320312 0.523438
iteration 464: loss 0.525 0.296875 0.523438
iteration 465: loss 0.602 0.335938 0.445312
iteration 466: loss 0.561 0.281250 0.484375
iteration 467: loss 0.562 0.351562 0.476562
iteration 468: loss 0.638 0.281250 0.437500
iteration 469: loss 0.506 0.328125 0.492188
iteration 470: loss 0.378 0.335938 0.546875
iteration 471: loss 0.548 0.312500 0.429688
iteration 472: loss 0.778 0.312500 0.453125
iteration 473: loss 0.576 0.257812 0.460938
iteration 474: loss 0.612 0.328125 0.437500
iteration 475: loss 0.712 0.343750 0.406250
iteration 476: loss 0.524 0.226562 0.507812
iteration 477: loss 0.546 0.273438 0.539062
iteration 478: loss 0.565 0.296875 0.445312
iteration 479: loss 0.716 0.203125 0.429688
iteration 480: loss 0.463 0.296875 0.515625
iteration 481: loss 0.514 0.390625 0.460938
iteration 482: loss 0.617 0.335938 0.414062
iteration 483: loss 0.456 0.328125 0.562500
iteration 484: loss 0.712 0.328125 0.453125
iteration 485: loss 0.532 0.265625 0.500000
iteration 486: loss 0.452 0.328125 0.578125
iteration 487: loss 0.497 0.328125 0.468750
iteration 488: loss 0.749 0.242188 0.398438
iteration 489: loss 0.610 0.304688 0.398438
iteration 490: loss 0.546 0.312500 0.414062
iteration 491: loss 0.594 0.289062 0.414062
iteration 492: loss 0.498 0.289062 0.492188
iteration 493: loss 0.501 0.289062 0.523438
iteration 494: loss 0.562 0.312500 0.507812
iteration 495: loss 0.514 0.335938 0.476562
iteration 496: loss 0.646 0.273438 0.460938
iteration 497: loss 0.564 0.390625 0.460938
iteration 498: loss 0.719 0.328125 0.421875
iteration 499: loss 0.502 0.304688 0.460938
iteration 500: loss 0.528 0.250000 0.507812
iteration 501: loss 0.701 0.242188 0.453125
iteration 502: loss 0.466 0.343750 0.531250
iteration 503: loss 0.635 0.273438 0.429688
iteration 504: loss 0.622 0.257812 0.492188
iteration 505: loss 0.586 0.312500 0.468750
iteration 506: loss 0.608 0.398438 0.437500
iteration 507: loss 0.602 0.296875 0.460938
iteration 508: loss 0.496 0.304688 0.429688
iteration 509: loss 0.520 0.335938 0.531250
iteration 510: loss 0.449 0.304688 0.507812
iteration 511: loss 0.599 0.296875 0.484375
iteration 512: loss 0.443 0.343750 0.507812
iteration 513: loss 0.544 0.328125 0.531250
iteration 514: loss 0.579 0.296875 0.437500
iteration 515: loss 0.494 0.296875 0.507812
iteration 516: loss 0.568 0.265625 0.500000
iteration 517: loss 0.580 0.257812 0.523438
iteration 518: loss 0.519 0.304688 0.437500
iteration 519: loss 0.548 0.351562 0.445312
iteration 520: loss 0.552 0.343750 0.421875
iteration 521: loss 0.545 0.320312 0.429688
iteration 522: loss 0.441 0.328125 0.539062
iteration 523: loss 0.562 0.281250 0.445312
iteration 524: loss 0.425 0.320312 0.593750
iteration 525: loss 0.486 0.257812 0.539062
iteration 526: loss 0.518 0.367188 0.531250
iteration 527: loss 0.560 0.312500 0.437500
iteration 528: loss 0.618 0.257812 0.515625
iteration 529: loss 0.657 0.250000 0.492188
iteration 530: loss 0.507 0.289062 0.484375
iteration 531: loss 0.542 0.296875 0.476562
iteration 532: loss 0.494 0.359375 0.468750
iteration 533: loss 0.473 0.304688 0.507812
iteration 534: loss 0.449 0.273438 0.507812
iteration 535: loss 0.522 0.289062 0.453125
iteration 536: loss 0.462 0.289062 0.546875
iteration 537: loss 0.471 0.328125 0.460938
iteration 538: loss 0.475 0.273438 0.539062
iteration 539: loss 0.615 0.351562 0.367188
iteration 540: loss 0.636 0.312500 0.398438
iteration 541: loss 0.702 0.296875 0.351562
iteration 542: loss 0.580 0.281250 0.460938
iteration 543: loss 0.610 0.257812 0.406250
iteration 544: loss 0.664 0.343750 0.320312
iteration 545: loss 0.634 0.281250 0.328125
iteration 546: loss 0.445 0.312500 0.476562
iteration 547: loss 0.475 0.398438 0.437500
iteration 548: loss 0.495 0.320312 0.476562
iteration 549: loss 0.598 0.359375 0.523438
iteration 550: loss 0.604 0.335938 0.453125
iteration 551: loss 0.543 0.265625 0.453125
iteration 552: loss 0.578 0.312500 0.460938
iteration 553: loss 0.560 0.335938 0.460938
iteration 554: loss 0.652 0.343750 0.429688
iteration 555: loss 0.607 0.343750 0.421875
iteration 556: loss 0.641 0.281250 0.484375
iteration 557: loss 0.703 0.304688 0.351562
iteration 558: loss 0.629 0.312500 0.398438
iteration 559: loss 0.763 0.289062 0.343750
iteration 560: loss 0.513 0.328125 0.476562
iteration 561: loss 0.623 0.312500 0.484375
iteration 562: loss 0.643 0.320312 0.460938
iteration 563: loss 0.518 0.328125 0.531250
iteration 564: loss 0.660 0.351562 0.414062
iteration 565: loss 0.638 0.242188 0.492188
iteration 566: loss 0.672 0.351562 0.453125
iteration 567: loss 0.560 0.210938 0.492188
iteration 568: loss 0.545 0.367188 0.484375
iteration 569: loss 0.637 0.250000 0.445312
iteration 570: loss 0.582 0.367188 0.437500
iteration 571: loss 0.825 0.312500 0.492188
iteration 572: loss 0.614 0.343750 0.500000
iteration 573: loss 0.648 0.320312 0.507812
iteration 574: loss 0.856 0.281250 0.343750
iteration 575: loss 0.741 0.242188 0.390625
iteration 576: loss 0.544 0.234375 0.500000
iteration 577: loss 0.633 0.320312 0.453125
iteration 578: loss 0.575 0.343750 0.453125
iteration 579: loss 0.753 0.312500 0.367188
iteration 580: loss 0.616 0.273438 0.421875
iteration 581: loss 0.606 0.289062 0.468750
iteration 582: loss 0.542 0.296875 0.460938
iteration 583: loss 0.400 0.281250 0.578125
iteration 584: loss 0.524 0.351562 0.500000
iteration 585: loss 0.490 0.382812 0.546875
iteration 586: loss 0.620 0.281250 0.500000
iteration 587: loss 0.601 0.328125 0.429688
iteration 588: loss 0.646 0.265625 0.421875
iteration 589: loss 0.702 0.304688 0.460938
iteration 590: loss 0.674 0.242188 0.429688
iteration 591: loss 0.660 0.304688 0.507812
iteration 592: loss 0.441 0.250000 0.554688
iteration 593: loss 0.617 0.367188 0.390625
iteration 594: loss 0.531 0.304688 0.515625
iteration 595: loss 0.509 0.265625 0.476562
iteration 596: loss 0.626 0.343750 0.507812
iteration 597: loss 0.569 0.296875 0.460938
iteration 598: loss 0.549 0.273438 0.484375
iteration 599: loss 0.659 0.234375 0.375000
iteration 600: loss 0.514 0.265625 0.460938
iteration 601: loss 0.606 0.328125 0.406250
iteration 602: loss 0.708 0.359375 0.406250
iteration 603: loss 0.522 0.328125 0.484375
iteration 604: loss 0.488 0.367188 0.546875
iteration 605: loss 0.522 0.218750 0.500000
iteration 606: loss 0.567 0.273438 0.492188
iteration 607: loss 0.552 0.265625 0.437500
iteration 608: loss 0.597 0.312500 0.414062
iteration 609: loss 0.656 0.257812 0.460938
iteration 610: loss 0.552 0.304688 0.421875
iteration 611: loss 0.513 0.226562 0.507812
iteration 612: loss 0.534 0.312500 0.539062
iteration 613: loss 0.632 0.265625 0.429688
iteration 614: loss 0.557 0.265625 0.492188
iteration 615: loss 0.578 0.257812 0.476562
iteration 616: loss 0.644 0.312500 0.484375
iteration 617: loss 0.625 0.312500 0.468750
iteration 618: loss 0.588 0.281250 0.453125
iteration 619: loss 0.476 0.304688 0.507812
iteration 620: loss 0.550 0.257812 0.453125
iteration 621: loss 0.560 0.242188 0.406250
iteration 622: loss 0.591 0.289062 0.445312
iteration 623: loss 0.734 0.265625 0.375000
iteration 624: loss 0.603 0.281250 0.390625
iteration 625: loss 0.540 0.328125 0.476562
iteration 626: loss 0.458 0.296875 0.515625
iteration 627: loss 0.716 0.304688 0.390625
iteration 628: loss 0.544 0.335938 0.546875
iteration 629: loss 0.445 0.343750 0.523438
iteration 630: loss 0.580 0.289062 0.445312
iteration 631: loss 0.581 0.273438 0.421875
iteration 632: loss 0.562 0.320312 0.421875
iteration 633: loss 0.558 0.226562 0.484375
iteration 634: loss 0.616 0.375000 0.421875
iteration 635: loss 0.702 0.265625 0.453125
iteration 636: loss 0.612 0.257812 0.476562
iteration 637: loss 0.592 0.343750 0.453125
iteration 638: loss 0.455 0.335938 0.476562
iteration 639: loss 0.560 0.320312 0.492188
iteration 640: loss 0.503 0.273438 0.539062
iteration 641: loss 0.552 0.296875 0.539062
iteration 642: loss 0.609 0.312500 0.460938
iteration 643: loss 0.524 0.406250 0.382812
iteration 644: loss 0.602 0.289062 0.390625
iteration 645: loss 0.778 0.304688 0.414062
iteration 646: loss 0.691 0.359375 0.476562
iteration 647: loss 0.662 0.320312 0.429688
iteration 648: loss 0.519 0.335938 0.445312
iteration 649: loss 0.725 0.335938 0.437500
iteration 650: loss 0.649 0.281250 0.421875
iteration 651: loss 0.600 0.281250 0.414062
iteration 652: loss 0.519 0.343750 0.484375
iteration 653: loss 0.607 0.328125 0.476562
iteration 654: loss 0.614 0.234375 0.414062
iteration 655: loss 0.481 0.304688 0.523438
iteration 656: loss 0.661 0.312500 0.414062
iteration 657: loss 0.623 0.312500 0.437500
iteration 658: loss 0.650 0.320312 0.406250
iteration 659: loss 0.586 0.343750 0.476562
iteration 660: loss 0.663 0.296875 0.421875
iteration 661: loss 0.636 0.328125 0.398438
iteration 662: loss 0.501 0.320312 0.453125
iteration 663: loss 0.481 0.296875 0.523438
iteration 664: loss 0.570 0.406250 0.445312
iteration 665: loss 0.618 0.289062 0.460938
iteration 666: loss 0.562 0.375000 0.476562
iteration 667: loss 0.645 0.281250 0.453125
iteration 668: loss 0.661 0.226562 0.421875
iteration 669: loss 0.597 0.289062 0.429688
iteration 670: loss 0.497 0.289062 0.476562
iteration 671: loss 0.535 0.382812 0.468750
iteration 672: loss 0.488 0.179688 0.539062
iteration 673: loss 0.596 0.257812 0.460938
iteration 674: loss 0.519 0.250000 0.492188
iteration 675: loss 0.611 0.312500 0.421875
iteration 676: loss 0.677 0.359375 0.460938
iteration 677: loss 0.532 0.359375 0.468750
iteration 678: loss 0.517 0.359375 0.453125
iteration 679: loss 0.624 0.304688 0.406250
iteration 680: loss 0.553 0.289062 0.453125
iteration 681: loss 0.615 0.328125 0.421875
iteration 682: loss 0.518 0.328125 0.492188
iteration 683: loss 0.451 0.281250 0.515625
iteration 684: loss 0.460 0.312500 0.593750
iteration 685: loss 0.643 0.273438 0.515625
iteration 686: loss 0.533 0.367188 0.562500
iteration 687: loss 0.612 0.390625 0.484375
iteration 688: loss 0.613 0.273438 0.468750
iteration 689: loss 0.490 0.312500 0.484375
iteration 690: loss 0.668 0.328125 0.453125
iteration 691: loss 0.484 0.296875 0.523438
iteration 692: loss 0.585 0.312500 0.500000
iteration 693: loss 0.641 0.265625 0.414062
iteration 694: loss 0.639 0.265625 0.437500
iteration 695: loss 0.497 0.289062 0.484375
iteration 696: loss 0.669 0.359375 0.476562
iteration 697: loss 0.661 0.289062 0.523438
iteration 698: loss 0.561 0.320312 0.484375
iteration 699: loss 0.500 0.312500 0.570312
iteration 700: loss 0.661 0.289062 0.406250
iteration 701: loss 0.736 0.328125 0.343750
iteration 702: loss 0.497 0.320312 0.453125
iteration 703: loss 0.570 0.296875 0.484375
iteration 704: loss 0.571 0.320312 0.453125
iteration 705: loss 0.584 0.304688 0.539062
iteration 706: loss 0.721 0.367188 0.414062
iteration 707: loss 0.590 0.273438 0.492188
iteration 708: loss 0.665 0.273438 0.460938
iteration 709: loss 0.643 0.257812 0.390625
iteration 710: loss 0.498 0.250000 0.562500
iteration 711: loss 0.678 0.273438 0.507812
iteration 712: loss 0.538 0.304688 0.554688
iteration 713: loss 0.531 0.375000 0.453125
iteration 714: loss 0.510 0.289062 0.421875
iteration 715: loss 0.556 0.296875 0.523438
iteration 716: loss 0.587 0.234375 0.453125
iteration 717: loss 0.601 0.273438 0.421875
iteration 718: loss 0.563 0.234375 0.492188
iteration 719: loss 0.594 0.296875 0.445312
iteration 720: loss 0.592 0.218750 0.429688
iteration 721: loss 0.525 0.351562 0.414062
iteration 722: loss 0.494 0.257812 0.476562
iteration 723: loss 0.496 0.328125 0.507812
iteration 724: loss 0.407 0.359375 0.562500
iteration 725: loss 0.512 0.304688 0.531250
iteration 726: loss 0.655 0.281250 0.429688
iteration 727: loss 0.572 0.296875 0.445312
iteration 728: loss 0.591 0.328125 0.445312
iteration 729: loss 0.571 0.367188 0.507812
iteration 730: loss 0.526 0.296875 0.492188
iteration 731: loss 0.527 0.273438 0.484375
iteration 732: loss 0.563 0.296875 0.445312
iteration 733: loss 0.549 0.312500 0.507812
iteration 734: loss 0.568 0.328125 0.453125
iteration 735: loss 0.447 0.335938 0.507812
iteration 736: loss 0.561 0.210938 0.453125
iteration 737: loss 0.547 0.273438 0.484375
iteration 738: loss 0.567 0.265625 0.414062
iteration 739: loss 0.604 0.351562 0.476562
iteration 740: loss 0.555 0.312500 0.492188
iteration 741: loss 0.562 0.312500 0.421875
iteration 742: loss 0.526 0.289062 0.546875
iteration 743: loss 0.476 0.328125 0.429688
iteration 744: loss 0.606 0.257812 0.445312
iteration 745: loss 0.490 0.273438 0.523438
iteration 746: loss 0.646 0.289062 0.445312
iteration 747: loss 0.619 0.242188 0.453125
iteration 748: loss 0.465 0.296875 0.476562
iteration 749: loss 0.624 0.289062 0.460938
iteration 750: loss 0.654 0.343750 0.476562
iteration 751: loss 0.446 0.304688 0.578125
iteration 752: loss 0.693 0.351562 0.539062
iteration 753: loss 0.636 0.289062 0.453125
iteration 754: loss 0.497 0.351562 0.539062
iteration 755: loss 0.644 0.328125 0.468750
iteration 756: loss 0.607 0.296875 0.390625
iteration 757: loss 0.548 0.281250 0.507812
iteration 758: loss 0.557 0.281250 0.460938
iteration 759: loss 0.599 0.296875 0.507812
iteration 760: loss 0.700 0.335938 0.507812
iteration 761: loss 0.569 0.281250 0.437500
iteration 762: loss 0.517 0.343750 0.460938
iteration 763: loss 0.523 0.257812 0.460938
iteration 764: loss 0.651 0.265625 0.445312
iteration 765: loss 0.629 0.273438 0.453125
iteration 766: loss 0.562 0.320312 0.406250
iteration 767: loss 0.592 0.304688 0.453125
iteration 768: loss 0.447 0.234375 0.554688
iteration 769: loss 0.546 0.320312 0.500000
iteration 770: loss 0.571 0.281250 0.531250
iteration 771: loss 0.589 0.265625 0.445312
iteration 772: loss 0.463 0.320312 0.523438
iteration 773: loss 0.657 0.375000 0.421875
iteration 774: loss 0.600 0.312500 0.460938
iteration 775: loss 0.571 0.289062 0.359375
iteration 776: loss 0.564 0.335938 0.468750
iteration 777: loss 0.548 0.328125 0.484375
iteration 778: loss 0.590 0.328125 0.421875
iteration 779: loss 0.660 0.320312 0.484375
iteration 780: loss 0.605 0.351562 0.445312
iteration 781: loss 0.608 0.296875 0.460938
iteration 782: loss 0.639 0.328125 0.468750
iteration 783: loss 0.505 0.328125 0.468750
iteration 784: loss 0.643 0.250000 0.375000
iteration 785: loss 0.620 0.250000 0.367188
iteration 786: loss 0.536 0.390625 0.500000
iteration 787: loss 0.602 0.335938 0.476562
iteration 788: loss 0.626 0.367188 0.468750
iteration 789: loss 0.731 0.343750 0.406250
iteration 790: loss 0.703 0.265625 0.437500
iteration 791: loss 0.583 0.257812 0.429688
iteration 792: loss 0.652 0.312500 0.429688
iteration 793: loss 0.553 0.296875 0.445312
iteration 794: loss 0.540 0.265625 0.437500
iteration 795: loss 0.545 0.304688 0.476562
iteration 796: loss 0.429 0.304688 0.585938
iteration 797: loss 0.573 0.351562 0.476562
iteration 798: loss 0.613 0.289062 0.429688
iteration 799: loss 0.638 0.367188 0.476562
iteration 800: loss 0.606 0.312500 0.468750
iteration 801: loss 0.681 0.265625 0.359375
iteration 802: loss 0.653 0.281250 0.429688
iteration 803: loss 0.443 0.320312 0.539062
iteration 804: loss 0.610 0.335938 0.437500
iteration 805: loss 0.540 0.265625 0.429688
iteration 806: loss 0.500 0.218750 0.460938
iteration 807: loss 0.629 0.289062 0.429688
iteration 808: loss 0.548 0.335938 0.500000
iteration 809: loss 0.585 0.359375 0.507812
iteration 810: loss 0.630 0.335938 0.484375
iteration 811: loss 0.560 0.351562 0.445312
iteration 812: loss 0.549 0.289062 0.437500
iteration 813: loss 0.721 0.320312 0.398438
iteration 814: loss 0.468 0.296875 0.500000
iteration 815: loss 0.531 0.265625 0.554688
iteration 816: loss 0.587 0.320312 0.460938
iteration 817: loss 0.589 0.328125 0.437500
iteration 818: loss 0.613 0.234375 0.500000
iteration 819: loss 0.488 0.304688 0.484375
iteration 820: loss 0.645 0.335938 0.421875
iteration 821: loss 0.533 0.343750 0.476562
iteration 822: loss 0.655 0.289062 0.414062
iteration 823: loss 0.614 0.312500 0.437500
iteration 824: loss 0.592 0.296875 0.429688
iteration 825: loss 0.491 0.343750 0.476562
iteration 826: loss 0.598 0.250000 0.414062
iteration 827: loss 0.644 0.328125 0.398438
iteration 828: loss 0.490 0.335938 0.492188
iteration 829: loss 0.538 0.343750 0.437500
iteration 830: loss 0.495 0.265625 0.492188
iteration 831: loss 0.698 0.304688 0.406250
iteration 832: loss 0.600 0.375000 0.406250
iteration 833: loss 0.582 0.296875 0.445312
iteration 834: loss 0.768 0.351562 0.375000
iteration 835: loss 0.506 0.273438 0.492188
iteration 836: loss 0.634 0.304688 0.484375
iteration 837: loss 0.601 0.320312 0.460938
iteration 838: loss 0.511 0.250000 0.500000
iteration 839: loss 0.558 0.312500 0.390625
iteration 840: loss 0.530 0.281250 0.484375
iteration 841: loss 0.637 0.296875 0.429688
iteration 842: loss 0.430 0.289062 0.468750
iteration 843: loss 0.536 0.281250 0.460938
iteration 844: loss 0.625 0.312500 0.484375
iteration 845: loss 0.495 0.343750 0.523438
iteration 846: loss 0.650 0.328125 0.390625
iteration 847: loss 0.554 0.250000 0.414062
iteration 848: loss 0.715 0.359375 0.421875
iteration 849: loss 0.530 0.296875 0.507812
iteration 850: loss 0.485 0.312500 0.453125
iteration 851: loss 0.572 0.343750 0.476562
iteration 852: loss 0.496 0.320312 0.492188
iteration 853: loss 0.641 0.257812 0.429688
iteration 854: loss 0.505 0.367188 0.468750
iteration 855: loss 0.536 0.421875 0.492188
iteration 856: loss 0.635 0.437500 0.445312
iteration 857: loss 0.685 0.335938 0.414062
iteration 858: loss 0.567 0.320312 0.375000
iteration 859: loss 0.500 0.304688 0.468750
iteration 860: loss 0.512 0.281250 0.484375
iteration 861: loss 0.534 0.335938 0.500000
iteration 862: loss 0.611 0.296875 0.429688
iteration 863: loss 0.702 0.265625 0.429688
iteration 864: loss 0.743 0.296875 0.414062
iteration 865: loss 0.639 0.304688 0.421875
iteration 866: loss 0.631 0.335938 0.398438
iteration 867: loss 0.593 0.273438 0.437500
iteration 868: loss 0.619 0.265625 0.460938
iteration 869: loss 0.484 0.359375 0.484375
iteration 870: loss 0.603 0.328125 0.476562
iteration 871: loss 0.586 0.335938 0.492188
iteration 872: loss 0.613 0.312500 0.453125
iteration 873: loss 0.703 0.289062 0.375000
iteration 874: loss 0.598 0.335938 0.460938
iteration 875: loss 0.558 0.320312 0.437500
iteration 876: loss 0.627 0.367188 0.398438
iteration 877: loss 0.537 0.250000 0.531250
iteration 878: loss 0.676 0.312500 0.460938
iteration 879: loss 0.631 0.359375 0.398438
iteration 880: loss 0.472 0.250000 0.484375
iteration 881: loss 0.585 0.273438 0.468750
iteration 882: loss 0.603 0.351562 0.429688
iteration 883: loss 0.555 0.335938 0.500000
iteration 884: loss 0.579 0.312500 0.515625
iteration 885: loss 0.614 0.250000 0.414062
iteration 886: loss 0.608 0.265625 0.468750
iteration 887: loss 0.449 0.390625 0.507812
iteration 888: loss 0.512 0.351562 0.445312
iteration 889: loss 0.741 0.296875 0.398438
iteration 890: loss 0.537 0.304688 0.476562
iteration 891: loss 0.579 0.351562 0.515625
iteration 892: loss 0.549 0.375000 0.468750
iteration 893: loss 0.447 0.281250 0.546875
iteration 894: loss 0.530 0.375000 0.492188
iteration 895: loss 0.519 0.289062 0.531250
iteration 896: loss 0.454 0.375000 0.570312
iteration 897: loss 0.550 0.335938 0.484375
iteration 898: loss 0.640 0.328125 0.414062
iteration 899: loss 0.546 0.296875 0.453125
iteration 900: loss 0.555 0.289062 0.445312
iteration 901: loss 0.480 0.265625 0.445312
iteration 902: loss 0.648 0.390625 0.414062
iteration 903: loss 0.502 0.343750 0.476562
iteration 904: loss 0.609 0.320312 0.460938
iteration 905: loss 0.605 0.296875 0.429688
iteration 906: loss 0.640 0.359375 0.398438
iteration 907: loss 0.587 0.234375 0.507812
iteration 908: loss 0.561 0.312500 0.500000
iteration 909: loss 0.479 0.289062 0.468750
iteration 910: loss 0.498 0.328125 0.523438
iteration 911: loss 0.656 0.257812 0.343750
iteration 912: loss 0.501 0.257812 0.414062
iteration 913: loss 0.489 0.265625 0.421875
iteration 914: loss 0.511 0.312500 0.453125
iteration 915: loss 0.565 0.351562 0.500000
iteration 916: loss 0.496 0.289062 0.468750
iteration 917: loss 0.584 0.289062 0.492188
iteration 918: loss 0.594 0.289062 0.484375
iteration 919: loss 0.573 0.273438 0.429688
iteration 920: loss 0.528 0.242188 0.476562
iteration 921: loss 0.607 0.265625 0.468750
iteration 922: loss 0.563 0.289062 0.476562
iteration 923: loss 0.463 0.328125 0.492188
iteration 924: loss 0.602 0.273438 0.492188
iteration 925: loss 0.595 0.421875 0.492188
iteration 926: loss 0.529 0.343750 0.398438
iteration 927: loss 0.608 0.320312 0.437500
iteration 928: loss 0.515 0.265625 0.460938
iteration 929: loss 0.671 0.328125 0.460938
iteration 930: loss 0.533 0.312500 0.515625
iteration 931: loss 0.649 0.304688 0.453125
iteration 932: loss 0.590 0.312500 0.375000
iteration 933: loss 0.598 0.250000 0.414062
iteration 934: loss 0.656 0.273438 0.468750
iteration 935: loss 0.580 0.304688 0.515625
iteration 936: loss 0.577 0.367188 0.460938
iteration 937: loss 0.503 0.351562 0.500000
iteration 938: loss 0.523 0.312500 0.468750
iteration 939: loss 0.524 0.335938 0.476562
iteration 940: loss 0.459 0.304688 0.484375
iteration 941: loss 0.504 0.343750 0.507812
iteration 942: loss 0.528 0.359375 0.476562
iteration 943: loss 0.438 0.281250 0.554688
iteration 944: loss 0.522 0.250000 0.570312
iteration 945: loss 0.698 0.367188 0.476562
iteration 946: loss 0.579 0.312500 0.492188
iteration 947: loss 0.542 0.273438 0.445312
iteration 948: loss 0.448 0.343750 0.531250
iteration 949: loss 0.454 0.289062 0.515625
iteration 950: loss 0.693 0.312500 0.429688
iteration 951: loss 0.711 0.265625 0.390625
iteration 952: loss 0.574 0.296875 0.492188
iteration 953: loss 0.557 0.359375 0.476562
iteration 954: loss 0.579 0.296875 0.429688
iteration 955: loss 0.485 0.304688 0.468750
iteration 956: loss 0.517 0.343750 0.515625
iteration 957: loss 0.655 0.359375 0.500000
iteration 958: loss 0.692 0.351562 0.437500
iteration 959: loss 0.546 0.281250 0.484375
iteration 960: loss 0.484 0.328125 0.484375
iteration 961: loss 0.596 0.343750 0.421875
iteration 962: loss 0.578 0.328125 0.531250
iteration 963: loss 0.537 0.343750 0.484375
iteration 964: loss 0.611 0.289062 0.359375
iteration 965: loss 0.498 0.320312 0.546875
iteration 966: loss 0.681 0.242188 0.437500
iteration 967: loss 0.609 0.289062 0.492188
iteration 968: loss 0.521 0.320312 0.437500
iteration 969: loss 0.645 0.382812 0.414062
iteration 970: loss 0.522 0.265625 0.476562
iteration 971: loss 0.588 0.273438 0.437500
iteration 972: loss 0.617 0.367188 0.445312
iteration 973: loss 0.579 0.265625 0.492188
iteration 974: loss 0.545 0.250000 0.492188
iteration 975: loss 0.502 0.335938 0.476562
iteration 976: loss 0.595 0.296875 0.453125
iteration 977: loss 0.643 0.343750 0.398438
iteration 978: loss 0.508 0.312500 0.453125
iteration 979: loss 0.488 0.281250 0.539062
iteration 980: loss 0.620 0.343750 0.445312
iteration 981: loss 0.564 0.281250 0.484375
iteration 982: loss 0.595 0.343750 0.523438
iteration 983: loss 0.493 0.304688 0.523438
iteration 984: loss 0.625 0.414062 0.476562
iteration 985: loss 0.632 0.242188 0.382812
iteration 986: loss 0.525 0.304688 0.500000
iteration 987: loss 0.589 0.304688 0.476562
iteration 988: loss 0.577 0.296875 0.460938
iteration 989: loss 0.551 0.304688 0.460938
iteration 990: loss 0.552 0.265625 0.390625
iteration 991: loss 0.579 0.343750 0.492188
iteration 992: loss 0.620 0.320312 0.421875
iteration 993: loss 0.617 0.296875 0.429688
iteration 994: loss 0.548 0.335938 0.492188
iteration 995: loss 0.601 0.328125 0.437500
iteration 996: loss 0.586 0.312500 0.554688
iteration 997: loss 0.470 0.351562 0.476562
iteration 998: loss 0.495 0.273438 0.437500
iteration 999: loss 0.563 0.250000 0.367188
epoch 13: training: 0.312500 validation: 0.210938
iteration 0: loss 0.543 0.335938 0.500000
iteration 1: loss 0.587 0.312500 0.484375
iteration 2: loss 0.569 0.351562 0.429688
iteration 3: loss 0.552 0.289062 0.492188
iteration 4: loss 0.546 0.234375 0.460938
iteration 5: loss 0.505 0.218750 0.406250
iteration 6: loss 0.570 0.281250 0.445312
iteration 7: loss 0.559 0.328125 0.429688
iteration 8: loss 0.539 0.273438 0.484375
iteration 9: loss 0.625 0.296875 0.382812
iteration 10: loss 0.518 0.390625 0.453125
iteration 11: loss 0.539 0.265625 0.484375
iteration 12: loss 0.504 0.312500 0.523438
iteration 13: loss 0.675 0.351562 0.453125
iteration 14: loss 0.522 0.312500 0.492188
iteration 15: loss 0.605 0.304688 0.367188
iteration 16: loss 0.446 0.289062 0.562500
iteration 17: loss 0.551 0.312500 0.484375
iteration 18: loss 0.484 0.187500 0.492188
iteration 19: loss 0.624 0.343750 0.414062
iteration 20: loss 0.618 0.320312 0.406250
iteration 21: loss 0.550 0.351562 0.437500
iteration 22: loss 0.528 0.312500 0.445312
iteration 23: loss 0.648 0.328125 0.390625
iteration 24: loss 0.450 0.312500 0.539062
iteration 25: loss 0.561 0.335938 0.492188
iteration 26: loss 0.763 0.375000 0.421875
iteration 27: loss 0.506 0.296875 0.421875
iteration 28: loss 0.583 0.335938 0.437500
iteration 29: loss 0.641 0.250000 0.429688
iteration 30: loss 0.589 0.312500 0.453125
iteration 31: loss 0.453 0.273438 0.507812
iteration 32: loss 0.581 0.312500 0.382812
iteration 33: loss 0.474 0.304688 0.500000
iteration 34: loss 0.482 0.312500 0.429688
iteration 35: loss 0.445 0.265625 0.507812
iteration 36: loss 0.545 0.250000 0.429688
iteration 37: loss 0.476 0.289062 0.437500
iteration 38: loss 0.578 0.273438 0.500000
iteration 39: loss 0.558 0.390625 0.484375
iteration 40: loss 0.469 0.351562 0.570312
iteration 41: loss 0.463 0.351562 0.500000
iteration 42: loss 0.473 0.257812 0.507812
iteration 43: loss 0.542 0.296875 0.421875
iteration 44: loss 0.564 0.335938 0.414062
iteration 45: loss 0.585 0.296875 0.484375
iteration 46: loss 0.514 0.335938 0.445312
iteration 47: loss 0.567 0.328125 0.406250
iteration 48: loss 0.521 0.343750 0.531250
iteration 49: loss 0.640 0.289062 0.429688
iteration 50: loss 0.397 0.328125 0.539062
iteration 51: loss 0.622 0.187500 0.335938
iteration 52: loss 0.621 0.250000 0.437500
iteration 53: loss 0.530 0.289062 0.382812
iteration 54: loss 0.559 0.289062 0.414062
iteration 55: loss 0.676 0.304688 0.500000
iteration 56: loss 0.667 0.335938 0.468750
iteration 57: loss 0.549 0.328125 0.453125
iteration 58: loss 0.561 0.375000 0.484375
iteration 59: loss 0.546 0.312500 0.429688
iteration 60: loss 0.602 0.359375 0.414062
iteration 61: loss 0.533 0.328125 0.500000
iteration 62: loss 0.505 0.273438 0.507812
iteration 63: loss 0.590 0.335938 0.492188
iteration 64: loss 0.614 0.281250 0.460938
iteration 65: loss 0.610 0.335938 0.515625
iteration 66: loss 0.573 0.289062 0.484375
iteration 67: loss 0.703 0.304688 0.406250
iteration 68: loss 0.531 0.304688 0.507812
iteration 69: loss 0.543 0.257812 0.437500
iteration 70: loss 0.593 0.281250 0.484375
iteration 71: loss 0.719 0.234375 0.351562
iteration 72: loss 0.509 0.304688 0.515625
iteration 73: loss 0.645 0.320312 0.492188
iteration 74: loss 0.533 0.320312 0.476562
iteration 75: loss 0.801 0.304688 0.375000
iteration 76: loss 0.727 0.304688 0.460938
iteration 77: loss 0.597 0.281250 0.429688
iteration 78: loss 0.558 0.351562 0.500000
iteration 79: loss 0.599 0.304688 0.484375
iteration 80: loss 0.696 0.351562 0.414062
iteration 81: loss 0.460 0.351562 0.492188
iteration 82: loss 0.566 0.265625 0.445312
iteration 83: loss 0.555 0.304688 0.476562
iteration 84: loss 0.696 0.335938 0.390625
iteration 85: loss 0.644 0.328125 0.507812
iteration 86: loss 0.713 0.343750 0.492188
iteration 87: loss 0.526 0.328125 0.468750
iteration 88: loss 0.615 0.257812 0.437500
iteration 89: loss 0.581 0.320312 0.414062
iteration 90: loss 0.540 0.242188 0.484375
iteration 91: loss 0.462 0.367188 0.531250
iteration 92: loss 0.483 0.281250 0.546875
iteration 93: loss 0.536 0.375000 0.453125
iteration 94: loss 0.415 0.296875 0.554688
iteration 95: loss 0.547 0.250000 0.445312
iteration 96: loss 0.579 0.273438 0.468750
iteration 97: loss 0.684 0.296875 0.445312
iteration 98: loss 0.409 0.343750 0.531250
iteration 99: loss 0.533 0.281250 0.460938
iteration 100: loss 0.608 0.218750 0.507812
iteration 101: loss 0.523 0.296875 0.507812
iteration 102: loss 0.488 0.320312 0.523438
iteration 103: loss 0.506 0.210938 0.531250
iteration 104: loss 0.530 0.250000 0.492188
iteration 105: loss 0.546 0.335938 0.437500
iteration 106: loss 0.556 0.289062 0.445312
iteration 107: loss 0.659 0.234375 0.421875
iteration 108: loss 0.665 0.304688 0.421875
iteration 109: loss 0.533 0.335938 0.453125
iteration 110: loss 0.613 0.304688 0.398438
iteration 111: loss 0.723 0.304688 0.468750
iteration 112: loss 0.487 0.281250 0.492188
iteration 113: loss 0.509 0.328125 0.460938
iteration 114: loss 0.464 0.328125 0.523438
iteration 115: loss 0.579 0.351562 0.507812
iteration 116: loss 0.530 0.250000 0.484375
iteration 117: loss 0.507 0.343750 0.515625
iteration 118: loss 0.567 0.398438 0.429688
iteration 119: loss 0.499 0.242188 0.468750
iteration 120: loss 0.581 0.265625 0.414062
iteration 121: loss 0.522 0.234375 0.453125
iteration 122: loss 0.500 0.359375 0.492188
iteration 123: loss 0.544 0.273438 0.523438
iteration 124: loss 0.586 0.343750 0.515625
iteration 125: loss 0.405 0.351562 0.554688
iteration 126: loss 0.609 0.218750 0.421875
iteration 127: loss 0.580 0.328125 0.421875
iteration 128: loss 0.512 0.375000 0.437500
iteration 129: loss 0.571 0.226562 0.476562
iteration 130: loss 0.487 0.273438 0.492188
iteration 131: loss 0.482 0.328125 0.515625
iteration 132: loss 0.560 0.312500 0.390625
iteration 133: loss 0.621 0.273438 0.484375
iteration 134: loss 0.500 0.281250 0.492188
iteration 135: loss 0.484 0.289062 0.539062
iteration 136: loss 0.655 0.304688 0.468750
iteration 137: loss 0.582 0.281250 0.507812
iteration 138: loss 0.498 0.257812 0.476562
iteration 139: loss 0.612 0.359375 0.421875
iteration 140: loss 0.483 0.320312 0.421875
iteration 141: loss 0.620 0.289062 0.445312
iteration 142: loss 0.470 0.312500 0.476562
iteration 143: loss 0.584 0.312500 0.453125
iteration 144: loss 0.617 0.312500 0.453125
iteration 145: loss 0.541 0.320312 0.507812
iteration 146: loss 0.622 0.289062 0.445312
iteration 147: loss 0.449 0.265625 0.468750
iteration 148: loss 0.430 0.320312 0.507812
iteration 149: loss 0.500 0.351562 0.484375
iteration 150: loss 0.525 0.406250 0.492188
iteration 151: loss 0.670 0.289062 0.437500
iteration 152: loss 0.711 0.218750 0.406250
iteration 153: loss 0.600 0.304688 0.367188
iteration 154: loss 0.581 0.289062 0.445312
iteration 155: loss 0.492 0.343750 0.460938
iteration 156: loss 0.474 0.359375 0.546875
iteration 157: loss 0.478 0.320312 0.554688
iteration 158: loss 0.623 0.359375 0.468750
iteration 159: loss 0.682 0.375000 0.421875
iteration 160: loss 0.457 0.335938 0.554688
iteration 161: loss 0.403 0.351562 0.546875
iteration 162: loss 0.605 0.257812 0.453125
iteration 163: loss 0.619 0.359375 0.492188
iteration 164: loss 0.527 0.281250 0.539062
iteration 165: loss 0.575 0.320312 0.546875
iteration 166: loss 0.577 0.320312 0.476562
iteration 167: loss 0.619 0.335938 0.476562
iteration 168: loss 0.487 0.273438 0.406250
iteration 169: loss 0.484 0.320312 0.460938
iteration 170: loss 0.504 0.382812 0.500000
iteration 171: loss 0.614 0.250000 0.445312
iteration 172: loss 0.757 0.328125 0.484375
iteration 173: loss 0.542 0.359375 0.460938
iteration 174: loss 0.613 0.281250 0.445312
iteration 175: loss 0.673 0.296875 0.437500
iteration 176: loss 0.406 0.273438 0.531250
iteration 177: loss 0.585 0.226562 0.406250
iteration 178: loss 0.646 0.265625 0.406250
iteration 179: loss 0.584 0.265625 0.492188
iteration 180: loss 0.633 0.304688 0.445312
iteration 181: loss 0.656 0.390625 0.507812
iteration 182: loss 0.536 0.265625 0.546875
iteration 183: loss 0.604 0.304688 0.484375
iteration 184: loss 0.733 0.289062 0.429688
iteration 185: loss 0.634 0.328125 0.445312
iteration 186: loss 0.534 0.320312 0.484375
iteration 187: loss 0.734 0.242188 0.437500
iteration 188: loss 0.630 0.242188 0.390625
iteration 189: loss 0.605 0.304688 0.500000
iteration 190: loss 0.561 0.343750 0.554688
iteration 191: loss 0.651 0.351562 0.460938
iteration 192: loss 0.587 0.289062 0.468750
iteration 193: loss 0.569 0.281250 0.421875
iteration 194: loss 0.627 0.218750 0.429688
iteration 195: loss 0.512 0.257812 0.515625
iteration 196: loss 0.690 0.273438 0.421875
iteration 197: loss 0.666 0.335938 0.429688
iteration 198: loss 0.526 0.312500 0.468750
iteration 199: loss 0.594 0.312500 0.476562
iteration 200: loss 0.706 0.343750 0.406250
iteration 201: loss 0.706 0.351562 0.406250
iteration 202: loss 0.606 0.351562 0.492188
iteration 203: loss 0.595 0.335938 0.460938
iteration 204: loss 0.585 0.265625 0.390625
iteration 205: loss 0.588 0.312500 0.406250
iteration 206: loss 0.630 0.289062 0.523438
iteration 207: loss 0.531 0.304688 0.515625
iteration 208: loss 0.524 0.257812 0.437500
iteration 209: loss 0.705 0.343750 0.437500
iteration 210: loss 0.646 0.320312 0.445312
iteration 211: loss 0.555 0.296875 0.468750
iteration 212: loss 0.603 0.289062 0.421875
iteration 213: loss 0.535 0.257812 0.500000
iteration 214: loss 0.597 0.382812 0.476562
iteration 215: loss 0.567 0.273438 0.515625
iteration 216: loss 0.505 0.343750 0.523438
iteration 217: loss 0.760 0.367188 0.398438
iteration 218: loss 0.623 0.250000 0.445312
iteration 219: loss 0.539 0.281250 0.460938
iteration 220: loss 0.604 0.335938 0.484375
iteration 221: loss 0.591 0.320312 0.406250
iteration 222: loss 0.635 0.328125 0.468750
iteration 223: loss 0.542 0.257812 0.429688
iteration 224: loss 0.520 0.328125 0.492188
iteration 225: loss 0.533 0.265625 0.429688
iteration 226: loss 0.563 0.312500 0.414062
iteration 227: loss 0.524 0.242188 0.523438
iteration 228: loss 0.508 0.289062 0.492188
iteration 229: loss 0.599 0.359375 0.398438
iteration 230: loss 0.453 0.257812 0.578125
iteration 231: loss 0.511 0.343750 0.453125
iteration 232: loss 0.500 0.296875 0.476562
iteration 233: loss 0.540 0.289062 0.523438
iteration 234: loss 0.488 0.296875 0.539062
iteration 235: loss 0.553 0.273438 0.484375
iteration 236: loss 0.508 0.273438 0.554688
iteration 237: loss 0.558 0.281250 0.468750
iteration 238: loss 0.583 0.328125 0.453125
iteration 239: loss 0.612 0.312500 0.367188
iteration 240: loss 0.604 0.343750 0.421875
iteration 241: loss 0.494 0.328125 0.476562
iteration 242: loss 0.594 0.390625 0.500000
iteration 243: loss 0.612 0.398438 0.421875
iteration 244: loss 0.529 0.273438 0.414062
iteration 245: loss 0.514 0.304688 0.468750
iteration 246: loss 0.706 0.226562 0.406250
iteration 247: loss 0.579 0.328125 0.500000
iteration 248: loss 0.711 0.304688 0.375000
iteration 249: loss 0.670 0.273438 0.382812
iteration 250: loss 0.610 0.296875 0.414062
iteration 251: loss 0.561 0.296875 0.421875
iteration 252: loss 0.506 0.273438 0.484375
iteration 253: loss 0.585 0.304688 0.453125
iteration 254: loss 0.638 0.296875 0.390625
iteration 255: loss 0.482 0.273438 0.523438
iteration 256: loss 0.621 0.304688 0.382812
iteration 257: loss 0.448 0.328125 0.554688
iteration 258: loss 0.499 0.257812 0.500000
iteration 259: loss 0.577 0.304688 0.468750
iteration 260: loss 0.605 0.187500 0.476562
iteration 261: loss 0.546 0.289062 0.460938
iteration 262: loss 0.577 0.218750 0.421875
iteration 263: loss 0.448 0.320312 0.585938
iteration 264: loss 0.533 0.273438 0.492188
iteration 265: loss 0.555 0.226562 0.421875
iteration 266: loss 0.553 0.328125 0.468750
iteration 267: loss 0.552 0.320312 0.468750
iteration 268: loss 0.524 0.351562 0.539062
iteration 269: loss 0.641 0.320312 0.476562
iteration 270: loss 0.589 0.281250 0.453125
iteration 271: loss 0.574 0.234375 0.421875
iteration 272: loss 0.519 0.320312 0.500000
iteration 273: loss 0.431 0.289062 0.468750
iteration 274: loss 0.596 0.281250 0.500000
iteration 275: loss 0.468 0.273438 0.468750
iteration 276: loss 0.559 0.343750 0.460938
iteration 277: loss 0.508 0.320312 0.445312
iteration 278: loss 0.613 0.320312 0.460938
iteration 279: loss 0.546 0.328125 0.437500
iteration 280: loss 0.484 0.296875 0.468750
iteration 281: loss 0.422 0.289062 0.476562
iteration 282: loss 0.498 0.289062 0.445312
iteration 283: loss 0.564 0.296875 0.507812
iteration 284: loss 0.578 0.312500 0.476562
iteration 285: loss 0.476 0.273438 0.500000
iteration 286: loss 0.666 0.320312 0.500000
iteration 287: loss 0.452 0.265625 0.601562
iteration 288: loss 0.624 0.281250 0.414062
iteration 289: loss 0.620 0.304688 0.437500
iteration 290: loss 0.605 0.414062 0.445312
iteration 291: loss 0.579 0.328125 0.382812
iteration 292: loss 0.680 0.328125 0.382812
iteration 293: loss 0.518 0.265625 0.515625
iteration 294: loss 0.523 0.273438 0.492188
iteration 295: loss 0.628 0.296875 0.398438
iteration 296: loss 0.508 0.351562 0.492188
iteration 297: loss 0.493 0.289062 0.476562
iteration 298: loss 0.503 0.289062 0.515625
iteration 299: loss 0.462 0.328125 0.484375
iteration 300: loss 0.468 0.312500 0.523438
iteration 301: loss 0.483 0.328125 0.546875
iteration 302: loss 0.452 0.328125 0.515625
iteration 303: loss 0.675 0.312500 0.382812
iteration 304: loss 0.561 0.351562 0.453125
iteration 305: loss 0.640 0.351562 0.445312
iteration 306: loss 0.654 0.296875 0.437500
iteration 307: loss 0.434 0.335938 0.562500
iteration 308: loss 0.422 0.304688 0.546875
iteration 309: loss 0.644 0.320312 0.460938
iteration 310: loss 0.509 0.289062 0.531250
iteration 311: loss 0.552 0.289062 0.484375
iteration 312: loss 0.658 0.335938 0.460938
iteration 313: loss 0.565 0.304688 0.476562
iteration 314: loss 0.483 0.320312 0.460938
iteration 315: loss 0.552 0.343750 0.460938
iteration 316: loss 0.513 0.320312 0.484375
iteration 317: loss 0.394 0.312500 0.500000
iteration 318: loss 0.569 0.351562 0.453125
iteration 319: loss 0.531 0.273438 0.445312
iteration 320: loss 0.564 0.382812 0.414062
iteration 321: loss 0.569 0.382812 0.500000
iteration 322: loss 0.491 0.320312 0.507812
iteration 323: loss 0.494 0.351562 0.523438
iteration 324: loss 0.565 0.265625 0.507812
iteration 325: loss 0.618 0.265625 0.445312
iteration 326: loss 0.673 0.335938 0.437500
iteration 327: loss 0.541 0.265625 0.445312
iteration 328: loss 0.494 0.359375 0.445312
iteration 329: loss 0.485 0.289062 0.437500
iteration 330: loss 0.587 0.218750 0.453125
iteration 331: loss 0.566 0.265625 0.484375
iteration 332: loss 0.455 0.312500 0.562500
iteration 333: loss 0.475 0.296875 0.531250
iteration 334: loss 0.588 0.312500 0.406250
iteration 335: loss 0.503 0.289062 0.484375
iteration 336: loss 0.534 0.304688 0.507812
iteration 337: loss 0.350 0.375000 0.593750
iteration 338: loss 0.535 0.335938 0.492188
iteration 339: loss 0.503 0.273438 0.414062
iteration 340: loss 0.516 0.296875 0.445312
iteration 341: loss 0.530 0.296875 0.507812
iteration 342: loss 0.582 0.257812 0.453125
iteration 343: loss 0.516 0.320312 0.453125
iteration 344: loss 0.603 0.304688 0.429688
iteration 345: loss 0.559 0.328125 0.554688
iteration 346: loss 0.686 0.343750 0.406250
iteration 347: loss 0.613 0.289062 0.460938
iteration 348: loss 0.542 0.382812 0.468750
iteration 349: loss 0.590 0.281250 0.468750
iteration 350: loss 0.549 0.296875 0.468750
iteration 351: loss 0.488 0.312500 0.437500
iteration 352: loss 0.565 0.343750 0.414062
iteration 353: loss 0.468 0.257812 0.500000
iteration 354: loss 0.594 0.343750 0.484375
iteration 355: loss 0.572 0.304688 0.500000
iteration 356: loss 0.441 0.351562 0.507812
iteration 357: loss 0.495 0.296875 0.507812
iteration 358: loss 0.565 0.312500 0.468750
iteration 359: loss 0.506 0.328125 0.492188
iteration 360: loss 0.512 0.351562 0.429688
iteration 361: loss 0.516 0.281250 0.468750
iteration 362: loss 0.561 0.234375 0.437500
iteration 363: loss 0.628 0.281250 0.445312
iteration 364: loss 0.540 0.265625 0.492188
iteration 365: loss 0.645 0.289062 0.375000
iteration 366: loss 0.647 0.359375 0.367188
iteration 367: loss 0.441 0.257812 0.539062
iteration 368: loss 0.586 0.351562 0.468750
iteration 369: loss 0.410 0.289062 0.492188
iteration 370: loss 0.512 0.328125 0.515625
iteration 371: loss 0.461 0.273438 0.507812
iteration 372: loss 0.572 0.250000 0.484375
iteration 373: loss 0.576 0.289062 0.468750
iteration 374: loss 0.511 0.296875 0.453125
iteration 375: loss 0.546 0.273438 0.460938
iteration 376: loss 0.563 0.304688 0.453125
iteration 377: loss 0.521 0.304688 0.460938
iteration 378: loss 0.541 0.304688 0.429688
iteration 379: loss 0.486 0.335938 0.476562
iteration 380: loss 0.617 0.343750 0.429688
iteration 381: loss 0.575 0.273438 0.406250
iteration 382: loss 0.542 0.296875 0.484375
iteration 383: loss 0.594 0.289062 0.445312
iteration 384: loss 0.457 0.265625 0.492188
iteration 385: loss 0.556 0.351562 0.429688
iteration 386: loss 0.486 0.265625 0.429688
iteration 387: loss 0.509 0.281250 0.515625
iteration 388: loss 0.536 0.203125 0.484375
iteration 389: loss 0.633 0.257812 0.484375
iteration 390: loss 0.514 0.250000 0.445312
iteration 391: loss 0.548 0.210938 0.468750
iteration 392: loss 0.370 0.359375 0.500000
iteration 393: loss 0.452 0.312500 0.453125
iteration 394: loss 0.516 0.257812 0.500000
iteration 395: loss 0.599 0.296875 0.492188
iteration 396: loss 0.520 0.296875 0.523438
iteration 397: loss 0.540 0.289062 0.515625
iteration 398: loss 0.529 0.367188 0.484375
iteration 399: loss 0.551 0.320312 0.429688
iteration 400: loss 0.547 0.382812 0.507812
iteration 401: loss 0.482 0.328125 0.492188
iteration 402: loss 0.721 0.296875 0.453125
iteration 403: loss 0.640 0.320312 0.382812
iteration 404: loss 0.550 0.289062 0.476562
iteration 405: loss 0.404 0.257812 0.546875
iteration 406: loss 0.509 0.281250 0.539062
iteration 407: loss 0.489 0.328125 0.507812
iteration 408: loss 0.464 0.265625 0.507812
iteration 409: loss 0.501 0.343750 0.546875
iteration 410: loss 0.730 0.257812 0.421875
iteration 411: loss 0.573 0.320312 0.515625
iteration 412: loss 0.714 0.359375 0.406250
iteration 413: loss 0.443 0.273438 0.531250
iteration 414: loss 0.407 0.296875 0.539062
iteration 415: loss 0.522 0.343750 0.492188
iteration 416: loss 0.705 0.328125 0.421875
iteration 417: loss 0.539 0.312500 0.531250
iteration 418: loss 0.573 0.367188 0.453125
iteration 419: loss 0.413 0.242188 0.546875
iteration 420: loss 0.575 0.320312 0.476562
iteration 421: loss 0.608 0.335938 0.484375
iteration 422: loss 0.599 0.273438 0.460938
iteration 423: loss 0.502 0.265625 0.476562
iteration 424: loss 0.573 0.328125 0.445312
iteration 425: loss 0.565 0.289062 0.460938
iteration 426: loss 0.680 0.312500 0.343750
iteration 427: loss 0.659 0.257812 0.468750
iteration 428: loss 0.509 0.375000 0.546875
iteration 429: loss 0.706 0.343750 0.390625
iteration 430: loss 0.661 0.304688 0.320312
iteration 431: loss 0.425 0.265625 0.539062
iteration 432: loss 0.570 0.296875 0.468750
iteration 433: loss 0.719 0.335938 0.367188
iteration 434: loss 0.504 0.328125 0.484375
iteration 435: loss 0.633 0.265625 0.414062
iteration 436: loss 0.512 0.296875 0.484375
iteration 437: loss 0.572 0.296875 0.437500
iteration 438: loss 0.462 0.218750 0.476562
iteration 439: loss 0.587 0.250000 0.500000
iteration 440: loss 0.427 0.265625 0.523438
iteration 441: loss 0.614 0.343750 0.492188
iteration 442: loss 0.660 0.296875 0.390625
iteration 443: loss 0.463 0.296875 0.523438
iteration 444: loss 0.589 0.312500 0.445312
iteration 445: loss 0.501 0.320312 0.492188
iteration 446: loss 0.644 0.351562 0.421875
iteration 447: loss 0.491 0.304688 0.492188
iteration 448: loss 0.539 0.250000 0.453125
iteration 449: loss 0.583 0.328125 0.453125
iteration 450: loss 0.518 0.281250 0.492188
iteration 451: loss 0.466 0.304688 0.515625
iteration 452: loss 0.533 0.289062 0.476562
iteration 453: loss 0.609 0.320312 0.476562
iteration 454: loss 0.558 0.273438 0.492188
iteration 455: loss 0.559 0.265625 0.468750
iteration 456: loss 0.559 0.351562 0.375000
iteration 457: loss 0.504 0.312500 0.554688
iteration 458: loss 0.489 0.304688 0.429688
iteration 459: loss 0.580 0.257812 0.492188
iteration 460: loss 0.562 0.304688 0.500000
iteration 461: loss 0.618 0.320312 0.484375
iteration 462: loss 0.489 0.328125 0.468750
iteration 463: loss 0.650 0.328125 0.468750
iteration 464: loss 0.476 0.210938 0.484375
iteration 465: loss 0.536 0.273438 0.539062
iteration 466: loss 0.523 0.203125 0.445312
iteration 467: loss 0.609 0.257812 0.445312
iteration 468: loss 0.544 0.312500 0.468750
iteration 469: loss 0.623 0.281250 0.437500
iteration 470: loss 0.601 0.289062 0.476562
iteration 471: loss 0.556 0.289062 0.460938
iteration 472: loss 0.654 0.234375 0.468750
iteration 473: loss 0.606 0.281250 0.398438
iteration 474: loss 0.584 0.257812 0.468750
iteration 475: loss 0.555 0.257812 0.453125
iteration 476: loss 0.543 0.289062 0.476562
iteration 477: loss 0.525 0.343750 0.507812
iteration 478: loss 0.586 0.351562 0.398438
iteration 479: loss 0.437 0.335938 0.554688
iteration 480: loss 0.501 0.304688 0.515625
iteration 481: loss 0.548 0.312500 0.445312
iteration 482: loss 0.506 0.375000 0.507812
iteration 483: loss 0.616 0.281250 0.429688
iteration 484: loss 0.582 0.296875 0.382812
iteration 485: loss 0.547 0.296875 0.453125
iteration 486: loss 0.543 0.312500 0.406250
iteration 487: loss 0.459 0.296875 0.500000
iteration 488: loss 0.670 0.328125 0.421875
iteration 489: loss 0.549 0.265625 0.460938
iteration 490: loss 0.563 0.367188 0.398438
iteration 491: loss 0.480 0.328125 0.531250
iteration 492: loss 0.421 0.296875 0.476562
iteration 493: loss 0.501 0.343750 0.492188
iteration 494: loss 0.495 0.273438 0.523438
iteration 495: loss 0.456 0.335938 0.492188
iteration 496: loss 0.537 0.312500 0.531250
iteration 497: loss 0.682 0.335938 0.414062
iteration 498: loss 0.592 0.328125 0.406250
iteration 499: loss 0.615 0.312500 0.460938
iteration 500: loss 0.609 0.328125 0.445312
iteration 501: loss 0.610 0.351562 0.414062
iteration 502: loss 0.604 0.367188 0.390625
iteration 503: loss 0.568 0.289062 0.492188
iteration 504: loss 0.568 0.359375 0.507812
iteration 505: loss 0.504 0.304688 0.507812
iteration 506: loss 0.616 0.320312 0.484375
iteration 507: loss 0.575 0.335938 0.476562
iteration 508: loss 0.540 0.335938 0.468750
iteration 509: loss 0.634 0.312500 0.367188
iteration 510: loss 0.565 0.335938 0.507812
iteration 511: loss 0.457 0.250000 0.554688
iteration 512: loss 0.548 0.312500 0.492188
iteration 513: loss 0.533 0.328125 0.460938
iteration 514: loss 0.576 0.226562 0.515625
iteration 515: loss 0.506 0.265625 0.492188
iteration 516: loss 0.649 0.273438 0.445312
iteration 517: loss 0.614 0.257812 0.468750
iteration 518: loss 0.628 0.304688 0.351562
iteration 519: loss 0.631 0.382812 0.445312
iteration 520: loss 0.670 0.281250 0.445312
iteration 521: loss 0.660 0.265625 0.367188
iteration 522: loss 0.536 0.242188 0.507812
iteration 523: loss 0.644 0.281250 0.351562
iteration 524: loss 0.556 0.312500 0.429688
iteration 525: loss 0.481 0.250000 0.468750
iteration 526: loss 0.475 0.242188 0.515625
iteration 527: loss 0.607 0.351562 0.414062
iteration 528: loss 0.527 0.312500 0.507812
iteration 529: loss 0.456 0.312500 0.507812
iteration 530: loss 0.550 0.281250 0.429688
iteration 531: loss 0.477 0.304688 0.429688
iteration 532: loss 0.556 0.304688 0.429688
iteration 533: loss 0.462 0.281250 0.484375
iteration 534: loss 0.599 0.367188 0.500000
iteration 535: loss 0.538 0.343750 0.539062
iteration 536: loss 0.639 0.296875 0.476562
iteration 537: loss 0.574 0.250000 0.460938
iteration 538: loss 0.532 0.250000 0.421875
iteration 539: loss 0.541 0.281250 0.453125
iteration 540: loss 0.545 0.320312 0.445312
iteration 541: loss 0.587 0.289062 0.398438
iteration 542: loss 0.492 0.296875 0.507812
iteration 543: loss 0.461 0.320312 0.539062
iteration 544: loss 0.547 0.328125 0.539062
iteration 545: loss 0.705 0.320312 0.421875
iteration 546: loss 0.445 0.328125 0.507812
iteration 547: loss 0.498 0.265625 0.500000
iteration 548: loss 0.679 0.359375 0.468750
iteration 549: loss 0.387 0.367188 0.515625
iteration 550: loss 0.554 0.359375 0.468750
iteration 551: loss 0.531 0.273438 0.507812
iteration 552: loss 0.500 0.320312 0.531250
iteration 553: loss 0.406 0.273438 0.539062
iteration 554: loss 0.571 0.328125 0.484375
iteration 555: loss 0.513 0.265625 0.468750
iteration 556: loss 0.591 0.210938 0.515625
iteration 557: loss 0.659 0.257812 0.421875
iteration 558: loss 0.489 0.281250 0.476562
iteration 559: loss 0.605 0.312500 0.398438
iteration 560: loss 0.581 0.343750 0.421875
iteration 561: loss 0.516 0.312500 0.445312
iteration 562: loss 0.627 0.304688 0.351562
iteration 563: loss 0.544 0.234375 0.445312
iteration 564: loss 0.485 0.312500 0.500000
iteration 565: loss 0.649 0.312500 0.414062
iteration 566: loss 0.498 0.320312 0.468750
iteration 567: loss 0.554 0.273438 0.406250
iteration 568: loss 0.672 0.273438 0.390625
iteration 569: loss 0.560 0.289062 0.492188
iteration 570: loss 0.600 0.304688 0.406250
iteration 571: loss 0.567 0.281250 0.476562
iteration 572: loss 0.571 0.296875 0.484375
iteration 573: loss 0.560 0.320312 0.484375
iteration 574: loss 0.550 0.265625 0.406250
iteration 575: loss 0.530 0.328125 0.507812
iteration 576: loss 0.444 0.335938 0.531250
iteration 577: loss 0.423 0.335938 0.562500
iteration 578: loss 0.476 0.281250 0.500000
iteration 579: loss 0.532 0.273438 0.500000
iteration 580: loss 0.439 0.257812 0.515625
iteration 581: loss 0.550 0.382812 0.484375
iteration 582: loss 0.547 0.351562 0.414062
iteration 583: loss 0.664 0.304688 0.445312
iteration 584: loss 0.739 0.312500 0.406250
iteration 585: loss 0.431 0.382812 0.585938
iteration 586: loss 0.592 0.320312 0.476562
iteration 587: loss 0.530 0.296875 0.492188
iteration 588: loss 0.619 0.226562 0.492188
iteration 589: loss 0.608 0.367188 0.539062
iteration 590: loss 0.812 0.351562 0.367188
iteration 591: loss 0.766 0.351562 0.414062
iteration 592: loss 0.611 0.320312 0.453125
iteration 593: loss 0.666 0.304688 0.406250
iteration 594: loss 0.715 0.328125 0.343750
iteration 595: loss 0.547 0.289062 0.515625
iteration 596: loss 0.589 0.343750 0.539062
iteration 597: loss 0.471 0.281250 0.562500
iteration 598: loss 0.615 0.320312 0.406250
iteration 599: loss 0.577 0.250000 0.507812
iteration 600: loss 0.516 0.281250 0.515625
iteration 601: loss 0.544 0.226562 0.484375
iteration 602: loss 0.593 0.304688 0.414062
iteration 603: loss 0.753 0.328125 0.460938
iteration 604: loss 0.436 0.289062 0.609375
iteration 605: loss 0.541 0.328125 0.468750
iteration 606: loss 0.854 0.281250 0.398438
iteration 607: loss 0.704 0.265625 0.382812
iteration 608: loss 0.535 0.289062 0.476562
iteration 609: loss 0.614 0.234375 0.445312
iteration 610: loss 0.567 0.226562 0.437500
iteration 611: loss 0.592 0.265625 0.453125
iteration 612: loss 0.568 0.320312 0.515625
iteration 613: loss 0.440 0.320312 0.585938
iteration 614: loss 0.578 0.335938 0.421875
iteration 615: loss 0.477 0.296875 0.460938
iteration 616: loss 0.580 0.281250 0.468750
iteration 617: loss 0.602 0.320312 0.429688
iteration 618: loss 0.638 0.257812 0.421875
iteration 619: loss 0.581 0.351562 0.421875
iteration 620: loss 0.596 0.281250 0.468750
iteration 621: loss 0.598 0.226562 0.484375
iteration 622: loss 0.657 0.273438 0.468750
iteration 623: loss 0.455 0.343750 0.554688
iteration 624: loss 0.509 0.281250 0.570312
iteration 625: loss 0.493 0.281250 0.484375
iteration 626: loss 0.635 0.296875 0.398438
iteration 627: loss 0.626 0.281250 0.406250
iteration 628: loss 0.371 0.312500 0.625000
iteration 629: loss 0.456 0.351562 0.492188
iteration 630: loss 0.573 0.351562 0.382812
iteration 631: loss 0.589 0.320312 0.382812
iteration 632: loss 0.642 0.289062 0.492188
iteration 633: loss 0.588 0.289062 0.414062
iteration 634: loss 0.593 0.312500 0.429688
iteration 635: loss 0.551 0.296875 0.406250
iteration 636: loss 0.590 0.296875 0.445312
iteration 637: loss 0.609 0.320312 0.460938
iteration 638: loss 0.556 0.375000 0.507812
iteration 639: loss 0.522 0.304688 0.492188
iteration 640: loss 0.447 0.281250 0.500000
iteration 641: loss 0.487 0.312500 0.468750
iteration 642: loss 0.424 0.312500 0.492188
iteration 643: loss 0.545 0.328125 0.539062
iteration 644: loss 0.457 0.273438 0.453125
iteration 645: loss 0.486 0.265625 0.523438
iteration 646: loss 0.642 0.250000 0.414062
iteration 647: loss 0.388 0.343750 0.507812
iteration 648: loss 0.493 0.304688 0.453125
iteration 649: loss 0.532 0.234375 0.476562
iteration 650: loss 0.483 0.289062 0.523438
iteration 651: loss 0.413 0.328125 0.539062
iteration 652: loss 0.489 0.328125 0.523438
iteration 653: loss 0.462 0.328125 0.531250
iteration 654: loss 0.443 0.343750 0.523438
iteration 655: loss 0.547 0.351562 0.507812
iteration 656: loss 0.617 0.273438 0.414062
iteration 657: loss 0.538 0.273438 0.476562
iteration 658: loss 0.504 0.328125 0.445312
iteration 659: loss 0.625 0.359375 0.421875
iteration 660: loss 0.369 0.335938 0.531250
iteration 661: loss 0.668 0.320312 0.445312
iteration 662: loss 0.420 0.328125 0.562500
iteration 663: loss 0.652 0.312500 0.398438
iteration 664: loss 0.543 0.328125 0.453125
iteration 665: loss 0.525 0.312500 0.500000
iteration 666: loss 0.443 0.242188 0.523438
iteration 667: loss 0.522 0.320312 0.507812
iteration 668: loss 0.484 0.304688 0.476562
iteration 669: loss 0.530 0.328125 0.492188
iteration 670: loss 0.542 0.226562 0.460938
iteration 671: loss 0.473 0.320312 0.414062
iteration 672: loss 0.643 0.289062 0.351562
iteration 673: loss 0.644 0.296875 0.335938
iteration 674: loss 0.559 0.289062 0.382812
iteration 675: loss 0.538 0.320312 0.437500
iteration 676: loss 0.545 0.375000 0.453125
iteration 677: loss 0.526 0.296875 0.484375
iteration 678: loss 0.527 0.320312 0.492188
iteration 679: loss 0.461 0.328125 0.539062
iteration 680: loss 0.453 0.281250 0.476562
iteration 681: loss 0.480 0.289062 0.492188
iteration 682: loss 0.573 0.328125 0.437500
iteration 683: loss 0.641 0.320312 0.421875
iteration 684: loss 0.605 0.351562 0.531250
iteration 685: loss 0.537 0.328125 0.445312
iteration 686: loss 0.508 0.273438 0.515625
iteration 687: loss 0.537 0.304688 0.492188
iteration 688: loss 0.609 0.328125 0.429688
iteration 689: loss 0.604 0.281250 0.437500
iteration 690: loss 0.388 0.359375 0.546875
iteration 691: loss 0.559 0.398438 0.453125
iteration 692: loss 0.589 0.390625 0.437500
iteration 693: loss 0.575 0.296875 0.421875
iteration 694: loss 0.411 0.320312 0.453125
iteration 695: loss 0.555 0.304688 0.429688
iteration 696: loss 0.527 0.257812 0.437500
iteration 697: loss 0.474 0.281250 0.531250
iteration 698: loss 0.568 0.250000 0.398438
iteration 699: loss 0.438 0.351562 0.500000
iteration 700: loss 0.575 0.335938 0.375000
iteration 701: loss 0.532 0.312500 0.421875
iteration 702: loss 0.500 0.335938 0.468750
iteration 703: loss 0.514 0.320312 0.492188
iteration 704: loss 0.676 0.257812 0.406250
iteration 705: loss 0.481 0.250000 0.445312
iteration 706: loss 0.620 0.351562 0.429688
iteration 707: loss 0.642 0.320312 0.406250
iteration 708: loss 0.509 0.359375 0.492188
iteration 709: loss 0.674 0.273438 0.421875
iteration 710: loss 0.662 0.343750 0.437500
iteration 711: loss 0.605 0.289062 0.484375
iteration 712: loss 0.764 0.304688 0.421875
iteration 713: loss 0.518 0.335938 0.476562
iteration 714: loss 0.471 0.351562 0.531250
iteration 715: loss 0.682 0.328125 0.382812
iteration 716: loss 0.509 0.359375 0.476562
iteration 717: loss 0.448 0.273438 0.523438
iteration 718: loss 0.601 0.351562 0.453125
iteration 719: loss 0.647 0.289062 0.382812
iteration 720: loss 0.439 0.312500 0.546875
iteration 721: loss 0.438 0.304688 0.476562
iteration 722: loss 0.542 0.328125 0.453125
iteration 723: loss 0.520 0.234375 0.437500
iteration 724: loss 0.593 0.296875 0.492188
iteration 725: loss 0.480 0.281250 0.539062
iteration 726: loss 0.459 0.281250 0.546875
iteration 727: loss 0.517 0.343750 0.445312
iteration 728: loss 0.469 0.335938 0.476562
iteration 729: loss 0.522 0.304688 0.523438
iteration 730: loss 0.503 0.359375 0.500000
iteration 731: loss 0.572 0.296875 0.468750
iteration 732: loss 0.448 0.343750 0.460938
iteration 733: loss 0.600 0.335938 0.390625
iteration 734: loss 0.622 0.335938 0.421875
iteration 735: loss 0.539 0.281250 0.476562
iteration 736: loss 0.493 0.312500 0.429688
iteration 737: loss 0.526 0.335938 0.492188
iteration 738: loss 0.529 0.273438 0.468750
iteration 739: loss 0.662 0.281250 0.445312
iteration 740: loss 0.604 0.320312 0.414062
iteration 741: loss 0.413 0.257812 0.445312
iteration 742: loss 0.524 0.312500 0.437500
iteration 743: loss 0.614 0.250000 0.476562
iteration 744: loss 0.533 0.328125 0.476562
iteration 745: loss 0.461 0.343750 0.539062
iteration 746: loss 0.471 0.281250 0.429688
iteration 747: loss 0.459 0.296875 0.515625
iteration 748: loss 0.521 0.343750 0.460938
iteration 749: loss 0.530 0.335938 0.476562
iteration 750: loss 0.533 0.398438 0.460938
iteration 751: loss 0.561 0.312500 0.476562
iteration 752: loss 0.541 0.289062 0.507812
iteration 753: loss 0.468 0.289062 0.492188
iteration 754: loss 0.473 0.312500 0.515625
iteration 755: loss 0.440 0.328125 0.500000
iteration 756: loss 0.598 0.257812 0.406250
iteration 757: loss 0.614 0.343750 0.367188
iteration 758: loss 0.600 0.281250 0.437500
iteration 759: loss 0.497 0.304688 0.539062
iteration 760: loss 0.556 0.312500 0.500000
iteration 761: loss 0.446 0.289062 0.500000
iteration 762: loss 0.576 0.273438 0.468750
iteration 763: loss 0.590 0.312500 0.507812
iteration 764: loss 0.497 0.281250 0.484375
iteration 765: loss 0.509 0.359375 0.515625
iteration 766: loss 0.547 0.320312 0.460938
iteration 767: loss 0.539 0.289062 0.398438
iteration 768: loss 0.538 0.273438 0.531250
iteration 769: loss 0.402 0.281250 0.531250
iteration 770: loss 0.434 0.312500 0.476562
iteration 771: loss 0.578 0.250000 0.367188
iteration 772: loss 0.556 0.320312 0.414062
iteration 773: loss 0.620 0.320312 0.500000
iteration 774: loss 0.409 0.281250 0.437500
iteration 775: loss 0.414 0.328125 0.515625
iteration 776: loss 0.651 0.289062 0.406250
iteration 777: loss 0.618 0.367188 0.460938
iteration 778: loss 0.481 0.281250 0.445312
iteration 779: loss 0.605 0.250000 0.421875
iteration 780: loss 0.399 0.265625 0.492188
iteration 781: loss 0.449 0.257812 0.484375
iteration 782: loss 0.708 0.367188 0.351562
iteration 783: loss 0.642 0.250000 0.414062
iteration 784: loss 0.536 0.320312 0.453125
iteration 785: loss 0.483 0.320312 0.507812
iteration 786: loss 0.676 0.312500 0.398438
iteration 787: loss 0.478 0.335938 0.531250
iteration 788: loss 0.579 0.343750 0.500000
iteration 789: loss 0.489 0.320312 0.460938
iteration 790: loss 0.482 0.304688 0.468750
iteration 791: loss 0.497 0.296875 0.523438
iteration 792: loss 0.586 0.265625 0.437500
iteration 793: loss 0.563 0.343750 0.468750
iteration 794: loss 0.627 0.273438 0.531250
iteration 795: loss 0.527 0.296875 0.460938
iteration 796: loss 0.512 0.289062 0.437500
iteration 797: loss 0.608 0.375000 0.445312
iteration 798: loss 0.656 0.265625 0.437500
iteration 799: loss 0.555 0.367188 0.437500
iteration 800: loss 0.492 0.328125 0.507812
iteration 801: loss 0.476 0.390625 0.539062
iteration 802: loss 0.505 0.242188 0.539062
iteration 803: loss 0.585 0.320312 0.445312
iteration 804: loss 0.483 0.265625 0.515625
iteration 805: loss 0.560 0.335938 0.398438
iteration 806: loss 0.512 0.281250 0.468750
iteration 807: loss 0.514 0.289062 0.484375
iteration 808: loss 0.563 0.312500 0.476562
iteration 809: loss 0.576 0.281250 0.445312
iteration 810: loss 0.557 0.273438 0.445312
iteration 811: loss 0.520 0.335938 0.445312
iteration 812: loss 0.673 0.296875 0.460938
iteration 813: loss 0.712 0.320312 0.429688
iteration 814: loss 0.532 0.226562 0.476562
iteration 815: loss 0.568 0.281250 0.437500
iteration 816: loss 0.568 0.242188 0.484375
iteration 817: loss 0.570 0.281250 0.468750
iteration 818: loss 0.615 0.304688 0.445312
iteration 819: loss 0.675 0.320312 0.398438
iteration 820: loss 0.503 0.257812 0.507812
iteration 821: loss 0.495 0.320312 0.523438
iteration 822: loss 0.422 0.273438 0.523438
iteration 823: loss 0.502 0.242188 0.554688
iteration 824: loss 0.658 0.257812 0.460938
iteration 825: loss 0.566 0.265625 0.445312
iteration 826: loss 0.580 0.312500 0.414062
iteration 827: loss 0.503 0.351562 0.406250
iteration 828: loss 0.571 0.273438 0.507812
iteration 829: loss 0.610 0.242188 0.492188
iteration 830: loss 0.616 0.304688 0.476562
iteration 831: loss 0.684 0.367188 0.500000
iteration 832: loss 0.523 0.281250 0.515625
iteration 833: loss 0.542 0.289062 0.523438
iteration 834: loss 0.689 0.281250 0.343750
iteration 835: loss 0.662 0.312500 0.343750
iteration 836: loss 0.570 0.273438 0.398438
iteration 837: loss 0.640 0.281250 0.453125
iteration 838: loss 0.386 0.343750 0.515625
iteration 839: loss 0.555 0.312500 0.515625
iteration 840: loss 0.472 0.265625 0.484375
iteration 841: loss 0.571 0.320312 0.437500
iteration 842: loss 0.540 0.335938 0.476562
iteration 843: loss 0.593 0.296875 0.515625
iteration 844: loss 0.555 0.304688 0.460938
iteration 845: loss 0.658 0.320312 0.406250
iteration 846: loss 0.664 0.312500 0.382812
iteration 847: loss 0.469 0.351562 0.515625
iteration 848: loss 0.421 0.351562 0.562500
iteration 849: loss 0.425 0.343750 0.570312
iteration 850: loss 0.605 0.257812 0.445312
iteration 851: loss 0.563 0.343750 0.492188
iteration 852: loss 0.557 0.320312 0.539062
iteration 853: loss 0.544 0.304688 0.468750
iteration 854: loss 0.515 0.289062 0.453125
iteration 855: loss 0.537 0.296875 0.445312
iteration 856: loss 0.549 0.281250 0.460938
iteration 857: loss 0.492 0.335938 0.460938
iteration 858: loss 0.502 0.320312 0.500000
iteration 859: loss 0.607 0.375000 0.476562
iteration 860: loss 0.584 0.320312 0.476562
iteration 861: loss 0.516 0.257812 0.414062
iteration 862: loss 0.696 0.312500 0.406250
iteration 863: loss 0.594 0.414062 0.445312
iteration 864: loss 0.580 0.304688 0.453125
iteration 865: loss 0.536 0.281250 0.468750
iteration 866: loss 0.534 0.312500 0.476562
iteration 867: loss 0.490 0.296875 0.570312
iteration 868: loss 0.646 0.343750 0.523438
iteration 869: loss 0.525 0.335938 0.476562
iteration 870: loss 0.611 0.242188 0.429688
iteration 871: loss 0.603 0.335938 0.468750
iteration 872: loss 0.489 0.289062 0.507812
iteration 873: loss 0.554 0.281250 0.445312
iteration 874: loss 0.592 0.273438 0.460938
iteration 875: loss 0.680 0.359375 0.460938
iteration 876: loss 0.486 0.382812 0.515625
iteration 877: loss 0.494 0.250000 0.562500
iteration 878: loss 0.616 0.367188 0.375000
iteration 879: loss 0.862 0.281250 0.382812
iteration 880: loss 0.543 0.289062 0.445312
iteration 881: loss 0.660 0.406250 0.390625
iteration 882: loss 0.627 0.265625 0.515625
iteration 883: loss 0.672 0.312500 0.390625
iteration 884: loss 0.731 0.265625 0.421875
iteration 885: loss 0.549 0.351562 0.476562
iteration 886: loss 0.674 0.273438 0.421875
iteration 887: loss 0.564 0.351562 0.484375
iteration 888: loss 0.484 0.281250 0.546875
iteration 889: loss 0.603 0.265625 0.390625
iteration 890: loss 0.532 0.281250 0.453125
iteration 891: loss 0.473 0.296875 0.460938
iteration 892: loss 0.383 0.250000 0.585938
iteration 893: loss 0.624 0.273438 0.453125
iteration 894: loss 0.553 0.320312 0.468750
iteration 895: loss 0.612 0.289062 0.484375
iteration 896: loss 0.549 0.289062 0.460938
iteration 897: loss 0.500 0.257812 0.500000
iteration 898: loss 0.511 0.265625 0.515625
iteration 899: loss 0.587 0.281250 0.421875
iteration 900: loss 0.479 0.296875 0.507812
iteration 901: loss 0.474 0.289062 0.500000
iteration 902: loss 0.544 0.320312 0.484375
iteration 903: loss 0.512 0.375000 0.414062
iteration 904: loss 0.429 0.265625 0.507812
iteration 905: loss 0.639 0.367188 0.492188
iteration 906: loss 0.579 0.265625 0.500000
iteration 907: loss 0.591 0.273438 0.468750
iteration 908: loss 0.553 0.343750 0.437500
iteration 909: loss 0.658 0.296875 0.437500
iteration 910: loss 0.563 0.226562 0.382812
iteration 911: loss 0.538 0.273438 0.437500
iteration 912: loss 0.560 0.273438 0.468750
iteration 913: loss 0.531 0.320312 0.453125
iteration 914: loss 0.516 0.257812 0.476562
iteration 915: loss 0.476 0.328125 0.500000
iteration 916: loss 0.639 0.390625 0.468750
iteration 917: loss 0.616 0.226562 0.500000
iteration 918: loss 0.517 0.320312 0.500000
iteration 919: loss 0.510 0.335938 0.500000
iteration 920: loss 0.513 0.312500 0.500000
iteration 921: loss 0.521 0.320312 0.429688
iteration 922: loss 0.493 0.328125 0.453125
iteration 923: loss 0.556 0.359375 0.437500
iteration 924: loss 0.504 0.312500 0.546875
iteration 925: loss 0.548 0.273438 0.515625
iteration 926: loss 0.544 0.335938 0.460938
iteration 927: loss 0.513 0.296875 0.429688
iteration 928: loss 0.608 0.250000 0.398438
iteration 929: loss 0.559 0.289062 0.476562
iteration 930: loss 0.619 0.289062 0.484375
iteration 931: loss 0.566 0.328125 0.492188
iteration 932: loss 0.632 0.289062 0.468750
iteration 933: loss 0.564 0.281250 0.468750
iteration 934: loss 0.661 0.281250 0.421875
iteration 935: loss 0.482 0.312500 0.453125
iteration 936: loss 0.586 0.273438 0.484375
iteration 937: loss 0.488 0.328125 0.492188
iteration 938: loss 0.537 0.265625 0.468750
iteration 939: loss 0.433 0.281250 0.539062
iteration 940: loss 0.589 0.242188 0.468750
iteration 941: loss 0.563 0.320312 0.453125
iteration 942: loss 0.494 0.289062 0.492188
iteration 943: loss 0.574 0.343750 0.453125
iteration 944: loss 0.511 0.265625 0.460938
iteration 945: loss 0.539 0.273438 0.460938
iteration 946: loss 0.412 0.281250 0.460938
iteration 947: loss 0.602 0.242188 0.429688
iteration 948: loss 0.523 0.289062 0.476562
iteration 949: loss 0.471 0.328125 0.437500
iteration 950: loss 0.462 0.359375 0.562500
iteration 951: loss 0.484 0.171875 0.484375
iteration 952: loss 0.500 0.257812 0.531250
iteration 953: loss 0.412 0.273438 0.585938
iteration 954: loss 0.622 0.312500 0.453125
iteration 955: loss 0.516 0.289062 0.492188
iteration 956: loss 0.603 0.226562 0.375000
iteration 957: loss 0.544 0.320312 0.421875
iteration 958: loss 0.541 0.234375 0.414062
iteration 959: loss 0.499 0.312500 0.539062
iteration 960: loss 0.574 0.335938 0.429688
iteration 961: loss 0.576 0.257812 0.437500
iteration 962: loss 0.614 0.320312 0.453125
iteration 963: loss 0.490 0.242188 0.507812
iteration 964: loss 0.517 0.296875 0.476562
iteration 965: loss 0.635 0.367188 0.453125
iteration 966: loss 0.546 0.281250 0.476562
iteration 967: loss 0.503 0.343750 0.437500
iteration 968: loss 0.539 0.351562 0.476562
iteration 969: loss 0.668 0.296875 0.398438
iteration 970: loss 0.530 0.289062 0.437500
iteration 971: loss 0.572 0.343750 0.437500
iteration 972: loss 0.577 0.375000 0.476562
iteration 973: loss 0.628 0.281250 0.507812
iteration 974: loss 0.613 0.273438 0.460938
iteration 975: loss 0.539 0.289062 0.515625
iteration 976: loss 0.545 0.289062 0.484375
iteration 977: loss 0.433 0.296875 0.531250
iteration 978: loss 0.641 0.273438 0.453125
iteration 979: loss 0.455 0.281250 0.554688
iteration 980: loss 0.613 0.320312 0.460938
iteration 981: loss 0.469 0.335938 0.531250
iteration 982: loss 0.520 0.296875 0.453125
iteration 983: loss 0.407 0.203125 0.523438
iteration 984: loss 0.591 0.234375 0.382812
iteration 985: loss 0.518 0.265625 0.523438
iteration 986: loss 0.599 0.312500 0.429688
iteration 987: loss 0.567 0.273438 0.453125
iteration 988: loss 0.544 0.296875 0.445312
iteration 989: loss 0.531 0.281250 0.453125
iteration 990: loss 0.656 0.320312 0.398438
iteration 991: loss 0.504 0.351562 0.507812
iteration 992: loss 0.506 0.296875 0.468750
iteration 993: loss 0.522 0.273438 0.507812
iteration 994: loss 0.522 0.335938 0.492188
iteration 995: loss 0.581 0.296875 0.421875
iteration 996: loss 0.525 0.289062 0.515625
iteration 997: loss 0.505 0.304688 0.453125
iteration 998: loss 0.462 0.281250 0.460938
iteration 999: loss 0.479 0.328125 0.539062
epoch 14: training: 0.367188 validation: 0.187500
iteration 0: loss 0.592 0.304688 0.445312
iteration 1: loss 0.456 0.343750 0.460938
iteration 2: loss 0.559 0.296875 0.531250
iteration 3: loss 0.487 0.203125 0.460938
iteration 4: loss 0.530 0.328125 0.445312
iteration 5: loss 0.516 0.265625 0.445312
iteration 6: loss 0.464 0.351562 0.554688
iteration 7: loss 0.545 0.265625 0.453125
iteration 8: loss 0.536 0.289062 0.453125
iteration 9: loss 0.561 0.312500 0.453125
iteration 10: loss 0.368 0.281250 0.562500
iteration 11: loss 0.492 0.359375 0.429688
iteration 12: loss 0.539 0.343750 0.460938
iteration 13: loss 0.618 0.312500 0.476562
iteration 14: loss 0.548 0.242188 0.468750
iteration 15: loss 0.598 0.414062 0.453125
iteration 16: loss 0.522 0.335938 0.476562
iteration 17: loss 0.475 0.328125 0.570312
iteration 18: loss 0.613 0.359375 0.414062
iteration 19: loss 0.451 0.328125 0.476562
iteration 20: loss 0.610 0.242188 0.343750
iteration 21: loss 0.504 0.296875 0.507812
iteration 22: loss 0.637 0.289062 0.437500
iteration 23: loss 0.616 0.312500 0.507812
iteration 24: loss 0.610 0.312500 0.453125
iteration 25: loss 0.431 0.195312 0.445312
iteration 26: loss 0.580 0.265625 0.507812
iteration 27: loss 0.529 0.281250 0.414062
iteration 28: loss 0.601 0.257812 0.453125
iteration 29: loss 0.438 0.296875 0.492188
iteration 30: loss 0.466 0.265625 0.468750
iteration 31: loss 0.452 0.281250 0.484375
iteration 32: loss 0.441 0.281250 0.500000
iteration 33: loss 0.490 0.382812 0.531250
iteration 34: loss 0.644 0.367188 0.445312
iteration 35: loss 0.583 0.343750 0.375000
iteration 36: loss 0.404 0.359375 0.523438
iteration 37: loss 0.493 0.281250 0.445312
iteration 38: loss 0.696 0.289062 0.367188
iteration 39: loss 0.641 0.328125 0.390625
iteration 40: loss 0.447 0.265625 0.507812
iteration 41: loss 0.537 0.218750 0.460938
iteration 42: loss 0.535 0.242188 0.398438
iteration 43: loss 0.601 0.296875 0.445312
iteration 44: loss 0.486 0.312500 0.523438
iteration 45: loss 0.601 0.281250 0.414062
iteration 46: loss 0.545 0.335938 0.476562
iteration 47: loss 0.521 0.242188 0.453125
iteration 48: loss 0.442 0.289062 0.437500
iteration 49: loss 0.526 0.312500 0.507812
iteration 50: loss 0.574 0.273438 0.437500
iteration 51: loss 0.582 0.257812 0.429688
iteration 52: loss 0.476 0.312500 0.453125
iteration 53: loss 0.448 0.320312 0.445312
iteration 54: loss 0.587 0.320312 0.429688
iteration 55: loss 0.671 0.328125 0.476562
iteration 56: loss 0.446 0.343750 0.523438
iteration 57: loss 0.648 0.304688 0.492188
iteration 58: loss 0.625 0.273438 0.484375
iteration 59: loss 0.622 0.281250 0.429688
iteration 60: loss 0.574 0.289062 0.398438
iteration 61: loss 0.386 0.218750 0.507812
iteration 62: loss 0.679 0.328125 0.421875
iteration 63: loss 0.632 0.335938 0.398438
iteration 64: loss 0.621 0.281250 0.492188
iteration 65: loss 0.564 0.328125 0.515625
iteration 66: loss 0.589 0.343750 0.468750
iteration 67: loss 0.597 0.335938 0.421875
iteration 68: loss 0.538 0.296875 0.468750
iteration 69: loss 0.486 0.328125 0.453125
iteration 70: loss 0.595 0.312500 0.414062
iteration 71: loss 0.430 0.304688 0.515625
iteration 72: loss 0.601 0.312500 0.398438
iteration 73: loss 0.503 0.312500 0.492188
iteration 74: loss 0.434 0.257812 0.500000
iteration 75: loss 0.502 0.304688 0.515625
iteration 76: loss 0.384 0.296875 0.500000
iteration 77: loss 0.596 0.335938 0.468750
iteration 78: loss 0.457 0.296875 0.546875
iteration 79: loss 0.513 0.320312 0.468750
iteration 80: loss 0.560 0.351562 0.500000
iteration 81: loss 0.525 0.304688 0.476562
iteration 82: loss 0.501 0.304688 0.476562
iteration 83: loss 0.537 0.328125 0.476562
iteration 84: loss 0.485 0.242188 0.500000
iteration 85: loss 0.500 0.320312 0.562500
iteration 86: loss 0.537 0.367188 0.445312
iteration 87: loss 0.480 0.304688 0.523438
iteration 88: loss 0.395 0.265625 0.554688
iteration 89: loss 0.478 0.289062 0.500000
iteration 90: loss 0.514 0.281250 0.445312
iteration 91: loss 0.423 0.335938 0.500000
iteration 92: loss 0.492 0.273438 0.507812
iteration 93: loss 0.684 0.265625 0.414062
iteration 94: loss 0.551 0.281250 0.421875
iteration 95: loss 0.525 0.320312 0.484375
iteration 96: loss 0.544 0.304688 0.492188
iteration 97: loss 0.484 0.296875 0.523438
iteration 98: loss 0.500 0.312500 0.460938
iteration 99: loss 0.522 0.289062 0.437500
iteration 100: loss 0.535 0.273438 0.437500
iteration 101: loss 0.555 0.257812 0.476562
iteration 102: loss 0.572 0.304688 0.429688
iteration 103: loss 0.534 0.343750 0.476562
iteration 104: loss 0.594 0.390625 0.367188
iteration 105: loss 0.442 0.312500 0.515625
iteration 106: loss 0.589 0.335938 0.492188
iteration 107: loss 0.555 0.281250 0.468750
iteration 108: loss 0.549 0.335938 0.468750
iteration 109: loss 0.656 0.351562 0.414062
iteration 110: loss 0.464 0.335938 0.484375
iteration 111: loss 0.595 0.304688 0.429688
iteration 112: loss 0.497 0.304688 0.492188
iteration 113: loss 0.567 0.304688 0.476562
iteration 114: loss 0.505 0.257812 0.531250
iteration 115: loss 0.524 0.281250 0.453125
iteration 116: loss 0.534 0.289062 0.453125
iteration 117: loss 0.598 0.328125 0.492188
iteration 118: loss 0.457 0.250000 0.523438
iteration 119: loss 0.610 0.242188 0.421875
iteration 120: loss 0.538 0.304688 0.492188
iteration 121: loss 0.561 0.273438 0.437500
iteration 122: loss 0.565 0.328125 0.445312
iteration 123: loss 0.557 0.343750 0.476562
iteration 124: loss 0.528 0.273438 0.476562
iteration 125: loss 0.508 0.257812 0.429688
iteration 126: loss 0.499 0.320312 0.468750
iteration 127: loss 0.427 0.367188 0.500000
iteration 128: loss 0.435 0.312500 0.578125
iteration 129: loss 0.512 0.320312 0.421875
iteration 130: loss 0.476 0.351562 0.476562
iteration 131: loss 0.479 0.273438 0.562500
iteration 132: loss 0.665 0.281250 0.421875
iteration 133: loss 0.575 0.304688 0.492188
iteration 134: loss 0.511 0.375000 0.500000
iteration 135: loss 0.513 0.289062 0.531250
iteration 136: loss 0.660 0.328125 0.390625
iteration 137: loss 0.524 0.257812 0.453125
iteration 138: loss 0.608 0.250000 0.453125
iteration 139: loss 0.544 0.312500 0.492188
iteration 140: loss 0.550 0.265625 0.507812
iteration 141: loss 0.437 0.250000 0.468750
iteration 142: loss 0.485 0.304688 0.460938
iteration 143: loss 0.591 0.265625 0.460938
iteration 144: loss 0.470 0.242188 0.507812
iteration 145: loss 0.460 0.289062 0.460938
iteration 146: loss 0.612 0.312500 0.429688
iteration 147: loss 0.410 0.343750 0.539062
iteration 148: loss 0.461 0.250000 0.476562
iteration 149: loss 0.412 0.257812 0.507812
iteration 150: loss 0.465 0.257812 0.484375
iteration 151: loss 0.603 0.289062 0.375000
iteration 152: loss 0.485 0.328125 0.468750
iteration 153: loss 0.548 0.312500 0.484375
iteration 154: loss 0.556 0.234375 0.539062
iteration 155: loss 0.566 0.343750 0.445312
iteration 156: loss 0.514 0.304688 0.531250
iteration 157: loss 0.558 0.343750 0.492188
iteration 158: loss 0.634 0.265625 0.421875
iteration 159: loss 0.530 0.304688 0.406250
iteration 160: loss 0.419 0.289062 0.531250
iteration 161: loss 0.657 0.257812 0.468750
iteration 162: loss 0.674 0.281250 0.390625
iteration 163: loss 0.393 0.289062 0.593750
iteration 164: loss 0.545 0.257812 0.484375
iteration 165: loss 0.642 0.289062 0.406250
iteration 166: loss 0.504 0.359375 0.445312
iteration 167: loss 0.485 0.343750 0.437500
iteration 168: loss 0.498 0.328125 0.484375
iteration 169: loss 0.535 0.359375 0.523438
iteration 170: loss 0.522 0.296875 0.421875
iteration 171: loss 0.639 0.289062 0.429688
iteration 172: loss 0.570 0.335938 0.500000
iteration 173: loss 0.590 0.312500 0.453125
iteration 174: loss 0.447 0.289062 0.500000
iteration 175: loss 0.520 0.328125 0.445312
iteration 176: loss 0.499 0.257812 0.492188
iteration 177: loss 0.508 0.335938 0.437500
iteration 178: loss 0.556 0.320312 0.445312
iteration 179: loss 0.408 0.320312 0.562500
iteration 180: loss 0.612 0.320312 0.398438
iteration 181: loss 0.501 0.257812 0.468750
iteration 182: loss 0.656 0.351562 0.445312
iteration 183: loss 0.474 0.281250 0.515625
iteration 184: loss 0.648 0.250000 0.453125
iteration 185: loss 0.577 0.320312 0.414062
iteration 186: loss 0.715 0.328125 0.453125
iteration 187: loss 0.637 0.296875 0.437500
iteration 188: loss 0.613 0.312500 0.429688
iteration 189: loss 0.514 0.359375 0.476562
iteration 190: loss 0.520 0.273438 0.453125
iteration 191: loss 0.538 0.296875 0.437500
iteration 192: loss 0.650 0.242188 0.421875
iteration 193: loss 0.662 0.265625 0.390625
iteration 194: loss 0.583 0.273438 0.367188
iteration 195: loss 0.422 0.257812 0.468750
iteration 196: loss 0.447 0.343750 0.453125
iteration 197: loss 0.537 0.250000 0.476562
iteration 198: loss 0.466 0.335938 0.476562
iteration 199: loss 0.594 0.226562 0.453125
iteration 200: loss 0.470 0.273438 0.492188
iteration 201: loss 0.474 0.320312 0.507812
iteration 202: loss 0.514 0.312500 0.421875
iteration 203: loss 0.509 0.289062 0.484375
iteration 204: loss 0.501 0.406250 0.453125
iteration 205: loss 0.535 0.335938 0.515625
iteration 206: loss 0.656 0.335938 0.421875
iteration 207: loss 0.652 0.312500 0.476562
iteration 208: loss 0.677 0.257812 0.421875
iteration 209: loss 0.592 0.289062 0.414062
iteration 210: loss 0.574 0.328125 0.460938
iteration 211: loss 0.526 0.343750 0.500000
iteration 212: loss 0.555 0.351562 0.445312
iteration 213: loss 0.421 0.351562 0.500000
iteration 214: loss 0.599 0.328125 0.429688
iteration 215: loss 0.526 0.234375 0.437500
iteration 216: loss 0.624 0.273438 0.382812
iteration 217: loss 0.468 0.296875 0.492188
iteration 218: loss 0.582 0.320312 0.531250
iteration 219: loss 0.563 0.320312 0.453125
iteration 220: loss 0.574 0.312500 0.476562
iteration 221: loss 0.516 0.351562 0.476562
iteration 222: loss 0.565 0.296875 0.453125
iteration 223: loss 0.607 0.281250 0.445312
iteration 224: loss 0.628 0.234375 0.437500
iteration 225: loss 0.489 0.257812 0.531250
iteration 226: loss 0.503 0.335938 0.484375
iteration 227: loss 0.432 0.257812 0.507812
iteration 228: loss 0.431 0.320312 0.523438
iteration 229: loss 0.574 0.320312 0.492188
iteration 230: loss 0.578 0.328125 0.484375
iteration 231: loss 0.461 0.343750 0.546875
iteration 232: loss 0.479 0.312500 0.492188
iteration 233: loss 0.574 0.335938 0.429688
iteration 234: loss 0.467 0.273438 0.476562
iteration 235: loss 0.573 0.335938 0.484375
iteration 236: loss 0.567 0.273438 0.406250
iteration 237: loss 0.574 0.359375 0.429688
iteration 238: loss 0.584 0.250000 0.414062
iteration 239: loss 0.547 0.367188 0.460938
iteration 240: loss 0.543 0.320312 0.429688
iteration 241: loss 0.516 0.320312 0.445312
iteration 242: loss 0.545 0.406250 0.507812
iteration 243: loss 0.551 0.312500 0.445312
iteration 244: loss 0.699 0.335938 0.367188
iteration 245: loss 0.634 0.296875 0.390625
iteration 246: loss 0.473 0.335938 0.476562
iteration 247: loss 0.611 0.289062 0.437500
iteration 248: loss 0.596 0.289062 0.460938
iteration 249: loss 0.634 0.273438 0.429688
iteration 250: loss 0.507 0.289062 0.421875
iteration 251: loss 0.583 0.273438 0.445312
iteration 252: loss 0.471 0.304688 0.437500
iteration 253: loss 0.473 0.320312 0.445312
iteration 254: loss 0.533 0.382812 0.453125
iteration 255: loss 0.510 0.343750 0.554688
iteration 256: loss 0.543 0.343750 0.546875
iteration 257: loss 0.726 0.328125 0.453125
iteration 258: loss 0.545 0.328125 0.445312
iteration 259: loss 0.434 0.304688 0.492188
iteration 260: loss 0.518 0.281250 0.414062
iteration 261: loss 0.674 0.250000 0.421875
iteration 262: loss 0.668 0.250000 0.437500
iteration 263: loss 0.552 0.281250 0.515625
iteration 264: loss 0.578 0.281250 0.359375
iteration 265: loss 0.546 0.429688 0.429688
iteration 266: loss 0.549 0.242188 0.406250
iteration 267: loss 0.558 0.281250 0.382812
iteration 268: loss 0.597 0.343750 0.531250
iteration 269: loss 0.634 0.320312 0.460938
iteration 270: loss 0.505 0.304688 0.507812
iteration 271: loss 0.607 0.296875 0.484375
iteration 272: loss 0.662 0.328125 0.429688
iteration 273: loss 0.429 0.335938 0.539062
iteration 274: loss 0.528 0.304688 0.460938
iteration 275: loss 0.515 0.304688 0.460938
iteration 276: loss 0.540 0.328125 0.421875
iteration 277: loss 0.559 0.273438 0.500000
iteration 278: loss 0.406 0.312500 0.421875
iteration 279: loss 0.466 0.296875 0.468750
iteration 280: loss 0.498 0.382812 0.492188
iteration 281: loss 0.475 0.312500 0.492188
iteration 282: loss 0.516 0.250000 0.507812
iteration 283: loss 0.543 0.320312 0.468750
iteration 284: loss 0.475 0.289062 0.484375
iteration 285: loss 0.476 0.242188 0.476562
iteration 286: loss 0.350 0.320312 0.546875
iteration 287: loss 0.600 0.312500 0.453125
iteration 288: loss 0.625 0.304688 0.460938
iteration 289: loss 0.692 0.390625 0.492188
iteration 290: loss 0.551 0.242188 0.460938
iteration 291: loss 0.484 0.296875 0.507812
iteration 292: loss 0.577 0.304688 0.421875
iteration 293: loss 0.562 0.273438 0.406250
iteration 294: loss 0.561 0.265625 0.406250
iteration 295: loss 0.503 0.351562 0.468750
iteration 296: loss 0.551 0.351562 0.500000
iteration 297: loss 0.633 0.312500 0.460938
iteration 298: loss 0.649 0.328125 0.453125
iteration 299: loss 0.585 0.304688 0.414062
iteration 300: loss 0.541 0.312500 0.445312
iteration 301: loss 0.507 0.312500 0.492188
iteration 302: loss 0.545 0.312500 0.468750
iteration 303: loss 0.565 0.328125 0.429688
iteration 304: loss 0.720 0.328125 0.460938
iteration 305: loss 0.678 0.242188 0.406250
iteration 306: loss 0.521 0.203125 0.468750
iteration 307: loss 0.482 0.289062 0.484375
iteration 308: loss 0.710 0.250000 0.414062
iteration 309: loss 0.499 0.257812 0.539062
iteration 310: loss 0.598 0.343750 0.460938
iteration 311: loss 0.609 0.343750 0.500000
iteration 312: loss 0.604 0.265625 0.414062
iteration 313: loss 0.527 0.359375 0.468750
iteration 314: loss 0.601 0.281250 0.437500
iteration 315: loss 0.630 0.289062 0.445312
iteration 316: loss 0.496 0.367188 0.445312
iteration 317: loss 0.450 0.265625 0.492188
iteration 318: loss 0.399 0.242188 0.515625
iteration 319: loss 0.445 0.265625 0.515625
iteration 320: loss 0.674 0.296875 0.421875
iteration 321: loss 0.502 0.296875 0.460938
iteration 322: loss 0.511 0.296875 0.453125
iteration 323: loss 0.611 0.289062 0.414062
iteration 324: loss 0.529 0.273438 0.437500
iteration 325: loss 0.521 0.312500 0.476562
iteration 326: loss 0.543 0.289062 0.476562
iteration 327: loss 0.552 0.210938 0.367188
iteration 328: loss 0.574 0.265625 0.484375
iteration 329: loss 0.594 0.273438 0.453125
iteration 330: loss 0.477 0.343750 0.492188
iteration 331: loss 0.514 0.304688 0.453125
iteration 332: loss 0.470 0.289062 0.523438
iteration 333: loss 0.492 0.289062 0.468750
iteration 334: loss 0.480 0.273438 0.492188
iteration 335: loss 0.477 0.289062 0.476562
iteration 336: loss 0.499 0.304688 0.468750
iteration 337: loss 0.565 0.296875 0.382812
iteration 338: loss 0.501 0.265625 0.468750
iteration 339: loss 0.647 0.273438 0.460938
iteration 340: loss 0.512 0.265625 0.460938
iteration 341: loss 0.517 0.296875 0.437500
iteration 342: loss 0.456 0.304688 0.500000
iteration 343: loss 0.391 0.343750 0.531250
iteration 344: loss 0.492 0.273438 0.437500
iteration 345: loss 0.488 0.351562 0.476562
iteration 346: loss 0.510 0.281250 0.500000
iteration 347: loss 0.462 0.289062 0.515625
iteration 348: loss 0.505 0.335938 0.429688
iteration 349: loss 0.617 0.257812 0.390625
iteration 350: loss 0.455 0.359375 0.476562
iteration 351: loss 0.541 0.312500 0.437500
iteration 352: loss 0.553 0.343750 0.515625
iteration 353: loss 0.586 0.312500 0.460938
iteration 354: loss 0.515 0.320312 0.468750
iteration 355: loss 0.565 0.359375 0.421875
iteration 356: loss 0.520 0.320312 0.468750
iteration 357: loss 0.475 0.273438 0.492188
iteration 358: loss 0.547 0.343750 0.421875
iteration 359: loss 0.476 0.273438 0.492188
iteration 360: loss 0.522 0.257812 0.492188
iteration 361: loss 0.499 0.328125 0.500000
iteration 362: loss 0.593 0.273438 0.468750
iteration 363: loss 0.450 0.273438 0.492188
iteration 364: loss 0.483 0.273438 0.484375
iteration 365: loss 0.635 0.320312 0.437500
iteration 366: loss 0.646 0.328125 0.382812
iteration 367: loss 0.461 0.382812 0.507812
iteration 368: loss 0.455 0.320312 0.515625
iteration 369: loss 0.614 0.359375 0.421875
iteration 370: loss 0.578 0.320312 0.492188
iteration 371: loss 0.542 0.281250 0.476562
iteration 372: loss 0.471 0.312500 0.453125
iteration 373: loss 0.460 0.304688 0.484375
iteration 374: loss 0.479 0.304688 0.531250
iteration 375: loss 0.426 0.304688 0.546875
iteration 376: loss 0.465 0.281250 0.484375
iteration 377: loss 0.609 0.296875 0.382812
iteration 378: loss 0.504 0.343750 0.476562
iteration 379: loss 0.541 0.375000 0.460938
iteration 380: loss 0.413 0.375000 0.476562
iteration 381: loss 0.472 0.265625 0.515625
iteration 382: loss 0.619 0.289062 0.453125
iteration 383: loss 0.585 0.343750 0.421875
iteration 384: loss 0.564 0.250000 0.453125
iteration 385: loss 0.510 0.304688 0.468750
iteration 386: loss 0.578 0.320312 0.500000
iteration 387: loss 0.488 0.312500 0.414062
iteration 388: loss 0.550 0.289062 0.414062
iteration 389: loss 0.446 0.234375 0.468750
iteration 390: loss 0.576 0.320312 0.476562
iteration 391: loss 0.493 0.320312 0.492188
iteration 392: loss 0.470 0.320312 0.484375
iteration 393: loss 0.479 0.320312 0.445312
iteration 394: loss 0.502 0.281250 0.453125
iteration 395: loss 0.572 0.328125 0.484375
iteration 396: loss 0.612 0.335938 0.445312
iteration 397: loss 0.666 0.250000 0.328125
iteration 398: loss 0.528 0.265625 0.554688
iteration 399: loss 0.534 0.242188 0.460938
iteration 400: loss 0.521 0.289062 0.453125
iteration 401: loss 0.509 0.296875 0.492188
iteration 402: loss 0.549 0.296875 0.421875
iteration 403: loss 0.607 0.289062 0.421875
iteration 404: loss 0.517 0.351562 0.460938
iteration 405: loss 0.579 0.289062 0.445312
iteration 406: loss 0.591 0.296875 0.406250
iteration 407: loss 0.453 0.281250 0.531250
iteration 408: loss 0.550 0.296875 0.476562
iteration 409: loss 0.469 0.390625 0.515625
iteration 410: loss 0.616 0.289062 0.484375
iteration 411: loss 0.499 0.289062 0.484375
iteration 412: loss 0.484 0.320312 0.500000
iteration 413: loss 0.638 0.304688 0.453125
iteration 414: loss 0.515 0.203125 0.507812
iteration 415: loss 0.506 0.273438 0.468750
iteration 416: loss 0.603 0.250000 0.460938
iteration 417: loss 0.504 0.273438 0.500000
iteration 418: loss 0.641 0.250000 0.460938
iteration 419: loss 0.474 0.335938 0.515625
iteration 420: loss 0.564 0.281250 0.500000
iteration 421: loss 0.528 0.257812 0.468750
iteration 422: loss 0.528 0.296875 0.460938
iteration 423: loss 0.413 0.250000 0.500000
iteration 424: loss 0.492 0.351562 0.515625
iteration 425: loss 0.504 0.265625 0.484375
iteration 426: loss 0.554 0.273438 0.546875
iteration 427: loss 0.493 0.296875 0.523438
iteration 428: loss 0.516 0.359375 0.437500
iteration 429: loss 0.579 0.328125 0.476562
iteration 430: loss 0.527 0.328125 0.515625
iteration 431: loss 0.649 0.257812 0.421875
iteration 432: loss 0.433 0.304688 0.570312
iteration 433: loss 0.573 0.289062 0.507812
iteration 434: loss 0.539 0.281250 0.484375
iteration 435: loss 0.621 0.320312 0.390625
iteration 436: loss 0.521 0.304688 0.453125
iteration 437: loss 0.568 0.289062 0.437500
iteration 438: loss 0.595 0.304688 0.476562
iteration 439: loss 0.513 0.343750 0.492188
iteration 440: loss 0.557 0.304688 0.453125
iteration 441: loss 0.620 0.257812 0.414062
iteration 442: loss 0.539 0.398438 0.484375
iteration 443: loss 0.651 0.320312 0.523438
iteration 444: loss 0.591 0.296875 0.453125
iteration 445: loss 0.465 0.250000 0.523438
iteration 446: loss 0.499 0.312500 0.492188
iteration 447: loss 0.651 0.273438 0.390625
iteration 448: loss 0.602 0.234375 0.476562
iteration 449: loss 0.621 0.296875 0.445312
iteration 450: loss 0.536 0.312500 0.453125
iteration 451: loss 0.410 0.273438 0.523438
iteration 452: loss 0.635 0.351562 0.468750
iteration 453: loss 0.464 0.281250 0.531250
iteration 454: loss 0.554 0.312500 0.437500
iteration 455: loss 0.718 0.351562 0.398438
iteration 456: loss 0.499 0.320312 0.539062
iteration 457: loss 0.529 0.296875 0.507812
iteration 458: loss 0.630 0.273438 0.398438
iteration 459: loss 0.537 0.273438 0.468750
iteration 460: loss 0.569 0.398438 0.367188
iteration 461: loss 0.604 0.289062 0.476562
iteration 462: loss 0.457 0.242188 0.515625
iteration 463: loss 0.504 0.273438 0.500000
iteration 464: loss 0.493 0.273438 0.523438
iteration 465: loss 0.523 0.281250 0.539062
iteration 466: loss 0.621 0.242188 0.429688
iteration 467: loss 0.566 0.289062 0.531250
iteration 468: loss 0.492 0.250000 0.500000
iteration 469: loss 0.518 0.281250 0.460938
iteration 470: loss 0.589 0.289062 0.437500
iteration 471: loss 0.490 0.328125 0.554688
iteration 472: loss 0.494 0.312500 0.414062
iteration 473: loss 0.589 0.234375 0.437500
iteration 474: loss 0.619 0.312500 0.468750
iteration 475: loss 0.625 0.312500 0.398438
iteration 476: loss 0.543 0.234375 0.507812
iteration 477: loss 0.593 0.296875 0.445312
iteration 478: loss 0.595 0.304688 0.476562
iteration 479: loss 0.603 0.210938 0.390625
iteration 480: loss 0.520 0.296875 0.468750
iteration 481: loss 0.480 0.304688 0.515625
iteration 482: loss 0.508 0.343750 0.445312
iteration 483: loss 0.557 0.343750 0.468750
iteration 484: loss 0.574 0.312500 0.484375
iteration 485: loss 0.547 0.257812 0.421875
iteration 486: loss 0.565 0.257812 0.445312
iteration 487: loss 0.555 0.375000 0.460938
iteration 488: loss 0.631 0.289062 0.445312
iteration 489: loss 0.696 0.281250 0.406250
iteration 490: loss 0.514 0.343750 0.484375
iteration 491: loss 0.442 0.242188 0.515625
iteration 492: loss 0.439 0.234375 0.507812
iteration 493: loss 0.610 0.335938 0.390625
iteration 494: loss 0.643 0.242188 0.468750
iteration 495: loss 0.555 0.304688 0.539062
iteration 496: loss 0.645 0.281250 0.460938
iteration 497: loss 0.475 0.296875 0.539062
iteration 498: loss 0.612 0.218750 0.359375
iteration 499: loss 0.454 0.296875 0.539062
iteration 500: loss 0.541 0.343750 0.492188
iteration 501: loss 0.540 0.296875 0.484375
iteration 502: loss 0.636 0.226562 0.429688
iteration 503: loss 0.554 0.273438 0.476562
iteration 504: loss 0.463 0.335938 0.539062
iteration 505: loss 0.500 0.289062 0.546875
iteration 506: loss 0.393 0.210938 0.476562
iteration 507: loss 0.612 0.296875 0.421875
iteration 508: loss 0.607 0.281250 0.429688
iteration 509: loss 0.629 0.257812 0.476562
iteration 510: loss 0.585 0.265625 0.421875
iteration 511: loss 0.634 0.328125 0.406250
iteration 512: loss 0.514 0.382812 0.546875
iteration 513: loss 0.392 0.265625 0.531250
iteration 514: loss 0.522 0.320312 0.453125
iteration 515: loss 0.521 0.367188 0.492188
iteration 516: loss 0.536 0.351562 0.460938
iteration 517: loss 0.498 0.304688 0.500000
iteration 518: loss 0.505 0.281250 0.460938
iteration 519: loss 0.542 0.359375 0.500000
iteration 520: loss 0.466 0.328125 0.492188
iteration 521: loss 0.609 0.281250 0.437500
iteration 522: loss 0.582 0.343750 0.437500
iteration 523: loss 0.568 0.375000 0.468750
iteration 524: loss 0.674 0.257812 0.382812
iteration 525: loss 0.558 0.296875 0.476562
iteration 526: loss 0.515 0.320312 0.476562
iteration 527: loss 0.565 0.312500 0.398438
iteration 528: loss 0.415 0.312500 0.531250
iteration 529: loss 0.426 0.226562 0.500000
iteration 530: loss 0.485 0.343750 0.531250
iteration 531: loss 0.440 0.281250 0.523438
iteration 532: loss 0.583 0.289062 0.476562
iteration 533: loss 0.837 0.328125 0.390625
iteration 534: loss 0.538 0.257812 0.507812
iteration 535: loss 0.599 0.289062 0.492188
iteration 536: loss 0.525 0.343750 0.429688
iteration 537: loss 0.560 0.296875 0.414062
iteration 538: loss 0.530 0.281250 0.500000
iteration 539: loss 0.523 0.312500 0.421875
iteration 540: loss 0.505 0.289062 0.468750
iteration 541: loss 0.532 0.289062 0.492188
iteration 542: loss 0.532 0.265625 0.500000
iteration 543: loss 0.587 0.234375 0.398438
iteration 544: loss 0.456 0.273438 0.476562
iteration 545: loss 0.583 0.375000 0.437500
iteration 546: loss 0.595 0.289062 0.351562
iteration 547: loss 0.526 0.218750 0.500000
iteration 548: loss 0.540 0.265625 0.484375
iteration 549: loss 0.489 0.257812 0.531250
iteration 550: loss 0.600 0.320312 0.382812
iteration 551: loss 0.493 0.312500 0.484375
iteration 552: loss 0.551 0.335938 0.429688
iteration 553: loss 0.641 0.296875 0.437500
iteration 554: loss 0.574 0.296875 0.445312
iteration 555: loss 0.541 0.218750 0.492188
iteration 556: loss 0.542 0.195312 0.468750
iteration 557: loss 0.515 0.335938 0.445312
iteration 558: loss 0.427 0.265625 0.562500
iteration 559: loss 0.587 0.296875 0.460938
iteration 560: loss 0.611 0.296875 0.445312
iteration 561: loss 0.461 0.289062 0.484375
iteration 562: loss 0.494 0.335938 0.507812
iteration 563: loss 0.475 0.328125 0.492188
iteration 564: loss 0.499 0.328125 0.515625
iteration 565: loss 0.604 0.296875 0.421875
iteration 566: loss 0.450 0.328125 0.484375
iteration 567: loss 0.422 0.296875 0.492188
iteration 568: loss 0.424 0.281250 0.500000
iteration 569: loss 0.504 0.265625 0.476562
iteration 570: loss 0.450 0.382812 0.460938
iteration 571: loss 0.461 0.320312 0.453125
iteration 572: loss 0.582 0.296875 0.460938
iteration 573: loss 0.513 0.320312 0.500000
iteration 574: loss 0.495 0.226562 0.468750
iteration 575: loss 0.513 0.281250 0.406250
iteration 576: loss 0.438 0.351562 0.460938
iteration 577: loss 0.499 0.382812 0.476562
iteration 578: loss 0.519 0.351562 0.437500
iteration 579: loss 0.488 0.296875 0.484375
iteration 580: loss 0.441 0.296875 0.484375
iteration 581: loss 0.528 0.273438 0.554688
iteration 582: loss 0.505 0.320312 0.531250
iteration 583: loss 0.400 0.257812 0.539062
iteration 584: loss 0.502 0.375000 0.453125
iteration 585: loss 0.494 0.226562 0.539062
iteration 586: loss 0.474 0.359375 0.507812
iteration 587: loss 0.519 0.281250 0.468750
iteration 588: loss 0.413 0.320312 0.523438
iteration 589: loss 0.511 0.281250 0.414062
iteration 590: loss 0.429 0.289062 0.460938
iteration 591: loss 0.446 0.359375 0.437500
iteration 592: loss 0.709 0.320312 0.414062
iteration 593: loss 0.717 0.304688 0.421875
iteration 594: loss 0.549 0.242188 0.453125
iteration 595: loss 0.425 0.289062 0.476562
iteration 596: loss 0.485 0.304688 0.468750
iteration 597: loss 0.548 0.304688 0.390625
iteration 598: loss 0.474 0.296875 0.468750
iteration 599: loss 0.473 0.273438 0.468750
iteration 600: loss 0.511 0.296875 0.406250
iteration 601: loss 0.598 0.351562 0.429688
iteration 602: loss 0.509 0.367188 0.453125
iteration 603: loss 0.587 0.320312 0.429688
iteration 604: loss 0.520 0.304688 0.437500
iteration 605: loss 0.574 0.312500 0.468750
iteration 606: loss 0.558 0.328125 0.382812
iteration 607: loss 0.527 0.289062 0.453125
iteration 608: loss 0.666 0.304688 0.421875
iteration 609: loss 0.527 0.296875 0.476562
iteration 610: loss 0.515 0.265625 0.476562
iteration 611: loss 0.416 0.296875 0.445312
iteration 612: loss 0.458 0.281250 0.429688
iteration 613: loss 0.518 0.304688 0.421875
iteration 614: loss 0.488 0.312500 0.468750
iteration 615: loss 0.440 0.265625 0.507812
iteration 616: loss 0.559 0.289062 0.429688
iteration 617: loss 0.522 0.289062 0.445312
iteration 618: loss 0.629 0.320312 0.429688
iteration 619: loss 0.434 0.312500 0.429688
iteration 620: loss 0.595 0.367188 0.437500
iteration 621: loss 0.417 0.304688 0.546875
iteration 622: loss 0.599 0.335938 0.484375
iteration 623: loss 0.474 0.304688 0.437500
iteration 624: loss 0.592 0.328125 0.437500
iteration 625: loss 0.509 0.210938 0.437500
iteration 626: loss 0.480 0.289062 0.539062
iteration 627: loss 0.541 0.328125 0.445312
iteration 628: loss 0.472 0.304688 0.484375
iteration 629: loss 0.437 0.351562 0.570312
iteration 630: loss 0.484 0.304688 0.468750
iteration 631: loss 0.502 0.343750 0.500000
iteration 632: loss 0.583 0.312500 0.414062
iteration 633: loss 0.551 0.257812 0.523438
iteration 634: loss 0.548 0.257812 0.382812
iteration 635: loss 0.481 0.312500 0.429688
iteration 636: loss 0.627 0.296875 0.453125
iteration 637: loss 0.478 0.265625 0.406250
iteration 638: loss 0.475 0.335938 0.515625
iteration 639: loss 0.498 0.398438 0.492188
iteration 640: loss 0.514 0.304688 0.531250
iteration 641: loss 0.576 0.312500 0.460938
iteration 642: loss 0.601 0.304688 0.476562
iteration 643: loss 0.709 0.296875 0.453125
iteration 644: loss 0.591 0.375000 0.398438
iteration 645: loss 0.491 0.421875 0.484375
iteration 646: loss 0.520 0.312500 0.515625
iteration 647: loss 0.589 0.296875 0.429688
iteration 648: loss 0.500 0.335938 0.531250
iteration 649: loss 0.557 0.289062 0.492188
iteration 650: loss 0.464 0.328125 0.515625
iteration 651: loss 0.535 0.304688 0.484375
iteration 652: loss 0.642 0.312500 0.492188
iteration 653: loss 0.488 0.289062 0.484375
iteration 654: loss 0.650 0.304688 0.406250
iteration 655: loss 0.544 0.265625 0.453125
iteration 656: loss 0.624 0.296875 0.429688
iteration 657: loss 0.431 0.289062 0.507812
iteration 658: loss 0.434 0.351562 0.523438
iteration 659: loss 0.509 0.328125 0.453125
iteration 660: loss 0.521 0.343750 0.507812
iteration 661: loss 0.561 0.281250 0.484375
iteration 662: loss 0.558 0.296875 0.484375
iteration 663: loss 0.585 0.359375 0.429688
iteration 664: loss 0.468 0.312500 0.484375
iteration 665: loss 0.568 0.343750 0.460938
iteration 666: loss 0.515 0.320312 0.468750
iteration 667: loss 0.481 0.289062 0.468750
iteration 668: loss 0.518 0.257812 0.515625
iteration 669: loss 0.642 0.242188 0.398438
iteration 670: loss 0.547 0.281250 0.437500
iteration 671: loss 0.494 0.265625 0.523438
iteration 672: loss 0.552 0.382812 0.460938
iteration 673: loss 0.454 0.273438 0.507812
iteration 674: loss 0.526 0.375000 0.484375
iteration 675: loss 0.562 0.320312 0.453125
iteration 676: loss 0.695 0.351562 0.390625
iteration 677: loss 0.473 0.328125 0.453125
iteration 678: loss 0.488 0.265625 0.531250
iteration 679: loss 0.539 0.250000 0.453125
iteration 680: loss 0.547 0.296875 0.429688
iteration 681: loss 0.563 0.296875 0.445312
iteration 682: loss 0.447 0.257812 0.476562
iteration 683: loss 0.625 0.273438 0.445312
iteration 684: loss 0.507 0.335938 0.515625
iteration 685: loss 0.628 0.257812 0.453125
iteration 686: loss 0.425 0.375000 0.570312
iteration 687: loss 0.521 0.242188 0.437500
iteration 688: loss 0.486 0.351562 0.507812
iteration 689: loss 0.550 0.312500 0.453125
iteration 690: loss 0.440 0.296875 0.492188
iteration 691: loss 0.541 0.312500 0.460938
iteration 692: loss 0.537 0.335938 0.460938
iteration 693: loss 0.522 0.320312 0.476562
iteration 694: loss 0.596 0.296875 0.406250
iteration 695: loss 0.599 0.304688 0.421875
iteration 696: loss 0.546 0.281250 0.492188
iteration 697: loss 0.463 0.304688 0.468750
iteration 698: loss 0.551 0.281250 0.437500
iteration 699: loss 0.482 0.335938 0.453125
iteration 700: loss 0.544 0.351562 0.398438
iteration 701: loss 0.561 0.351562 0.375000
iteration 702: loss 0.585 0.335938 0.382812
iteration 703: loss 0.537 0.304688 0.421875
iteration 704: loss 0.435 0.304688 0.460938
iteration 705: loss 0.429 0.273438 0.476562
iteration 706: loss 0.559 0.335938 0.398438
iteration 707: loss 0.580 0.250000 0.492188
iteration 708: loss 0.570 0.296875 0.398438
iteration 709: loss 0.514 0.226562 0.453125
iteration 710: loss 0.551 0.257812 0.421875
iteration 711: loss 0.583 0.304688 0.460938
iteration 712: loss 0.443 0.367188 0.546875
iteration 713: loss 0.474 0.296875 0.437500
iteration 714: loss 0.556 0.359375 0.398438
iteration 715: loss 0.473 0.335938 0.492188
iteration 716: loss 0.435 0.296875 0.515625
iteration 717: loss 0.506 0.343750 0.484375
iteration 718: loss 0.523 0.351562 0.414062
iteration 719: loss 0.396 0.250000 0.585938
iteration 720: loss 0.547 0.296875 0.484375
iteration 721: loss 0.553 0.257812 0.406250
iteration 722: loss 0.594 0.250000 0.382812
iteration 723: loss 0.508 0.226562 0.515625
iteration 724: loss 0.530 0.328125 0.484375
iteration 725: loss 0.524 0.289062 0.468750
iteration 726: loss 0.520 0.320312 0.515625
iteration 727: loss 0.607 0.265625 0.476562
iteration 728: loss 0.612 0.382812 0.460938
iteration 729: loss 0.474 0.304688 0.484375
iteration 730: loss 0.529 0.359375 0.484375
iteration 731: loss 0.461 0.304688 0.460938
iteration 732: loss 0.495 0.320312 0.421875
iteration 733: loss 0.573 0.312500 0.476562
iteration 734: loss 0.451 0.312500 0.492188
iteration 735: loss 0.472 0.242188 0.507812
iteration 736: loss 0.559 0.367188 0.460938
iteration 737: loss 0.538 0.296875 0.468750
iteration 738: loss 0.518 0.257812 0.421875
iteration 739: loss 0.543 0.289062 0.492188
iteration 740: loss 0.391 0.375000 0.531250
iteration 741: loss 0.660 0.359375 0.445312
iteration 742: loss 0.468 0.328125 0.460938
iteration 743: loss 0.518 0.320312 0.460938
iteration 744: loss 0.548 0.328125 0.445312
iteration 745: loss 0.458 0.296875 0.539062
iteration 746: loss 0.598 0.257812 0.429688
iteration 747: loss 0.524 0.320312 0.429688
iteration 748: loss 0.395 0.273438 0.492188
iteration 749: loss 0.545 0.265625 0.390625
iteration 750: loss 0.619 0.257812 0.453125
iteration 751: loss 0.543 0.296875 0.492188
iteration 752: loss 0.520 0.242188 0.453125
iteration 753: loss 0.560 0.328125 0.437500
iteration 754: loss 0.473 0.351562 0.507812
iteration 755: loss 0.515 0.382812 0.546875
iteration 756: loss 0.486 0.320312 0.507812
iteration 757: loss 0.440 0.281250 0.500000
iteration 758: loss 0.422 0.335938 0.484375
iteration 759: loss 0.634 0.289062 0.421875
iteration 760: loss 0.417 0.289062 0.539062
iteration 761: loss 0.581 0.367188 0.445312
iteration 762: loss 0.612 0.296875 0.406250
iteration 763: loss 0.457 0.289062 0.476562
iteration 764: loss 0.522 0.289062 0.484375
iteration 765: loss 0.448 0.265625 0.484375
iteration 766: loss 0.478 0.312500 0.500000
iteration 767: loss 0.489 0.304688 0.500000
iteration 768: loss 0.505 0.296875 0.515625
iteration 769: loss 0.443 0.296875 0.578125
iteration 770: loss 0.538 0.296875 0.492188
iteration 771: loss 0.426 0.367188 0.500000
iteration 772: loss 0.441 0.218750 0.500000
iteration 773: loss 0.563 0.328125 0.492188
iteration 774: loss 0.452 0.375000 0.492188
iteration 775: loss 0.548 0.250000 0.500000
iteration 776: loss 0.552 0.273438 0.500000
iteration 777: loss 0.484 0.273438 0.492188
iteration 778: loss 0.455 0.296875 0.437500
iteration 779: loss 0.446 0.335938 0.421875
iteration 780: loss 0.419 0.320312 0.570312
iteration 781: loss 0.552 0.328125 0.507812
iteration 782: loss 0.475 0.343750 0.484375
iteration 783: loss 0.570 0.312500 0.414062
iteration 784: loss 0.526 0.265625 0.468750
iteration 785: loss 0.570 0.296875 0.445312
iteration 786: loss 0.552 0.281250 0.476562
iteration 787: loss 0.520 0.296875 0.492188
iteration 788: loss 0.479 0.281250 0.500000
iteration 789: loss 0.569 0.359375 0.468750
iteration 790: loss 0.488 0.289062 0.562500
iteration 791: loss 0.467 0.289062 0.507812
iteration 792: loss 0.563 0.304688 0.476562
iteration 793: loss 0.493 0.320312 0.421875
iteration 794: loss 0.446 0.312500 0.515625
iteration 795: loss 0.508 0.312500 0.523438
iteration 796: loss 0.670 0.328125 0.445312
iteration 797: loss 0.544 0.320312 0.515625
iteration 798: loss 0.551 0.273438 0.421875
iteration 799: loss 0.539 0.218750 0.421875
iteration 800: loss 0.598 0.289062 0.476562
iteration 801: loss 0.521 0.304688 0.445312
iteration 802: loss 0.406 0.359375 0.546875
iteration 803: loss 0.393 0.312500 0.500000
iteration 804: loss 0.580 0.296875 0.445312
iteration 805: loss 0.499 0.289062 0.515625
iteration 806: loss 0.451 0.328125 0.507812
iteration 807: loss 0.416 0.343750 0.546875
iteration 808: loss 0.473 0.257812 0.445312
iteration 809: loss 0.541 0.250000 0.492188
iteration 810: loss 0.519 0.312500 0.500000
iteration 811: loss 0.589 0.335938 0.375000
iteration 812: loss 0.519 0.312500 0.460938
iteration 813: loss 0.463 0.281250 0.546875
iteration 814: loss 0.477 0.242188 0.468750
iteration 815: loss 0.493 0.390625 0.476562
iteration 816: loss 0.521 0.328125 0.476562
iteration 817: loss 0.576 0.328125 0.484375
iteration 818: loss 0.515 0.289062 0.484375
iteration 819: loss 0.448 0.250000 0.523438
iteration 820: loss 0.579 0.296875 0.445312
iteration 821: loss 0.500 0.281250 0.453125
iteration 822: loss 0.527 0.289062 0.398438
iteration 823: loss 0.542 0.312500 0.484375
iteration 824: loss 0.591 0.289062 0.468750
iteration 825: loss 0.502 0.320312 0.515625
iteration 826: loss 0.429 0.304688 0.570312
iteration 827: loss 0.566 0.234375 0.507812
iteration 828: loss 0.575 0.273438 0.460938
iteration 829: loss 0.594 0.289062 0.500000
iteration 830: loss 0.406 0.328125 0.390625
iteration 831: loss 0.549 0.304688 0.390625
iteration 832: loss 0.528 0.281250 0.500000
iteration 833: loss 0.485 0.343750 0.492188
iteration 834: loss 0.537 0.398438 0.406250
iteration 835: loss 0.575 0.289062 0.429688
iteration 836: loss 0.481 0.320312 0.460938
iteration 837: loss 0.511 0.257812 0.476562
iteration 838: loss 0.507 0.296875 0.468750
iteration 839: loss 0.545 0.296875 0.445312
iteration 840: loss 0.492 0.343750 0.429688
iteration 841: loss 0.447 0.296875 0.507812
iteration 842: loss 0.507 0.312500 0.468750
iteration 843: loss 0.469 0.312500 0.492188
iteration 844: loss 0.485 0.375000 0.375000
iteration 845: loss 0.552 0.273438 0.476562
iteration 846: loss 0.561 0.335938 0.398438
iteration 847: loss 0.468 0.296875 0.500000
iteration 848: loss 0.439 0.226562 0.500000
iteration 849: loss 0.661 0.265625 0.414062
iteration 850: loss 0.422 0.289062 0.460938
iteration 851: loss 0.643 0.320312 0.468750
iteration 852: loss 0.650 0.320312 0.382812
iteration 853: loss 0.536 0.281250 0.460938
iteration 854: loss 0.510 0.351562 0.421875
iteration 855: loss 0.485 0.273438 0.484375
iteration 856: loss 0.519 0.296875 0.468750
iteration 857: loss 0.434 0.234375 0.468750
iteration 858: loss 0.550 0.304688 0.421875
iteration 859: loss 0.536 0.312500 0.460938
iteration 860: loss 0.566 0.421875 0.492188
iteration 861: loss 0.606 0.343750 0.445312
iteration 862: loss 0.520 0.304688 0.484375
iteration 863: loss 0.518 0.312500 0.476562
iteration 864: loss 0.556 0.343750 0.460938
iteration 865: loss 0.644 0.335938 0.453125
iteration 866: loss 0.597 0.250000 0.429688
iteration 867: loss 0.540 0.242188 0.500000
iteration 868: loss 0.742 0.281250 0.445312
iteration 869: loss 0.545 0.312500 0.445312
iteration 870: loss 0.520 0.312500 0.445312
iteration 871: loss 0.585 0.304688 0.398438
iteration 872: loss 0.514 0.296875 0.367188
iteration 873: loss 0.444 0.328125 0.460938
iteration 874: loss 0.473 0.390625 0.460938
iteration 875: loss 0.701 0.281250 0.445312
iteration 876: loss 0.594 0.250000 0.507812
iteration 877: loss 0.528 0.304688 0.468750
iteration 878: loss 0.663 0.273438 0.382812
iteration 879: loss 0.570 0.242188 0.421875
iteration 880: loss 0.470 0.320312 0.445312
iteration 881: loss 0.546 0.304688 0.460938
iteration 882: loss 0.513 0.296875 0.468750
iteration 883: loss 0.573 0.289062 0.476562
iteration 884: loss 0.527 0.296875 0.484375
iteration 885: loss 0.596 0.250000 0.406250
iteration 886: loss 0.708 0.296875 0.375000
iteration 887: loss 0.547 0.257812 0.562500
iteration 888: loss 0.597 0.312500 0.421875
iteration 889: loss 0.469 0.359375 0.570312
iteration 890: loss 0.491 0.281250 0.507812
iteration 891: loss 0.573 0.367188 0.539062
iteration 892: loss 0.525 0.257812 0.460938
iteration 893: loss 0.557 0.304688 0.437500
iteration 894: loss 0.489 0.242188 0.484375
iteration 895: loss 0.553 0.289062 0.437500
iteration 896: loss 0.573 0.226562 0.437500
iteration 897: loss 0.483 0.375000 0.429688
iteration 898: loss 0.475 0.320312 0.554688
iteration 899: loss 0.486 0.328125 0.460938
iteration 900: loss 0.555 0.351562 0.453125
iteration 901: loss 0.487 0.312500 0.453125
iteration 902: loss 0.598 0.304688 0.406250
iteration 903: loss 0.440 0.375000 0.445312
iteration 904: loss 0.562 0.273438 0.421875
iteration 905: loss 0.542 0.328125 0.476562
iteration 906: loss 0.455 0.343750 0.437500
iteration 907: loss 0.534 0.328125 0.500000
iteration 908: loss 0.581 0.296875 0.453125
iteration 909: loss 0.404 0.273438 0.523438
iteration 910: loss 0.523 0.226562 0.484375
iteration 911: loss 0.499 0.328125 0.484375
iteration 912: loss 0.576 0.273438 0.398438
iteration 913: loss 0.529 0.273438 0.453125
iteration 914: loss 0.557 0.382812 0.414062
iteration 915: loss 0.530 0.281250 0.429688
iteration 916: loss 0.589 0.328125 0.414062
iteration 917: loss 0.487 0.343750 0.484375
iteration 918: loss 0.595 0.281250 0.476562
iteration 919: loss 0.535 0.273438 0.453125
iteration 920: loss 0.825 0.367188 0.328125
iteration 921: loss 0.436 0.281250 0.554688
iteration 922: loss 0.522 0.304688 0.531250
iteration 923: loss 0.618 0.320312 0.382812
iteration 924: loss 0.440 0.304688 0.460938
iteration 925: loss 0.554 0.328125 0.468750
iteration 926: loss 0.512 0.296875 0.539062
iteration 927: loss 0.618 0.304688 0.421875
iteration 928: loss 0.578 0.312500 0.460938
iteration 929: loss 0.572 0.328125 0.445312
iteration 930: loss 0.531 0.351562 0.398438
iteration 931: loss 0.596 0.312500 0.375000
iteration 932: loss 0.536 0.296875 0.500000
iteration 933: loss 0.440 0.343750 0.492188
iteration 934: loss 0.453 0.304688 0.554688
iteration 935: loss 0.572 0.328125 0.546875
iteration 936: loss 0.549 0.343750 0.460938
iteration 937: loss 0.587 0.304688 0.445312
iteration 938: loss 0.608 0.257812 0.437500
iteration 939: loss 0.573 0.312500 0.445312
iteration 940: loss 0.626 0.265625 0.382812
iteration 941: loss 0.500 0.289062 0.437500
iteration 942: loss 0.526 0.289062 0.460938
iteration 943: loss 0.470 0.359375 0.554688
iteration 944: loss 0.502 0.257812 0.500000
iteration 945: loss 0.573 0.296875 0.523438
iteration 946: loss 0.640 0.265625 0.460938
iteration 947: loss 0.523 0.304688 0.476562
iteration 948: loss 0.445 0.281250 0.515625
iteration 949: loss 0.393 0.320312 0.554688
iteration 950: loss 0.484 0.296875 0.492188
iteration 951: loss 0.518 0.335938 0.546875
iteration 952: loss 0.418 0.335938 0.484375
iteration 953: loss 0.363 0.320312 0.539062
iteration 954: loss 0.685 0.226562 0.390625
iteration 955: loss 0.611 0.304688 0.492188
iteration 956: loss 0.550 0.304688 0.453125
iteration 957: loss 0.494 0.382812 0.414062
iteration 958: loss 0.571 0.281250 0.406250
iteration 959: loss 0.501 0.281250 0.468750
iteration 960: loss 0.615 0.312500 0.484375
iteration 961: loss 0.651 0.242188 0.468750
iteration 962: loss 0.608 0.312500 0.429688
iteration 963: loss 0.483 0.351562 0.492188
iteration 964: loss 0.647 0.328125 0.460938
iteration 965: loss 0.600 0.242188 0.453125
iteration 966: loss 0.585 0.273438 0.406250
iteration 967: loss 0.428 0.203125 0.500000
iteration 968: loss 0.554 0.328125 0.453125
iteration 969: loss 0.627 0.343750 0.460938
iteration 970: loss 0.623 0.265625 0.476562
iteration 971: loss 0.529 0.281250 0.500000
iteration 972: loss 0.477 0.289062 0.468750
iteration 973: loss 0.600 0.234375 0.492188
iteration 974: loss 0.464 0.281250 0.492188
iteration 975: loss 0.485 0.328125 0.500000
iteration 976: loss 0.540 0.242188 0.539062
iteration 977: loss 0.520 0.312500 0.476562
iteration 978: loss 0.476 0.335938 0.523438
iteration 979: loss 0.522 0.289062 0.445312
iteration 980: loss 0.541 0.312500 0.445312
iteration 981: loss 0.473 0.328125 0.437500
iteration 982: loss 0.440 0.281250 0.476562
iteration 983: loss 0.527 0.234375 0.406250
iteration 984: loss 0.592 0.289062 0.468750
iteration 985: loss 0.510 0.234375 0.515625
iteration 986: loss 0.361 0.226562 0.539062
iteration 987: loss 0.585 0.304688 0.492188
iteration 988: loss 0.465 0.320312 0.531250
iteration 989: loss 0.534 0.328125 0.507812
iteration 990: loss 0.479 0.390625 0.460938
iteration 991: loss 0.495 0.335938 0.468750
iteration 992: loss 0.505 0.296875 0.484375
iteration 993: loss 0.447 0.257812 0.492188
iteration 994: loss 0.480 0.304688 0.468750
iteration 995: loss 0.439 0.328125 0.531250
iteration 996: loss 0.494 0.312500 0.507812
iteration 997: loss 0.450 0.265625 0.531250
iteration 998: loss 0.632 0.320312 0.390625
iteration 999: loss 0.620 0.320312 0.421875
epoch 15: training: 0.234375 validation: 0.203125
iteration 0: loss 0.481 0.312500 0.484375
iteration 1: loss 0.572 0.312500 0.398438
iteration 2: loss 0.671 0.265625 0.437500
iteration 3: loss 0.505 0.328125 0.476562
iteration 4: loss 0.500 0.296875 0.445312
iteration 5: loss 0.379 0.304688 0.585938
iteration 6: loss 0.556 0.296875 0.460938
iteration 7: loss 0.524 0.312500 0.476562
iteration 8: loss 0.488 0.312500 0.500000
iteration 9: loss 0.627 0.382812 0.429688
iteration 10: loss 0.768 0.335938 0.328125
iteration 11: loss 0.492 0.281250 0.515625
iteration 12: loss 0.588 0.250000 0.445312
iteration 13: loss 0.520 0.312500 0.507812
iteration 14: loss 0.587 0.351562 0.382812
iteration 15: loss 0.576 0.304688 0.421875
iteration 16: loss 0.473 0.265625 0.484375
iteration 17: loss 0.582 0.234375 0.421875
iteration 18: loss 0.565 0.312500 0.421875
iteration 19: loss 0.640 0.320312 0.492188
iteration 20: loss 0.544 0.273438 0.500000
iteration 21: loss 0.503 0.281250 0.468750
iteration 22: loss 0.443 0.296875 0.531250
iteration 23: loss 0.510 0.250000 0.453125
iteration 24: loss 0.452 0.289062 0.507812
iteration 25: loss 0.555 0.320312 0.437500
iteration 26: loss 0.580 0.304688 0.367188
iteration 27: loss 0.457 0.312500 0.531250
iteration 28: loss 0.415 0.343750 0.515625
iteration 29: loss 0.604 0.281250 0.468750
iteration 30: loss 0.469 0.281250 0.515625
iteration 31: loss 0.692 0.289062 0.398438
iteration 32: loss 0.556 0.343750 0.515625
iteration 33: loss 0.483 0.304688 0.468750
iteration 34: loss 0.478 0.265625 0.515625
iteration 35: loss 0.505 0.273438 0.539062
iteration 36: loss 0.630 0.273438 0.414062
iteration 37: loss 0.652 0.273438 0.421875
iteration 38: loss 0.484 0.398438 0.539062
iteration 39: loss 0.467 0.250000 0.484375
iteration 40: loss 0.524 0.312500 0.445312
iteration 41: loss 0.478 0.351562 0.492188
iteration 42: loss 0.623 0.335938 0.375000
iteration 43: loss 0.526 0.296875 0.515625
iteration 44: loss 0.534 0.328125 0.468750
iteration 45: loss 0.571 0.273438 0.445312
iteration 46: loss 0.460 0.320312 0.531250
iteration 47: loss 0.608 0.265625 0.445312
iteration 48: loss 0.480 0.187500 0.453125
iteration 49: loss 0.431 0.289062 0.523438
iteration 50: loss 0.557 0.406250 0.429688
iteration 51: loss 0.569 0.320312 0.476562
iteration 52: loss 0.431 0.289062 0.492188
iteration 53: loss 0.570 0.343750 0.492188
iteration 54: loss 0.510 0.406250 0.460938
iteration 55: loss 0.500 0.312500 0.476562
iteration 56: loss 0.377 0.265625 0.531250
iteration 57: loss 0.441 0.281250 0.492188
iteration 58: loss 0.563 0.312500 0.492188
iteration 59: loss 0.454 0.375000 0.500000
iteration 60: loss 0.482 0.289062 0.460938
iteration 61: loss 0.537 0.359375 0.453125
iteration 62: loss 0.502 0.242188 0.554688
iteration 63: loss 0.557 0.296875 0.492188
iteration 64: loss 0.458 0.281250 0.453125
iteration 65: loss 0.548 0.281250 0.484375
iteration 66: loss 0.439 0.312500 0.468750
iteration 67: loss 0.475 0.335938 0.476562
iteration 68: loss 0.472 0.234375 0.460938
iteration 69: loss 0.492 0.343750 0.476562
iteration 70: loss 0.658 0.273438 0.429688
iteration 71: loss 0.426 0.304688 0.492188
iteration 72: loss 0.492 0.320312 0.468750
iteration 73: loss 0.368 0.328125 0.593750
iteration 74: loss 0.572 0.312500 0.429688
iteration 75: loss 0.507 0.328125 0.460938
iteration 76: loss 0.628 0.406250 0.421875
iteration 77: loss 0.475 0.289062 0.484375
iteration 78: loss 0.461 0.304688 0.515625
iteration 79: loss 0.514 0.296875 0.414062
iteration 80: loss 0.626 0.343750 0.335938
iteration 81: loss 0.575 0.304688 0.476562
iteration 82: loss 0.593 0.312500 0.429688
iteration 83: loss 0.513 0.265625 0.460938
iteration 84: loss 0.503 0.296875 0.468750
iteration 85: loss 0.340 0.257812 0.539062
iteration 86: loss 0.609 0.257812 0.492188
iteration 87: loss 0.568 0.343750 0.515625
iteration 88: loss 0.536 0.296875 0.492188
iteration 89: loss 0.486 0.335938 0.515625
iteration 90: loss 0.660 0.367188 0.437500
iteration 91: loss 0.635 0.296875 0.460938
iteration 92: loss 0.610 0.289062 0.359375
iteration 93: loss 0.572 0.328125 0.492188
iteration 94: loss 0.583 0.320312 0.414062
iteration 95: loss 0.527 0.320312 0.414062
iteration 96: loss 0.513 0.320312 0.421875
iteration 97: loss 0.644 0.203125 0.351562
iteration 98: loss 0.615 0.296875 0.406250
iteration 99: loss 0.502 0.320312 0.507812
iteration 100: loss 0.554 0.351562 0.421875
iteration 101: loss 0.546 0.304688 0.445312
iteration 102: loss 0.523 0.351562 0.484375
iteration 103: loss 0.601 0.328125 0.460938
iteration 104: loss 0.437 0.250000 0.523438
iteration 105: loss 0.553 0.312500 0.484375
iteration 106: loss 0.555 0.257812 0.429688
iteration 107: loss 0.491 0.257812 0.429688
iteration 108: loss 0.627 0.320312 0.445312
iteration 109: loss 0.398 0.250000 0.523438
iteration 110: loss 0.598 0.273438 0.484375
iteration 111: loss 0.534 0.265625 0.546875
iteration 112: loss 0.533 0.257812 0.453125
iteration 113: loss 0.423 0.304688 0.539062
iteration 114: loss 0.503 0.273438 0.453125
iteration 115: loss 0.430 0.304688 0.523438
iteration 116: loss 0.571 0.296875 0.507812
iteration 117: loss 0.624 0.304688 0.492188
iteration 118: loss 0.519 0.312500 0.476562
iteration 119: loss 0.399 0.351562 0.531250
iteration 120: loss 0.387 0.195312 0.554688
iteration 121: loss 0.516 0.312500 0.398438
iteration 122: loss 0.480 0.304688 0.492188
iteration 123: loss 0.461 0.296875 0.460938
iteration 124: loss 0.574 0.320312 0.500000
iteration 125: loss 0.520 0.328125 0.507812
iteration 126: loss 0.635 0.273438 0.375000
iteration 127: loss 0.471 0.351562 0.484375
iteration 128: loss 0.597 0.328125 0.468750
iteration 129: loss 0.465 0.242188 0.531250
iteration 130: loss 0.643 0.265625 0.421875
iteration 131: loss 0.588 0.250000 0.390625
iteration 132: loss 0.470 0.304688 0.539062
iteration 133: loss 0.506 0.343750 0.500000
iteration 134: loss 0.520 0.312500 0.476562
iteration 135: loss 0.549 0.265625 0.515625
iteration 136: loss 0.564 0.281250 0.500000
iteration 137: loss 0.425 0.312500 0.523438
iteration 138: loss 0.498 0.296875 0.484375
iteration 139: loss 0.588 0.406250 0.406250
iteration 140: loss 0.507 0.281250 0.359375
iteration 141: loss 0.585 0.335938 0.453125
iteration 142: loss 0.683 0.312500 0.453125
iteration 143: loss 0.524 0.273438 0.453125
iteration 144: loss 0.590 0.226562 0.398438
iteration 145: loss 0.555 0.312500 0.343750
iteration 146: loss 0.620 0.312500 0.375000
iteration 147: loss 0.429 0.320312 0.484375
iteration 148: loss 0.451 0.343750 0.531250
iteration 149: loss 0.559 0.312500 0.515625
iteration 150: loss 0.402 0.328125 0.578125
iteration 151: loss 0.635 0.312500 0.367188
iteration 152: loss 0.539 0.304688 0.523438
iteration 153: loss 0.493 0.296875 0.460938
iteration 154: loss 0.513 0.281250 0.484375
iteration 155: loss 0.497 0.250000 0.453125
iteration 156: loss 0.559 0.289062 0.500000
iteration 157: loss 0.536 0.273438 0.484375
iteration 158: loss 0.583 0.328125 0.523438
iteration 159: loss 0.489 0.265625 0.515625
iteration 160: loss 0.606 0.273438 0.414062
iteration 161: loss 0.580 0.304688 0.421875
iteration 162: loss 0.551 0.250000 0.429688
iteration 163: loss 0.496 0.296875 0.523438
iteration 164: loss 0.559 0.328125 0.445312
iteration 165: loss 0.576 0.312500 0.421875
iteration 166: loss 0.510 0.289062 0.429688
iteration 167: loss 0.499 0.289062 0.453125
iteration 168: loss 0.528 0.335938 0.445312
iteration 169: loss 0.660 0.328125 0.453125
iteration 170: loss 0.541 0.328125 0.531250
iteration 171: loss 0.587 0.351562 0.562500
iteration 172: loss 0.644 0.312500 0.437500
iteration 173: loss 0.530 0.351562 0.437500
iteration 174: loss 0.581 0.312500 0.460938
iteration 175: loss 0.472 0.335938 0.546875
iteration 176: loss 0.601 0.320312 0.437500
iteration 177: loss 0.599 0.250000 0.390625
iteration 178: loss 0.484 0.320312 0.453125
iteration 179: loss 0.516 0.273438 0.398438
iteration 180: loss 0.629 0.328125 0.476562
iteration 181: loss 0.561 0.296875 0.484375
iteration 182: loss 0.519 0.296875 0.460938
iteration 183: loss 0.484 0.250000 0.460938
iteration 184: loss 0.610 0.289062 0.406250
iteration 185: loss 0.471 0.289062 0.445312
iteration 186: loss 0.521 0.320312 0.437500
iteration 187: loss 0.510 0.265625 0.492188
iteration 188: loss 0.594 0.359375 0.570312
iteration 189: loss 0.689 0.304688 0.406250
iteration 190: loss 0.573 0.367188 0.507812
iteration 191: loss 0.538 0.296875 0.492188
iteration 192: loss 0.647 0.289062 0.414062
iteration 193: loss 0.400 0.335938 0.539062
iteration 194: loss 0.629 0.304688 0.468750
iteration 195: loss 0.520 0.273438 0.554688
iteration 196: loss 0.503 0.265625 0.507812
iteration 197: loss 0.638 0.320312 0.468750
iteration 198: loss 0.413 0.250000 0.484375
iteration 199: loss 0.572 0.312500 0.429688
iteration 200: loss 0.564 0.390625 0.460938
iteration 201: loss 0.551 0.328125 0.507812
iteration 202: loss 0.613 0.273438 0.453125
iteration 203: loss 0.593 0.281250 0.421875
iteration 204: loss 0.520 0.281250 0.507812
iteration 205: loss 0.534 0.242188 0.367188
iteration 206: loss 0.594 0.328125 0.453125
iteration 207: loss 0.543 0.273438 0.492188
iteration 208: loss 0.540 0.343750 0.523438
iteration 209: loss 0.415 0.359375 0.546875
iteration 210: loss 0.520 0.281250 0.468750
iteration 211: loss 0.508 0.242188 0.492188
iteration 212: loss 0.663 0.304688 0.382812
iteration 213: loss 0.430 0.296875 0.468750
iteration 214: loss 0.541 0.304688 0.414062
iteration 215: loss 0.593 0.273438 0.468750
iteration 216: loss 0.548 0.257812 0.453125
iteration 217: loss 0.647 0.257812 0.382812
iteration 218: loss 0.529 0.320312 0.500000
iteration 219: loss 0.617 0.312500 0.421875
iteration 220: loss 0.464 0.351562 0.445312
iteration 221: loss 0.427 0.343750 0.562500
iteration 222: loss 0.570 0.281250 0.468750
iteration 223: loss 0.473 0.250000 0.507812
iteration 224: loss 0.510 0.304688 0.445312
iteration 225: loss 0.688 0.343750 0.398438
iteration 226: loss 0.568 0.312500 0.421875
iteration 227: loss 0.573 0.382812 0.476562
iteration 228: loss 0.527 0.296875 0.359375
iteration 229: loss 0.518 0.273438 0.414062
iteration 230: loss 0.416 0.296875 0.531250
iteration 231: loss 0.575 0.351562 0.507812
iteration 232: loss 0.488 0.281250 0.468750
iteration 233: loss 0.428 0.242188 0.578125
iteration 234: loss 0.511 0.250000 0.484375
iteration 235: loss 0.452 0.250000 0.546875
iteration 236: loss 0.438 0.351562 0.476562
iteration 237: loss 0.428 0.296875 0.593750
iteration 238: loss 0.537 0.234375 0.507812
iteration 239: loss 0.634 0.257812 0.437500
iteration 240: loss 0.557 0.250000 0.460938
iteration 241: loss 0.437 0.359375 0.453125
iteration 242: loss 0.546 0.289062 0.437500
iteration 243: loss 0.565 0.257812 0.429688
iteration 244: loss 0.542 0.304688 0.453125
iteration 245: loss 0.444 0.312500 0.570312
iteration 246: loss 0.391 0.335938 0.562500
iteration 247: loss 0.573 0.312500 0.476562
iteration 248: loss 0.563 0.203125 0.445312
iteration 249: loss 0.564 0.351562 0.421875
iteration 250: loss 0.513 0.351562 0.500000
iteration 251: loss 0.588 0.359375 0.460938
iteration 252: loss 0.582 0.257812 0.445312
iteration 253: loss 0.501 0.281250 0.460938
iteration 254: loss 0.585 0.257812 0.445312
iteration 255: loss 0.544 0.296875 0.453125
iteration 256: loss 0.615 0.312500 0.445312
iteration 257: loss 0.532 0.335938 0.500000
iteration 258: loss 0.581 0.296875 0.476562
iteration 259: loss 0.549 0.281250 0.460938
iteration 260: loss 0.634 0.210938 0.390625
iteration 261: loss 0.620 0.289062 0.343750
iteration 262: loss 0.472 0.304688 0.492188
iteration 263: loss 0.673 0.296875 0.421875
iteration 264: loss 0.530 0.328125 0.453125
iteration 265: loss 0.512 0.289062 0.453125
iteration 266: loss 0.471 0.312500 0.546875
iteration 267: loss 0.475 0.343750 0.500000
iteration 268: loss 0.487 0.320312 0.531250
iteration 269: loss 0.575 0.343750 0.523438
iteration 270: loss 0.513 0.421875 0.507812
iteration 271: loss 0.557 0.351562 0.445312
iteration 272: loss 0.451 0.320312 0.507812
iteration 273: loss 0.628 0.265625 0.421875
iteration 274: loss 0.687 0.367188 0.390625
iteration 275: loss 0.660 0.250000 0.343750
iteration 276: loss 0.467 0.296875 0.445312
iteration 277: loss 0.575 0.359375 0.390625
iteration 278: loss 0.558 0.226562 0.437500
iteration 279: loss 0.474 0.304688 0.484375
iteration 280: loss 0.479 0.390625 0.460938
iteration 281: loss 0.530 0.289062 0.531250
iteration 282: loss 0.533 0.296875 0.531250
iteration 283: loss 0.602 0.359375 0.476562
iteration 284: loss 0.600 0.367188 0.445312
iteration 285: loss 0.436 0.296875 0.546875
iteration 286: loss 0.503 0.281250 0.531250
iteration 287: loss 0.541 0.312500 0.500000
iteration 288: loss 0.610 0.312500 0.453125
iteration 289: loss 0.654 0.296875 0.476562
iteration 290: loss 0.517 0.218750 0.460938
iteration 291: loss 0.511 0.335938 0.453125
iteration 292: loss 0.512 0.351562 0.421875
iteration 293: loss 0.545 0.359375 0.500000
iteration 294: loss 0.601 0.281250 0.468750
iteration 295: loss 0.443 0.257812 0.460938
iteration 296: loss 0.538 0.304688 0.460938
iteration 297: loss 0.388 0.320312 0.484375
iteration 298: loss 0.627 0.257812 0.429688
iteration 299: loss 0.621 0.351562 0.421875
iteration 300: loss 0.491 0.312500 0.484375
iteration 301: loss 0.514 0.273438 0.390625
iteration 302: loss 0.544 0.304688 0.445312
iteration 303: loss 0.712 0.289062 0.429688
iteration 304: loss 0.568 0.289062 0.437500
iteration 305: loss 0.526 0.312500 0.437500
iteration 306: loss 0.524 0.304688 0.476562
iteration 307: loss 0.353 0.242188 0.601562
iteration 308: loss 0.524 0.375000 0.476562
iteration 309: loss 0.629 0.320312 0.460938
iteration 310: loss 0.672 0.273438 0.484375
iteration 311: loss 0.454 0.265625 0.523438
iteration 312: loss 0.525 0.203125 0.500000
iteration 313: loss 0.530 0.218750 0.453125
iteration 314: loss 0.453 0.343750 0.562500
iteration 315: loss 0.578 0.289062 0.406250
iteration 316: loss 0.476 0.304688 0.515625
iteration 317: loss 0.557 0.359375 0.476562
iteration 318: loss 0.563 0.234375 0.421875
iteration 319: loss 0.505 0.242188 0.476562
iteration 320: loss 0.502 0.273438 0.539062
iteration 321: loss 0.495 0.351562 0.570312
iteration 322: loss 0.589 0.281250 0.476562
iteration 323: loss 0.543 0.265625 0.445312
iteration 324: loss 0.638 0.343750 0.414062
iteration 325: loss 0.446 0.281250 0.468750
iteration 326: loss 0.573 0.234375 0.468750
iteration 327: loss 0.548 0.312500 0.414062
iteration 328: loss 0.479 0.289062 0.523438
iteration 329: loss 0.517 0.296875 0.484375
iteration 330: loss 0.620 0.242188 0.421875
iteration 331: loss 0.519 0.289062 0.468750
iteration 332: loss 0.564 0.273438 0.476562
iteration 333: loss 0.616 0.328125 0.468750
iteration 334: loss 0.590 0.265625 0.445312
iteration 335: loss 0.541 0.335938 0.445312
iteration 336: loss 0.450 0.296875 0.445312
iteration 337: loss 0.492 0.359375 0.523438
iteration 338: loss 0.469 0.304688 0.507812
iteration 339: loss 0.482 0.273438 0.406250
iteration 340: loss 0.570 0.281250 0.507812
iteration 341: loss 0.382 0.335938 0.484375
iteration 342: loss 0.554 0.304688 0.468750
iteration 343: loss 0.444 0.343750 0.476562
iteration 344: loss 0.443 0.289062 0.515625
iteration 345: loss 0.551 0.250000 0.359375
iteration 346: loss 0.519 0.281250 0.500000
iteration 347: loss 0.575 0.304688 0.484375
iteration 348: loss 0.583 0.289062 0.460938
iteration 349: loss 0.560 0.304688 0.507812
iteration 350: loss 0.595 0.335938 0.429688
iteration 351: loss 0.529 0.328125 0.429688
iteration 352: loss 0.542 0.203125 0.476562
iteration 353: loss 0.513 0.335938 0.515625
iteration 354: loss 0.477 0.335938 0.507812
iteration 355: loss 0.589 0.359375 0.445312
iteration 356: loss 0.484 0.304688 0.570312
iteration 357: loss 0.373 0.320312 0.578125
iteration 358: loss 0.553 0.367188 0.484375
iteration 359: loss 0.573 0.242188 0.421875
iteration 360: loss 0.661 0.359375 0.398438
iteration 361: loss 0.729 0.328125 0.398438
iteration 362: loss 0.537 0.328125 0.507812
iteration 363: loss 0.738 0.265625 0.421875
iteration 364: loss 0.636 0.296875 0.445312
iteration 365: loss 0.501 0.390625 0.476562
iteration 366: loss 0.514 0.382812 0.460938
iteration 367: loss 0.601 0.281250 0.382812
iteration 368: loss 0.614 0.320312 0.390625
iteration 369: loss 0.501 0.281250 0.546875
iteration 370: loss 0.464 0.296875 0.554688
iteration 371: loss 0.528 0.304688 0.500000
iteration 372: loss 0.524 0.281250 0.507812
iteration 373: loss 0.555 0.320312 0.351562
iteration 374: loss 0.620 0.343750 0.476562
iteration 375: loss 0.628 0.382812 0.429688
iteration 376: loss 0.498 0.296875 0.500000
iteration 377: loss 0.536 0.375000 0.453125
iteration 378: loss 0.565 0.289062 0.437500
iteration 379: loss 0.547 0.289062 0.484375
iteration 380: loss 0.439 0.328125 0.460938
iteration 381: loss 0.544 0.304688 0.468750
iteration 382: loss 0.575 0.242188 0.515625
iteration 383: loss 0.526 0.265625 0.500000
iteration 384: loss 0.600 0.296875 0.476562
iteration 385: loss 0.529 0.343750 0.398438
iteration 386: loss 0.617 0.289062 0.453125
iteration 387: loss 0.666 0.328125 0.453125
iteration 388: loss 0.505 0.265625 0.507812
iteration 389: loss 0.574 0.304688 0.484375
iteration 390: loss 0.488 0.328125 0.570312
iteration 391: loss 0.636 0.343750 0.375000
iteration 392: loss 0.618 0.320312 0.375000
iteration 393: loss 0.506 0.281250 0.484375
iteration 394: loss 0.481 0.273438 0.523438
iteration 395: loss 0.416 0.320312 0.554688
iteration 396: loss 0.545 0.328125 0.507812
iteration 397: loss 0.390 0.320312 0.554688
iteration 398: loss 0.768 0.312500 0.359375
iteration 399: loss 0.517 0.320312 0.500000
iteration 400: loss 0.436 0.328125 0.492188
iteration 401: loss 0.579 0.312500 0.437500
iteration 402: loss 0.546 0.335938 0.523438
iteration 403: loss 0.663 0.328125 0.484375
iteration 404: loss 0.458 0.320312 0.523438
iteration 405: loss 0.536 0.351562 0.453125
iteration 406: loss 0.517 0.296875 0.515625
iteration 407: loss 0.533 0.281250 0.460938
iteration 408: loss 0.540 0.304688 0.468750
iteration 409: loss 0.675 0.335938 0.414062
iteration 410: loss 0.521 0.414062 0.460938
iteration 411: loss 0.521 0.296875 0.500000
iteration 412: loss 0.495 0.265625 0.539062
iteration 413: loss 0.554 0.328125 0.507812
iteration 414: loss 0.549 0.273438 0.445312
iteration 415: loss 0.463 0.273438 0.484375
iteration 416: loss 0.668 0.304688 0.406250
iteration 417: loss 0.497 0.265625 0.484375
iteration 418: loss 0.654 0.328125 0.421875
iteration 419: loss 0.544 0.320312 0.468750
iteration 420: loss 0.591 0.343750 0.460938
iteration 421: loss 0.617 0.328125 0.437500
iteration 422: loss 0.466 0.328125 0.484375
iteration 423: loss 0.483 0.343750 0.515625
iteration 424: loss 0.600 0.289062 0.367188
iteration 425: loss 0.489 0.296875 0.484375
iteration 426: loss 0.564 0.335938 0.398438
iteration 427: loss 0.527 0.289062 0.484375
iteration 428: loss 0.502 0.273438 0.453125
iteration 429: loss 0.560 0.398438 0.453125
iteration 430: loss 0.527 0.257812 0.507812
iteration 431: loss 0.452 0.335938 0.500000
iteration 432: loss 0.513 0.226562 0.429688
iteration 433: loss 0.463 0.351562 0.421875
iteration 434: loss 0.571 0.257812 0.414062
iteration 435: loss 0.528 0.195312 0.429688
iteration 436: loss 0.592 0.289062 0.445312
iteration 437: loss 0.525 0.375000 0.437500
iteration 438: loss 0.385 0.335938 0.539062
iteration 439: loss 0.600 0.320312 0.437500
iteration 440: loss 0.478 0.289062 0.492188
iteration 441: loss 0.515 0.281250 0.507812
iteration 442: loss 0.447 0.257812 0.539062
iteration 443: loss 0.507 0.250000 0.453125
iteration 444: loss 0.513 0.273438 0.468750
iteration 445: loss 0.446 0.273438 0.468750
iteration 446: loss 0.447 0.359375 0.476562
iteration 447: loss 0.644 0.289062 0.398438
iteration 448: loss 0.476 0.250000 0.484375
iteration 449: loss 0.543 0.390625 0.414062
iteration 450: loss 0.481 0.281250 0.429688
iteration 451: loss 0.344 0.328125 0.562500
iteration 452: loss 0.546 0.382812 0.421875
iteration 453: loss 0.492 0.218750 0.484375
iteration 454: loss 0.526 0.343750 0.468750
iteration 455: loss 0.550 0.281250 0.460938
iteration 456: loss 0.513 0.281250 0.460938
iteration 457: loss 0.587 0.265625 0.468750
iteration 458: loss 0.589 0.289062 0.468750
iteration 459: loss 0.411 0.296875 0.476562
iteration 460: loss 0.559 0.250000 0.414062
iteration 461: loss 0.594 0.234375 0.460938
iteration 462: loss 0.415 0.226562 0.507812
iteration 463: loss 0.566 0.296875 0.492188
iteration 464: loss 0.468 0.328125 0.476562
iteration 465: loss 0.620 0.289062 0.445312
iteration 466: loss 0.445 0.281250 0.523438
iteration 467: loss 0.535 0.343750 0.460938
iteration 468: loss 0.448 0.312500 0.515625
iteration 469: loss 0.467 0.367188 0.492188
iteration 470: loss 0.541 0.367188 0.500000
iteration 471: loss 0.459 0.296875 0.453125
iteration 472: loss 0.563 0.359375 0.476562
iteration 473: loss 0.501 0.312500 0.453125
iteration 474: loss 0.405 0.296875 0.507812
iteration 475: loss 0.603 0.398438 0.375000
iteration 476: loss 0.517 0.312500 0.515625
iteration 477: loss 0.506 0.281250 0.460938
iteration 478: loss 0.462 0.218750 0.484375
iteration 479: loss 0.432 0.351562 0.492188
iteration 480: loss 0.630 0.320312 0.414062
iteration 481: loss 0.501 0.320312 0.460938
iteration 482: loss 0.560 0.257812 0.453125
iteration 483: loss 0.439 0.320312 0.484375
iteration 484: loss 0.515 0.328125 0.460938
iteration 485: loss 0.498 0.343750 0.445312
iteration 486: loss 0.411 0.343750 0.429688
iteration 487: loss 0.487 0.320312 0.453125
iteration 488: loss 0.523 0.226562 0.445312
iteration 489: loss 0.551 0.250000 0.507812
iteration 490: loss 0.568 0.281250 0.460938
iteration 491: loss 0.505 0.250000 0.468750
iteration 492: loss 0.490 0.312500 0.500000
iteration 493: loss 0.490 0.296875 0.507812
iteration 494: loss 0.454 0.281250 0.500000
iteration 495: loss 0.517 0.265625 0.437500
iteration 496: loss 0.460 0.265625 0.445312
iteration 497: loss 0.465 0.367188 0.445312
iteration 498: loss 0.567 0.289062 0.437500
iteration 499: loss 0.580 0.273438 0.406250
iteration 500: loss 0.558 0.242188 0.453125
iteration 501: loss 0.516 0.265625 0.546875
iteration 502: loss 0.411 0.328125 0.546875
iteration 503: loss 0.524 0.257812 0.406250
iteration 504: loss 0.568 0.335938 0.492188
iteration 505: loss 0.551 0.296875 0.523438
iteration 506: loss 0.467 0.351562 0.539062
iteration 507: loss 0.489 0.289062 0.484375
iteration 508: loss 0.468 0.242188 0.500000
iteration 509: loss 0.467 0.335938 0.523438
iteration 510: loss 0.387 0.296875 0.500000
iteration 511: loss 0.522 0.335938 0.460938
iteration 512: loss 0.551 0.281250 0.453125
iteration 513: loss 0.495 0.273438 0.468750
iteration 514: loss 0.538 0.289062 0.421875
iteration 515: loss 0.557 0.390625 0.437500
iteration 516: loss 0.474 0.335938 0.500000
iteration 517: loss 0.487 0.328125 0.453125
iteration 518: loss 0.502 0.335938 0.453125
iteration 519: loss 0.421 0.335938 0.484375
iteration 520: loss 0.470 0.289062 0.546875
iteration 521: loss 0.448 0.304688 0.492188
iteration 522: loss 0.428 0.242188 0.523438
iteration 523: loss 0.460 0.296875 0.460938
iteration 524: loss 0.545 0.343750 0.406250
iteration 525: loss 0.630 0.367188 0.414062
iteration 526: loss 0.554 0.257812 0.445312
iteration 527: loss 0.425 0.320312 0.484375
iteration 528: loss 0.699 0.257812 0.359375
iteration 529: loss 0.428 0.320312 0.523438
iteration 530: loss 0.505 0.343750 0.507812
iteration 531: loss 0.491 0.328125 0.500000
iteration 532: loss 0.622 0.281250 0.468750
iteration 533: loss 0.586 0.234375 0.429688
iteration 534: loss 0.584 0.312500 0.445312
iteration 535: loss 0.641 0.351562 0.421875
iteration 536: loss 0.545 0.320312 0.437500
iteration 537: loss 0.553 0.265625 0.476562
iteration 538: loss 0.537 0.320312 0.492188
iteration 539: loss 0.602 0.320312 0.460938
iteration 540: loss 0.424 0.281250 0.554688
iteration 541: loss 0.496 0.281250 0.484375
iteration 542: loss 0.557 0.304688 0.484375
iteration 543: loss 0.455 0.281250 0.515625
iteration 544: loss 0.545 0.335938 0.445312
iteration 545: loss 0.519 0.429688 0.460938
iteration 546: loss 0.527 0.328125 0.507812
iteration 547: loss 0.453 0.406250 0.468750
iteration 548: loss 0.552 0.304688 0.406250
iteration 549: loss 0.454 0.242188 0.492188
iteration 550: loss 0.550 0.320312 0.453125
iteration 551: loss 0.478 0.289062 0.476562
iteration 552: loss 0.492 0.265625 0.445312
iteration 553: loss 0.471 0.281250 0.507812
iteration 554: loss 0.557 0.234375 0.445312
iteration 555: loss 0.570 0.304688 0.437500
iteration 556: loss 0.442 0.265625 0.562500
iteration 557: loss 0.588 0.367188 0.429688
iteration 558: loss 0.655 0.273438 0.445312
iteration 559: loss 0.408 0.359375 0.531250
iteration 560: loss 0.573 0.281250 0.460938
iteration 561: loss 0.794 0.265625 0.335938
iteration 562: loss 0.565 0.281250 0.406250
iteration 563: loss 0.521 0.296875 0.476562
iteration 564: loss 0.673 0.328125 0.390625
iteration 565: loss 0.476 0.304688 0.476562
iteration 566: loss 0.459 0.335938 0.484375
iteration 567: loss 0.604 0.195312 0.484375
iteration 568: loss 0.458 0.367188 0.507812
iteration 569: loss 0.371 0.343750 0.570312
iteration 570: loss 0.431 0.257812 0.507812
iteration 571: loss 0.683 0.257812 0.390625
iteration 572: loss 0.553 0.242188 0.515625
iteration 573: loss 0.665 0.242188 0.375000
iteration 574: loss 0.552 0.281250 0.445312
iteration 575: loss 0.607 0.304688 0.406250
iteration 576: loss 0.476 0.312500 0.468750
iteration 577: loss 0.588 0.320312 0.398438
iteration 578: loss 0.524 0.250000 0.460938
iteration 579: loss 0.454 0.382812 0.539062
iteration 580: loss 0.478 0.273438 0.468750
iteration 581: loss 0.496 0.296875 0.484375
iteration 582: loss 0.611 0.257812 0.351562
iteration 583: loss 0.535 0.328125 0.492188
iteration 584: loss 0.532 0.273438 0.468750
iteration 585: loss 0.500 0.320312 0.484375
iteration 586: loss 0.564 0.289062 0.414062
iteration 587: loss 0.446 0.320312 0.484375
iteration 588: loss 0.465 0.328125 0.507812
iteration 589: loss 0.491 0.328125 0.500000
iteration 590: loss 0.484 0.320312 0.492188
iteration 591: loss 0.508 0.273438 0.445312
iteration 592: loss 0.466 0.250000 0.554688
iteration 593: loss 0.383 0.367188 0.523438
iteration 594: loss 0.520 0.335938 0.492188
iteration 595: loss 0.587 0.265625 0.375000
iteration 596: loss 0.423 0.304688 0.500000
iteration 597: loss 0.512 0.281250 0.421875
iteration 598: loss 0.495 0.257812 0.468750
iteration 599: loss 0.478 0.281250 0.507812
iteration 600: loss 0.514 0.226562 0.468750
iteration 601: loss 0.519 0.281250 0.406250
iteration 602: loss 0.390 0.335938 0.578125
iteration 603: loss 0.644 0.304688 0.437500
iteration 604: loss 0.505 0.304688 0.460938
iteration 605: loss 0.529 0.257812 0.476562
iteration 606: loss 0.586 0.312500 0.437500
iteration 607: loss 0.513 0.312500 0.492188
iteration 608: loss 0.472 0.304688 0.429688
iteration 609: loss 0.499 0.390625 0.460938
iteration 610: loss 0.615 0.296875 0.437500
iteration 611: loss 0.535 0.296875 0.445312
iteration 612: loss 0.511 0.273438 0.468750
iteration 613: loss 0.432 0.242188 0.523438
iteration 614: loss 0.537 0.320312 0.398438
iteration 615: loss 0.459 0.304688 0.484375
iteration 616: loss 0.469 0.304688 0.546875
iteration 617: loss 0.590 0.320312 0.351562
iteration 618: loss 0.537 0.304688 0.476562
iteration 619: loss 0.384 0.234375 0.523438
iteration 620: loss 0.510 0.335938 0.390625
iteration 621: loss 0.477 0.312500 0.437500
iteration 622: loss 0.535 0.312500 0.437500
iteration 623: loss 0.388 0.281250 0.539062
iteration 624: loss 0.464 0.281250 0.523438
iteration 625: loss 0.365 0.265625 0.546875
iteration 626: loss 0.457 0.273438 0.507812
iteration 627: loss 0.600 0.296875 0.437500
iteration 628: loss 0.489 0.257812 0.429688
iteration 629: loss 0.561 0.296875 0.468750
iteration 630: loss 0.475 0.335938 0.507812
iteration 631: loss 0.466 0.335938 0.453125
iteration 632: loss 0.550 0.250000 0.460938
iteration 633: loss 0.545 0.320312 0.484375
iteration 634: loss 0.545 0.351562 0.398438
iteration 635: loss 0.454 0.375000 0.453125
iteration 636: loss 0.417 0.265625 0.468750
iteration 637: loss 0.492 0.226562 0.500000
iteration 638: loss 0.433 0.273438 0.476562
iteration 639: loss 0.496 0.304688 0.445312
iteration 640: loss 0.518 0.250000 0.484375
iteration 641: loss 0.473 0.375000 0.476562
iteration 642: loss 0.484 0.320312 0.523438
iteration 643: loss 0.564 0.265625 0.515625
iteration 644: loss 0.576 0.343750 0.406250
iteration 645: loss 0.601 0.265625 0.453125
iteration 646: loss 0.454 0.335938 0.507812
iteration 647: loss 0.572 0.242188 0.429688
iteration 648: loss 0.481 0.250000 0.468750
iteration 649: loss 0.541 0.281250 0.460938
iteration 650: loss 0.601 0.296875 0.390625
iteration 651: loss 0.502 0.343750 0.437500
iteration 652: loss 0.429 0.296875 0.453125
iteration 653: loss 0.484 0.304688 0.500000
iteration 654: loss 0.492 0.296875 0.375000
iteration 655: loss 0.500 0.281250 0.421875
iteration 656: loss 0.475 0.281250 0.492188
iteration 657: loss 0.589 0.312500 0.500000
iteration 658: loss 0.505 0.312500 0.476562
iteration 659: loss 0.536 0.328125 0.476562
iteration 660: loss 0.513 0.296875 0.445312
iteration 661: loss 0.515 0.296875 0.453125
iteration 662: loss 0.494 0.343750 0.492188
iteration 663: loss 0.517 0.312500 0.429688
iteration 664: loss 0.399 0.289062 0.476562
iteration 665: loss 0.570 0.304688 0.468750
iteration 666: loss 0.480 0.281250 0.539062
iteration 667: loss 0.482 0.312500 0.484375
iteration 668: loss 0.530 0.367188 0.476562
iteration 669: loss 0.543 0.320312 0.453125
iteration 670: loss 0.508 0.296875 0.414062
iteration 671: loss 0.510 0.312500 0.500000
iteration 672: loss 0.515 0.257812 0.390625
iteration 673: loss 0.436 0.304688 0.453125
iteration 674: loss 0.440 0.335938 0.460938
iteration 675: loss 0.527 0.304688 0.476562
iteration 676: loss 0.590 0.335938 0.398438
iteration 677: loss 0.511 0.304688 0.515625
iteration 678: loss 0.491 0.328125 0.359375
iteration 679: loss 0.525 0.320312 0.437500
iteration 680: loss 0.492 0.304688 0.492188
iteration 681: loss 0.496 0.234375 0.500000
iteration 682: loss 0.436 0.359375 0.515625
iteration 683: loss 0.668 0.296875 0.437500
iteration 684: loss 0.505 0.296875 0.476562
iteration 685: loss 0.548 0.265625 0.429688
iteration 686: loss 0.641 0.328125 0.414062
iteration 687: loss 0.552 0.320312 0.390625
iteration 688: loss 0.615 0.273438 0.476562
iteration 689: loss 0.506 0.312500 0.375000
iteration 690: loss 0.532 0.335938 0.507812
iteration 691: loss 0.493 0.335938 0.460938
iteration 692: loss 0.427 0.281250 0.523438
iteration 693: loss 0.518 0.289062 0.437500
iteration 694: loss 0.516 0.250000 0.507812
iteration 695: loss 0.608 0.304688 0.460938
iteration 696: loss 0.594 0.265625 0.445312
iteration 697: loss 0.520 0.304688 0.476562
iteration 698: loss 0.547 0.351562 0.421875
iteration 699: loss 0.500 0.296875 0.421875
iteration 700: loss 0.426 0.335938 0.531250
iteration 701: loss 0.553 0.257812 0.492188
iteration 702: loss 0.472 0.296875 0.468750
iteration 703: loss 0.681 0.289062 0.500000
iteration 704: loss 0.603 0.265625 0.476562
iteration 705: loss 0.565 0.320312 0.515625
iteration 706: loss 0.502 0.335938 0.460938
iteration 707: loss 0.517 0.328125 0.468750
iteration 708: loss 0.613 0.210938 0.367188
iteration 709: loss 0.495 0.257812 0.445312
iteration 710: loss 0.566 0.234375 0.453125
iteration 711: loss 0.480 0.273438 0.500000
iteration 712: loss 0.525 0.343750 0.500000
iteration 713: loss 0.599 0.257812 0.406250
iteration 714: loss 0.554 0.328125 0.507812
iteration 715: loss 0.466 0.273438 0.546875
iteration 716: loss 0.470 0.281250 0.500000
iteration 717: loss 0.443 0.343750 0.507812
iteration 718: loss 0.531 0.289062 0.468750
iteration 719: loss 0.492 0.210938 0.476562
iteration 720: loss 0.532 0.289062 0.445312
iteration 721: loss 0.507 0.304688 0.460938
iteration 722: loss 0.524 0.421875 0.492188
iteration 723: loss 0.550 0.289062 0.460938
iteration 724: loss 0.627 0.359375 0.414062
iteration 725: loss 0.612 0.335938 0.445312
iteration 726: loss 0.467 0.320312 0.468750
iteration 727: loss 0.492 0.359375 0.484375
iteration 728: loss 0.432 0.250000 0.468750
iteration 729: loss 0.465 0.320312 0.539062
iteration 730: loss 0.524 0.257812 0.421875
iteration 731: loss 0.570 0.304688 0.468750
iteration 732: loss 0.491 0.273438 0.468750
iteration 733: loss 0.560 0.257812 0.414062
iteration 734: loss 0.457 0.265625 0.500000
iteration 735: loss 0.460 0.257812 0.468750
iteration 736: loss 0.604 0.273438 0.429688
iteration 737: loss 0.596 0.328125 0.453125
iteration 738: loss 0.392 0.250000 0.531250
iteration 739: loss 0.709 0.281250 0.367188
iteration 740: loss 0.562 0.320312 0.437500
iteration 741: loss 0.530 0.367188 0.460938
iteration 742: loss 0.622 0.304688 0.398438
iteration 743: loss 0.504 0.359375 0.500000
iteration 744: loss 0.451 0.257812 0.492188
iteration 745: loss 0.468 0.265625 0.476562
iteration 746: loss 0.573 0.328125 0.515625
iteration 747: loss 0.593 0.289062 0.453125
iteration 748: loss 0.435 0.250000 0.429688
iteration 749: loss 0.510 0.343750 0.484375
iteration 750: loss 0.545 0.304688 0.476562
iteration 751: loss 0.666 0.343750 0.500000
iteration 752: loss 0.550 0.390625 0.500000
iteration 753: loss 0.549 0.179688 0.421875
iteration 754: loss 0.476 0.257812 0.476562
iteration 755: loss 0.565 0.390625 0.445312
iteration 756: loss 0.560 0.273438 0.445312
iteration 757: loss 0.556 0.312500 0.390625
iteration 758: loss 0.429 0.257812 0.492188
iteration 759: loss 0.422 0.375000 0.500000
iteration 760: loss 0.535 0.289062 0.437500
iteration 761: loss 0.620 0.328125 0.406250
iteration 762: loss 0.523 0.304688 0.484375
iteration 763: loss 0.454 0.312500 0.515625
iteration 764: loss 0.458 0.320312 0.492188
iteration 765: loss 0.425 0.273438 0.523438
iteration 766: loss 0.543 0.257812 0.453125
iteration 767: loss 0.492 0.296875 0.476562
iteration 768: loss 0.458 0.257812 0.531250
iteration 769: loss 0.606 0.351562 0.523438
iteration 770: loss 0.590 0.390625 0.421875
iteration 771: loss 0.447 0.328125 0.500000
iteration 772: loss 0.498 0.289062 0.460938
iteration 773: loss 0.523 0.375000 0.429688
iteration 774: loss 0.495 0.250000 0.484375
iteration 775: loss 0.553 0.296875 0.500000
iteration 776: loss 0.435 0.289062 0.500000
iteration 777: loss 0.518 0.265625 0.453125
iteration 778: loss 0.509 0.226562 0.437500
iteration 779: loss 0.618 0.390625 0.406250
iteration 780: loss 0.512 0.320312 0.500000
iteration 781: loss 0.484 0.328125 0.453125
iteration 782: loss 0.553 0.242188 0.445312
iteration 783: loss 0.538 0.289062 0.437500
iteration 784: loss 0.534 0.289062 0.515625
iteration 785: loss 0.516 0.250000 0.437500
iteration 786: loss 0.506 0.312500 0.460938
iteration 787: loss 0.589 0.281250 0.453125
iteration 788: loss 0.539 0.218750 0.468750
iteration 789: loss 0.590 0.312500 0.445312
iteration 790: loss 0.559 0.273438 0.476562
iteration 791: loss 0.474 0.328125 0.523438
iteration 792: loss 0.458 0.226562 0.507812
iteration 793: loss 0.561 0.273438 0.421875
iteration 794: loss 0.383 0.320312 0.484375
iteration 795: loss 0.587 0.390625 0.429688
iteration 796: loss 0.489 0.281250 0.476562
iteration 797: loss 0.603 0.390625 0.445312
iteration 798: loss 0.508 0.226562 0.500000
iteration 799: loss 0.491 0.273438 0.453125
iteration 800: loss 0.500 0.343750 0.523438
iteration 801: loss 0.551 0.281250 0.468750
iteration 802: loss 0.512 0.335938 0.531250
iteration 803: loss 0.498 0.250000 0.476562
iteration 804: loss 0.516 0.281250 0.484375
iteration 805: loss 0.531 0.328125 0.515625
iteration 806: loss 0.567 0.265625 0.453125
iteration 807: loss 0.626 0.265625 0.406250
iteration 808: loss 0.526 0.320312 0.406250
iteration 809: loss 0.457 0.351562 0.429688
iteration 810: loss 0.454 0.250000 0.484375
iteration 811: loss 0.474 0.359375 0.453125
iteration 812: loss 0.616 0.359375 0.500000
iteration 813: loss 0.604 0.359375 0.476562
iteration 814: loss 0.473 0.242188 0.562500
iteration 815: loss 0.569 0.335938 0.398438
iteration 816: loss 0.456 0.351562 0.476562
iteration 817: loss 0.456 0.328125 0.585938
iteration 818: loss 0.518 0.390625 0.492188
iteration 819: loss 0.594 0.296875 0.453125
iteration 820: loss 0.542 0.390625 0.398438
iteration 821: loss 0.511 0.304688 0.460938
iteration 822: loss 0.523 0.312500 0.437500
iteration 823: loss 0.516 0.304688 0.460938
iteration 824: loss 0.476 0.312500 0.476562
iteration 825: loss 0.544 0.335938 0.421875
iteration 826: loss 0.581 0.281250 0.453125
iteration 827: loss 0.480 0.234375 0.531250
iteration 828: loss 0.576 0.320312 0.390625
iteration 829: loss 0.435 0.281250 0.578125
iteration 830: loss 0.556 0.257812 0.406250
iteration 831: loss 0.467 0.250000 0.507812
iteration 832: loss 0.499 0.367188 0.500000
iteration 833: loss 0.509 0.242188 0.445312
iteration 834: loss 0.412 0.320312 0.468750
iteration 835: loss 0.472 0.343750 0.523438
iteration 836: loss 0.519 0.351562 0.468750
iteration 837: loss 0.505 0.265625 0.453125
iteration 838: loss 0.404 0.351562 0.539062
iteration 839: loss 0.524 0.320312 0.453125
iteration 840: loss 0.566 0.296875 0.500000
iteration 841: loss 0.614 0.289062 0.406250
iteration 842: loss 0.662 0.320312 0.406250
iteration 843: loss 0.560 0.335938 0.429688
iteration 844: loss 0.599 0.351562 0.343750
iteration 845: loss 0.468 0.312500 0.476562
iteration 846: loss 0.550 0.304688 0.468750
iteration 847: loss 0.686 0.335938 0.468750
iteration 848: loss 0.528 0.289062 0.523438
iteration 849: loss 0.542 0.281250 0.453125
iteration 850: loss 0.618 0.257812 0.382812
iteration 851: loss 0.483 0.343750 0.484375
iteration 852: loss 0.501 0.328125 0.437500
iteration 853: loss 0.535 0.265625 0.429688
iteration 854: loss 0.478 0.257812 0.500000
iteration 855: loss 0.600 0.304688 0.507812
iteration 856: loss 0.471 0.289062 0.468750
iteration 857: loss 0.585 0.390625 0.421875
iteration 858: loss 0.556 0.281250 0.429688
iteration 859: loss 0.508 0.265625 0.492188
iteration 860: loss 0.498 0.343750 0.453125
iteration 861: loss 0.519 0.296875 0.476562
iteration 862: loss 0.365 0.367188 0.578125
iteration 863: loss 0.471 0.289062 0.531250
iteration 864: loss 0.587 0.328125 0.460938
iteration 865: loss 0.509 0.250000 0.492188
iteration 866: loss 0.505 0.335938 0.460938
iteration 867: loss 0.530 0.359375 0.445312
iteration 868: loss 0.460 0.273438 0.484375
iteration 869: loss 0.401 0.273438 0.562500
iteration 870: loss 0.628 0.265625 0.421875
iteration 871: loss 0.470 0.375000 0.507812
iteration 872: loss 0.493 0.210938 0.515625
iteration 873: loss 0.448 0.242188 0.515625
iteration 874: loss 0.424 0.296875 0.531250
iteration 875: loss 0.414 0.335938 0.523438
iteration 876: loss 0.537 0.296875 0.453125
iteration 877: loss 0.660 0.382812 0.429688
iteration 878: loss 0.483 0.242188 0.507812
iteration 879: loss 0.483 0.296875 0.531250
iteration 880: loss 0.662 0.281250 0.421875
iteration 881: loss 0.593 0.289062 0.500000
iteration 882: loss 0.497 0.296875 0.468750
iteration 883: loss 0.683 0.281250 0.367188
iteration 884: loss 0.527 0.281250 0.523438
iteration 885: loss 0.460 0.312500 0.398438
iteration 886: loss 0.531 0.296875 0.406250
iteration 887: loss 0.517 0.390625 0.453125
iteration 888: loss 0.459 0.296875 0.476562
iteration 889: loss 0.481 0.257812 0.523438
iteration 890: loss 0.526 0.296875 0.484375
iteration 891: loss 0.485 0.265625 0.492188
iteration 892: loss 0.601 0.328125 0.406250
iteration 893: loss 0.481 0.281250 0.546875
iteration 894: loss 0.553 0.265625 0.468750
iteration 895: loss 0.544 0.250000 0.437500
iteration 896: loss 0.513 0.273438 0.437500
iteration 897: loss 0.442 0.312500 0.515625
iteration 898: loss 0.427 0.242188 0.500000
iteration 899: loss 0.508 0.289062 0.515625
iteration 900: loss 0.519 0.343750 0.515625
iteration 901: loss 0.542 0.390625 0.476562
iteration 902: loss 0.448 0.343750 0.492188
iteration 903: loss 0.489 0.312500 0.523438
iteration 904: loss 0.530 0.281250 0.406250
iteration 905: loss 0.399 0.281250 0.476562
iteration 906: loss 0.576 0.351562 0.437500
iteration 907: loss 0.461 0.304688 0.484375
iteration 908: loss 0.548 0.265625 0.476562
iteration 909: loss 0.649 0.273438 0.390625
iteration 910: loss 0.583 0.296875 0.406250
iteration 911: loss 0.587 0.304688 0.414062
iteration 912: loss 0.529 0.296875 0.421875
iteration 913: loss 0.487 0.273438 0.460938
iteration 914: loss 0.517 0.250000 0.453125
iteration 915: loss 0.602 0.289062 0.531250
iteration 916: loss 0.460 0.320312 0.468750
iteration 917: loss 0.479 0.273438 0.515625
iteration 918: loss 0.377 0.273438 0.515625
iteration 919: loss 0.494 0.257812 0.460938
iteration 920: loss 0.468 0.218750 0.398438
iteration 921: loss 0.470 0.328125 0.460938
iteration 922: loss 0.446 0.289062 0.507812
iteration 923: loss 0.425 0.320312 0.515625
iteration 924: loss 0.454 0.312500 0.492188
iteration 925: loss 0.499 0.265625 0.492188
iteration 926: loss 0.547 0.250000 0.539062
iteration 927: loss 0.549 0.335938 0.468750
iteration 928: loss 0.517 0.312500 0.445312
iteration 929: loss 0.537 0.273438 0.484375
iteration 930: loss 0.496 0.289062 0.390625
iteration 931: loss 0.574 0.359375 0.460938
iteration 932: loss 0.614 0.289062 0.453125
iteration 933: loss 0.530 0.328125 0.500000
iteration 934: loss 0.570 0.304688 0.453125
iteration 935: loss 0.442 0.257812 0.468750
iteration 936: loss 0.529 0.312500 0.414062
iteration 937: loss 0.584 0.289062 0.460938
iteration 938: loss 0.545 0.257812 0.429688
iteration 939: loss 0.486 0.296875 0.460938
iteration 940: loss 0.659 0.296875 0.414062
iteration 941: loss 0.632 0.351562 0.414062
iteration 942: loss 0.516 0.351562 0.453125
iteration 943: loss 0.522 0.382812 0.437500
iteration 944: loss 0.482 0.265625 0.554688
iteration 945: loss 0.656 0.312500 0.437500
iteration 946: loss 0.476 0.273438 0.531250
iteration 947: loss 0.491 0.343750 0.523438
iteration 948: loss 0.451 0.281250 0.507812
iteration 949: loss 0.600 0.273438 0.460938
iteration 950: loss 0.524 0.304688 0.445312
iteration 951: loss 0.498 0.242188 0.445312
iteration 952: loss 0.551 0.257812 0.414062
iteration 953: loss 0.563 0.234375 0.437500
iteration 954: loss 0.649 0.328125 0.367188
iteration 955: loss 0.544 0.289062 0.492188
iteration 956: loss 0.402 0.203125 0.562500
iteration 957: loss 0.520 0.304688 0.484375
iteration 958: loss 0.536 0.257812 0.484375
iteration 959: loss 0.522 0.273438 0.468750
iteration 960: loss 0.468 0.335938 0.484375
iteration 961: loss 0.473 0.226562 0.460938
iteration 962: loss 0.475 0.257812 0.484375
iteration 963: loss 0.537 0.296875 0.476562
iteration 964: loss 0.496 0.351562 0.476562
iteration 965: loss 0.525 0.281250 0.492188
iteration 966: loss 0.666 0.375000 0.453125
iteration 967: loss 0.546 0.304688 0.468750
iteration 968: loss 0.517 0.296875 0.484375
iteration 969: loss 0.668 0.289062 0.468750
iteration 970: loss 0.632 0.320312 0.414062
iteration 971: loss 0.579 0.351562 0.453125
iteration 972: loss 0.606 0.312500 0.375000
iteration 973: loss 0.427 0.296875 0.460938
iteration 974: loss 0.608 0.296875 0.375000
iteration 975: loss 0.541 0.312500 0.460938
iteration 976: loss 0.567 0.335938 0.460938
iteration 977: loss 0.630 0.335938 0.460938
iteration 978: loss 0.528 0.320312 0.546875
iteration 979: loss 0.465 0.281250 0.515625
iteration 980: loss 0.518 0.289062 0.523438
iteration 981: loss 0.459 0.328125 0.492188
iteration 982: loss 0.579 0.281250 0.453125
iteration 983: loss 0.425 0.312500 0.554688
iteration 984: loss 0.391 0.320312 0.476562
iteration 985: loss 0.534 0.234375 0.406250
iteration 986: loss 0.528 0.281250 0.398438
iteration 987: loss 0.497 0.250000 0.414062
iteration 988: loss 0.484 0.242188 0.445312
iteration 989: loss 0.401 0.351562 0.578125
iteration 990: loss 0.359 0.296875 0.578125
iteration 991: loss 0.439 0.265625 0.562500
iteration 992: loss 0.517 0.320312 0.445312
iteration 993: loss 0.501 0.265625 0.460938
iteration 994: loss 0.567 0.296875 0.421875
iteration 995: loss 0.585 0.335938 0.437500
iteration 996: loss 0.487 0.257812 0.492188
iteration 997: loss 0.570 0.265625 0.382812
iteration 998: loss 0.570 0.265625 0.437500
iteration 999: loss 0.521 0.351562 0.406250
epoch 16: training: 0.257812 validation: 0.195312
iteration 0: loss 0.563 0.304688 0.468750
iteration 1: loss 0.505 0.335938 0.453125
iteration 2: loss 0.435 0.343750 0.476562
iteration 3: loss 0.377 0.421875 0.531250
iteration 4: loss 0.457 0.351562 0.476562
iteration 5: loss 0.489 0.273438 0.523438
iteration 6: loss 0.501 0.351562 0.453125
iteration 7: loss 0.714 0.234375 0.445312
iteration 8: loss 0.517 0.343750 0.539062
iteration 9: loss 0.708 0.289062 0.492188
iteration 10: loss 0.504 0.304688 0.484375
iteration 11: loss 0.499 0.335938 0.507812
iteration 12: loss 0.625 0.281250 0.437500
iteration 13: loss 0.603 0.234375 0.421875
iteration 14: loss 0.616 0.406250 0.460938
iteration 15: loss 0.635 0.281250 0.476562
iteration 16: loss 0.472 0.289062 0.531250
iteration 17: loss 0.709 0.328125 0.367188
iteration 18: loss 0.460 0.265625 0.445312
iteration 19: loss 0.538 0.320312 0.398438
iteration 20: loss 0.528 0.265625 0.429688
iteration 21: loss 0.521 0.312500 0.484375
iteration 22: loss 0.453 0.343750 0.515625
iteration 23: loss 0.599 0.289062 0.468750
iteration 24: loss 0.594 0.335938 0.492188
iteration 25: loss 0.572 0.343750 0.468750
iteration 26: loss 0.524 0.328125 0.460938
iteration 27: loss 0.526 0.367188 0.406250
iteration 28: loss 0.554 0.320312 0.531250
iteration 29: loss 0.405 0.296875 0.578125
iteration 30: loss 0.520 0.359375 0.507812
iteration 31: loss 0.583 0.265625 0.398438
iteration 32: loss 0.510 0.242188 0.492188
iteration 33: loss 0.511 0.250000 0.484375
iteration 34: loss 0.764 0.257812 0.445312
iteration 35: loss 0.464 0.335938 0.468750
iteration 36: loss 0.594 0.273438 0.414062
iteration 37: loss 0.553 0.281250 0.429688
iteration 38: loss 0.592 0.382812 0.453125
iteration 39: loss 0.438 0.265625 0.515625
iteration 40: loss 0.481 0.289062 0.515625
iteration 41: loss 0.747 0.187500 0.390625
iteration 42: loss 0.542 0.226562 0.484375
iteration 43: loss 0.489 0.250000 0.343750
iteration 44: loss 0.507 0.335938 0.437500
iteration 45: loss 0.539 0.375000 0.515625
iteration 46: loss 0.610 0.281250 0.507812
iteration 47: loss 0.627 0.335938 0.484375
iteration 48: loss 0.547 0.312500 0.437500
iteration 49: loss 0.571 0.226562 0.437500
iteration 50: loss 0.542 0.281250 0.476562
iteration 51: loss 0.425 0.265625 0.500000
iteration 52: loss 0.454 0.296875 0.437500
iteration 53: loss 0.451 0.375000 0.492188
iteration 54: loss 0.585 0.273438 0.406250
iteration 55: loss 0.437 0.289062 0.492188
iteration 56: loss 0.537 0.281250 0.460938
iteration 57: loss 0.540 0.281250 0.492188
iteration 58: loss 0.552 0.335938 0.445312
iteration 59: loss 0.493 0.218750 0.453125
iteration 60: loss 0.478 0.273438 0.507812
iteration 61: loss 0.538 0.250000 0.429688
iteration 62: loss 0.493 0.296875 0.507812
iteration 63: loss 0.526 0.242188 0.453125
iteration 64: loss 0.499 0.281250 0.460938
iteration 65: loss 0.483 0.289062 0.414062
iteration 66: loss 0.524 0.335938 0.484375
iteration 67: loss 0.596 0.312500 0.453125
iteration 68: loss 0.592 0.265625 0.484375
iteration 69: loss 0.514 0.273438 0.523438
iteration 70: loss 0.499 0.226562 0.476562
iteration 71: loss 0.621 0.328125 0.476562
iteration 72: loss 0.587 0.328125 0.429688
iteration 73: loss 0.630 0.320312 0.390625
iteration 74: loss 0.478 0.328125 0.562500
iteration 75: loss 0.624 0.304688 0.445312
iteration 76: loss 0.526 0.273438 0.460938
iteration 77: loss 0.494 0.273438 0.468750
iteration 78: loss 0.598 0.281250 0.437500
iteration 79: loss 0.420 0.296875 0.539062
iteration 80: loss 0.593 0.312500 0.468750
iteration 81: loss 0.582 0.343750 0.484375
iteration 82: loss 0.429 0.335938 0.539062
iteration 83: loss 0.605 0.265625 0.445312
iteration 84: loss 0.459 0.312500 0.468750
iteration 85: loss 0.432 0.265625 0.492188
iteration 86: loss 0.536 0.335938 0.492188
iteration 87: loss 0.435 0.375000 0.585938
iteration 88: loss 0.699 0.328125 0.492188
iteration 89: loss 0.640 0.359375 0.367188
iteration 90: loss 0.368 0.320312 0.562500
iteration 91: loss 0.413 0.359375 0.492188
iteration 92: loss 0.656 0.281250 0.359375
iteration 93: loss 0.549 0.320312 0.515625
iteration 94: loss 0.527 0.343750 0.500000
iteration 95: loss 0.387 0.320312 0.554688
iteration 96: loss 0.531 0.265625 0.414062
iteration 97: loss 0.547 0.250000 0.390625
iteration 98: loss 0.428 0.312500 0.453125
iteration 99: loss 0.479 0.281250 0.476562
iteration 100: loss 0.515 0.375000 0.484375
iteration 101: loss 0.451 0.359375 0.531250
iteration 102: loss 0.465 0.343750 0.492188
iteration 103: loss 0.447 0.265625 0.500000
iteration 104: loss 0.582 0.242188 0.453125
iteration 105: loss 0.522 0.281250 0.429688
iteration 106: loss 0.555 0.218750 0.406250
iteration 107: loss 0.518 0.320312 0.453125
iteration 108: loss 0.561 0.359375 0.390625
iteration 109: loss 0.482 0.281250 0.515625
iteration 110: loss 0.457 0.296875 0.500000
iteration 111: loss 0.521 0.335938 0.515625
iteration 112: loss 0.501 0.328125 0.476562
iteration 113: loss 0.582 0.273438 0.406250
iteration 114: loss 0.483 0.320312 0.476562
iteration 115: loss 0.423 0.296875 0.523438
iteration 116: loss 0.470 0.257812 0.484375
iteration 117: loss 0.589 0.328125 0.382812
iteration 118: loss 0.499 0.281250 0.539062
iteration 119: loss 0.631 0.304688 0.429688
iteration 120: loss 0.475 0.312500 0.539062
iteration 121: loss 0.644 0.273438 0.382812
iteration 122: loss 0.543 0.304688 0.414062
iteration 123: loss 0.546 0.281250 0.429688
iteration 124: loss 0.348 0.289062 0.546875
iteration 125: loss 0.409 0.328125 0.515625
iteration 126: loss 0.587 0.257812 0.507812
iteration 127: loss 0.505 0.304688 0.523438
iteration 128: loss 0.467 0.343750 0.507812
iteration 129: loss 0.482 0.289062 0.515625
iteration 130: loss 0.526 0.312500 0.445312
iteration 131: loss 0.517 0.335938 0.437500
iteration 132: loss 0.555 0.226562 0.429688
iteration 133: loss 0.408 0.320312 0.585938
iteration 134: loss 0.437 0.304688 0.492188
iteration 135: loss 0.525 0.312500 0.476562
iteration 136: loss 0.527 0.312500 0.437500
iteration 137: loss 0.521 0.335938 0.468750
iteration 138: loss 0.587 0.328125 0.437500
iteration 139: loss 0.445 0.273438 0.500000
iteration 140: loss 0.437 0.257812 0.445312
iteration 141: loss 0.509 0.351562 0.484375
iteration 142: loss 0.525 0.312500 0.429688
iteration 143: loss 0.542 0.328125 0.406250
iteration 144: loss 0.594 0.320312 0.453125
iteration 145: loss 0.473 0.273438 0.476562
iteration 146: loss 0.420 0.304688 0.460938
iteration 147: loss 0.539 0.265625 0.484375
iteration 148: loss 0.401 0.312500 0.531250
iteration 149: loss 0.617 0.312500 0.375000
iteration 150: loss 0.397 0.273438 0.515625
iteration 151: loss 0.516 0.375000 0.460938
iteration 152: loss 0.526 0.367188 0.468750
iteration 153: loss 0.545 0.351562 0.437500
iteration 154: loss 0.507 0.359375 0.445312
iteration 155: loss 0.453 0.320312 0.468750
iteration 156: loss 0.535 0.312500 0.453125
iteration 157: loss 0.432 0.289062 0.476562
iteration 158: loss 0.494 0.296875 0.390625
iteration 159: loss 0.462 0.296875 0.531250
iteration 160: loss 0.470 0.328125 0.500000
iteration 161: loss 0.494 0.281250 0.523438
iteration 162: loss 0.552 0.328125 0.460938
iteration 163: loss 0.564 0.421875 0.375000
iteration 164: loss 0.518 0.273438 0.445312
iteration 165: loss 0.550 0.242188 0.460938
iteration 166: loss 0.461 0.296875 0.492188
iteration 167: loss 0.518 0.398438 0.429688
iteration 168: loss 0.538 0.367188 0.453125
iteration 169: loss 0.501 0.242188 0.406250
iteration 170: loss 0.411 0.320312 0.515625
iteration 171: loss 0.441 0.335938 0.625000
iteration 172: loss 0.666 0.304688 0.468750
iteration 173: loss 0.586 0.320312 0.429688
iteration 174: loss 0.516 0.304688 0.476562
iteration 175: loss 0.555 0.328125 0.468750
iteration 176: loss 0.448 0.265625 0.500000
iteration 177: loss 0.458 0.351562 0.523438
iteration 178: loss 0.492 0.265625 0.500000
iteration 179: loss 0.619 0.242188 0.484375
iteration 180: loss 0.487 0.289062 0.476562
iteration 181: loss 0.424 0.328125 0.500000
iteration 182: loss 0.548 0.289062 0.500000
iteration 183: loss 0.582 0.335938 0.445312
iteration 184: loss 0.437 0.343750 0.468750
iteration 185: loss 0.480 0.312500 0.515625
iteration 186: loss 0.601 0.296875 0.429688
iteration 187: loss 0.446 0.335938 0.523438
iteration 188: loss 0.539 0.375000 0.406250
iteration 189: loss 0.510 0.312500 0.500000
iteration 190: loss 0.532 0.234375 0.460938
iteration 191: loss 0.574 0.265625 0.468750
iteration 192: loss 0.521 0.335938 0.484375
iteration 193: loss 0.533 0.304688 0.406250
iteration 194: loss 0.351 0.304688 0.554688
iteration 195: loss 0.486 0.335938 0.531250
iteration 196: loss 0.502 0.265625 0.429688
iteration 197: loss 0.471 0.351562 0.507812
iteration 198: loss 0.399 0.289062 0.476562
iteration 199: loss 0.498 0.312500 0.492188
iteration 200: loss 0.609 0.226562 0.445312
iteration 201: loss 0.337 0.265625 0.500000
iteration 202: loss 0.461 0.296875 0.570312
iteration 203: loss 0.517 0.328125 0.429688
iteration 204: loss 0.497 0.312500 0.515625
iteration 205: loss 0.563 0.312500 0.500000
iteration 206: loss 0.638 0.289062 0.453125
iteration 207: loss 0.582 0.328125 0.398438
iteration 208: loss 0.441 0.257812 0.562500
iteration 209: loss 0.524 0.335938 0.437500
iteration 210: loss 0.478 0.382812 0.523438
iteration 211: loss 0.449 0.312500 0.460938
iteration 212: loss 0.536 0.281250 0.523438
iteration 213: loss 0.622 0.250000 0.484375
iteration 214: loss 0.540 0.226562 0.445312
iteration 215: loss 0.604 0.273438 0.445312
iteration 216: loss 0.610 0.265625 0.429688
iteration 217: loss 0.423 0.289062 0.476562
iteration 218: loss 0.531 0.335938 0.406250
iteration 219: loss 0.392 0.250000 0.562500
iteration 220: loss 0.475 0.304688 0.468750
iteration 221: loss 0.472 0.343750 0.484375
iteration 222: loss 0.517 0.351562 0.390625
iteration 223: loss 0.466 0.257812 0.484375
iteration 224: loss 0.434 0.257812 0.500000
iteration 225: loss 0.468 0.320312 0.421875
iteration 226: loss 0.484 0.289062 0.515625
iteration 227: loss 0.433 0.281250 0.492188
iteration 228: loss 0.530 0.257812 0.460938
iteration 229: loss 0.489 0.304688 0.468750
iteration 230: loss 0.537 0.304688 0.421875
iteration 231: loss 0.439 0.304688 0.500000
iteration 232: loss 0.641 0.265625 0.421875
iteration 233: loss 0.493 0.359375 0.484375
iteration 234: loss 0.577 0.343750 0.500000
iteration 235: loss 0.521 0.289062 0.515625
iteration 236: loss 0.605 0.312500 0.468750
iteration 237: loss 0.479 0.289062 0.398438
iteration 238: loss 0.467 0.304688 0.484375
iteration 239: loss 0.484 0.304688 0.476562
iteration 240: loss 0.451 0.289062 0.507812
iteration 241: loss 0.422 0.281250 0.484375
iteration 242: loss 0.481 0.359375 0.468750
iteration 243: loss 0.590 0.367188 0.398438
iteration 244: loss 0.441 0.257812 0.460938
iteration 245: loss 0.464 0.289062 0.515625
iteration 246: loss 0.570 0.312500 0.468750
iteration 247: loss 0.605 0.335938 0.460938
iteration 248: loss 0.545 0.375000 0.445312
iteration 249: loss 0.547 0.367188 0.515625
iteration 250: loss 0.492 0.265625 0.578125
iteration 251: loss 0.501 0.289062 0.453125
iteration 252: loss 0.585 0.296875 0.437500
iteration 253: loss 0.440 0.351562 0.437500
iteration 254: loss 0.430 0.273438 0.515625
iteration 255: loss 0.571 0.328125 0.468750
iteration 256: loss 0.478 0.304688 0.476562
iteration 257: loss 0.640 0.234375 0.429688
iteration 258: loss 0.538 0.328125 0.460938
iteration 259: loss 0.608 0.304688 0.359375
iteration 260: loss 0.439 0.296875 0.492188
iteration 261: loss 0.399 0.351562 0.507812
iteration 262: loss 0.455 0.312500 0.531250
iteration 263: loss 0.442 0.289062 0.476562
iteration 264: loss 0.518 0.296875 0.476562
iteration 265: loss 0.477 0.304688 0.421875
iteration 266: loss 0.428 0.273438 0.531250
iteration 267: loss 0.423 0.273438 0.492188
iteration 268: loss 0.584 0.382812 0.468750
iteration 269: loss 0.571 0.375000 0.500000
iteration 270: loss 0.480 0.289062 0.523438
iteration 271: loss 0.503 0.250000 0.484375
iteration 272: loss 0.410 0.320312 0.531250
iteration 273: loss 0.559 0.289062 0.445312
iteration 274: loss 0.404 0.242188 0.492188
iteration 275: loss 0.554 0.312500 0.460938
iteration 276: loss 0.459 0.250000 0.500000
iteration 277: loss 0.653 0.304688 0.445312
iteration 278: loss 0.571 0.343750 0.453125
iteration 279: loss 0.574 0.281250 0.492188
iteration 280: loss 0.588 0.296875 0.460938
iteration 281: loss 0.495 0.359375 0.515625
iteration 282: loss 0.377 0.289062 0.570312
iteration 283: loss 0.468 0.359375 0.546875
iteration 284: loss 0.532 0.281250 0.500000
iteration 285: loss 0.554 0.281250 0.429688
iteration 286: loss 0.608 0.421875 0.429688
iteration 287: loss 0.421 0.289062 0.515625
iteration 288: loss 0.497 0.250000 0.507812
iteration 289: loss 0.418 0.320312 0.492188
iteration 290: loss 0.575 0.265625 0.468750
iteration 291: loss 0.518 0.343750 0.507812
iteration 292: loss 0.392 0.289062 0.500000
iteration 293: loss 0.477 0.250000 0.468750
iteration 294: loss 0.483 0.296875 0.414062
iteration 295: loss 0.571 0.179688 0.476562
iteration 296: loss 0.495 0.265625 0.445312
iteration 297: loss 0.516 0.304688 0.523438
iteration 298: loss 0.460 0.273438 0.523438
iteration 299: loss 0.555 0.289062 0.507812
iteration 300: loss 0.522 0.359375 0.398438
iteration 301: loss 0.508 0.304688 0.468750
iteration 302: loss 0.581 0.296875 0.429688
iteration 303: loss 0.531 0.320312 0.437500
iteration 304: loss 0.563 0.359375 0.453125
iteration 305: loss 0.609 0.312500 0.375000
iteration 306: loss 0.427 0.242188 0.492188
iteration 307: loss 0.519 0.367188 0.421875
iteration 308: loss 0.511 0.375000 0.453125
iteration 309: loss 0.313 0.296875 0.562500
iteration 310: loss 0.476 0.343750 0.507812
iteration 311: loss 0.431 0.242188 0.507812
iteration 312: loss 0.446 0.289062 0.507812
iteration 313: loss 0.450 0.218750 0.468750
iteration 314: loss 0.510 0.328125 0.460938
iteration 315: loss 0.564 0.320312 0.476562
iteration 316: loss 0.578 0.296875 0.429688
iteration 317: loss 0.559 0.304688 0.437500
iteration 318: loss 0.428 0.289062 0.531250
iteration 319: loss 0.566 0.281250 0.453125
iteration 320: loss 0.580 0.242188 0.429688
iteration 321: loss 0.608 0.312500 0.460938
iteration 322: loss 0.437 0.296875 0.531250
iteration 323: loss 0.545 0.375000 0.476562
iteration 324: loss 0.442 0.250000 0.460938
iteration 325: loss 0.376 0.210938 0.578125
iteration 326: loss 0.554 0.226562 0.437500
iteration 327: loss 0.541 0.375000 0.484375
iteration 328: loss 0.470 0.210938 0.492188
iteration 329: loss 0.450 0.281250 0.523438
iteration 330: loss 0.515 0.242188 0.460938
iteration 331: loss 0.491 0.312500 0.453125
iteration 332: loss 0.597 0.289062 0.437500
iteration 333: loss 0.522 0.312500 0.398438
iteration 334: loss 0.601 0.289062 0.460938
iteration 335: loss 0.547 0.304688 0.437500
iteration 336: loss 0.533 0.210938 0.460938
iteration 337: loss 0.450 0.289062 0.484375
iteration 338: loss 0.564 0.343750 0.468750
iteration 339: loss 0.528 0.281250 0.460938
iteration 340: loss 0.483 0.265625 0.476562
iteration 341: loss 0.497 0.367188 0.484375
iteration 342: loss 0.505 0.335938 0.492188
iteration 343: loss 0.491 0.265625 0.492188
iteration 344: loss 0.490 0.281250 0.445312
iteration 345: loss 0.458 0.281250 0.484375
iteration 346: loss 0.491 0.328125 0.546875
iteration 347: loss 0.493 0.226562 0.468750
iteration 348: loss 0.439 0.257812 0.484375
iteration 349: loss 0.574 0.320312 0.421875
iteration 350: loss 0.566 0.210938 0.476562
iteration 351: loss 0.532 0.289062 0.421875
iteration 352: loss 0.486 0.296875 0.445312
iteration 353: loss 0.448 0.289062 0.523438
iteration 354: loss 0.518 0.296875 0.476562
iteration 355: loss 0.568 0.312500 0.453125
iteration 356: loss 0.546 0.320312 0.421875
iteration 357: loss 0.515 0.289062 0.539062
iteration 358: loss 0.454 0.335938 0.460938
iteration 359: loss 0.453 0.296875 0.468750
iteration 360: loss 0.431 0.335938 0.531250
iteration 361: loss 0.539 0.320312 0.484375
iteration 362: loss 0.500 0.304688 0.468750
iteration 363: loss 0.504 0.312500 0.476562
iteration 364: loss 0.442 0.234375 0.507812
iteration 365: loss 0.456 0.312500 0.523438
iteration 366: loss 0.390 0.351562 0.585938
iteration 367: loss 0.482 0.359375 0.492188
iteration 368: loss 0.487 0.265625 0.453125
iteration 369: loss 0.488 0.328125 0.414062
iteration 370: loss 0.441 0.281250 0.476562
iteration 371: loss 0.479 0.312500 0.484375
iteration 372: loss 0.542 0.328125 0.453125
iteration 373: loss 0.562 0.312500 0.382812
iteration 374: loss 0.469 0.242188 0.468750
iteration 375: loss 0.575 0.328125 0.421875
iteration 376: loss 0.531 0.273438 0.500000
iteration 377: loss 0.426 0.289062 0.554688
iteration 378: loss 0.483 0.335938 0.460938
iteration 379: loss 0.456 0.328125 0.445312
iteration 380: loss 0.604 0.281250 0.445312
iteration 381: loss 0.545 0.250000 0.460938
iteration 382: loss 0.583 0.257812 0.398438
iteration 383: loss 0.487 0.367188 0.500000
iteration 384: loss 0.481 0.296875 0.507812
iteration 385: loss 0.514 0.367188 0.476562
iteration 386: loss 0.524 0.296875 0.492188
iteration 387: loss 0.523 0.296875 0.539062
iteration 388: loss 0.613 0.390625 0.460938
iteration 389: loss 0.467 0.296875 0.460938
iteration 390: loss 0.441 0.312500 0.468750
iteration 391: loss 0.535 0.257812 0.460938
iteration 392: loss 0.390 0.234375 0.546875
iteration 393: loss 0.536 0.351562 0.492188
iteration 394: loss 0.457 0.328125 0.500000
iteration 395: loss 0.480 0.328125 0.507812
iteration 396: loss 0.516 0.296875 0.476562
iteration 397: loss 0.547 0.250000 0.421875
iteration 398: loss 0.531 0.273438 0.421875
iteration 399: loss 0.419 0.273438 0.546875
iteration 400: loss 0.397 0.312500 0.507812
iteration 401: loss 0.462 0.265625 0.523438
iteration 402: loss 0.463 0.304688 0.515625
iteration 403: loss 0.452 0.289062 0.546875
iteration 404: loss 0.556 0.359375 0.484375
iteration 405: loss 0.510 0.296875 0.507812
iteration 406: loss 0.482 0.304688 0.484375
iteration 407: loss 0.533 0.328125 0.367188
iteration 408: loss 0.515 0.234375 0.460938
iteration 409: loss 0.527 0.351562 0.562500
iteration 410: loss 0.454 0.320312 0.460938
iteration 411: loss 0.557 0.265625 0.421875
iteration 412: loss 0.531 0.351562 0.507812
iteration 413: loss 0.645 0.296875 0.429688
iteration 414: loss 0.620 0.367188 0.406250
iteration 415: loss 0.454 0.335938 0.500000
iteration 416: loss 0.507 0.226562 0.398438
iteration 417: loss 0.588 0.296875 0.523438
iteration 418: loss 0.492 0.289062 0.453125
iteration 419: loss 0.543 0.296875 0.468750
iteration 420: loss 0.427 0.296875 0.484375
iteration 421: loss 0.441 0.210938 0.468750
iteration 422: loss 0.467 0.250000 0.484375
iteration 423: loss 0.526 0.296875 0.476562
iteration 424: loss 0.495 0.289062 0.507812
iteration 425: loss 0.503 0.312500 0.484375
iteration 426: loss 0.511 0.281250 0.476562
iteration 427: loss 0.566 0.265625 0.453125
iteration 428: loss 0.493 0.296875 0.515625
iteration 429: loss 0.459 0.257812 0.515625
iteration 430: loss 0.596 0.335938 0.437500
iteration 431: loss 0.491 0.273438 0.460938
iteration 432: loss 0.531 0.273438 0.570312
iteration 433: loss 0.441 0.312500 0.492188
iteration 434: loss 0.407 0.312500 0.468750
iteration 435: loss 0.596 0.304688 0.351562
iteration 436: loss 0.506 0.289062 0.476562
iteration 437: loss 0.418 0.328125 0.453125
iteration 438: loss 0.482 0.304688 0.507812
iteration 439: loss 0.537 0.343750 0.437500
iteration 440: loss 0.524 0.312500 0.406250
iteration 441: loss 0.540 0.242188 0.351562
iteration 442: loss 0.454 0.296875 0.468750
iteration 443: loss 0.394 0.296875 0.539062
iteration 444: loss 0.598 0.226562 0.484375
iteration 445: loss 0.571 0.335938 0.453125
iteration 446: loss 0.610 0.273438 0.484375
iteration 447: loss 0.470 0.250000 0.515625
iteration 448: loss 0.511 0.281250 0.484375
iteration 449: loss 0.452 0.281250 0.523438
iteration 450: loss 0.427 0.382812 0.460938
iteration 451: loss 0.655 0.281250 0.375000
iteration 452: loss 0.469 0.335938 0.453125
iteration 453: loss 0.534 0.312500 0.437500
iteration 454: loss 0.614 0.296875 0.382812
iteration 455: loss 0.505 0.250000 0.484375
iteration 456: loss 0.483 0.367188 0.476562
iteration 457: loss 0.449 0.281250 0.421875
iteration 458: loss 0.390 0.281250 0.492188
iteration 459: loss 0.535 0.320312 0.437500
iteration 460: loss 0.547 0.273438 0.476562
iteration 461: loss 0.471 0.281250 0.492188
iteration 462: loss 0.570 0.367188 0.398438
iteration 463: loss 0.484 0.281250 0.453125
iteration 464: loss 0.465 0.257812 0.492188
iteration 465: loss 0.440 0.328125 0.429688
iteration 466: loss 0.511 0.281250 0.398438
iteration 467: loss 0.531 0.242188 0.445312
iteration 468: loss 0.501 0.328125 0.484375
iteration 469: loss 0.494 0.312500 0.507812
iteration 470: loss 0.495 0.296875 0.453125
iteration 471: loss 0.500 0.265625 0.476562
iteration 472: loss 0.548 0.289062 0.421875
iteration 473: loss 0.461 0.296875 0.484375
iteration 474: loss 0.515 0.304688 0.476562
iteration 475: loss 0.385 0.257812 0.523438
iteration 476: loss 0.548 0.296875 0.398438
iteration 477: loss 0.417 0.265625 0.531250
iteration 478: loss 0.563 0.343750 0.484375
iteration 479: loss 0.659 0.296875 0.406250
iteration 480: loss 0.631 0.304688 0.429688
iteration 481: loss 0.496 0.304688 0.515625
iteration 482: loss 0.421 0.289062 0.554688
iteration 483: loss 0.535 0.304688 0.515625
iteration 484: loss 0.491 0.242188 0.507812
iteration 485: loss 0.511 0.296875 0.453125
iteration 486: loss 0.465 0.273438 0.500000
iteration 487: loss 0.546 0.320312 0.492188
iteration 488: loss 0.578 0.390625 0.414062
iteration 489: loss 0.510 0.265625 0.468750
iteration 490: loss 0.576 0.351562 0.429688
iteration 491: loss 0.557 0.320312 0.375000
iteration 492: loss 0.447 0.281250 0.468750
iteration 493: loss 0.575 0.289062 0.500000
iteration 494: loss 0.559 0.335938 0.468750
iteration 495: loss 0.506 0.234375 0.437500
iteration 496: loss 0.444 0.257812 0.539062
iteration 497: loss 0.441 0.257812 0.484375
iteration 498: loss 0.470 0.289062 0.460938
iteration 499: loss 0.475 0.273438 0.445312
iteration 500: loss 0.458 0.343750 0.453125
iteration 501: loss 0.486 0.335938 0.460938
iteration 502: loss 0.446 0.296875 0.507812
iteration 503: loss 0.555 0.281250 0.437500
iteration 504: loss 0.447 0.242188 0.468750
iteration 505: loss 0.507 0.304688 0.492188
iteration 506: loss 0.516 0.265625 0.437500
iteration 507: loss 0.489 0.281250 0.390625
iteration 508: loss 0.527 0.367188 0.484375
iteration 509: loss 0.402 0.265625 0.554688
iteration 510: loss 0.519 0.281250 0.445312
iteration 511: loss 0.435 0.289062 0.507812
iteration 512: loss 0.511 0.328125 0.460938
iteration 513: loss 0.462 0.289062 0.460938
iteration 514: loss 0.486 0.296875 0.445312
iteration 515: loss 0.519 0.296875 0.445312
iteration 516: loss 0.333 0.335938 0.585938
iteration 517: loss 0.410 0.304688 0.507812
iteration 518: loss 0.457 0.265625 0.460938
iteration 519: loss 0.532 0.351562 0.453125
iteration 520: loss 0.465 0.296875 0.500000
iteration 521: loss 0.452 0.289062 0.453125
iteration 522: loss 0.424 0.312500 0.453125
iteration 523: loss 0.562 0.296875 0.421875
iteration 524: loss 0.479 0.289062 0.515625
iteration 525: loss 0.390 0.265625 0.523438
iteration 526: loss 0.594 0.250000 0.429688
iteration 527: loss 0.518 0.281250 0.429688
iteration 528: loss 0.349 0.296875 0.484375
iteration 529: loss 0.476 0.359375 0.500000
iteration 530: loss 0.520 0.296875 0.382812
iteration 531: loss 0.476 0.250000 0.492188
iteration 532: loss 0.532 0.273438 0.429688
iteration 533: loss 0.448 0.304688 0.523438
iteration 534: loss 0.503 0.367188 0.453125
iteration 535: loss 0.479 0.289062 0.460938
iteration 536: loss 0.469 0.226562 0.468750
iteration 537: loss 0.518 0.328125 0.460938
iteration 538: loss 0.646 0.273438 0.437500
iteration 539: loss 0.481 0.351562 0.460938
iteration 540: loss 0.589 0.320312 0.367188
iteration 541: loss 0.447 0.304688 0.492188
iteration 542: loss 0.473 0.351562 0.500000
iteration 543: loss 0.446 0.335938 0.492188
iteration 544: loss 0.588 0.359375 0.460938
iteration 545: loss 0.563 0.273438 0.460938
iteration 546: loss 0.482 0.421875 0.437500
iteration 547: loss 0.438 0.265625 0.492188
iteration 548: loss 0.466 0.320312 0.492188
iteration 549: loss 0.463 0.375000 0.562500
iteration 550: loss 0.567 0.234375 0.437500
iteration 551: loss 0.456 0.296875 0.445312
iteration 552: loss 0.480 0.250000 0.507812
iteration 553: loss 0.499 0.304688 0.468750
iteration 554: loss 0.495 0.304688 0.445312
iteration 555: loss 0.440 0.320312 0.492188
iteration 556: loss 0.499 0.281250 0.429688
iteration 557: loss 0.540 0.328125 0.453125
iteration 558: loss 0.612 0.289062 0.453125
iteration 559: loss 0.498 0.351562 0.500000
iteration 560: loss 0.498 0.312500 0.445312
iteration 561: loss 0.499 0.257812 0.484375
iteration 562: loss 0.603 0.312500 0.414062
iteration 563: loss 0.436 0.351562 0.484375
iteration 564: loss 0.436 0.289062 0.460938
iteration 565: loss 0.616 0.328125 0.515625
iteration 566: loss 0.542 0.312500 0.445312
iteration 567: loss 0.487 0.234375 0.484375
iteration 568: loss 0.525 0.312500 0.468750
iteration 569: loss 0.433 0.289062 0.453125
iteration 570: loss 0.472 0.265625 0.429688
iteration 571: loss 0.493 0.312500 0.453125
iteration 572: loss 0.659 0.320312 0.406250
iteration 573: loss 0.527 0.335938 0.453125
iteration 574: loss 0.482 0.359375 0.429688
iteration 575: loss 0.388 0.273438 0.562500
iteration 576: loss 0.491 0.226562 0.492188
iteration 577: loss 0.392 0.335938 0.523438
iteration 578: loss 0.518 0.320312 0.476562
iteration 579: loss 0.536 0.226562 0.476562
iteration 580: loss 0.404 0.351562 0.546875
iteration 581: loss 0.484 0.304688 0.492188
iteration 582: loss 0.441 0.289062 0.414062
iteration 583: loss 0.506 0.289062 0.437500
iteration 584: loss 0.376 0.328125 0.554688
iteration 585: loss 0.571 0.273438 0.445312
iteration 586: loss 0.456 0.242188 0.437500
iteration 587: loss 0.473 0.320312 0.500000
iteration 588: loss 0.451 0.250000 0.500000
iteration 589: loss 0.482 0.320312 0.437500
iteration 590: loss 0.548 0.320312 0.421875
iteration 591: loss 0.477 0.312500 0.468750
iteration 592: loss 0.560 0.335938 0.445312
iteration 593: loss 0.400 0.328125 0.445312
iteration 594: loss 0.481 0.359375 0.468750
iteration 595: loss 0.558 0.398438 0.367188
iteration 596: loss 0.577 0.250000 0.437500
iteration 597: loss 0.537 0.328125 0.382812
iteration 598: loss 0.410 0.328125 0.414062
iteration 599: loss 0.555 0.328125 0.429688
iteration 600: loss 0.417 0.328125 0.523438
iteration 601: loss 0.421 0.296875 0.546875
iteration 602: loss 0.506 0.335938 0.484375
iteration 603: loss 0.523 0.328125 0.468750
iteration 604: loss 0.435 0.335938 0.515625
iteration 605: loss 0.427 0.289062 0.585938
iteration 606: loss 0.431 0.289062 0.507812
iteration 607: loss 0.446 0.320312 0.468750
iteration 608: loss 0.521 0.382812 0.492188
iteration 609: loss 0.490 0.210938 0.468750
iteration 610: loss 0.520 0.328125 0.468750
iteration 611: loss 0.346 0.320312 0.515625
iteration 612: loss 0.541 0.257812 0.421875
iteration 613: loss 0.589 0.273438 0.414062
iteration 614: loss 0.480 0.312500 0.507812
iteration 615: loss 0.362 0.312500 0.632812
iteration 616: loss 0.527 0.289062 0.476562
iteration 617: loss 0.486 0.312500 0.421875
iteration 618: loss 0.431 0.304688 0.484375
iteration 619: loss 0.440 0.164062 0.406250
iteration 620: loss 0.526 0.257812 0.414062
iteration 621: loss 0.493 0.273438 0.460938
iteration 622: loss 0.617 0.359375 0.429688
iteration 623: loss 0.578 0.343750 0.523438
iteration 624: loss 0.541 0.304688 0.445312
iteration 625: loss 0.411 0.335938 0.585938
iteration 626: loss 0.488 0.257812 0.468750
iteration 627: loss 0.596 0.320312 0.375000
iteration 628: loss 0.459 0.351562 0.429688
iteration 629: loss 0.490 0.289062 0.437500
iteration 630: loss 0.600 0.328125 0.429688
iteration 631: loss 0.539 0.312500 0.421875
iteration 632: loss 0.455 0.273438 0.460938
iteration 633: loss 0.440 0.312500 0.546875
iteration 634: loss 0.448 0.304688 0.523438
iteration 635: loss 0.603 0.335938 0.437500
iteration 636: loss 0.510 0.289062 0.492188
iteration 637: loss 0.513 0.328125 0.453125
iteration 638: loss 0.468 0.351562 0.484375
iteration 639: loss 0.436 0.359375 0.492188
iteration 640: loss 0.541 0.343750 0.367188
iteration 641: loss 0.449 0.328125 0.531250
iteration 642: loss 0.498 0.445312 0.531250
iteration 643: loss 0.503 0.351562 0.570312
iteration 644: loss 0.567 0.382812 0.507812
iteration 645: loss 0.432 0.312500 0.484375
iteration 646: loss 0.563 0.312500 0.421875
iteration 647: loss 0.468 0.289062 0.515625
iteration 648: loss 0.448 0.312500 0.492188
iteration 649: loss 0.467 0.367188 0.476562
iteration 650: loss 0.518 0.273438 0.437500
iteration 651: loss 0.465 0.343750 0.476562
iteration 652: loss 0.539 0.296875 0.468750
iteration 653: loss 0.406 0.289062 0.484375
iteration 654: loss 0.474 0.335938 0.429688
iteration 655: loss 0.475 0.289062 0.507812
iteration 656: loss 0.502 0.375000 0.515625
iteration 657: loss 0.464 0.265625 0.445312
iteration 658: loss 0.509 0.242188 0.531250
iteration 659: loss 0.411 0.234375 0.515625
iteration 660: loss 0.537 0.296875 0.492188
iteration 661: loss 0.387 0.359375 0.507812
iteration 662: loss 0.674 0.289062 0.390625
iteration 663: loss 0.491 0.296875 0.414062
iteration 664: loss 0.548 0.289062 0.421875
iteration 665: loss 0.542 0.250000 0.382812
iteration 666: loss 0.479 0.273438 0.507812
iteration 667: loss 0.591 0.328125 0.406250
iteration 668: loss 0.348 0.257812 0.546875
iteration 669: loss 0.392 0.312500 0.476562
iteration 670: loss 0.590 0.273438 0.421875
iteration 671: loss 0.401 0.281250 0.492188
iteration 672: loss 0.465 0.296875 0.468750
iteration 673: loss 0.508 0.234375 0.500000
iteration 674: loss 0.460 0.320312 0.468750
iteration 675: loss 0.532 0.343750 0.445312
iteration 676: loss 0.415 0.289062 0.500000
iteration 677: loss 0.407 0.406250 0.531250
iteration 678: loss 0.553 0.320312 0.453125
iteration 679: loss 0.420 0.281250 0.531250
iteration 680: loss 0.483 0.375000 0.468750
iteration 681: loss 0.518 0.281250 0.468750
iteration 682: loss 0.438 0.320312 0.500000
iteration 683: loss 0.507 0.265625 0.429688
iteration 684: loss 0.486 0.289062 0.468750
iteration 685: loss 0.403 0.351562 0.492188
iteration 686: loss 0.513 0.210938 0.492188
iteration 687: loss 0.489 0.343750 0.515625
iteration 688: loss 0.531 0.351562 0.437500
iteration 689: loss 0.504 0.273438 0.421875
iteration 690: loss 0.650 0.312500 0.421875
iteration 691: loss 0.528 0.257812 0.375000
iteration 692: loss 0.445 0.367188 0.453125
iteration 693: loss 0.424 0.234375 0.531250
iteration 694: loss 0.480 0.289062 0.500000
iteration 695: loss 0.549 0.296875 0.398438
iteration 696: loss 0.535 0.304688 0.437500
iteration 697: loss 0.629 0.351562 0.421875
iteration 698: loss 0.491 0.273438 0.437500
iteration 699: loss 0.489 0.367188 0.515625
iteration 700: loss 0.558 0.289062 0.453125
iteration 701: loss 0.577 0.265625 0.445312
iteration 702: loss 0.478 0.304688 0.460938
iteration 703: loss 0.580 0.296875 0.468750
iteration 704: loss 0.498 0.328125 0.515625
iteration 705: loss 0.542 0.343750 0.453125
iteration 706: loss 0.481 0.304688 0.507812
iteration 707: loss 0.509 0.359375 0.445312
iteration 708: loss 0.503 0.367188 0.515625
iteration 709: loss 0.480 0.281250 0.500000
iteration 710: loss 0.517 0.328125 0.421875
iteration 711: loss 0.630 0.218750 0.429688
iteration 712: loss 0.595 0.335938 0.421875
iteration 713: loss 0.564 0.343750 0.359375
iteration 714: loss 0.422 0.265625 0.546875
iteration 715: loss 0.498 0.242188 0.484375
iteration 716: loss 0.557 0.328125 0.476562
iteration 717: loss 0.577 0.312500 0.421875
iteration 718: loss 0.386 0.281250 0.539062
iteration 719: loss 0.505 0.281250 0.507812
iteration 720: loss 0.566 0.367188 0.460938
iteration 721: loss 0.526 0.304688 0.484375
iteration 722: loss 0.430 0.359375 0.476562
iteration 723: loss 0.567 0.351562 0.421875
iteration 724: loss 0.665 0.250000 0.437500
iteration 725: loss 0.458 0.367188 0.492188
iteration 726: loss 0.572 0.273438 0.343750
iteration 727: loss 0.401 0.234375 0.492188
iteration 728: loss 0.521 0.343750 0.460938
iteration 729: loss 0.443 0.289062 0.468750
iteration 730: loss 0.524 0.304688 0.492188
iteration 731: loss 0.464 0.226562 0.484375
iteration 732: loss 0.477 0.312500 0.445312
iteration 733: loss 0.499 0.289062 0.453125
iteration 734: loss 0.469 0.273438 0.476562
iteration 735: loss 0.427 0.312500 0.453125
iteration 736: loss 0.420 0.273438 0.523438
iteration 737: loss 0.608 0.312500 0.421875
iteration 738: loss 0.529 0.226562 0.437500
iteration 739: loss 0.504 0.304688 0.453125
iteration 740: loss 0.404 0.351562 0.500000
iteration 741: loss 0.465 0.265625 0.523438
iteration 742: loss 0.453 0.328125 0.468750
iteration 743: loss 0.361 0.265625 0.531250
iteration 744: loss 0.513 0.343750 0.460938
iteration 745: loss 0.513 0.250000 0.421875
iteration 746: loss 0.453 0.273438 0.445312
iteration 747: loss 0.522 0.226562 0.437500
iteration 748: loss 0.458 0.312500 0.437500
iteration 749: loss 0.509 0.226562 0.468750
iteration 750: loss 0.457 0.234375 0.468750
iteration 751: loss 0.414 0.351562 0.554688
iteration 752: loss 0.379 0.296875 0.484375
iteration 753: loss 0.329 0.328125 0.585938
iteration 754: loss 0.415 0.281250 0.507812
iteration 755: loss 0.386 0.312500 0.546875
iteration 756: loss 0.384 0.382812 0.523438
iteration 757: loss 0.451 0.328125 0.492188
iteration 758: loss 0.522 0.359375 0.421875
iteration 759: loss 0.468 0.359375 0.507812
iteration 760: loss 0.501 0.320312 0.406250
iteration 761: loss 0.535 0.328125 0.437500
iteration 762: loss 0.504 0.375000 0.453125
iteration 763: loss 0.523 0.234375 0.460938
iteration 764: loss 0.561 0.289062 0.406250
iteration 765: loss 0.492 0.328125 0.437500
iteration 766: loss 0.509 0.281250 0.492188
iteration 767: loss 0.438 0.382812 0.515625
iteration 768: loss 0.625 0.312500 0.343750
iteration 769: loss 0.452 0.320312 0.468750
iteration 770: loss 0.494 0.265625 0.492188
iteration 771: loss 0.606 0.250000 0.382812
iteration 772: loss 0.558 0.273438 0.398438
iteration 773: loss 0.472 0.312500 0.437500
iteration 774: loss 0.434 0.289062 0.507812
iteration 775: loss 0.455 0.281250 0.406250
iteration 776: loss 0.609 0.289062 0.375000
iteration 777: loss 0.508 0.312500 0.476562
iteration 778: loss 0.381 0.250000 0.492188
iteration 779: loss 0.414 0.328125 0.492188
iteration 780: loss 0.428 0.226562 0.539062
iteration 781: loss 0.584 0.304688 0.445312
iteration 782: loss 0.418 0.320312 0.500000
iteration 783: loss 0.547 0.312500 0.429688
iteration 784: loss 0.545 0.343750 0.429688
iteration 785: loss 0.577 0.351562 0.460938
iteration 786: loss 0.512 0.265625 0.390625
iteration 787: loss 0.491 0.304688 0.414062
iteration 788: loss 0.433 0.226562 0.476562
iteration 789: loss 0.387 0.226562 0.554688
iteration 790: loss 0.465 0.304688 0.445312
iteration 791: loss 0.401 0.281250 0.554688
iteration 792: loss 0.547 0.289062 0.398438
iteration 793: loss 0.562 0.281250 0.492188
iteration 794: loss 0.513 0.304688 0.476562
iteration 795: loss 0.464 0.328125 0.460938
iteration 796: loss 0.541 0.328125 0.476562
iteration 797: loss 0.459 0.273438 0.484375
iteration 798: loss 0.577 0.304688 0.500000
iteration 799: loss 0.472 0.320312 0.476562
iteration 800: loss 0.584 0.289062 0.460938
iteration 801: loss 0.493 0.328125 0.507812
iteration 802: loss 0.436 0.273438 0.460938
iteration 803: loss 0.449 0.257812 0.507812
iteration 804: loss 0.532 0.375000 0.445312
iteration 805: loss 0.593 0.281250 0.445312
iteration 806: loss 0.662 0.265625 0.382812
iteration 807: loss 0.465 0.351562 0.531250
iteration 808: loss 0.425 0.281250 0.515625
iteration 809: loss 0.477 0.273438 0.453125
iteration 810: loss 0.503 0.250000 0.429688
iteration 811: loss 0.463 0.210938 0.539062
iteration 812: loss 0.394 0.257812 0.523438
iteration 813: loss 0.447 0.296875 0.484375
iteration 814: loss 0.412 0.390625 0.500000
iteration 815: loss 0.498 0.351562 0.476562
iteration 816: loss 0.510 0.320312 0.429688
iteration 817: loss 0.547 0.265625 0.453125
iteration 818: loss 0.434 0.351562 0.484375
iteration 819: loss 0.612 0.273438 0.460938
iteration 820: loss 0.599 0.351562 0.437500
iteration 821: loss 0.428 0.304688 0.500000
iteration 822: loss 0.592 0.281250 0.382812
iteration 823: loss 0.446 0.281250 0.406250
iteration 824: loss 0.435 0.250000 0.476562
iteration 825: loss 0.484 0.312500 0.429688
iteration 826: loss 0.607 0.250000 0.460938
iteration 827: loss 0.556 0.312500 0.460938
iteration 828: loss 0.483 0.328125 0.484375
iteration 829: loss 0.481 0.250000 0.476562
iteration 830: loss 0.577 0.257812 0.429688
iteration 831: loss 0.524 0.273438 0.367188
iteration 832: loss 0.535 0.250000 0.437500
iteration 833: loss 0.497 0.281250 0.468750
iteration 834: loss 0.527 0.281250 0.429688
iteration 835: loss 0.546 0.281250 0.414062
iteration 836: loss 0.518 0.312500 0.492188
iteration 837: loss 0.454 0.296875 0.492188
iteration 838: loss 0.519 0.320312 0.437500
iteration 839: loss 0.552 0.312500 0.414062
iteration 840: loss 0.550 0.250000 0.437500
iteration 841: loss 0.627 0.296875 0.429688
iteration 842: loss 0.613 0.296875 0.375000
iteration 843: loss 0.566 0.335938 0.414062
iteration 844: loss 0.505 0.382812 0.460938
iteration 845: loss 0.561 0.296875 0.460938
iteration 846: loss 0.435 0.359375 0.468750
iteration 847: loss 0.567 0.242188 0.375000
iteration 848: loss 0.527 0.359375 0.406250
iteration 849: loss 0.488 0.335938 0.453125
iteration 850: loss 0.553 0.234375 0.406250
iteration 851: loss 0.540 0.218750 0.390625
iteration 852: loss 0.508 0.390625 0.468750
iteration 853: loss 0.505 0.304688 0.406250
iteration 854: loss 0.531 0.335938 0.460938
iteration 855: loss 0.456 0.335938 0.484375
iteration 856: loss 0.490 0.281250 0.437500
iteration 857: loss 0.441 0.312500 0.460938
iteration 858: loss 0.479 0.281250 0.484375
iteration 859: loss 0.482 0.273438 0.468750
iteration 860: loss 0.501 0.296875 0.507812
iteration 861: loss 0.453 0.289062 0.453125
iteration 862: loss 0.458 0.257812 0.484375
iteration 863: loss 0.497 0.273438 0.406250
iteration 864: loss 0.591 0.273438 0.460938
iteration 865: loss 0.397 0.257812 0.468750
iteration 866: loss 0.480 0.289062 0.460938
iteration 867: loss 0.508 0.296875 0.468750
iteration 868: loss 0.542 0.320312 0.445312
iteration 869: loss 0.440 0.273438 0.476562
iteration 870: loss 0.490 0.312500 0.500000
iteration 871: loss 0.360 0.406250 0.570312
iteration 872: loss 0.527 0.312500 0.406250
iteration 873: loss 0.536 0.304688 0.492188
iteration 874: loss 0.483 0.281250 0.531250
iteration 875: loss 0.498 0.281250 0.492188
iteration 876: loss 0.598 0.351562 0.429688
iteration 877: loss 0.423 0.234375 0.500000
iteration 878: loss 0.480 0.320312 0.546875
iteration 879: loss 0.508 0.320312 0.429688
iteration 880: loss 0.472 0.273438 0.437500
iteration 881: loss 0.591 0.390625 0.445312
iteration 882: loss 0.618 0.265625 0.437500
iteration 883: loss 0.551 0.304688 0.453125
iteration 884: loss 0.520 0.281250 0.460938
iteration 885: loss 0.476 0.289062 0.531250
iteration 886: loss 0.442 0.257812 0.421875
iteration 887: loss 0.590 0.320312 0.476562
iteration 888: loss 0.582 0.312500 0.484375
iteration 889: loss 0.529 0.335938 0.484375
iteration 890: loss 0.413 0.296875 0.507812
iteration 891: loss 0.449 0.320312 0.468750
iteration 892: loss 0.586 0.343750 0.468750
iteration 893: loss 0.499 0.304688 0.437500
iteration 894: loss 0.430 0.320312 0.429688
iteration 895: loss 0.517 0.335938 0.421875
iteration 896: loss 0.538 0.359375 0.445312
iteration 897: loss 0.496 0.289062 0.437500
iteration 898: loss 0.532 0.273438 0.476562
iteration 899: loss 0.409 0.257812 0.539062
iteration 900: loss 0.524 0.343750 0.492188
iteration 901: loss 0.430 0.382812 0.500000
iteration 902: loss 0.513 0.273438 0.445312
iteration 903: loss 0.633 0.304688 0.390625
iteration 904: loss 0.566 0.343750 0.429688
iteration 905: loss 0.681 0.281250 0.406250
iteration 906: loss 0.492 0.304688 0.500000
iteration 907: loss 0.455 0.406250 0.515625
iteration 908: loss 0.410 0.351562 0.500000
iteration 909: loss 0.418 0.328125 0.531250
iteration 910: loss 0.511 0.242188 0.375000
iteration 911: loss 0.487 0.359375 0.445312
iteration 912: loss 0.538 0.312500 0.414062
iteration 913: loss 0.477 0.304688 0.468750
iteration 914: loss 0.499 0.328125 0.476562
iteration 915: loss 0.564 0.281250 0.367188
iteration 916: loss 0.547 0.304688 0.460938
iteration 917: loss 0.424 0.289062 0.500000
iteration 918: loss 0.523 0.234375 0.453125
iteration 919: loss 0.399 0.289062 0.515625
iteration 920: loss 0.515 0.234375 0.507812
iteration 921: loss 0.519 0.296875 0.484375
iteration 922: loss 0.507 0.289062 0.570312
iteration 923: loss 0.536 0.296875 0.460938
iteration 924: loss 0.548 0.257812 0.429688
iteration 925: loss 0.555 0.312500 0.398438
iteration 926: loss 0.455 0.226562 0.500000
iteration 927: loss 0.547 0.273438 0.468750
iteration 928: loss 0.497 0.328125 0.546875
iteration 929: loss 0.462 0.328125 0.500000
iteration 930: loss 0.533 0.273438 0.484375
iteration 931: loss 0.522 0.281250 0.476562
iteration 932: loss 0.498 0.312500 0.500000
iteration 933: loss 0.570 0.187500 0.406250
iteration 934: loss 0.572 0.351562 0.414062
iteration 935: loss 0.646 0.328125 0.390625
iteration 936: loss 0.500 0.210938 0.492188
iteration 937: loss 0.379 0.335938 0.460938
iteration 938: loss 0.570 0.242188 0.453125
iteration 939: loss 0.536 0.250000 0.406250
iteration 940: loss 0.517 0.304688 0.476562
iteration 941: loss 0.475 0.242188 0.468750
iteration 942: loss 0.447 0.335938 0.445312
iteration 943: loss 0.423 0.351562 0.554688
iteration 944: loss 0.528 0.351562 0.507812
iteration 945: loss 0.527 0.242188 0.468750
iteration 946: loss 0.573 0.250000 0.468750
iteration 947: loss 0.507 0.359375 0.468750
iteration 948: loss 0.454 0.242188 0.492188
iteration 949: loss 0.551 0.320312 0.398438
iteration 950: loss 0.419 0.343750 0.500000
iteration 951: loss 0.375 0.265625 0.515625
iteration 952: loss 0.451 0.296875 0.484375
iteration 953: loss 0.504 0.265625 0.468750
iteration 954: loss 0.449 0.242188 0.554688
iteration 955: loss 0.354 0.320312 0.585938
iteration 956: loss 0.445 0.265625 0.460938
iteration 957: loss 0.525 0.367188 0.546875
iteration 958: loss 0.685 0.242188 0.382812
iteration 959: loss 0.490 0.304688 0.492188
iteration 960: loss 0.567 0.304688 0.453125
iteration 961: loss 0.482 0.351562 0.492188
iteration 962: loss 0.600 0.351562 0.382812
iteration 963: loss 0.524 0.226562 0.453125
iteration 964: loss 0.556 0.312500 0.437500
iteration 965: loss 0.521 0.273438 0.429688
iteration 966: loss 0.542 0.328125 0.414062
iteration 967: loss 0.442 0.343750 0.437500
iteration 968: loss 0.463 0.265625 0.515625
iteration 969: loss 0.612 0.328125 0.421875
iteration 970: loss 0.611 0.273438 0.468750
iteration 971: loss 0.504 0.296875 0.507812
iteration 972: loss 0.547 0.242188 0.476562
iteration 973: loss 0.442 0.289062 0.445312
iteration 974: loss 0.419 0.328125 0.515625
iteration 975: loss 0.564 0.242188 0.406250
iteration 976: loss 0.481 0.281250 0.531250
iteration 977: loss 0.574 0.218750 0.453125
iteration 978: loss 0.459 0.257812 0.515625
iteration 979: loss 0.485 0.296875 0.468750
iteration 980: loss 0.476 0.281250 0.453125
iteration 981: loss 0.421 0.312500 0.460938
iteration 982: loss 0.572 0.304688 0.429688
iteration 983: loss 0.486 0.359375 0.453125
iteration 984: loss 0.513 0.359375 0.398438
iteration 985: loss 0.597 0.296875 0.437500
iteration 986: loss 0.429 0.335938 0.539062
iteration 987: loss 0.548 0.367188 0.500000
iteration 988: loss 0.558 0.351562 0.562500
iteration 989: loss 0.682 0.234375 0.437500
iteration 990: loss 0.432 0.273438 0.492188
iteration 991: loss 0.535 0.320312 0.453125
iteration 992: loss 0.459 0.234375 0.500000
iteration 993: loss 0.515 0.304688 0.453125
iteration 994: loss 0.507 0.312500 0.476562
iteration 995: loss 0.601 0.304688 0.375000
iteration 996: loss 0.571 0.218750 0.398438
iteration 997: loss 0.456 0.406250 0.460938
iteration 998: loss 0.588 0.351562 0.414062
iteration 999: loss 0.509 0.320312 0.414062
epoch 17: training: 0.226562 validation: 0.203125
iteration 0: loss 0.455 0.265625 0.453125
iteration 1: loss 0.470 0.289062 0.500000
iteration 2: loss 0.457 0.289062 0.492188
iteration 3: loss 0.408 0.281250 0.492188
iteration 4: loss 0.505 0.359375 0.453125
iteration 5: loss 0.415 0.351562 0.578125
iteration 6: loss 0.474 0.390625 0.539062
iteration 7: loss 0.483 0.257812 0.570312
iteration 8: loss 0.525 0.257812 0.515625
iteration 9: loss 0.511 0.257812 0.453125
iteration 10: loss 0.561 0.281250 0.437500
iteration 11: loss 0.452 0.351562 0.414062
iteration 12: loss 0.458 0.375000 0.492188
iteration 13: loss 0.414 0.273438 0.507812
iteration 14: loss 0.474 0.281250 0.453125
iteration 15: loss 0.510 0.335938 0.453125
iteration 16: loss 0.504 0.289062 0.414062
iteration 17: loss 0.475 0.226562 0.500000
iteration 18: loss 0.587 0.375000 0.492188
iteration 19: loss 0.489 0.328125 0.460938
iteration 20: loss 0.552 0.250000 0.484375
iteration 21: loss 0.486 0.281250 0.523438
iteration 22: loss 0.498 0.242188 0.453125
iteration 23: loss 0.382 0.343750 0.500000
iteration 24: loss 0.518 0.335938 0.421875
iteration 25: loss 0.434 0.328125 0.492188
iteration 26: loss 0.511 0.257812 0.453125
iteration 27: loss 0.430 0.296875 0.554688
iteration 28: loss 0.559 0.328125 0.492188
iteration 29: loss 0.557 0.304688 0.414062
iteration 30: loss 0.567 0.328125 0.453125
iteration 31: loss 0.553 0.281250 0.507812
iteration 32: loss 0.490 0.328125 0.437500
iteration 33: loss 0.368 0.343750 0.484375
iteration 34: loss 0.464 0.320312 0.445312
iteration 35: loss 0.410 0.367188 0.468750
iteration 36: loss 0.585 0.273438 0.437500
iteration 37: loss 0.579 0.281250 0.468750
iteration 38: loss 0.516 0.289062 0.492188
iteration 39: loss 0.463 0.218750 0.500000
iteration 40: loss 0.581 0.343750 0.429688
iteration 41: loss 0.573 0.351562 0.406250
iteration 42: loss 0.394 0.304688 0.453125
iteration 43: loss 0.497 0.289062 0.468750
iteration 44: loss 0.430 0.273438 0.500000
iteration 45: loss 0.485 0.304688 0.523438
iteration 46: loss 0.551 0.257812 0.468750
iteration 47: loss 0.534 0.265625 0.437500
iteration 48: loss 0.432 0.351562 0.460938
iteration 49: loss 0.456 0.289062 0.515625
iteration 50: loss 0.448 0.265625 0.460938
iteration 51: loss 0.540 0.304688 0.398438
iteration 52: loss 0.377 0.250000 0.468750
iteration 53: loss 0.404 0.289062 0.507812
iteration 54: loss 0.438 0.312500 0.484375
iteration 55: loss 0.467 0.312500 0.468750
iteration 56: loss 0.547 0.351562 0.429688
iteration 57: loss 0.533 0.351562 0.507812
iteration 58: loss 0.391 0.289062 0.562500
iteration 59: loss 0.541 0.343750 0.460938
iteration 60: loss 0.582 0.351562 0.460938
iteration 61: loss 0.480 0.250000 0.468750
iteration 62: loss 0.517 0.289062 0.453125
iteration 63: loss 0.615 0.210938 0.406250
iteration 64: loss 0.407 0.320312 0.554688
iteration 65: loss 0.501 0.265625 0.437500
iteration 66: loss 0.523 0.265625 0.468750
iteration 67: loss 0.465 0.312500 0.523438
iteration 68: loss 0.527 0.320312 0.539062
iteration 69: loss 0.528 0.304688 0.500000
iteration 70: loss 0.543 0.390625 0.468750
iteration 71: loss 0.496 0.304688 0.460938
iteration 72: loss 0.470 0.257812 0.500000
iteration 73: loss 0.571 0.390625 0.390625
iteration 74: loss 0.534 0.210938 0.453125
iteration 75: loss 0.532 0.351562 0.429688
iteration 76: loss 0.469 0.250000 0.562500
iteration 77: loss 0.460 0.304688 0.507812
iteration 78: loss 0.578 0.335938 0.445312
iteration 79: loss 0.605 0.312500 0.398438
iteration 80: loss 0.629 0.289062 0.382812
iteration 81: loss 0.606 0.296875 0.453125
iteration 82: loss 0.484 0.296875 0.539062
iteration 83: loss 0.505 0.234375 0.476562
iteration 84: loss 0.455 0.289062 0.515625
iteration 85: loss 0.728 0.296875 0.414062
iteration 86: loss 0.567 0.351562 0.414062
iteration 87: loss 0.545 0.351562 0.468750
iteration 88: loss 0.487 0.328125 0.500000
iteration 89: loss 0.596 0.296875 0.468750
iteration 90: loss 0.461 0.328125 0.578125
iteration 91: loss 0.638 0.218750 0.476562
iteration 92: loss 0.610 0.328125 0.453125
iteration 93: loss 0.480 0.335938 0.484375
iteration 94: loss 0.543 0.328125 0.437500
iteration 95: loss 0.493 0.335938 0.437500
iteration 96: loss 0.447 0.273438 0.492188
iteration 97: loss 0.375 0.265625 0.523438
iteration 98: loss 0.485 0.281250 0.546875
iteration 99: loss 0.472 0.296875 0.484375
iteration 100: loss 0.438 0.328125 0.507812
iteration 101: loss 0.428 0.242188 0.554688
iteration 102: loss 0.570 0.367188 0.398438
iteration 103: loss 0.480 0.343750 0.445312
iteration 104: loss 0.593 0.234375 0.421875
iteration 105: loss 0.656 0.257812 0.375000
iteration 106: loss 0.405 0.273438 0.445312
iteration 107: loss 0.594 0.343750 0.484375
iteration 108: loss 0.494 0.343750 0.562500
iteration 109: loss 0.523 0.296875 0.437500
iteration 110: loss 0.503 0.312500 0.453125
iteration 111: loss 0.421 0.265625 0.468750
iteration 112: loss 0.523 0.320312 0.429688
iteration 113: loss 0.421 0.320312 0.445312
iteration 114: loss 0.406 0.265625 0.468750
iteration 115: loss 0.521 0.281250 0.507812
iteration 116: loss 0.535 0.312500 0.476562
iteration 117: loss 0.569 0.265625 0.460938
iteration 118: loss 0.669 0.359375 0.437500
iteration 119: loss 0.488 0.328125 0.476562
iteration 120: loss 0.584 0.328125 0.445312
iteration 121: loss 0.567 0.312500 0.476562
iteration 122: loss 0.507 0.328125 0.546875
iteration 123: loss 0.521 0.304688 0.562500
iteration 124: loss 0.457 0.289062 0.515625
iteration 125: loss 0.460 0.312500 0.460938
iteration 126: loss 0.461 0.304688 0.390625
iteration 127: loss 0.403 0.359375 0.562500
iteration 128: loss 0.389 0.335938 0.500000
iteration 129: loss 0.456 0.296875 0.523438
iteration 130: loss 0.520 0.351562 0.500000
iteration 131: loss 0.555 0.335938 0.453125
iteration 132: loss 0.458 0.359375 0.539062
iteration 133: loss 0.432 0.296875 0.539062
iteration 134: loss 0.650 0.312500 0.367188
iteration 135: loss 0.450 0.296875 0.484375
iteration 136: loss 0.413 0.203125 0.539062
iteration 137: loss 0.552 0.296875 0.500000
iteration 138: loss 0.471 0.257812 0.460938
iteration 139: loss 0.444 0.289062 0.453125
iteration 140: loss 0.576 0.242188 0.390625
iteration 141: loss 0.425 0.304688 0.453125
iteration 142: loss 0.513 0.304688 0.421875
iteration 143: loss 0.570 0.335938 0.453125
iteration 144: loss 0.589 0.359375 0.445312
iteration 145: loss 0.541 0.304688 0.484375
iteration 146: loss 0.463 0.335938 0.484375
iteration 147: loss 0.436 0.382812 0.398438
iteration 148: loss 0.478 0.343750 0.437500
iteration 149: loss 0.537 0.281250 0.421875
iteration 150: loss 0.510 0.328125 0.421875
iteration 151: loss 0.478 0.343750 0.414062
iteration 152: loss 0.562 0.335938 0.492188
iteration 153: loss 0.478 0.320312 0.500000
iteration 154: loss 0.578 0.296875 0.460938
iteration 155: loss 0.504 0.281250 0.460938
iteration 156: loss 0.495 0.296875 0.406250
iteration 157: loss 0.485 0.234375 0.414062
iteration 158: loss 0.473 0.289062 0.476562
iteration 159: loss 0.540 0.296875 0.429688
iteration 160: loss 0.465 0.367188 0.484375
iteration 161: loss 0.499 0.273438 0.492188
iteration 162: loss 0.494 0.343750 0.531250
iteration 163: loss 0.528 0.320312 0.515625
iteration 164: loss 0.555 0.289062 0.429688
iteration 165: loss 0.559 0.335938 0.437500
iteration 166: loss 0.466 0.328125 0.476562
iteration 167: loss 0.583 0.273438 0.492188
iteration 168: loss 0.458 0.242188 0.500000
iteration 169: loss 0.480 0.390625 0.484375
iteration 170: loss 0.542 0.343750 0.414062
iteration 171: loss 0.404 0.273438 0.546875
iteration 172: loss 0.499 0.242188 0.507812
iteration 173: loss 0.558 0.179688 0.500000
iteration 174: loss 0.530 0.304688 0.492188
iteration 175: loss 0.633 0.320312 0.382812
iteration 176: loss 0.556 0.359375 0.367188
iteration 177: loss 0.446 0.265625 0.492188
iteration 178: loss 0.531 0.343750 0.500000
iteration 179: loss 0.579 0.320312 0.500000
iteration 180: loss 0.580 0.343750 0.476562
iteration 181: loss 0.609 0.382812 0.460938
iteration 182: loss 0.523 0.289062 0.492188
iteration 183: loss 0.524 0.312500 0.531250
iteration 184: loss 0.502 0.250000 0.507812
iteration 185: loss 0.597 0.335938 0.453125
iteration 186: loss 0.468 0.289062 0.460938
iteration 187: loss 0.471 0.328125 0.453125
iteration 188: loss 0.533 0.312500 0.421875
iteration 189: loss 0.464 0.304688 0.453125
iteration 190: loss 0.513 0.281250 0.476562
iteration 191: loss 0.446 0.281250 0.468750
iteration 192: loss 0.411 0.273438 0.507812
iteration 193: loss 0.446 0.281250 0.460938
iteration 194: loss 0.483 0.304688 0.523438
iteration 195: loss 0.597 0.312500 0.460938
iteration 196: loss 0.493 0.289062 0.421875
iteration 197: loss 0.537 0.328125 0.484375
iteration 198: loss 0.612 0.335938 0.437500
iteration 199: loss 0.584 0.320312 0.398438
iteration 200: loss 0.469 0.351562 0.484375
iteration 201: loss 0.667 0.218750 0.390625
iteration 202: loss 0.580 0.335938 0.414062
iteration 203: loss 0.499 0.328125 0.539062
iteration 204: loss 0.629 0.343750 0.406250
iteration 205: loss 0.496 0.257812 0.476562
iteration 206: loss 0.530 0.304688 0.437500
iteration 207: loss 0.518 0.234375 0.539062
iteration 208: loss 0.478 0.289062 0.500000
iteration 209: loss 0.511 0.359375 0.523438
iteration 210: loss 0.588 0.250000 0.468750
iteration 211: loss 0.569 0.304688 0.421875
iteration 212: loss 0.470 0.328125 0.406250
iteration 213: loss 0.589 0.335938 0.328125
iteration 214: loss 0.523 0.335938 0.507812
iteration 215: loss 0.572 0.343750 0.445312
iteration 216: loss 0.632 0.304688 0.437500
iteration 217: loss 0.518 0.328125 0.468750
iteration 218: loss 0.522 0.296875 0.468750
iteration 219: loss 0.559 0.320312 0.406250
iteration 220: loss 0.527 0.304688 0.445312
iteration 221: loss 0.617 0.343750 0.421875
iteration 222: loss 0.510 0.273438 0.414062
iteration 223: loss 0.458 0.304688 0.492188
iteration 224: loss 0.420 0.304688 0.500000
iteration 225: loss 0.462 0.265625 0.507812
iteration 226: loss 0.556 0.257812 0.468750
iteration 227: loss 0.530 0.289062 0.492188
iteration 228: loss 0.537 0.375000 0.476562
iteration 229: loss 0.548 0.257812 0.406250
iteration 230: loss 0.539 0.320312 0.468750
iteration 231: loss 0.519 0.320312 0.445312
iteration 232: loss 0.526 0.320312 0.414062
iteration 233: loss 0.445 0.335938 0.484375
iteration 234: loss 0.469 0.296875 0.484375
iteration 235: loss 0.423 0.328125 0.507812
iteration 236: loss 0.470 0.375000 0.500000
iteration 237: loss 0.437 0.296875 0.507812
iteration 238: loss 0.426 0.328125 0.515625
iteration 239: loss 0.525 0.281250 0.453125
iteration 240: loss 0.402 0.421875 0.500000
iteration 241: loss 0.461 0.320312 0.484375
iteration 242: loss 0.486 0.335938 0.421875
iteration 243: loss 0.486 0.359375 0.523438
iteration 244: loss 0.446 0.351562 0.562500
iteration 245: loss 0.520 0.250000 0.492188
iteration 246: loss 0.422 0.335938 0.539062
iteration 247: loss 0.566 0.273438 0.500000
iteration 248: loss 0.549 0.359375 0.437500
iteration 249: loss 0.564 0.359375 0.414062
iteration 250: loss 0.444 0.296875 0.515625
iteration 251: loss 0.357 0.296875 0.507812
iteration 252: loss 0.422 0.359375 0.562500
iteration 253: loss 0.552 0.242188 0.460938
iteration 254: loss 0.511 0.351562 0.445312
iteration 255: loss 0.580 0.281250 0.453125
iteration 256: loss 0.488 0.359375 0.445312
iteration 257: loss 0.499 0.351562 0.421875
iteration 258: loss 0.473 0.351562 0.437500
iteration 259: loss 0.521 0.312500 0.476562
iteration 260: loss 0.467 0.234375 0.546875
iteration 261: loss 0.691 0.265625 0.312500
iteration 262: loss 0.445 0.320312 0.492188
iteration 263: loss 0.504 0.226562 0.515625
iteration 264: loss 0.582 0.320312 0.406250
iteration 265: loss 0.484 0.273438 0.437500
iteration 266: loss 0.549 0.242188 0.460938
iteration 267: loss 0.444 0.257812 0.546875
iteration 268: loss 0.604 0.359375 0.429688
iteration 269: loss 0.489 0.281250 0.484375
iteration 270: loss 0.467 0.328125 0.476562
iteration 271: loss 0.522 0.250000 0.445312
iteration 272: loss 0.478 0.359375 0.453125
iteration 273: loss 0.563 0.359375 0.382812
iteration 274: loss 0.664 0.281250 0.453125
iteration 275: loss 0.602 0.304688 0.453125
iteration 276: loss 0.375 0.273438 0.570312
iteration 277: loss 0.541 0.312500 0.445312
iteration 278: loss 0.480 0.304688 0.476562
iteration 279: loss 0.460 0.289062 0.453125
iteration 280: loss 0.535 0.289062 0.343750
iteration 281: loss 0.493 0.296875 0.414062
iteration 282: loss 0.559 0.335938 0.468750
iteration 283: loss 0.587 0.312500 0.375000
iteration 284: loss 0.506 0.304688 0.500000
iteration 285: loss 0.463 0.335938 0.460938
iteration 286: loss 0.536 0.351562 0.414062
iteration 287: loss 0.485 0.273438 0.484375
iteration 288: loss 0.475 0.281250 0.468750
iteration 289: loss 0.533 0.296875 0.468750
iteration 290: loss 0.487 0.312500 0.507812
iteration 291: loss 0.401 0.265625 0.546875
iteration 292: loss 0.504 0.328125 0.500000
iteration 293: loss 0.443 0.265625 0.484375
iteration 294: loss 0.463 0.289062 0.484375
iteration 295: loss 0.554 0.398438 0.453125
iteration 296: loss 0.502 0.296875 0.507812
iteration 297: loss 0.456 0.359375 0.507812
iteration 298: loss 0.485 0.328125 0.507812
iteration 299: loss 0.644 0.304688 0.437500
iteration 300: loss 0.717 0.265625 0.375000
iteration 301: loss 0.602 0.312500 0.414062
iteration 302: loss 0.505 0.343750 0.421875
iteration 303: loss 0.562 0.296875 0.453125
iteration 304: loss 0.594 0.359375 0.453125
iteration 305: loss 0.587 0.312500 0.523438
iteration 306: loss 0.407 0.343750 0.570312
iteration 307: loss 0.481 0.328125 0.507812
iteration 308: loss 0.529 0.296875 0.484375
iteration 309: loss 0.550 0.351562 0.437500
iteration 310: loss 0.531 0.312500 0.500000
iteration 311: loss 0.559 0.312500 0.398438
iteration 312: loss 0.437 0.320312 0.453125
iteration 313: loss 0.572 0.195312 0.414062
iteration 314: loss 0.572 0.367188 0.390625
iteration 315: loss 0.515 0.343750 0.390625
iteration 316: loss 0.509 0.289062 0.453125
iteration 317: loss 0.533 0.312500 0.476562
iteration 318: loss 0.485 0.414062 0.507812
iteration 319: loss 0.638 0.273438 0.421875
iteration 320: loss 0.502 0.265625 0.437500
iteration 321: loss 0.516 0.289062 0.390625
iteration 322: loss 0.495 0.320312 0.468750
iteration 323: loss 0.385 0.320312 0.515625
iteration 324: loss 0.546 0.289062 0.484375
iteration 325: loss 0.564 0.375000 0.445312
iteration 326: loss 0.501 0.359375 0.468750
iteration 327: loss 0.630 0.250000 0.390625
iteration 328: loss 0.584 0.343750 0.453125
iteration 329: loss 0.547 0.296875 0.398438
iteration 330: loss 0.521 0.273438 0.421875
iteration 331: loss 0.439 0.375000 0.476562
iteration 332: loss 0.500 0.359375 0.429688
iteration 333: loss 0.615 0.304688 0.414062
iteration 334: loss 0.397 0.265625 0.429688
iteration 335: loss 0.568 0.296875 0.507812
iteration 336: loss 0.622 0.281250 0.429688
iteration 337: loss 0.516 0.257812 0.492188
iteration 338: loss 0.485 0.312500 0.500000
iteration 339: loss 0.525 0.296875 0.429688
iteration 340: loss 0.504 0.281250 0.500000
iteration 341: loss 0.614 0.296875 0.367188
iteration 342: loss 0.537 0.312500 0.437500
iteration 343: loss 0.540 0.265625 0.437500
iteration 344: loss 0.433 0.226562 0.570312
iteration 345: loss 0.492 0.320312 0.460938
iteration 346: loss 0.487 0.343750 0.492188
iteration 347: loss 0.479 0.273438 0.476562
iteration 348: loss 0.571 0.296875 0.398438
iteration 349: loss 0.585 0.273438 0.484375
iteration 350: loss 0.622 0.265625 0.460938
iteration 351: loss 0.483 0.328125 0.429688
iteration 352: loss 0.481 0.343750 0.414062
iteration 353: loss 0.511 0.281250 0.437500
iteration 354: loss 0.537 0.382812 0.484375
iteration 355: loss 0.390 0.265625 0.539062
iteration 356: loss 0.628 0.265625 0.445312
iteration 357: loss 0.485 0.273438 0.453125
iteration 358: loss 0.558 0.320312 0.445312
iteration 359: loss 0.426 0.265625 0.484375
iteration 360: loss 0.569 0.320312 0.429688
iteration 361: loss 0.638 0.312500 0.445312
iteration 362: loss 0.592 0.250000 0.406250
iteration 363: loss 0.336 0.203125 0.578125
iteration 364: loss 0.516 0.328125 0.421875
iteration 365: loss 0.500 0.304688 0.445312
iteration 366: loss 0.483 0.335938 0.453125
iteration 367: loss 0.467 0.289062 0.484375
iteration 368: loss 0.395 0.273438 0.515625
iteration 369: loss 0.531 0.343750 0.468750
iteration 370: loss 0.465 0.335938 0.468750
iteration 371: loss 0.463 0.335938 0.445312
iteration 372: loss 0.512 0.320312 0.484375
iteration 373: loss 0.539 0.367188 0.460938
iteration 374: loss 0.508 0.351562 0.429688
iteration 375: loss 0.498 0.289062 0.453125
iteration 376: loss 0.564 0.250000 0.414062
iteration 377: loss 0.552 0.250000 0.476562
iteration 378: loss 0.531 0.304688 0.437500
iteration 379: loss 0.548 0.312500 0.476562
iteration 380: loss 0.472 0.304688 0.492188
iteration 381: loss 0.557 0.250000 0.445312
iteration 382: loss 0.610 0.289062 0.351562
iteration 383: loss 0.457 0.273438 0.500000
iteration 384: loss 0.443 0.312500 0.468750
iteration 385: loss 0.501 0.273438 0.445312
iteration 386: loss 0.500 0.304688 0.515625
iteration 387: loss 0.554 0.343750 0.406250
iteration 388: loss 0.427 0.304688 0.500000
iteration 389: loss 0.446 0.343750 0.484375
iteration 390: loss 0.417 0.218750 0.562500
iteration 391: loss 0.540 0.328125 0.492188
iteration 392: loss 0.604 0.242188 0.429688
iteration 393: loss 0.516 0.351562 0.468750
iteration 394: loss 0.426 0.226562 0.531250
iteration 395: loss 0.379 0.257812 0.500000
iteration 396: loss 0.515 0.273438 0.492188
iteration 397: loss 0.540 0.226562 0.445312
iteration 398: loss 0.524 0.320312 0.500000
iteration 399: loss 0.507 0.289062 0.437500
iteration 400: loss 0.505 0.210938 0.398438
iteration 401: loss 0.494 0.289062 0.500000
iteration 402: loss 0.496 0.335938 0.453125
iteration 403: loss 0.451 0.351562 0.507812
iteration 404: loss 0.427 0.335938 0.460938
iteration 405: loss 0.512 0.289062 0.515625
iteration 406: loss 0.528 0.328125 0.414062
iteration 407: loss 0.488 0.335938 0.484375
iteration 408: loss 0.397 0.273438 0.546875
iteration 409: loss 0.491 0.320312 0.484375
iteration 410: loss 0.492 0.312500 0.460938
iteration 411: loss 0.607 0.398438 0.398438
iteration 412: loss 0.380 0.375000 0.484375
iteration 413: loss 0.561 0.250000 0.359375
iteration 414: loss 0.584 0.281250 0.414062
iteration 415: loss 0.472 0.312500 0.375000
iteration 416: loss 0.533 0.273438 0.421875
iteration 417: loss 0.445 0.375000 0.492188
iteration 418: loss 0.521 0.359375 0.531250
iteration 419: loss 0.567 0.312500 0.406250
iteration 420: loss 0.431 0.289062 0.507812
iteration 421: loss 0.605 0.359375 0.414062
iteration 422: loss 0.495 0.382812 0.460938
iteration 423: loss 0.485 0.218750 0.484375
iteration 424: loss 0.624 0.304688 0.414062
iteration 425: loss 0.500 0.304688 0.492188
iteration 426: loss 0.475 0.226562 0.476562
iteration 427: loss 0.431 0.335938 0.468750
iteration 428: loss 0.439 0.304688 0.539062
iteration 429: loss 0.538 0.328125 0.453125
iteration 430: loss 0.574 0.335938 0.460938
iteration 431: loss 0.475 0.343750 0.484375
iteration 432: loss 0.484 0.359375 0.507812
iteration 433: loss 0.531 0.273438 0.492188
iteration 434: loss 0.389 0.265625 0.492188
iteration 435: loss 0.488 0.343750 0.476562
iteration 436: loss 0.640 0.273438 0.429688
iteration 437: loss 0.468 0.367188 0.437500
iteration 438: loss 0.432 0.312500 0.507812
iteration 439: loss 0.516 0.289062 0.468750
iteration 440: loss 0.442 0.335938 0.507812
iteration 441: loss 0.471 0.320312 0.468750
iteration 442: loss 0.514 0.218750 0.460938
iteration 443: loss 0.527 0.296875 0.460938
iteration 444: loss 0.497 0.320312 0.437500
iteration 445: loss 0.596 0.382812 0.437500
iteration 446: loss 0.548 0.234375 0.453125
iteration 447: loss 0.443 0.304688 0.523438
iteration 448: loss 0.429 0.320312 0.539062
iteration 449: loss 0.488 0.296875 0.445312
iteration 450: loss 0.511 0.312500 0.437500
iteration 451: loss 0.433 0.320312 0.484375
iteration 452: loss 0.462 0.289062 0.468750
iteration 453: loss 0.453 0.382812 0.492188
iteration 454: loss 0.426 0.328125 0.515625
iteration 455: loss 0.560 0.304688 0.500000
iteration 456: loss 0.614 0.328125 0.421875
iteration 457: loss 0.433 0.250000 0.507812
iteration 458: loss 0.550 0.304688 0.437500
iteration 459: loss 0.545 0.296875 0.406250
iteration 460: loss 0.502 0.320312 0.429688
iteration 461: loss 0.652 0.265625 0.406250
iteration 462: loss 0.555 0.328125 0.429688
iteration 463: loss 0.468 0.312500 0.476562
iteration 464: loss 0.369 0.273438 0.507812
iteration 465: loss 0.482 0.296875 0.500000
iteration 466: loss 0.494 0.335938 0.515625
iteration 467: loss 0.544 0.289062 0.484375
iteration 468: loss 0.599 0.312500 0.453125
iteration 469: loss 0.521 0.335938 0.468750
iteration 470: loss 0.431 0.304688 0.515625
iteration 471: loss 0.540 0.265625 0.453125
iteration 472: loss 0.527 0.304688 0.445312
iteration 473: loss 0.645 0.304688 0.468750
iteration 474: loss 0.531 0.281250 0.476562
iteration 475: loss 0.444 0.257812 0.546875
iteration 476: loss 0.677 0.281250 0.406250
iteration 477: loss 0.513 0.296875 0.468750
iteration 478: loss 0.460 0.304688 0.531250
iteration 479: loss 0.396 0.351562 0.500000
iteration 480: loss 0.457 0.312500 0.507812
iteration 481: loss 0.519 0.289062 0.484375
iteration 482: loss 0.515 0.265625 0.476562
iteration 483: loss 0.512 0.312500 0.515625
iteration 484: loss 0.480 0.312500 0.445312
iteration 485: loss 0.534 0.312500 0.468750
iteration 486: loss 0.484 0.367188 0.484375
iteration 487: loss 0.558 0.273438 0.484375
iteration 488: loss 0.672 0.296875 0.500000
iteration 489: loss 0.687 0.390625 0.406250
iteration 490: loss 0.459 0.304688 0.500000
iteration 491: loss 0.493 0.328125 0.531250
iteration 492: loss 0.516 0.296875 0.468750
iteration 493: loss 0.544 0.289062 0.468750
iteration 494: loss 0.545 0.257812 0.476562
iteration 495: loss 0.543 0.359375 0.421875
iteration 496: loss 0.492 0.359375 0.492188
iteration 497: loss 0.565 0.257812 0.453125
iteration 498: loss 0.562 0.273438 0.406250
iteration 499: loss 0.607 0.179688 0.382812
iteration 500: loss 0.541 0.312500 0.507812
iteration 501: loss 0.461 0.296875 0.531250
iteration 502: loss 0.518 0.273438 0.414062
iteration 503: loss 0.482 0.265625 0.445312
iteration 504: loss 0.598 0.312500 0.406250
iteration 505: loss 0.496 0.398438 0.437500
iteration 506: loss 0.427 0.343750 0.523438
iteration 507: loss 0.653 0.335938 0.468750
iteration 508: loss 0.446 0.281250 0.500000
iteration 509: loss 0.553 0.343750 0.359375
iteration 510: loss 0.491 0.375000 0.445312
iteration 511: loss 0.510 0.296875 0.476562
iteration 512: loss 0.473 0.335938 0.476562
iteration 513: loss 0.398 0.320312 0.492188
iteration 514: loss 0.462 0.289062 0.492188
iteration 515: loss 0.510 0.296875 0.367188
iteration 516: loss 0.488 0.351562 0.468750
iteration 517: loss 0.504 0.343750 0.453125
iteration 518: loss 0.501 0.343750 0.460938
iteration 519: loss 0.499 0.296875 0.500000
iteration 520: loss 0.570 0.281250 0.437500
iteration 521: loss 0.578 0.343750 0.445312
iteration 522: loss 0.411 0.328125 0.523438
iteration 523: loss 0.361 0.335938 0.585938
iteration 524: loss 0.522 0.382812 0.429688
iteration 525: loss 0.449 0.312500 0.492188
iteration 526: loss 0.414 0.281250 0.515625
iteration 527: loss 0.473 0.281250 0.453125
iteration 528: loss 0.643 0.273438 0.429688
iteration 529: loss 0.496 0.281250 0.437500
iteration 530: loss 0.504 0.312500 0.445312
iteration 531: loss 0.448 0.289062 0.460938
iteration 532: loss 0.385 0.296875 0.570312
iteration 533: loss 0.407 0.296875 0.507812
iteration 534: loss 0.533 0.234375 0.539062
iteration 535: loss 0.458 0.312500 0.539062
iteration 536: loss 0.516 0.296875 0.507812
iteration 537: loss 0.441 0.242188 0.406250
iteration 538: loss 0.429 0.265625 0.515625
iteration 539: loss 0.450 0.257812 0.515625
iteration 540: loss 0.464 0.328125 0.531250
iteration 541: loss 0.462 0.343750 0.460938
iteration 542: loss 0.452 0.289062 0.484375
iteration 543: loss 0.496 0.304688 0.515625
iteration 544: loss 0.440 0.296875 0.539062
iteration 545: loss 0.531 0.296875 0.484375
iteration 546: loss 0.455 0.312500 0.515625
iteration 547: loss 0.579 0.234375 0.468750
iteration 548: loss 0.505 0.250000 0.476562
iteration 549: loss 0.518 0.281250 0.367188
iteration 550: loss 0.524 0.359375 0.445312
iteration 551: loss 0.433 0.289062 0.468750
iteration 552: loss 0.472 0.328125 0.460938
iteration 553: loss 0.532 0.343750 0.421875
iteration 554: loss 0.538 0.343750 0.398438
iteration 555: loss 0.479 0.296875 0.468750
iteration 556: loss 0.556 0.367188 0.421875
iteration 557: loss 0.469 0.359375 0.500000
iteration 558: loss 0.459 0.304688 0.468750
iteration 559: loss 0.649 0.335938 0.500000
iteration 560: loss 0.528 0.343750 0.500000
iteration 561: loss 0.557 0.234375 0.515625
iteration 562: loss 0.531 0.296875 0.468750
iteration 563: loss 0.526 0.312500 0.421875
iteration 564: loss 0.423 0.335938 0.453125
iteration 565: loss 0.470 0.351562 0.484375
iteration 566: loss 0.616 0.281250 0.382812
iteration 567: loss 0.587 0.289062 0.390625
iteration 568: loss 0.636 0.375000 0.445312
iteration 569: loss 0.559 0.343750 0.398438
iteration 570: loss 0.483 0.281250 0.414062
iteration 571: loss 0.660 0.226562 0.382812
iteration 572: loss 0.567 0.210938 0.398438
iteration 573: loss 0.464 0.273438 0.421875
iteration 574: loss 0.507 0.273438 0.460938
iteration 575: loss 0.522 0.328125 0.453125
iteration 576: loss 0.536 0.304688 0.492188
iteration 577: loss 0.413 0.242188 0.585938
iteration 578: loss 0.425 0.335938 0.531250
iteration 579: loss 0.461 0.289062 0.445312
iteration 580: loss 0.469 0.351562 0.507812
iteration 581: loss 0.603 0.289062 0.382812
iteration 582: loss 0.553 0.375000 0.468750
iteration 583: loss 0.434 0.304688 0.562500
iteration 584: loss 0.563 0.328125 0.453125
iteration 585: loss 0.555 0.312500 0.414062
iteration 586: loss 0.497 0.257812 0.390625
iteration 587: loss 0.390 0.382812 0.484375
iteration 588: loss 0.524 0.328125 0.515625
iteration 589: loss 0.539 0.335938 0.414062
iteration 590: loss 0.473 0.304688 0.546875
iteration 591: loss 0.509 0.289062 0.492188
iteration 592: loss 0.499 0.289062 0.414062
iteration 593: loss 0.571 0.281250 0.476562
iteration 594: loss 0.499 0.210938 0.398438
iteration 595: loss 0.531 0.328125 0.437500
iteration 596: loss 0.562 0.320312 0.406250
iteration 597: loss 0.455 0.335938 0.429688
iteration 598: loss 0.575 0.304688 0.367188
iteration 599: loss 0.501 0.203125 0.437500
iteration 600: loss 0.577 0.343750 0.367188
iteration 601: loss 0.450 0.335938 0.507812
iteration 602: loss 0.583 0.328125 0.421875
iteration 603: loss 0.530 0.289062 0.414062
iteration 604: loss 0.405 0.281250 0.515625
iteration 605: loss 0.493 0.289062 0.468750
iteration 606: loss 0.457 0.242188 0.500000
iteration 607: loss 0.466 0.281250 0.468750
iteration 608: loss 0.537 0.296875 0.421875
iteration 609: loss 0.554 0.226562 0.398438
iteration 610: loss 0.414 0.304688 0.445312
iteration 611: loss 0.567 0.273438 0.398438
iteration 612: loss 0.474 0.304688 0.421875
iteration 613: loss 0.460 0.289062 0.500000
iteration 614: loss 0.441 0.312500 0.484375
iteration 615: loss 0.426 0.320312 0.539062
iteration 616: loss 0.442 0.312500 0.523438
iteration 617: loss 0.508 0.320312 0.507812
iteration 618: loss 0.396 0.289062 0.515625
iteration 619: loss 0.501 0.304688 0.468750
iteration 620: loss 0.466 0.296875 0.468750
iteration 621: loss 0.434 0.289062 0.429688
iteration 622: loss 0.455 0.312500 0.468750
iteration 623: loss 0.514 0.351562 0.453125
iteration 624: loss 0.364 0.304688 0.539062
iteration 625: loss 0.536 0.273438 0.484375
iteration 626: loss 0.386 0.281250 0.570312
iteration 627: loss 0.525 0.296875 0.500000
iteration 628: loss 0.453 0.335938 0.484375
iteration 629: loss 0.526 0.328125 0.468750
iteration 630: loss 0.485 0.304688 0.468750
iteration 631: loss 0.512 0.289062 0.468750
iteration 632: loss 0.503 0.320312 0.445312
iteration 633: loss 0.518 0.351562 0.460938
iteration 634: loss 0.600 0.335938 0.429688
iteration 635: loss 0.401 0.328125 0.500000
iteration 636: loss 0.430 0.281250 0.484375
iteration 637: loss 0.438 0.265625 0.476562
iteration 638: loss 0.558 0.320312 0.507812
iteration 639: loss 0.523 0.304688 0.484375
iteration 640: loss 0.655 0.343750 0.484375
iteration 641: loss 0.429 0.351562 0.515625
iteration 642: loss 0.427 0.226562 0.523438
iteration 643: loss 0.584 0.335938 0.476562
iteration 644: loss 0.534 0.335938 0.460938
iteration 645: loss 0.547 0.351562 0.460938
iteration 646: loss 0.506 0.328125 0.507812
iteration 647: loss 0.593 0.296875 0.421875
iteration 648: loss 0.569 0.335938 0.484375
iteration 649: loss 0.483 0.304688 0.445312
iteration 650: loss 0.554 0.296875 0.500000
iteration 651: loss 0.545 0.367188 0.445312
iteration 652: loss 0.469 0.281250 0.429688
iteration 653: loss 0.430 0.281250 0.492188
iteration 654: loss 0.616 0.335938 0.398438
iteration 655: loss 0.423 0.382812 0.500000
iteration 656: loss 0.558 0.343750 0.437500
iteration 657: loss 0.469 0.265625 0.468750
iteration 658: loss 0.414 0.375000 0.570312
iteration 659: loss 0.494 0.367188 0.453125
iteration 660: loss 0.469 0.289062 0.554688
iteration 661: loss 0.557 0.328125 0.460938
iteration 662: loss 0.661 0.195312 0.390625
iteration 663: loss 0.424 0.312500 0.453125
iteration 664: loss 0.530 0.382812 0.351562
iteration 665: loss 0.398 0.289062 0.476562
iteration 666: loss 0.465 0.296875 0.460938
iteration 667: loss 0.388 0.296875 0.523438
iteration 668: loss 0.543 0.257812 0.414062
iteration 669: loss 0.396 0.351562 0.484375
iteration 670: loss 0.479 0.281250 0.531250
iteration 671: loss 0.513 0.265625 0.476562
iteration 672: loss 0.618 0.265625 0.390625
iteration 673: loss 0.467 0.234375 0.406250
iteration 674: loss 0.401 0.304688 0.492188
iteration 675: loss 0.523 0.281250 0.453125
iteration 676: loss 0.570 0.273438 0.429688
iteration 677: loss 0.470 0.257812 0.507812
iteration 678: loss 0.521 0.234375 0.484375
iteration 679: loss 0.622 0.343750 0.429688
iteration 680: loss 0.549 0.281250 0.468750
iteration 681: loss 0.488 0.304688 0.414062
iteration 682: loss 0.625 0.296875 0.429688
iteration 683: loss 0.403 0.304688 0.492188
iteration 684: loss 0.491 0.257812 0.445312
iteration 685: loss 0.446 0.375000 0.507812
iteration 686: loss 0.524 0.375000 0.468750
iteration 687: loss 0.395 0.335938 0.570312
iteration 688: loss 0.608 0.218750 0.421875
iteration 689: loss 0.483 0.296875 0.500000
iteration 690: loss 0.344 0.281250 0.578125
iteration 691: loss 0.436 0.367188 0.523438
iteration 692: loss 0.385 0.210938 0.500000
iteration 693: loss 0.531 0.296875 0.382812
iteration 694: loss 0.556 0.343750 0.382812
iteration 695: loss 0.491 0.281250 0.531250
iteration 696: loss 0.513 0.359375 0.507812
iteration 697: loss 0.394 0.289062 0.546875
iteration 698: loss 0.377 0.312500 0.562500
iteration 699: loss 0.447 0.351562 0.484375
iteration 700: loss 0.527 0.312500 0.476562
iteration 701: loss 0.404 0.281250 0.453125
iteration 702: loss 0.516 0.312500 0.500000
iteration 703: loss 0.605 0.234375 0.468750
iteration 704: loss 0.438 0.281250 0.445312
iteration 705: loss 0.432 0.257812 0.476562
iteration 706: loss 0.554 0.328125 0.406250
iteration 707: loss 0.453 0.328125 0.507812
iteration 708: loss 0.489 0.382812 0.500000
iteration 709: loss 0.599 0.296875 0.445312
iteration 710: loss 0.491 0.304688 0.476562
iteration 711: loss 0.496 0.328125 0.453125
iteration 712: loss 0.521 0.265625 0.453125
iteration 713: loss 0.537 0.335938 0.476562
iteration 714: loss 0.466 0.250000 0.453125
iteration 715: loss 0.465 0.328125 0.523438
iteration 716: loss 0.382 0.234375 0.500000
iteration 717: loss 0.578 0.250000 0.484375
iteration 718: loss 0.466 0.304688 0.484375
iteration 719: loss 0.460 0.265625 0.437500
iteration 720: loss 0.556 0.312500 0.437500
iteration 721: loss 0.501 0.242188 0.468750
iteration 722: loss 0.458 0.343750 0.437500
iteration 723: loss 0.408 0.296875 0.476562
iteration 724: loss 0.563 0.328125 0.414062
iteration 725: loss 0.456 0.312500 0.515625
iteration 726: loss 0.544 0.265625 0.507812
iteration 727: loss 0.542 0.289062 0.484375
iteration 728: loss 0.414 0.265625 0.546875
iteration 729: loss 0.468 0.265625 0.437500
iteration 730: loss 0.410 0.312500 0.507812
iteration 731: loss 0.512 0.367188 0.484375
iteration 732: loss 0.565 0.226562 0.414062
iteration 733: loss 0.476 0.328125 0.492188
iteration 734: loss 0.535 0.304688 0.406250
iteration 735: loss 0.456 0.265625 0.453125
iteration 736: loss 0.392 0.421875 0.546875
iteration 737: loss 0.532 0.242188 0.421875
iteration 738: loss 0.457 0.281250 0.468750
iteration 739: loss 0.514 0.250000 0.398438
iteration 740: loss 0.433 0.304688 0.476562
iteration 741: loss 0.448 0.351562 0.492188
iteration 742: loss 0.542 0.304688 0.492188
iteration 743: loss 0.514 0.390625 0.468750
iteration 744: loss 0.533 0.257812 0.421875
iteration 745: loss 0.514 0.273438 0.476562
iteration 746: loss 0.454 0.320312 0.500000
iteration 747: loss 0.460 0.242188 0.460938
iteration 748: loss 0.651 0.320312 0.367188
iteration 749: loss 0.513 0.312500 0.500000
iteration 750: loss 0.494 0.304688 0.484375
iteration 751: loss 0.465 0.359375 0.515625
iteration 752: loss 0.583 0.265625 0.468750
iteration 753: loss 0.468 0.296875 0.460938
iteration 754: loss 0.486 0.312500 0.421875
iteration 755: loss 0.471 0.250000 0.531250
iteration 756: loss 0.465 0.312500 0.523438
iteration 757: loss 0.427 0.281250 0.492188
iteration 758: loss 0.438 0.289062 0.500000
iteration 759: loss 0.598 0.210938 0.453125
iteration 760: loss 0.417 0.312500 0.531250
iteration 761: loss 0.464 0.312500 0.468750
iteration 762: loss 0.419 0.320312 0.460938
iteration 763: loss 0.433 0.281250 0.523438
iteration 764: loss 0.508 0.328125 0.492188
iteration 765: loss 0.439 0.296875 0.492188
iteration 766: loss 0.374 0.296875 0.476562
iteration 767: loss 0.439 0.328125 0.507812
iteration 768: loss 0.436 0.312500 0.468750
iteration 769: loss 0.480 0.343750 0.460938
iteration 770: loss 0.440 0.312500 0.414062
iteration 771: loss 0.516 0.250000 0.468750
iteration 772: loss 0.520 0.304688 0.445312
iteration 773: loss 0.553 0.273438 0.460938
iteration 774: loss 0.475 0.304688 0.460938
iteration 775: loss 0.498 0.367188 0.500000
iteration 776: loss 0.617 0.281250 0.437500
iteration 777: loss 0.492 0.296875 0.515625
iteration 778: loss 0.427 0.265625 0.476562
iteration 779: loss 0.491 0.328125 0.460938
iteration 780: loss 0.461 0.242188 0.445312
iteration 781: loss 0.442 0.265625 0.460938
iteration 782: loss 0.537 0.343750 0.429688
iteration 783: loss 0.462 0.320312 0.507812
iteration 784: loss 0.433 0.304688 0.468750
iteration 785: loss 0.505 0.234375 0.476562
iteration 786: loss 0.526 0.312500 0.437500
iteration 787: loss 0.465 0.273438 0.437500
iteration 788: loss 0.434 0.265625 0.523438
iteration 789: loss 0.432 0.312500 0.500000
iteration 790: loss 0.449 0.296875 0.515625
iteration 791: loss 0.441 0.304688 0.539062
iteration 792: loss 0.361 0.343750 0.562500
iteration 793: loss 0.532 0.304688 0.437500
iteration 794: loss 0.463 0.320312 0.437500
iteration 795: loss 0.447 0.343750 0.507812
iteration 796: loss 0.461 0.265625 0.476562
iteration 797: loss 0.546 0.273438 0.460938
iteration 798: loss 0.537 0.335938 0.421875
iteration 799: loss 0.505 0.250000 0.500000
iteration 800: loss 0.538 0.304688 0.406250
iteration 801: loss 0.492 0.304688 0.406250
iteration 802: loss 0.530 0.289062 0.414062
iteration 803: loss 0.425 0.289062 0.515625
iteration 804: loss 0.386 0.289062 0.539062
iteration 805: loss 0.539 0.312500 0.476562
iteration 806: loss 0.661 0.250000 0.453125
iteration 807: loss 0.509 0.289062 0.460938
iteration 808: loss 0.564 0.367188 0.484375
iteration 809: loss 0.573 0.250000 0.398438
iteration 810: loss 0.541 0.382812 0.460938
iteration 811: loss 0.500 0.375000 0.437500
iteration 812: loss 0.497 0.296875 0.429688
iteration 813: loss 0.438 0.343750 0.500000
iteration 814: loss 0.487 0.359375 0.437500
iteration 815: loss 0.511 0.328125 0.453125
iteration 816: loss 0.463 0.328125 0.515625
iteration 817: loss 0.495 0.218750 0.445312
iteration 818: loss 0.417 0.296875 0.585938
iteration 819: loss 0.456 0.375000 0.437500
iteration 820: loss 0.505 0.320312 0.507812
iteration 821: loss 0.498 0.343750 0.484375
iteration 822: loss 0.470 0.343750 0.445312
iteration 823: loss 0.483 0.289062 0.375000
iteration 824: loss 0.402 0.312500 0.460938
iteration 825: loss 0.445 0.281250 0.445312
iteration 826: loss 0.464 0.351562 0.507812
iteration 827: loss 0.468 0.281250 0.523438
iteration 828: loss 0.505 0.273438 0.476562
iteration 829: loss 0.573 0.289062 0.460938
iteration 830: loss 0.458 0.273438 0.500000
iteration 831: loss 0.477 0.250000 0.453125
iteration 832: loss 0.624 0.312500 0.398438
iteration 833: loss 0.437 0.351562 0.437500
iteration 834: loss 0.429 0.203125 0.531250
iteration 835: loss 0.372 0.328125 0.523438
iteration 836: loss 0.438 0.265625 0.593750
iteration 837: loss 0.520 0.328125 0.445312
iteration 838: loss 0.501 0.335938 0.437500
iteration 839: loss 0.334 0.265625 0.570312
iteration 840: loss 0.450 0.250000 0.515625
iteration 841: loss 0.588 0.328125 0.460938
iteration 842: loss 0.412 0.351562 0.546875
iteration 843: loss 0.457 0.296875 0.492188
iteration 844: loss 0.401 0.234375 0.492188
iteration 845: loss 0.455 0.320312 0.437500
iteration 846: loss 0.496 0.289062 0.476562
iteration 847: loss 0.428 0.320312 0.500000
iteration 848: loss 0.488 0.304688 0.515625
iteration 849: loss 0.569 0.312500 0.445312
iteration 850: loss 0.501 0.289062 0.445312
iteration 851: loss 0.461 0.328125 0.500000
iteration 852: loss 0.552 0.250000 0.414062
iteration 853: loss 0.494 0.281250 0.398438
iteration 854: loss 0.510 0.304688 0.484375
iteration 855: loss 0.416 0.273438 0.492188
iteration 856: loss 0.406 0.281250 0.500000
iteration 857: loss 0.424 0.312500 0.523438
iteration 858: loss 0.471 0.304688 0.414062
iteration 859: loss 0.475 0.242188 0.484375
iteration 860: loss 0.489 0.304688 0.523438
iteration 861: loss 0.469 0.234375 0.476562
iteration 862: loss 0.618 0.265625 0.375000
iteration 863: loss 0.512 0.265625 0.437500
iteration 864: loss 0.338 0.265625 0.539062
iteration 865: loss 0.449 0.273438 0.484375
iteration 866: loss 0.434 0.289062 0.531250
iteration 867: loss 0.427 0.335938 0.468750
iteration 868: loss 0.378 0.265625 0.468750
iteration 869: loss 0.496 0.320312 0.437500
iteration 870: loss 0.506 0.343750 0.406250
iteration 871: loss 0.537 0.289062 0.492188
iteration 872: loss 0.388 0.273438 0.507812
iteration 873: loss 0.479 0.304688 0.460938
iteration 874: loss 0.412 0.312500 0.523438
iteration 875: loss 0.515 0.328125 0.421875
iteration 876: loss 0.506 0.265625 0.398438
iteration 877: loss 0.350 0.367188 0.562500
iteration 878: loss 0.529 0.328125 0.437500
iteration 879: loss 0.575 0.250000 0.437500
iteration 880: loss 0.569 0.359375 0.437500
iteration 881: loss 0.465 0.250000 0.460938
iteration 882: loss 0.484 0.265625 0.523438
iteration 883: loss 0.367 0.281250 0.515625
iteration 884: loss 0.500 0.289062 0.492188
iteration 885: loss 0.547 0.265625 0.414062
iteration 886: loss 0.514 0.359375 0.468750
iteration 887: loss 0.493 0.312500 0.484375
iteration 888: loss 0.512 0.312500 0.460938
iteration 889: loss 0.469 0.312500 0.609375
iteration 890: loss 0.557 0.304688 0.484375
iteration 891: loss 0.487 0.273438 0.476562
iteration 892: loss 0.555 0.281250 0.460938
iteration 893: loss 0.593 0.226562 0.476562
iteration 894: loss 0.439 0.250000 0.484375
iteration 895: loss 0.425 0.281250 0.515625
iteration 896: loss 0.497 0.328125 0.476562
iteration 897: loss 0.543 0.250000 0.437500
iteration 898: loss 0.453 0.304688 0.484375
iteration 899: loss 0.551 0.343750 0.421875
iteration 900: loss 0.451 0.273438 0.476562
iteration 901: loss 0.438 0.273438 0.484375
iteration 902: loss 0.429 0.289062 0.460938
iteration 903: loss 0.481 0.312500 0.468750
iteration 904: loss 0.529 0.328125 0.406250
iteration 905: loss 0.490 0.335938 0.523438
iteration 906: loss 0.548 0.242188 0.484375
iteration 907: loss 0.550 0.390625 0.437500
iteration 908: loss 0.501 0.335938 0.437500
iteration 909: loss 0.456 0.273438 0.429688
iteration 910: loss 0.417 0.281250 0.445312
iteration 911: loss 0.562 0.304688 0.460938
iteration 912: loss 0.513 0.335938 0.507812
iteration 913: loss 0.510 0.343750 0.445312
iteration 914: loss 0.469 0.304688 0.546875
iteration 915: loss 0.627 0.304688 0.468750
iteration 916: loss 0.624 0.257812 0.398438
iteration 917: loss 0.491 0.320312 0.468750
iteration 918: loss 0.435 0.242188 0.437500
iteration 919: loss 0.478 0.351562 0.437500
iteration 920: loss 0.527 0.351562 0.421875
iteration 921: loss 0.470 0.335938 0.476562
iteration 922: loss 0.433 0.273438 0.492188
iteration 923: loss 0.443 0.289062 0.500000
iteration 924: loss 0.420 0.281250 0.539062
iteration 925: loss 0.445 0.289062 0.414062
iteration 926: loss 0.500 0.359375 0.406250
iteration 927: loss 0.489 0.289062 0.414062
iteration 928: loss 0.459 0.312500 0.476562
iteration 929: loss 0.334 0.296875 0.523438
iteration 930: loss 0.528 0.375000 0.492188
iteration 931: loss 0.501 0.320312 0.468750
iteration 932: loss 0.473 0.296875 0.531250
iteration 933: loss 0.461 0.289062 0.476562
iteration 934: loss 0.496 0.382812 0.437500
iteration 935: loss 0.501 0.289062 0.492188
iteration 936: loss 0.360 0.304688 0.531250
iteration 937: loss 0.402 0.320312 0.539062
iteration 938: loss 0.499 0.289062 0.507812
iteration 939: loss 0.574 0.304688 0.453125
iteration 940: loss 0.532 0.234375 0.453125
iteration 941: loss 0.484 0.343750 0.492188
iteration 942: loss 0.494 0.359375 0.414062
iteration 943: loss 0.434 0.265625 0.476562
iteration 944: loss 0.519 0.375000 0.492188
iteration 945: loss 0.501 0.312500 0.554688
iteration 946: loss 0.616 0.320312 0.468750
iteration 947: loss 0.497 0.343750 0.437500
iteration 948: loss 0.668 0.265625 0.390625
iteration 949: loss 0.487 0.250000 0.484375
iteration 950: loss 0.487 0.273438 0.453125
iteration 951: loss 0.411 0.281250 0.437500
iteration 952: loss 0.582 0.265625 0.468750
iteration 953: loss 0.483 0.351562 0.468750
iteration 954: loss 0.457 0.320312 0.500000
iteration 955: loss 0.492 0.242188 0.429688
iteration 956: loss 0.348 0.289062 0.578125
iteration 957: loss 0.576 0.320312 0.367188
iteration 958: loss 0.414 0.281250 0.546875
iteration 959: loss 0.528 0.312500 0.468750
iteration 960: loss 0.492 0.320312 0.523438
iteration 961: loss 0.430 0.296875 0.492188
iteration 962: loss 0.458 0.414062 0.468750
iteration 963: loss 0.521 0.250000 0.429688
iteration 964: loss 0.543 0.312500 0.421875
iteration 965: loss 0.454 0.281250 0.578125
iteration 966: loss 0.433 0.210938 0.507812
iteration 967: loss 0.546 0.359375 0.460938
iteration 968: loss 0.450 0.304688 0.468750
iteration 969: loss 0.545 0.328125 0.359375
iteration 970: loss 0.490 0.304688 0.484375
iteration 971: loss 0.536 0.218750 0.445312
iteration 972: loss 0.455 0.265625 0.515625
iteration 973: loss 0.543 0.296875 0.484375
iteration 974: loss 0.538 0.203125 0.500000
iteration 975: loss 0.424 0.273438 0.406250
iteration 976: loss 0.412 0.304688 0.492188
iteration 977: loss 0.492 0.257812 0.453125
iteration 978: loss 0.452 0.289062 0.484375
iteration 979: loss 0.568 0.312500 0.476562
iteration 980: loss 0.512 0.289062 0.554688
iteration 981: loss 0.584 0.351562 0.406250
iteration 982: loss 0.629 0.296875 0.382812
iteration 983: loss 0.414 0.226562 0.554688
iteration 984: loss 0.462 0.273438 0.500000
iteration 985: loss 0.484 0.250000 0.476562
iteration 986: loss 0.539 0.335938 0.437500
iteration 987: loss 0.467 0.257812 0.507812
iteration 988: loss 0.416 0.296875 0.554688
iteration 989: loss 0.498 0.312500 0.453125
iteration 990: loss 0.500 0.289062 0.429688
iteration 991: loss 0.552 0.304688 0.421875
iteration 992: loss 0.464 0.367188 0.460938
iteration 993: loss 0.506 0.281250 0.460938
iteration 994: loss 0.514 0.312500 0.445312
iteration 995: loss 0.564 0.289062 0.398438
iteration 996: loss 0.395 0.226562 0.515625
iteration 997: loss 0.544 0.343750 0.421875
iteration 998: loss 0.603 0.312500 0.390625
iteration 999: loss 0.455 0.367188 0.421875
epoch 18: training: 0.234375 validation: 0.242188
iteration 0: loss 0.484 0.289062 0.398438
iteration 1: loss 0.581 0.328125 0.492188
iteration 2: loss 0.423 0.296875 0.554688
iteration 3: loss 0.398 0.304688 0.492188
iteration 4: loss 0.457 0.289062 0.500000
iteration 5: loss 0.472 0.281250 0.429688
iteration 6: loss 0.463 0.343750 0.500000
iteration 7: loss 0.515 0.296875 0.500000
iteration 8: loss 0.461 0.226562 0.460938
iteration 9: loss 0.446 0.296875 0.539062
iteration 10: loss 0.454 0.296875 0.492188
iteration 11: loss 0.553 0.273438 0.437500
iteration 12: loss 0.567 0.265625 0.406250
iteration 13: loss 0.485 0.296875 0.476562
iteration 14: loss 0.540 0.328125 0.390625
iteration 15: loss 0.511 0.304688 0.398438
iteration 16: loss 0.498 0.250000 0.476562
iteration 17: loss 0.436 0.375000 0.523438
iteration 18: loss 0.461 0.257812 0.507812
iteration 19: loss 0.458 0.312500 0.468750
iteration 20: loss 0.423 0.281250 0.468750
iteration 21: loss 0.450 0.281250 0.476562
iteration 22: loss 0.428 0.312500 0.460938
iteration 23: loss 0.536 0.335938 0.500000
iteration 24: loss 0.464 0.359375 0.398438
iteration 25: loss 0.448 0.304688 0.429688
iteration 26: loss 0.381 0.359375 0.468750
iteration 27: loss 0.461 0.359375 0.421875
iteration 28: loss 0.487 0.312500 0.390625
iteration 29: loss 0.459 0.242188 0.375000
iteration 30: loss 0.441 0.328125 0.460938
iteration 31: loss 0.484 0.312500 0.421875
iteration 32: loss 0.451 0.312500 0.539062
iteration 33: loss 0.430 0.320312 0.453125
iteration 34: loss 0.407 0.312500 0.492188
iteration 35: loss 0.509 0.265625 0.406250
iteration 36: loss 0.473 0.281250 0.492188
iteration 37: loss 0.491 0.250000 0.476562
iteration 38: loss 0.479 0.281250 0.445312
iteration 39: loss 0.403 0.335938 0.539062
iteration 40: loss 0.495 0.359375 0.429688
iteration 41: loss 0.449 0.367188 0.523438
iteration 42: loss 0.529 0.312500 0.390625
iteration 43: loss 0.569 0.250000 0.453125
iteration 44: loss 0.571 0.312500 0.453125
iteration 45: loss 0.515 0.343750 0.492188
iteration 46: loss 0.464 0.218750 0.476562
iteration 47: loss 0.541 0.398438 0.445312
iteration 48: loss 0.477 0.296875 0.507812
iteration 49: loss 0.412 0.257812 0.468750
iteration 50: loss 0.528 0.312500 0.414062
iteration 51: loss 0.583 0.312500 0.492188
iteration 52: loss 0.409 0.343750 0.531250
iteration 53: loss 0.590 0.304688 0.398438
iteration 54: loss 0.532 0.320312 0.406250
iteration 55: loss 0.543 0.296875 0.351562
iteration 56: loss 0.413 0.250000 0.437500
iteration 57: loss 0.479 0.375000 0.437500
iteration 58: loss 0.471 0.296875 0.492188
iteration 59: loss 0.397 0.343750 0.546875
iteration 60: loss 0.649 0.250000 0.414062
iteration 61: loss 0.490 0.335938 0.476562
iteration 62: loss 0.507 0.250000 0.460938
iteration 63: loss 0.473 0.351562 0.500000
iteration 64: loss 0.543 0.304688 0.406250
iteration 65: loss 0.487 0.281250 0.500000
iteration 66: loss 0.448 0.320312 0.476562
iteration 67: loss 0.497 0.343750 0.507812
iteration 68: loss 0.478 0.343750 0.445312
iteration 69: loss 0.369 0.250000 0.523438
iteration 70: loss 0.501 0.296875 0.382812
iteration 71: loss 0.450 0.242188 0.515625
iteration 72: loss 0.429 0.304688 0.515625
iteration 73: loss 0.579 0.289062 0.406250
iteration 74: loss 0.450 0.304688 0.554688
iteration 75: loss 0.412 0.335938 0.578125
iteration 76: loss 0.425 0.281250 0.484375
iteration 77: loss 0.481 0.320312 0.500000
iteration 78: loss 0.495 0.320312 0.406250
iteration 79: loss 0.496 0.281250 0.460938
iteration 80: loss 0.525 0.328125 0.476562
iteration 81: loss 0.391 0.296875 0.515625
iteration 82: loss 0.400 0.289062 0.468750
iteration 83: loss 0.496 0.335938 0.453125
iteration 84: loss 0.538 0.296875 0.437500
iteration 85: loss 0.534 0.289062 0.484375
iteration 86: loss 0.538 0.257812 0.484375
iteration 87: loss 0.491 0.312500 0.468750
iteration 88: loss 0.439 0.273438 0.515625
iteration 89: loss 0.473 0.320312 0.523438
iteration 90: loss 0.485 0.312500 0.437500
iteration 91: loss 0.589 0.312500 0.460938
iteration 92: loss 0.379 0.351562 0.546875
iteration 93: loss 0.490 0.281250 0.492188
iteration 94: loss 0.613 0.320312 0.390625
iteration 95: loss 0.554 0.312500 0.500000
iteration 96: loss 0.521 0.312500 0.445312
iteration 97: loss 0.540 0.281250 0.437500
iteration 98: loss 0.478 0.195312 0.429688
iteration 99: loss 0.606 0.265625 0.437500
iteration 100: loss 0.451 0.289062 0.445312
iteration 101: loss 0.592 0.281250 0.421875
iteration 102: loss 0.402 0.265625 0.546875
iteration 103: loss 0.454 0.320312 0.507812
iteration 104: loss 0.478 0.351562 0.507812
iteration 105: loss 0.418 0.296875 0.468750
iteration 106: loss 0.504 0.343750 0.453125
iteration 107: loss 0.563 0.382812 0.359375
iteration 108: loss 0.466 0.257812 0.507812
iteration 109: loss 0.584 0.289062 0.476562
iteration 110: loss 0.652 0.289062 0.460938
iteration 111: loss 0.415 0.406250 0.484375
iteration 112: loss 0.553 0.257812 0.445312
iteration 113: loss 0.552 0.273438 0.429688
iteration 114: loss 0.379 0.289062 0.562500
iteration 115: loss 0.391 0.312500 0.476562
iteration 116: loss 0.472 0.250000 0.476562
iteration 117: loss 0.597 0.265625 0.437500
iteration 118: loss 0.618 0.281250 0.398438
iteration 119: loss 0.513 0.328125 0.468750
iteration 120: loss 0.353 0.218750 0.562500
iteration 121: loss 0.437 0.320312 0.476562
iteration 122: loss 0.612 0.304688 0.390625
iteration 123: loss 0.372 0.312500 0.539062
iteration 124: loss 0.498 0.265625 0.453125
iteration 125: loss 0.458 0.289062 0.468750
iteration 126: loss 0.424 0.265625 0.468750
iteration 127: loss 0.469 0.281250 0.414062
iteration 128: loss 0.434 0.367188 0.523438
iteration 129: loss 0.459 0.296875 0.554688
iteration 130: loss 0.460 0.265625 0.531250
iteration 131: loss 0.570 0.367188 0.445312
iteration 132: loss 0.478 0.273438 0.500000
iteration 133: loss 0.525 0.234375 0.460938
iteration 134: loss 0.457 0.320312 0.539062
iteration 135: loss 0.541 0.320312 0.445312
iteration 136: loss 0.590 0.304688 0.437500
iteration 137: loss 0.547 0.296875 0.445312
iteration 138: loss 0.545 0.328125 0.453125
iteration 139: loss 0.598 0.281250 0.500000
iteration 140: loss 0.553 0.281250 0.382812
iteration 141: loss 0.498 0.250000 0.460938
iteration 142: loss 0.508 0.328125 0.445312
iteration 143: loss 0.410 0.320312 0.562500
iteration 144: loss 0.505 0.312500 0.507812
iteration 145: loss 0.533 0.273438 0.507812
iteration 146: loss 0.589 0.296875 0.437500
iteration 147: loss 0.532 0.312500 0.492188
iteration 148: loss 0.419 0.296875 0.500000
iteration 149: loss 0.497 0.359375 0.484375
iteration 150: loss 0.543 0.359375 0.429688
iteration 151: loss 0.516 0.281250 0.445312
iteration 152: loss 0.514 0.304688 0.429688
iteration 153: loss 0.485 0.320312 0.523438
iteration 154: loss 0.416 0.320312 0.554688
iteration 155: loss 0.546 0.250000 0.492188
iteration 156: loss 0.496 0.304688 0.460938
iteration 157: loss 0.497 0.257812 0.453125
iteration 158: loss 0.594 0.257812 0.429688
iteration 159: loss 0.404 0.375000 0.507812
iteration 160: loss 0.613 0.289062 0.421875
iteration 161: loss 0.378 0.304688 0.523438
iteration 162: loss 0.484 0.320312 0.484375
iteration 163: loss 0.485 0.265625 0.476562
iteration 164: loss 0.495 0.281250 0.476562
iteration 165: loss 0.644 0.289062 0.414062
iteration 166: loss 0.450 0.375000 0.507812
iteration 167: loss 0.465 0.242188 0.460938
iteration 168: loss 0.543 0.304688 0.421875
iteration 169: loss 0.511 0.281250 0.445312
iteration 170: loss 0.477 0.335938 0.484375
iteration 171: loss 0.532 0.289062 0.437500
iteration 172: loss 0.433 0.250000 0.554688
iteration 173: loss 0.419 0.257812 0.492188
iteration 174: loss 0.587 0.250000 0.453125
iteration 175: loss 0.642 0.195312 0.429688
iteration 176: loss 0.440 0.281250 0.500000
iteration 177: loss 0.601 0.328125 0.414062
iteration 178: loss 0.416 0.273438 0.500000
iteration 179: loss 0.517 0.265625 0.484375
iteration 180: loss 0.498 0.328125 0.367188
iteration 181: loss 0.521 0.289062 0.406250
iteration 182: loss 0.536 0.296875 0.406250
iteration 183: loss 0.432 0.281250 0.453125
iteration 184: loss 0.444 0.265625 0.500000
iteration 185: loss 0.351 0.312500 0.507812
iteration 186: loss 0.436 0.296875 0.484375
iteration 187: loss 0.530 0.226562 0.468750
iteration 188: loss 0.454 0.320312 0.492188
iteration 189: loss 0.492 0.351562 0.531250
iteration 190: loss 0.558 0.242188 0.406250
iteration 191: loss 0.384 0.304688 0.523438
iteration 192: loss 0.497 0.218750 0.476562
iteration 193: loss 0.596 0.304688 0.304688
iteration 194: loss 0.565 0.242188 0.421875
iteration 195: loss 0.535 0.296875 0.476562
iteration 196: loss 0.502 0.226562 0.437500
iteration 197: loss 0.467 0.335938 0.492188
iteration 198: loss 0.417 0.328125 0.453125
iteration 199: loss 0.456 0.328125 0.476562
iteration 200: loss 0.487 0.281250 0.515625
iteration 201: loss 0.506 0.351562 0.523438
iteration 202: loss 0.442 0.257812 0.429688
iteration 203: loss 0.513 0.281250 0.468750
iteration 204: loss 0.486 0.312500 0.437500
iteration 205: loss 0.656 0.296875 0.429688
iteration 206: loss 0.482 0.335938 0.445312
iteration 207: loss 0.637 0.328125 0.437500
iteration 208: loss 0.532 0.250000 0.492188
iteration 209: loss 0.420 0.304688 0.539062
iteration 210: loss 0.480 0.359375 0.476562
iteration 211: loss 0.413 0.328125 0.460938
iteration 212: loss 0.552 0.398438 0.507812
iteration 213: loss 0.520 0.359375 0.453125
iteration 214: loss 0.497 0.320312 0.445312
iteration 215: loss 0.526 0.312500 0.468750
iteration 216: loss 0.466 0.296875 0.437500
iteration 217: loss 0.509 0.273438 0.476562
iteration 218: loss 0.639 0.320312 0.437500
iteration 219: loss 0.513 0.242188 0.554688
iteration 220: loss 0.557 0.343750 0.515625
iteration 221: loss 0.614 0.296875 0.460938
iteration 222: loss 0.600 0.296875 0.390625
iteration 223: loss 0.422 0.265625 0.500000
iteration 224: loss 0.436 0.335938 0.523438
iteration 225: loss 0.511 0.320312 0.507812
iteration 226: loss 0.385 0.281250 0.492188
iteration 227: loss 0.599 0.328125 0.421875
iteration 228: loss 0.591 0.289062 0.382812
iteration 229: loss 0.426 0.328125 0.453125
iteration 230: loss 0.461 0.359375 0.500000
iteration 231: loss 0.451 0.281250 0.468750
iteration 232: loss 0.584 0.273438 0.468750
iteration 233: loss 0.462 0.304688 0.484375
iteration 234: loss 0.429 0.250000 0.484375
iteration 235: loss 0.501 0.359375 0.445312
iteration 236: loss 0.518 0.296875 0.484375
iteration 237: loss 0.559 0.296875 0.460938
iteration 238: loss 0.491 0.296875 0.468750
iteration 239: loss 0.608 0.367188 0.445312
iteration 240: loss 0.438 0.265625 0.492188
iteration 241: loss 0.457 0.312500 0.460938
iteration 242: loss 0.539 0.281250 0.414062
iteration 243: loss 0.507 0.257812 0.429688
iteration 244: loss 0.510 0.367188 0.476562
iteration 245: loss 0.651 0.343750 0.343750
iteration 246: loss 0.416 0.265625 0.515625
iteration 247: loss 0.479 0.320312 0.484375
iteration 248: loss 0.492 0.281250 0.460938
iteration 249: loss 0.515 0.257812 0.500000
iteration 250: loss 0.408 0.328125 0.484375
iteration 251: loss 0.430 0.343750 0.468750
iteration 252: loss 0.581 0.343750 0.453125
iteration 253: loss 0.475 0.289062 0.476562
iteration 254: loss 0.450 0.257812 0.492188
iteration 255: loss 0.353 0.304688 0.492188
iteration 256: loss 0.482 0.421875 0.476562
iteration 257: loss 0.584 0.335938 0.414062
iteration 258: loss 0.511 0.296875 0.453125
iteration 259: loss 0.472 0.257812 0.531250
iteration 260: loss 0.434 0.265625 0.421875
iteration 261: loss 0.413 0.304688 0.531250
iteration 262: loss 0.452 0.265625 0.468750
iteration 263: loss 0.500 0.226562 0.445312
iteration 264: loss 0.588 0.367188 0.437500
iteration 265: loss 0.511 0.312500 0.484375
iteration 266: loss 0.462 0.179688 0.476562
iteration 267: loss 0.532 0.328125 0.406250
iteration 268: loss 0.481 0.273438 0.492188
iteration 269: loss 0.645 0.343750 0.421875
iteration 270: loss 0.683 0.343750 0.460938
iteration 271: loss 0.498 0.257812 0.453125
iteration 272: loss 0.467 0.304688 0.492188
iteration 273: loss 0.487 0.312500 0.453125
iteration 274: loss 0.476 0.257812 0.515625
iteration 275: loss 0.551 0.304688 0.492188
iteration 276: loss 0.537 0.312500 0.460938
iteration 277: loss 0.460 0.312500 0.484375
iteration 278: loss 0.360 0.265625 0.554688
iteration 279: loss 0.416 0.281250 0.523438
iteration 280: loss 0.431 0.257812 0.476562
iteration 281: loss 0.460 0.351562 0.398438
iteration 282: loss 0.578 0.304688 0.421875
iteration 283: loss 0.608 0.351562 0.429688
iteration 284: loss 0.560 0.281250 0.421875
iteration 285: loss 0.482 0.281250 0.476562
iteration 286: loss 0.518 0.289062 0.500000
iteration 287: loss 0.560 0.320312 0.406250
iteration 288: loss 0.570 0.304688 0.406250
iteration 289: loss 0.507 0.273438 0.382812
iteration 290: loss 0.503 0.257812 0.445312
iteration 291: loss 0.507 0.312500 0.437500
iteration 292: loss 0.605 0.273438 0.382812
iteration 293: loss 0.447 0.359375 0.500000
iteration 294: loss 0.504 0.335938 0.453125
iteration 295: loss 0.493 0.343750 0.437500
iteration 296: loss 0.422 0.226562 0.570312
iteration 297: loss 0.517 0.367188 0.531250
iteration 298: loss 0.470 0.312500 0.460938
iteration 299: loss 0.476 0.343750 0.484375
iteration 300: loss 0.467 0.312500 0.515625
iteration 301: loss 0.488 0.312500 0.468750
iteration 302: loss 0.516 0.312500 0.492188
iteration 303: loss 0.416 0.265625 0.531250
iteration 304: loss 0.517 0.320312 0.468750
iteration 305: loss 0.423 0.312500 0.570312
iteration 306: loss 0.487 0.304688 0.421875
iteration 307: loss 0.554 0.398438 0.390625
iteration 308: loss 0.567 0.281250 0.476562
iteration 309: loss 0.543 0.250000 0.468750
iteration 310: loss 0.448 0.304688 0.484375
iteration 311: loss 0.433 0.312500 0.484375
iteration 312: loss 0.471 0.281250 0.492188
iteration 313: loss 0.505 0.265625 0.414062
iteration 314: loss 0.488 0.281250 0.484375
iteration 315: loss 0.600 0.281250 0.359375
iteration 316: loss 0.551 0.398438 0.414062
iteration 317: loss 0.461 0.312500 0.523438
iteration 318: loss 0.464 0.398438 0.453125
iteration 319: loss 0.510 0.328125 0.468750
iteration 320: loss 0.420 0.335938 0.500000
iteration 321: loss 0.454 0.312500 0.414062
iteration 322: loss 0.593 0.320312 0.445312
iteration 323: loss 0.522 0.281250 0.460938
iteration 324: loss 0.553 0.242188 0.382812
iteration 325: loss 0.459 0.312500 0.484375
iteration 326: loss 0.455 0.273438 0.507812
iteration 327: loss 0.370 0.250000 0.578125
iteration 328: loss 0.417 0.328125 0.492188
iteration 329: loss 0.530 0.367188 0.453125
iteration 330: loss 0.454 0.296875 0.476562
iteration 331: loss 0.557 0.328125 0.476562
iteration 332: loss 0.512 0.296875 0.421875
iteration 333: loss 0.466 0.242188 0.437500
iteration 334: loss 0.487 0.343750 0.484375
iteration 335: loss 0.502 0.343750 0.460938
iteration 336: loss 0.321 0.304688 0.515625
iteration 337: loss 0.418 0.328125 0.500000
iteration 338: loss 0.422 0.328125 0.421875
iteration 339: loss 0.442 0.250000 0.468750
iteration 340: loss 0.474 0.257812 0.460938
iteration 341: loss 0.417 0.312500 0.570312
iteration 342: loss 0.480 0.304688 0.523438
iteration 343: loss 0.433 0.335938 0.507812
iteration 344: loss 0.602 0.382812 0.406250
iteration 345: loss 0.430 0.304688 0.507812
iteration 346: loss 0.354 0.312500 0.585938
iteration 347: loss 0.456 0.265625 0.523438
iteration 348: loss 0.393 0.296875 0.492188
iteration 349: loss 0.421 0.328125 0.460938
iteration 350: loss 0.416 0.273438 0.507812
iteration 351: loss 0.511 0.312500 0.429688
iteration 352: loss 0.581 0.320312 0.421875
iteration 353: loss 0.468 0.351562 0.429688
iteration 354: loss 0.474 0.320312 0.445312
iteration 355: loss 0.457 0.289062 0.437500
iteration 356: loss 0.543 0.234375 0.445312
iteration 357: loss 0.466 0.304688 0.437500
iteration 358: loss 0.591 0.359375 0.468750
iteration 359: loss 0.424 0.343750 0.468750
iteration 360: loss 0.465 0.273438 0.484375
iteration 361: loss 0.447 0.328125 0.507812
iteration 362: loss 0.535 0.242188 0.421875
iteration 363: loss 0.509 0.312500 0.421875
iteration 364: loss 0.565 0.250000 0.406250
iteration 365: loss 0.445 0.328125 0.460938
iteration 366: loss 0.488 0.335938 0.507812
iteration 367: loss 0.437 0.335938 0.523438
iteration 368: loss 0.521 0.257812 0.515625
iteration 369: loss 0.558 0.375000 0.453125
iteration 370: loss 0.370 0.242188 0.507812
iteration 371: loss 0.464 0.234375 0.414062
iteration 372: loss 0.457 0.296875 0.390625
iteration 373: loss 0.382 0.328125 0.507812
iteration 374: loss 0.626 0.273438 0.453125
iteration 375: loss 0.494 0.343750 0.468750
iteration 376: loss 0.509 0.320312 0.523438
iteration 377: loss 0.462 0.343750 0.492188
iteration 378: loss 0.465 0.289062 0.476562
iteration 379: loss 0.458 0.281250 0.421875
iteration 380: loss 0.511 0.320312 0.390625
iteration 381: loss 0.524 0.265625 0.484375
iteration 382: loss 0.488 0.281250 0.500000
iteration 383: loss 0.489 0.320312 0.460938
iteration 384: loss 0.436 0.234375 0.476562
iteration 385: loss 0.479 0.296875 0.437500
iteration 386: loss 0.553 0.289062 0.429688
iteration 387: loss 0.519 0.304688 0.429688
iteration 388: loss 0.456 0.367188 0.468750
iteration 389: loss 0.541 0.296875 0.382812
iteration 390: loss 0.378 0.265625 0.476562
iteration 391: loss 0.390 0.320312 0.546875
iteration 392: loss 0.427 0.335938 0.554688
iteration 393: loss 0.452 0.312500 0.492188
iteration 394: loss 0.391 0.250000 0.539062
iteration 395: loss 0.510 0.289062 0.367188
iteration 396: loss 0.516 0.375000 0.414062
iteration 397: loss 0.474 0.273438 0.437500
iteration 398: loss 0.551 0.289062 0.476562
iteration 399: loss 0.480 0.273438 0.500000
iteration 400: loss 0.572 0.281250 0.437500
iteration 401: loss 0.491 0.281250 0.484375
iteration 402: loss 0.591 0.359375 0.453125
iteration 403: loss 0.463 0.390625 0.515625
iteration 404: loss 0.409 0.242188 0.406250
iteration 405: loss 0.479 0.289062 0.414062
iteration 406: loss 0.511 0.328125 0.453125
iteration 407: loss 0.561 0.273438 0.445312
iteration 408: loss 0.370 0.273438 0.546875
iteration 409: loss 0.541 0.226562 0.460938
iteration 410: loss 0.540 0.382812 0.398438
iteration 411: loss 0.439 0.304688 0.523438
iteration 412: loss 0.609 0.304688 0.335938
iteration 413: loss 0.583 0.265625 0.437500
iteration 414: loss 0.401 0.335938 0.539062
iteration 415: loss 0.423 0.343750 0.554688
iteration 416: loss 0.553 0.289062 0.406250
iteration 417: loss 0.409 0.375000 0.500000
iteration 418: loss 0.387 0.296875 0.515625
iteration 419: loss 0.391 0.375000 0.460938
iteration 420: loss 0.473 0.304688 0.453125
iteration 421: loss 0.477 0.281250 0.468750
iteration 422: loss 0.449 0.320312 0.546875
iteration 423: loss 0.446 0.273438 0.500000
iteration 424: loss 0.477 0.343750 0.429688
iteration 425: loss 0.408 0.226562 0.468750
iteration 426: loss 0.517 0.242188 0.476562
iteration 427: loss 0.448 0.281250 0.515625
iteration 428: loss 0.328 0.335938 0.531250
iteration 429: loss 0.532 0.312500 0.406250
iteration 430: loss 0.524 0.281250 0.398438
iteration 431: loss 0.445 0.257812 0.492188
iteration 432: loss 0.406 0.281250 0.437500
iteration 433: loss 0.482 0.289062 0.460938
iteration 434: loss 0.483 0.273438 0.429688
iteration 435: loss 0.390 0.296875 0.476562
iteration 436: loss 0.383 0.257812 0.515625
iteration 437: loss 0.477 0.312500 0.460938
iteration 438: loss 0.467 0.328125 0.453125
iteration 439: loss 0.384 0.312500 0.468750
iteration 440: loss 0.505 0.304688 0.484375
iteration 441: loss 0.472 0.304688 0.500000
iteration 442: loss 0.446 0.242188 0.507812
iteration 443: loss 0.350 0.328125 0.515625
iteration 444: loss 0.433 0.281250 0.437500
iteration 445: loss 0.489 0.281250 0.398438
iteration 446: loss 0.447 0.289062 0.468750
iteration 447: loss 0.437 0.375000 0.515625
iteration 448: loss 0.519 0.320312 0.429688
iteration 449: loss 0.375 0.304688 0.539062
iteration 450: loss 0.405 0.328125 0.484375
iteration 451: loss 0.450 0.289062 0.539062
iteration 452: loss 0.450 0.351562 0.492188
iteration 453: loss 0.445 0.328125 0.492188
iteration 454: loss 0.503 0.328125 0.562500
iteration 455: loss 0.383 0.265625 0.500000
iteration 456: loss 0.461 0.289062 0.484375
iteration 457: loss 0.429 0.359375 0.476562
iteration 458: loss 0.487 0.312500 0.453125
iteration 459: loss 0.562 0.257812 0.492188
iteration 460: loss 0.602 0.390625 0.429688
iteration 461: loss 0.449 0.328125 0.460938
iteration 462: loss 0.405 0.281250 0.500000
iteration 463: loss 0.535 0.367188 0.398438
iteration 464: loss 0.604 0.335938 0.460938
iteration 465: loss 0.522 0.265625 0.507812
iteration 466: loss 0.418 0.265625 0.507812
iteration 467: loss 0.410 0.296875 0.429688
iteration 468: loss 0.499 0.234375 0.437500
iteration 469: loss 0.475 0.304688 0.468750
iteration 470: loss 0.508 0.367188 0.429688
iteration 471: loss 0.439 0.265625 0.539062
iteration 472: loss 0.410 0.273438 0.531250
iteration 473: loss 0.429 0.335938 0.484375
iteration 474: loss 0.457 0.296875 0.507812
iteration 475: loss 0.415 0.257812 0.492188
iteration 476: loss 0.480 0.320312 0.515625
iteration 477: loss 0.425 0.343750 0.460938
iteration 478: loss 0.470 0.273438 0.429688
iteration 479: loss 0.485 0.304688 0.437500
iteration 480: loss 0.393 0.281250 0.515625
iteration 481: loss 0.469 0.250000 0.484375
iteration 482: loss 0.426 0.257812 0.476562
iteration 483: loss 0.446 0.273438 0.468750
iteration 484: loss 0.517 0.359375 0.437500
iteration 485: loss 0.518 0.296875 0.453125
iteration 486: loss 0.421 0.351562 0.460938
iteration 487: loss 0.529 0.320312 0.460938
iteration 488: loss 0.483 0.320312 0.500000
iteration 489: loss 0.519 0.335938 0.523438
iteration 490: loss 0.384 0.359375 0.554688
iteration 491: loss 0.425 0.304688 0.445312
iteration 492: loss 0.428 0.335938 0.429688
iteration 493: loss 0.499 0.335938 0.460938
iteration 494: loss 0.422 0.335938 0.523438
iteration 495: loss 0.460 0.257812 0.585938
iteration 496: loss 0.524 0.289062 0.476562
iteration 497: loss 0.422 0.281250 0.515625
iteration 498: loss 0.534 0.250000 0.421875
iteration 499: loss 0.360 0.343750 0.531250
iteration 500: loss 0.484 0.289062 0.445312
iteration 501: loss 0.512 0.328125 0.500000
iteration 502: loss 0.428 0.218750 0.492188
iteration 503: loss 0.453 0.343750 0.445312
iteration 504: loss 0.522 0.296875 0.414062
iteration 505: loss 0.447 0.304688 0.421875
iteration 506: loss 0.517 0.359375 0.398438
iteration 507: loss 0.504 0.296875 0.414062
iteration 508: loss 0.503 0.320312 0.468750
iteration 509: loss 0.536 0.421875 0.406250
iteration 510: loss 0.521 0.320312 0.406250
iteration 511: loss 0.481 0.257812 0.492188
iteration 512: loss 0.576 0.312500 0.375000
iteration 513: loss 0.550 0.257812 0.460938
iteration 514: loss 0.486 0.312500 0.515625
iteration 515: loss 0.481 0.296875 0.476562
iteration 516: loss 0.448 0.257812 0.468750
iteration 517: loss 0.499 0.265625 0.468750
iteration 518: loss 0.681 0.296875 0.398438
iteration 519: loss 0.422 0.265625 0.578125
iteration 520: loss 0.388 0.343750 0.554688
iteration 521: loss 0.520 0.335938 0.531250
iteration 522: loss 0.554 0.312500 0.445312
iteration 523: loss 0.433 0.281250 0.500000
iteration 524: loss 0.488 0.335938 0.453125
iteration 525: loss 0.507 0.312500 0.382812
iteration 526: loss 0.424 0.320312 0.531250
iteration 527: loss 0.573 0.382812 0.421875
iteration 528: loss 0.504 0.312500 0.437500
iteration 529: loss 0.460 0.367188 0.390625
iteration 530: loss 0.491 0.250000 0.460938
iteration 531: loss 0.515 0.296875 0.429688
iteration 532: loss 0.431 0.320312 0.414062
iteration 533: loss 0.466 0.335938 0.515625
iteration 534: loss 0.568 0.289062 0.453125
iteration 535: loss 0.492 0.304688 0.421875
iteration 536: loss 0.483 0.289062 0.460938
iteration 537: loss 0.484 0.320312 0.429688
iteration 538: loss 0.357 0.242188 0.539062
iteration 539: loss 0.525 0.304688 0.460938
iteration 540: loss 0.390 0.273438 0.460938
iteration 541: loss 0.415 0.281250 0.460938
iteration 542: loss 0.403 0.328125 0.453125
iteration 543: loss 0.459 0.281250 0.468750
iteration 544: loss 0.392 0.257812 0.484375
iteration 545: loss 0.508 0.296875 0.484375
iteration 546: loss 0.381 0.328125 0.531250
iteration 547: loss 0.453 0.257812 0.468750
iteration 548: loss 0.430 0.320312 0.523438
iteration 549: loss 0.391 0.281250 0.523438
iteration 550: loss 0.548 0.250000 0.406250
iteration 551: loss 0.464 0.328125 0.484375
iteration 552: loss 0.388 0.273438 0.554688
iteration 553: loss 0.500 0.257812 0.445312
iteration 554: loss 0.568 0.320312 0.414062
iteration 555: loss 0.555 0.343750 0.382812
iteration 556: loss 0.518 0.320312 0.414062
iteration 557: loss 0.467 0.312500 0.445312
iteration 558: loss 0.508 0.273438 0.445312
iteration 559: loss 0.499 0.304688 0.437500
iteration 560: loss 0.500 0.265625 0.445312
iteration 561: loss 0.472 0.421875 0.398438
iteration 562: loss 0.472 0.312500 0.445312
iteration 563: loss 0.514 0.226562 0.523438
iteration 564: loss 0.506 0.312500 0.476562
iteration 565: loss 0.410 0.265625 0.593750
iteration 566: loss 0.485 0.320312 0.460938
iteration 567: loss 0.475 0.312500 0.476562
iteration 568: loss 0.377 0.359375 0.515625
iteration 569: loss 0.492 0.343750 0.429688
iteration 570: loss 0.372 0.328125 0.531250
iteration 571: loss 0.561 0.257812 0.429688
iteration 572: loss 0.353 0.304688 0.523438
iteration 573: loss 0.562 0.296875 0.414062
iteration 574: loss 0.447 0.367188 0.429688
iteration 575: loss 0.518 0.328125 0.445312
iteration 576: loss 0.508 0.335938 0.445312
iteration 577: loss 0.464 0.320312 0.437500
iteration 578: loss 0.417 0.367188 0.515625
iteration 579: loss 0.482 0.320312 0.460938
iteration 580: loss 0.496 0.265625 0.484375
iteration 581: loss 0.419 0.265625 0.539062
iteration 582: loss 0.463 0.281250 0.460938
iteration 583: loss 0.485 0.382812 0.476562
iteration 584: loss 0.342 0.328125 0.468750
iteration 585: loss 0.448 0.312500 0.421875
iteration 586: loss 0.562 0.273438 0.445312
iteration 587: loss 0.391 0.359375 0.468750
iteration 588: loss 0.346 0.257812 0.507812
iteration 589: loss 0.582 0.359375 0.382812
iteration 590: loss 0.416 0.343750 0.468750
iteration 591: loss 0.524 0.367188 0.429688
iteration 592: loss 0.511 0.320312 0.445312
iteration 593: loss 0.413 0.257812 0.507812
iteration 594: loss 0.504 0.289062 0.468750
iteration 595: loss 0.523 0.320312 0.484375
iteration 596: loss 0.503 0.226562 0.421875
iteration 597: loss 0.446 0.320312 0.453125
iteration 598: loss 0.453 0.320312 0.500000
iteration 599: loss 0.528 0.351562 0.460938
iteration 600: loss 0.469 0.335938 0.476562
iteration 601: loss 0.350 0.335938 0.585938
iteration 602: loss 0.378 0.265625 0.523438
iteration 603: loss 0.453 0.312500 0.492188
iteration 604: loss 0.386 0.335938 0.476562
iteration 605: loss 0.348 0.320312 0.492188
iteration 606: loss 0.437 0.304688 0.414062
iteration 607: loss 0.380 0.351562 0.500000
iteration 608: loss 0.393 0.312500 0.484375
iteration 609: loss 0.408 0.296875 0.539062
iteration 610: loss 0.537 0.234375 0.445312
iteration 611: loss 0.416 0.242188 0.437500
iteration 612: loss 0.497 0.265625 0.359375
iteration 613: loss 0.482 0.289062 0.390625
iteration 614: loss 0.420 0.312500 0.492188
iteration 615: loss 0.415 0.351562 0.453125
iteration 616: loss 0.381 0.296875 0.507812
iteration 617: loss 0.629 0.320312 0.382812
iteration 618: loss 0.426 0.296875 0.507812
iteration 619: loss 0.420 0.328125 0.507812
iteration 620: loss 0.420 0.304688 0.429688
iteration 621: loss 0.444 0.250000 0.492188
iteration 622: loss 0.399 0.351562 0.445312
iteration 623: loss 0.616 0.273438 0.406250
iteration 624: loss 0.489 0.304688 0.414062
iteration 625: loss 0.539 0.359375 0.421875
iteration 626: loss 0.608 0.320312 0.476562
iteration 627: loss 0.450 0.343750 0.468750
iteration 628: loss 0.508 0.296875 0.445312
iteration 629: loss 0.481 0.328125 0.468750
iteration 630: loss 0.458 0.265625 0.515625
iteration 631: loss 0.541 0.195312 0.492188
iteration 632: loss 0.389 0.304688 0.593750
iteration 633: loss 0.508 0.289062 0.484375
iteration 634: loss 0.503 0.289062 0.445312
iteration 635: loss 0.535 0.335938 0.421875
iteration 636: loss 0.433 0.328125 0.507812
iteration 637: loss 0.505 0.328125 0.398438
iteration 638: loss 0.415 0.343750 0.484375
iteration 639: loss 0.568 0.390625 0.468750
iteration 640: loss 0.456 0.234375 0.476562
iteration 641: loss 0.442 0.351562 0.453125
iteration 642: loss 0.370 0.343750 0.500000
iteration 643: loss 0.422 0.312500 0.460938
iteration 644: loss 0.512 0.281250 0.468750
iteration 645: loss 0.459 0.382812 0.460938
iteration 646: loss 0.442 0.296875 0.500000
iteration 647: loss 0.503 0.265625 0.484375
iteration 648: loss 0.433 0.273438 0.484375
iteration 649: loss 0.462 0.281250 0.468750
iteration 650: loss 0.482 0.296875 0.445312
iteration 651: loss 0.495 0.257812 0.460938
iteration 652: loss 0.565 0.343750 0.492188
iteration 653: loss 0.463 0.273438 0.507812
iteration 654: loss 0.464 0.304688 0.484375
iteration 655: loss 0.407 0.359375 0.507812
iteration 656: loss 0.509 0.265625 0.437500
iteration 657: loss 0.622 0.320312 0.421875
iteration 658: loss 0.494 0.320312 0.476562
iteration 659: loss 0.419 0.312500 0.476562
iteration 660: loss 0.388 0.234375 0.523438
iteration 661: loss 0.496 0.296875 0.468750
iteration 662: loss 0.544 0.328125 0.507812
iteration 663: loss 0.422 0.328125 0.492188
iteration 664: loss 0.492 0.335938 0.492188
iteration 665: loss 0.576 0.320312 0.468750
iteration 666: loss 0.634 0.312500 0.414062
iteration 667: loss 0.590 0.257812 0.429688
iteration 668: loss 0.500 0.234375 0.421875
iteration 669: loss 0.571 0.234375 0.445312
iteration 670: loss 0.496 0.273438 0.507812
iteration 671: loss 0.541 0.375000 0.453125
iteration 672: loss 0.399 0.304688 0.468750
iteration 673: loss 0.397 0.367188 0.500000
iteration 674: loss 0.391 0.351562 0.562500
iteration 675: loss 0.362 0.343750 0.570312
iteration 676: loss 0.475 0.250000 0.515625
iteration 677: loss 0.450 0.351562 0.523438
iteration 678: loss 0.489 0.304688 0.476562
iteration 679: loss 0.447 0.265625 0.523438
iteration 680: loss 0.427 0.335938 0.476562
iteration 681: loss 0.493 0.257812 0.460938
iteration 682: loss 0.479 0.406250 0.484375
iteration 683: loss 0.491 0.289062 0.484375
iteration 684: loss 0.449 0.281250 0.507812
iteration 685: loss 0.526 0.312500 0.492188
iteration 686: loss 0.508 0.265625 0.421875
iteration 687: loss 0.505 0.359375 0.421875
iteration 688: loss 0.407 0.328125 0.500000
iteration 689: loss 0.485 0.335938 0.429688
iteration 690: loss 0.385 0.328125 0.523438
iteration 691: loss 0.519 0.289062 0.375000
iteration 692: loss 0.472 0.343750 0.414062
iteration 693: loss 0.404 0.296875 0.507812
iteration 694: loss 0.482 0.304688 0.476562
iteration 695: loss 0.592 0.398438 0.437500
iteration 696: loss 0.449 0.289062 0.492188
iteration 697: loss 0.491 0.320312 0.460938
iteration 698: loss 0.481 0.289062 0.468750
iteration 699: loss 0.619 0.281250 0.398438
iteration 700: loss 0.450 0.281250 0.429688
iteration 701: loss 0.445 0.265625 0.414062
iteration 702: loss 0.523 0.304688 0.390625
iteration 703: loss 0.500 0.281250 0.492188
iteration 704: loss 0.418 0.187500 0.507812
iteration 705: loss 0.477 0.312500 0.468750
iteration 706: loss 0.430 0.343750 0.484375
iteration 707: loss 0.419 0.312500 0.539062
iteration 708: loss 0.463 0.250000 0.445312
iteration 709: loss 0.443 0.312500 0.539062
iteration 710: loss 0.403 0.296875 0.492188
iteration 711: loss 0.568 0.296875 0.367188
iteration 712: loss 0.473 0.257812 0.468750
iteration 713: loss 0.537 0.296875 0.390625
iteration 714: loss 0.514 0.257812 0.445312
iteration 715: loss 0.484 0.351562 0.453125
iteration 716: loss 0.446 0.304688 0.515625
iteration 717: loss 0.435 0.343750 0.468750
iteration 718: loss 0.492 0.312500 0.507812
iteration 719: loss 0.386 0.273438 0.492188
iteration 720: loss 0.377 0.289062 0.523438
iteration 721: loss 0.578 0.367188 0.453125
iteration 722: loss 0.342 0.242188 0.460938
iteration 723: loss 0.562 0.343750 0.398438
iteration 724: loss 0.452 0.265625 0.437500
iteration 725: loss 0.412 0.281250 0.492188
iteration 726: loss 0.379 0.296875 0.515625
iteration 727: loss 0.415 0.250000 0.507812
iteration 728: loss 0.464 0.304688 0.460938
iteration 729: loss 0.433 0.320312 0.437500
iteration 730: loss 0.448 0.335938 0.500000
iteration 731: loss 0.450 0.289062 0.484375
iteration 732: loss 0.413 0.320312 0.546875
iteration 733: loss 0.502 0.289062 0.515625
iteration 734: loss 0.502 0.304688 0.507812
iteration 735: loss 0.414 0.265625 0.500000
iteration 736: loss 0.460 0.359375 0.468750
iteration 737: loss 0.402 0.382812 0.546875
iteration 738: loss 0.516 0.296875 0.460938
iteration 739: loss 0.434 0.320312 0.445312
iteration 740: loss 0.539 0.328125 0.382812
iteration 741: loss 0.491 0.234375 0.382812
iteration 742: loss 0.468 0.312500 0.437500
iteration 743: loss 0.422 0.296875 0.531250
iteration 744: loss 0.439 0.289062 0.531250
iteration 745: loss 0.463 0.312500 0.500000
iteration 746: loss 0.360 0.265625 0.500000
iteration 747: loss 0.493 0.242188 0.468750
iteration 748: loss 0.387 0.210938 0.453125
iteration 749: loss 0.408 0.312500 0.523438
iteration 750: loss 0.441 0.320312 0.484375
iteration 751: loss 0.403 0.328125 0.562500
iteration 752: loss 0.392 0.328125 0.500000
iteration 753: loss 0.504 0.304688 0.421875
iteration 754: loss 0.434 0.328125 0.484375
iteration 755: loss 0.407 0.281250 0.468750
iteration 756: loss 0.440 0.289062 0.492188
iteration 757: loss 0.484 0.257812 0.476562
iteration 758: loss 0.506 0.328125 0.460938
iteration 759: loss 0.433 0.265625 0.460938
iteration 760: loss 0.503 0.328125 0.453125
iteration 761: loss 0.564 0.335938 0.398438
iteration 762: loss 0.456 0.203125 0.453125
iteration 763: loss 0.477 0.281250 0.492188
iteration 764: loss 0.310 0.179688 0.500000
iteration 765: loss 0.464 0.257812 0.445312
iteration 766: loss 0.450 0.328125 0.445312
iteration 767: loss 0.478 0.320312 0.437500
iteration 768: loss 0.451 0.359375 0.531250
iteration 769: loss 0.422 0.265625 0.453125
iteration 770: loss 0.595 0.304688 0.414062
iteration 771: loss 0.408 0.312500 0.437500
iteration 772: loss 0.512 0.289062 0.453125
iteration 773: loss 0.544 0.289062 0.414062
iteration 774: loss 0.371 0.320312 0.523438
iteration 775: loss 0.451 0.296875 0.515625
iteration 776: loss 0.412 0.367188 0.539062
iteration 777: loss 0.481 0.265625 0.453125
iteration 778: loss 0.444 0.265625 0.437500
iteration 779: loss 0.392 0.312500 0.492188
iteration 780: loss 0.547 0.273438 0.468750
iteration 781: loss 0.587 0.335938 0.421875
iteration 782: loss 0.497 0.406250 0.437500
iteration 783: loss 0.509 0.273438 0.468750
iteration 784: loss 0.437 0.289062 0.453125
iteration 785: loss 0.553 0.257812 0.445312
iteration 786: loss 0.626 0.312500 0.375000
iteration 787: loss 0.494 0.312500 0.476562
iteration 788: loss 0.442 0.234375 0.484375
iteration 789: loss 0.541 0.335938 0.429688
iteration 790: loss 0.521 0.289062 0.476562
iteration 791: loss 0.558 0.304688 0.406250
iteration 792: loss 0.415 0.304688 0.507812
iteration 793: loss 0.561 0.320312 0.414062
iteration 794: loss 0.481 0.328125 0.468750
iteration 795: loss 0.407 0.226562 0.484375
iteration 796: loss 0.475 0.250000 0.445312
iteration 797: loss 0.480 0.265625 0.445312
iteration 798: loss 0.486 0.343750 0.515625
iteration 799: loss 0.411 0.257812 0.507812
iteration 800: loss 0.575 0.335938 0.445312
iteration 801: loss 0.476 0.265625 0.453125
iteration 802: loss 0.453 0.320312 0.468750
iteration 803: loss 0.495 0.242188 0.398438
iteration 804: loss 0.424 0.390625 0.500000
iteration 805: loss 0.460 0.242188 0.460938
iteration 806: loss 0.478 0.312500 0.390625
iteration 807: loss 0.449 0.351562 0.468750
iteration 808: loss 0.376 0.343750 0.523438
iteration 809: loss 0.467 0.312500 0.507812
iteration 810: loss 0.441 0.304688 0.437500
iteration 811: loss 0.561 0.312500 0.507812
iteration 812: loss 0.485 0.328125 0.429688
iteration 813: loss 0.461 0.320312 0.500000
iteration 814: loss 0.544 0.289062 0.460938
iteration 815: loss 0.568 0.328125 0.421875
iteration 816: loss 0.434 0.296875 0.492188
iteration 817: loss 0.476 0.257812 0.453125
iteration 818: loss 0.508 0.320312 0.437500
iteration 819: loss 0.458 0.203125 0.492188
iteration 820: loss 0.489 0.289062 0.437500
iteration 821: loss 0.443 0.296875 0.515625
iteration 822: loss 0.474 0.296875 0.507812
iteration 823: loss 0.505 0.296875 0.437500
iteration 824: loss 0.453 0.257812 0.492188
iteration 825: loss 0.332 0.312500 0.578125
iteration 826: loss 0.423 0.375000 0.453125
iteration 827: loss 0.527 0.296875 0.367188
iteration 828: loss 0.444 0.218750 0.484375
iteration 829: loss 0.577 0.343750 0.437500
iteration 830: loss 0.458 0.320312 0.453125
iteration 831: loss 0.511 0.296875 0.453125
iteration 832: loss 0.519 0.234375 0.460938
iteration 833: loss 0.541 0.296875 0.453125
iteration 834: loss 0.446 0.304688 0.429688
iteration 835: loss 0.496 0.382812 0.500000
iteration 836: loss 0.492 0.273438 0.445312
iteration 837: loss 0.540 0.367188 0.460938
iteration 838: loss 0.419 0.398438 0.539062
iteration 839: loss 0.644 0.304688 0.445312
iteration 840: loss 0.518 0.367188 0.445312
iteration 841: loss 0.453 0.273438 0.523438
iteration 842: loss 0.513 0.312500 0.460938
iteration 843: loss 0.454 0.335938 0.515625
iteration 844: loss 0.430 0.234375 0.445312
iteration 845: loss 0.459 0.273438 0.531250
iteration 846: loss 0.469 0.289062 0.453125
iteration 847: loss 0.442 0.359375 0.546875
iteration 848: loss 0.455 0.343750 0.460938
iteration 849: loss 0.503 0.343750 0.445312
iteration 850: loss 0.387 0.289062 0.515625
iteration 851: loss 0.497 0.312500 0.468750
iteration 852: loss 0.505 0.304688 0.453125
iteration 853: loss 0.569 0.359375 0.414062
iteration 854: loss 0.438 0.289062 0.460938
iteration 855: loss 0.584 0.343750 0.335938
iteration 856: loss 0.611 0.312500 0.429688
iteration 857: loss 0.518 0.234375 0.460938
iteration 858: loss 0.321 0.312500 0.578125
iteration 859: loss 0.577 0.257812 0.359375
iteration 860: loss 0.442 0.304688 0.445312
iteration 861: loss 0.408 0.320312 0.468750
iteration 862: loss 0.430 0.250000 0.484375
iteration 863: loss 0.382 0.304688 0.531250
iteration 864: loss 0.434 0.312500 0.500000
iteration 865: loss 0.549 0.328125 0.445312
iteration 866: loss 0.620 0.328125 0.437500
iteration 867: loss 0.418 0.382812 0.523438
iteration 868: loss 0.555 0.296875 0.476562
iteration 869: loss 0.396 0.320312 0.570312
iteration 870: loss 0.568 0.359375 0.382812
iteration 871: loss 0.493 0.281250 0.515625
iteration 872: loss 0.474 0.218750 0.484375
iteration 873: loss 0.483 0.218750 0.421875
iteration 874: loss 0.413 0.304688 0.523438
iteration 875: loss 0.385 0.351562 0.507812
iteration 876: loss 0.457 0.304688 0.460938
iteration 877: loss 0.441 0.265625 0.531250
iteration 878: loss 0.434 0.250000 0.515625
iteration 879: loss 0.390 0.250000 0.492188
iteration 880: loss 0.601 0.273438 0.421875
iteration 881: loss 0.542 0.335938 0.453125
iteration 882: loss 0.434 0.335938 0.468750
iteration 883: loss 0.489 0.281250 0.492188
iteration 884: loss 0.438 0.242188 0.570312
iteration 885: loss 0.380 0.320312 0.523438
iteration 886: loss 0.511 0.304688 0.398438
iteration 887: loss 0.486 0.312500 0.429688
iteration 888: loss 0.516 0.328125 0.429688
iteration 889: loss 0.394 0.289062 0.507812
iteration 890: loss 0.433 0.343750 0.507812
iteration 891: loss 0.404 0.304688 0.492188
iteration 892: loss 0.539 0.328125 0.359375
iteration 893: loss 0.467 0.257812 0.484375
iteration 894: loss 0.519 0.304688 0.484375
iteration 895: loss 0.463 0.312500 0.515625
iteration 896: loss 0.521 0.328125 0.484375
iteration 897: loss 0.486 0.281250 0.453125
iteration 898: loss 0.497 0.296875 0.460938
iteration 899: loss 0.511 0.320312 0.445312
iteration 900: loss 0.584 0.296875 0.398438
iteration 901: loss 0.478 0.359375 0.492188
iteration 902: loss 0.397 0.265625 0.507812
iteration 903: loss 0.391 0.390625 0.492188
iteration 904: loss 0.525 0.343750 0.437500
iteration 905: loss 0.443 0.296875 0.484375
iteration 906: loss 0.548 0.296875 0.460938
iteration 907: loss 0.492 0.328125 0.429688
iteration 908: loss 0.427 0.273438 0.476562
iteration 909: loss 0.394 0.351562 0.476562
iteration 910: loss 0.392 0.320312 0.492188
iteration 911: loss 0.515 0.281250 0.429688
iteration 912: loss 0.468 0.390625 0.445312
iteration 913: loss 0.513 0.281250 0.445312
iteration 914: loss 0.438 0.359375 0.484375
iteration 915: loss 0.459 0.320312 0.515625
iteration 916: loss 0.554 0.281250 0.343750
iteration 917: loss 0.338 0.296875 0.554688
iteration 918: loss 0.517 0.273438 0.375000
iteration 919: loss 0.441 0.296875 0.492188
iteration 920: loss 0.432 0.335938 0.531250
iteration 921: loss 0.411 0.296875 0.585938
iteration 922: loss 0.510 0.367188 0.453125
iteration 923: loss 0.667 0.382812 0.414062
iteration 924: loss 0.492 0.328125 0.468750
iteration 925: loss 0.473 0.265625 0.492188
iteration 926: loss 0.559 0.289062 0.398438
iteration 927: loss 0.530 0.328125 0.414062
iteration 928: loss 0.656 0.257812 0.453125
iteration 929: loss 0.530 0.273438 0.437500
iteration 930: loss 0.530 0.304688 0.453125
iteration 931: loss 0.449 0.320312 0.500000
iteration 932: loss 0.543 0.296875 0.429688
iteration 933: loss 0.468 0.304688 0.453125
iteration 934: loss 0.427 0.328125 0.460938
iteration 935: loss 0.406 0.359375 0.523438
iteration 936: loss 0.526 0.367188 0.445312
iteration 937: loss 0.540 0.257812 0.500000
iteration 938: loss 0.415 0.304688 0.554688
iteration 939: loss 0.524 0.296875 0.460938
iteration 940: loss 0.464 0.312500 0.445312
iteration 941: loss 0.457 0.343750 0.492188
iteration 942: loss 0.455 0.359375 0.500000
iteration 943: loss 0.492 0.257812 0.429688
iteration 944: loss 0.525 0.250000 0.390625
iteration 945: loss 0.464 0.320312 0.484375
iteration 946: loss 0.500 0.312500 0.437500
iteration 947: loss 0.551 0.289062 0.468750
iteration 948: loss 0.482 0.304688 0.500000
iteration 949: loss 0.426 0.265625 0.460938
iteration 950: loss 0.520 0.273438 0.429688
iteration 951: loss 0.517 0.328125 0.382812
iteration 952: loss 0.518 0.250000 0.421875
iteration 953: loss 0.442 0.351562 0.546875
iteration 954: loss 0.360 0.289062 0.531250
iteration 955: loss 0.515 0.320312 0.507812
iteration 956: loss 0.557 0.320312 0.437500
iteration 957: loss 0.528 0.265625 0.429688
iteration 958: loss 0.419 0.250000 0.523438
iteration 959: loss 0.509 0.304688 0.445312
iteration 960: loss 0.584 0.312500 0.390625
iteration 961: loss 0.540 0.242188 0.437500
iteration 962: loss 0.443 0.281250 0.484375
iteration 963: loss 0.514 0.304688 0.476562
iteration 964: loss 0.528 0.257812 0.437500
iteration 965: loss 0.496 0.242188 0.515625
iteration 966: loss 0.500 0.257812 0.414062
iteration 967: loss 0.396 0.265625 0.484375
iteration 968: loss 0.594 0.226562 0.351562
iteration 969: loss 0.528 0.304688 0.390625
iteration 970: loss 0.419 0.257812 0.460938
iteration 971: loss 0.484 0.304688 0.500000
iteration 972: loss 0.417 0.296875 0.437500
iteration 973: loss 0.554 0.281250 0.437500
iteration 974: loss 0.450 0.398438 0.539062
iteration 975: loss 0.520 0.328125 0.484375
iteration 976: loss 0.521 0.281250 0.453125
iteration 977: loss 0.585 0.250000 0.468750
iteration 978: loss 0.562 0.234375 0.421875
iteration 979: loss 0.528 0.289062 0.460938
iteration 980: loss 0.441 0.289062 0.507812
iteration 981: loss 0.479 0.335938 0.398438
iteration 982: loss 0.498 0.328125 0.421875
iteration 983: loss 0.420 0.312500 0.484375
iteration 984: loss 0.550 0.328125 0.390625
iteration 985: loss 0.535 0.398438 0.445312
iteration 986: loss 0.371 0.375000 0.476562
iteration 987: loss 0.478 0.320312 0.414062
iteration 988: loss 0.404 0.312500 0.507812
iteration 989: loss 0.434 0.296875 0.468750
iteration 990: loss 0.402 0.234375 0.531250
iteration 991: loss 0.389 0.382812 0.562500
iteration 992: loss 0.462 0.296875 0.382812
iteration 993: loss 0.455 0.328125 0.468750
iteration 994: loss 0.441 0.296875 0.445312
iteration 995: loss 0.517 0.335938 0.460938
iteration 996: loss 0.424 0.343750 0.484375
iteration 997: loss 0.427 0.281250 0.523438
iteration 998: loss 0.498 0.328125 0.468750
iteration 999: loss 0.486 0.304688 0.421875
epoch 19: training: 0.343750 validation: 0.250000
